{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torchdata.datapipes as dp\n",
    "import random\n",
    "from torch.utils.data.backward_compatibility import worker_init_fn\n",
    "from sklearn.metrics import classification_report\n",
    "# import wandb\n",
    "# import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_df = pd.read_csv(\"/gladstone/finkbeiner/steve//work/data/npsad_data/vivek/Datasets/amyb_wsi/apoe_training_dataset/train_full.csv\")\\nval_df = pd.read_csv(\"/gladstone/finkbeiner/steve//work/data/npsad_data/vivek/Datasets/amyb_wsi/apoe_training_dataset/val_full.csv\")\\n\\ntrain_df = train_df[[\"Imaging_XENum\",\"crop_filepath\",\"label\"]]\\nval_df= val_df[[\"Imaging_XENum\",\"crop_filepath\",\"label\"]]\\n\\ntrain_df.to_csv(\"/gladstone/finkbeiner/steve//work/data/npsad_data/vivek/Datasets/amyb_wsi/apoe_training_dataset/train.csv\")\\nval_df.to_csv(\"/gladstone/finkbeiner/steve//work/data/npsad_data/vivek/Datasets/amyb_wsi/apoe_training_dataset/val.csv\")\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_df = pd.read_csv(\"/gladstone/finkbeiner/steve//work/data/npsad_data/vivek/Datasets/amyb_wsi/apoe_training_dataset/train_full.csv\")\n",
    "val_df = pd.read_csv(\"/gladstone/finkbeiner/steve//work/data/npsad_data/vivek/Datasets/amyb_wsi/apoe_training_dataset/val_full.csv\")\n",
    "\n",
    "train_df = train_df[[\"Imaging_XENum\",\"crop_filepath\",\"label\"]]\n",
    "val_df= val_df[[\"Imaging_XENum\",\"crop_filepath\",\"label\"]]\n",
    "\n",
    "train_df.to_csv(\"/gladstone/finkbeiner/steve//work/data/npsad_data/vivek/Datasets/amyb_wsi/apoe_training_dataset/train.csv\")\n",
    "val_df.to_csv(\"/gladstone/finkbeiner/steve//work/data/npsad_data/vivek/Datasets/amyb_wsi/apoe_training_dataset/val.csv\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/mnt/new-nas/work/data/npsad_data/vivek/Datasets/amyb_wsi/apoe_training_dataset/train_detected_full2_exp4_caa.csv\")\n",
    "val_df = pd.read_csv(\"/mnt/new-nas/work/data/npsad_data/vivek/Datasets/amyb_wsi/apoe_training_dataset/val_detected_full2.csv\")\n",
    "\n",
    "train_df = train_df[[\"Imaging_XENum\",\"crop_filepath\",\"apoe_label\"]]\n",
    "val_df= val_df[[\"Imaging_XENum\",\"crop_filepath\",\"apoe_label\"]]\n",
    "\n",
    "train_df.to_csv(\"/mnt/new-nas/work/data/npsad_data/vivek/Datasets/amyb_wsi/apoe_training_dataset/train_detected.csv\")\n",
    "val_df.to_csv(\"/mnt/new-nas/work/data/npsad_data/vivek/Datasets/amyb_wsi/apoe_training_dataset/val_detected.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/new-nas/work/data/npsad_data/vivek/Datasets/amyb_wsi/test-patients/images/XE10-033_1_AmyB_1/x_32768_y_74752.png'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"crop_filepath\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(1024),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(1024),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(1024),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_image(inputs):\n",
    "    _, wsi_name, img_path, label = inputs\n",
    "    img = Image.open(img_path)\n",
    "    return wsi_name, img, int(label)\n",
    "\n",
    "def apply_train_transforms(inputs):\n",
    "    _, x, y = inputs\n",
    "    return data_transforms[\"train\"](x), y\n",
    "\n",
    "def apply_val_transforms(inputs):\n",
    "    wsi_name, x, y = inputs\n",
    "    return wsi_name, data_transforms[\"val\"](x), y\n",
    "\n",
    "def build_data_pipe(csv_file, transform , batch_size=32):\n",
    "    new_dp = dp.iter.FileOpener([csv_file])\n",
    "    new_dp = new_dp.parse_csv(skip_lines=1)\n",
    "    # returns tuples like ('0','filename', 'filepath', 'label')\n",
    "    if transform == \"train\":\n",
    "        new_dp = new_dp.shuffle()\n",
    "    \n",
    "    new_dp = new_dp.sharding_filter()\n",
    "    # important to use sharding_filter after (not before) shuffling -For the data source that needs to be sharded, it is crucial to add Shuffler before ShardingFilter to ensure data are globally shuffled before being split into shards. Otherwise, each worker process would always process the same shard of data for all epochs. And, it means each batch would only consist of data from the same shard, which leads to low accuracy during training. However, it doesn’t apply to the data source that has already been sharded for each multi-/distributed process, since ShardingFilter is no longer required to be presented in the pipeline.\n",
    "\n",
    "    new_dp = new_dp.map(open_image)\n",
    "\n",
    "    if transform == \"train\":\n",
    "        new_dp = new_dp.map(apply_train_transforms)\n",
    "        new_dp = new_dp.batch(batch_size=batch_size, drop_last=True)\n",
    "\n",
    "    elif transform == \"val\":\n",
    "        new_dp = new_dp.map(apply_val_transforms)\n",
    "        new_dp = new_dp.batch(batch_size=batch_size, drop_last=False)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid transform argument.\")\n",
    "\n",
    "    new_dp = new_dp.map(torch.utils.data.default_collate)\n",
    "    return new_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size = 1\n",
    "batch_size = 16\n",
    "#TRAIN_CSV = \"/gladstone/finkbeiner/steve//work/data/npsad_data/vivek/Datasets/amyb_wsi/apoe_training_dataset/train.csv\"\n",
    "#VAL_CSV = \"/gladstone/finkbeiner/steve//work/data/npsad_data/vivek/Datasets/amyb_wsi/apoe_training_dataset/val.csv\"\n",
    "\n",
    "TRAIN_CSV = \"/mnt/new-nas/work/data/npsad_data/vivek/Datasets/amyb_wsi/apoe_training_dataset/train_detected.csv\"\n",
    "VAL_CSV = \"/mnt/new-nas/work/data/npsad_data/vivek/Datasets/amyb_wsi/apoe_training_dataset/val_detected.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dp = build_data_pipe(TRAIN_CSV, \"train\", batch_size)\n",
    "val_dp = build_data_pipe(VAL_CSV, \"val\", batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_size(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    return len(df)\n",
    "\n",
    "train_datasize = dataset_size(TRAIN_CSV)\n",
    "val_datasize = dataset_size(VAL_CSV)\n",
    "dataset_sizes = {'train':train_datasize, 'val':val_datasize}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 1456, 'val': 4966}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dp, shuffle=True, num_workers=4)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_dp, shuffle=False, num_workers=4)\n",
    "\n",
    "dataloaders = {\"train\":train_loader, \"val\": val_loader}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = dict(\n",
    "    epochs = 10,\n",
    "    batch_size = 10,\n",
    "    num_classes = 2,\n",
    "    device_id = 0,\n",
    "    eval_freq = 5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = dict(lr=0.001, momentum=0.9)\n",
    "\n",
    "optim_config = dict(step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model( model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    log_metrics = list()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "                inputs=inputs.squeeze()\n",
    "                # print(inputs.shape)\n",
    "                inputs=inputs.squeeze(0)\n",
    "                labels = labels.squeeze()\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                #print(f'{phase} Loss: {loss.item():.4f} Batch No: {i}')\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            log_metrics.append(dict(epoch=epoch,phase=phase, loss=epoch_loss, metrics=epoch_acc))\n",
    "            # deep copy the model\n",
    "        \n",
    "        #if (epoch+1)%train_config[\"eval_freq\"]==0:\n",
    "        #    test_model(model)\n",
    "            \n",
    "            #if phase == 'val' and epoch_acc > best_acc:\n",
    "            ##if phase == 'val' and epoch+1==train_config[\"eval_freq\"]:\n",
    "                #test_model(model)\n",
    "            #    best_acc = epoch_acc\n",
    "            #    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 3600:.0f}h {time_elapsed % 60:.0f}m')\n",
    "    #print(f'Best val Acc: {best_acc:4f}')\n",
    "    #plot_training_curve(log_metrics)\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    #run.log({\"log\":log_metrics})\n",
    "    #torch.save({\"model\":model, \"state\": model.state_dict()}, '/gladstone/finkbeiner/steve/work/data/npsad_data/monika/LBD/WM_models/'+artifact_name+'.pth')\n",
    "    #artifact = wandb.Artifact(artifact_name, type='files')\n",
    "    #with artifact.new_file(f'ckpt/{epoch}.pt', 'wb') as f:\n",
    "    #    torch.save(model.state_dict(), f)\n",
    "    #run.log_artifact(artifact)\n",
    "    #run.finish()\n",
    "    return model, log_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESNET-18 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, train_config[\"num_classes\"])\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3905 Acc: 0.7912\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.1900 Acc: 0.8949\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.1640 Acc: 0.9025\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.1473 Acc: 0.9073\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.0794 Acc: 0.9382\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.0781 Acc: 0.9402\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.0544 Acc: 0.9457\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.0519 Acc: 0.9505\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.0387 Acc: 0.9547\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.0464 Acc: 0.9512\n",
      "Training complete in 0h 29m\n"
     ]
    }
   ],
   "source": [
    "model_ft, log_metrics = train_model( model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=train_config[\"epochs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"model\":model_ft, \"state\": model_ft.state_dict()}, '/mnt/new-nas/work/data/npsad_data/monika/Amy_plaque_Results/models/model_squished_label_4_detected.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/new-nas/work/data/npsad_data/monika/Amy_plaque_Results/models/model_5ep_detected.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved_model(path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model_ft = checkpoint[\"model\"]\n",
    "    model_ft.load_state_dict(checkpoint['state'])\n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = load_saved_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    actual_labels = []\n",
    "    pred_labels = []\n",
    "    wsi_names = []\n",
    "    scores=[]\n",
    "    with torch.no_grad():\n",
    "        for i, (wsi, inputs, labels) in enumerate(dataloaders['val']):\n",
    "            #print(inputs.shape)\n",
    "            inputs=inputs.squeeze()\n",
    "            labels = labels.squeeze()\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            #print(labels)\n",
    "            actual_labels.extend(labels.tolist())\n",
    "            outputs = model(inputs)\n",
    "            scores.extend(outputs.cpu().tolist())\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            pred_labels.extend(preds.tolist())\n",
    "            wsi=[x[0] for x in wsi]\n",
    "            wsi_names.extend(wsi)\n",
    "            output_df = pd.DataFrame({\"wsi_name\":wsi_names,\"actual_labels\":actual_labels,\"pred_labels\":pred_labels,\"scores\":scores})\n",
    "            if i%500==0:\n",
    "                print(i, \"Done\")\n",
    "        classes = [0,1]\n",
    "        eval_metrics = pd.DataFrame(columns=[\"WSI\",\"accu_score\",\"precision-control\",\"recall-control\",\"f1-score-control\",\"support-control\", \"precision-APOE\",\"recall-APOE\",\"f1-score-APOE\",\"support-APOE\"])\n",
    "        # for wsi in output_df['wsi_name'].unique():\n",
    "        #     tmp = output_df[output_df[\"wsi_name\"]==wsi]  \n",
    "        #     acc_score = accuracy_score(tmp[\"actual_labels\"], tmp[\"pred_labels\"])\n",
    "        #     prec_rec = precision_recall_fscore_support(tmp[\"actual_labels\"], tmp[\"pred_labels\"], labels=[0,1])\n",
    "        #     # eval_metrics.loc[ind] = (wsi, acc_score, prec_rec[0][0],prec_rec[1][0],prec_rec[2][0], prec_rec[0][1],prec_rec[1][1],prec_rec[2][1], prec_rec[0][2],prec_rec[1][2],prec_rec[2][2])\n",
    "        #     #plot_roc_auc_curve(run, tmp[\"actual_labels\"], tmp[\"scores\"], classes, wsi)\n",
    "        #     #plot_pr_curve(run, tmp[\"actual_labels\"], tmp[\"scores\"], classes, wsi)\n",
    "        #     ind=ind+1\n",
    "        #     #wandb.summary[\"Evaluation Metric for WSI :\" + wsi]=acc_score\n",
    "        \n",
    "        #tbl = wandb.Table(data=eval_metrics)\n",
    "        #run.log({\"Test Evaluation Metric\": tbl})\n",
    "        #eval_metrics.to_csv(eval_path + \"eval_metric.csv\")\n",
    "        # print(eval_metrics)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Done\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n    data.append(next(self.dataset_iter))\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/datapipes/_hook_iterator.py\", line 144, in __next__\n    return self._get_next()\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/datapipes/_hook_iterator.py\", line 132, in _get_next\n    result = next(self.iterator)\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/datapipes/_hook_iterator.py\", line 215, in wrap_next\n    result = next_func(*args, **kwargs)\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/datapipes/datapipe.py\", line 369, in __next__\n    return next(self._datapipe_iter)\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/datapipes/_hook_iterator.py\", line 185, in wrap_generator\n    response = gen.send(request)\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/datapipes/iter/callable.py\", line 123, in __iter__\n    yield self._apply_fn(data)\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/datapipes/iter/callable.py\", line 88, in _apply_fn\n    return self.fn(data)\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 142, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 142, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 162, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 1024, 1024] at entry 0 and [3, 4161, 1024] at entry 10\nThis exception is thrown by __iter__ of MapperIterDataPipe()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/vivek/Projects/amyb-plaque-detection/src/visualization/apoe/classifier.ipynb Cell 29\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vivek/Projects/amyb-plaque-detection/src/visualization/apoe/classifier.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m output_df \u001b[39m=\u001b[39m test_model(model_ft)\n",
      "\u001b[1;32m/home/vivek/Projects/amyb-plaque-detection/src/visualization/apoe/classifier.ipynb Cell 29\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vivek/Projects/amyb-plaque-detection/src/visualization/apoe/classifier.ipynb#X40sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m scores\u001b[39m=\u001b[39m[]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vivek/Projects/amyb-plaque-detection/src/visualization/apoe/classifier.ipynb#X40sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vivek/Projects/amyb-plaque-detection/src/visualization/apoe/classifier.ipynb#X40sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, (wsi, inputs, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloaders[\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vivek/Projects/amyb-plaque-detection/src/visualization/apoe/classifier.ipynb#X40sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39m#print(inputs.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vivek/Projects/amyb-plaque-detection/src/visualization/apoe/classifier.ipynb#X40sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vivek/Projects/amyb-plaque-detection/src/visualization/apoe/classifier.ipynb#X40sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m~/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1325\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1323\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rcvd_idx]) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m   1324\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info\u001b[39m.\u001b[39mpop(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rcvd_idx)[\u001b[39m1\u001b[39m]\n\u001b[0;32m-> 1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_data()\n",
      "File \u001b[0;32m~/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1371\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1372\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n    data.append(next(self.dataset_iter))\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/datapipes/_hook_iterator.py\", line 144, in __next__\n    return self._get_next()\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/datapipes/_hook_iterator.py\", line 132, in _get_next\n    result = next(self.iterator)\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/datapipes/_hook_iterator.py\", line 215, in wrap_next\n    result = next_func(*args, **kwargs)\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/datapipes/datapipe.py\", line 369, in __next__\n    return next(self._datapipe_iter)\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/datapipes/_hook_iterator.py\", line 185, in wrap_generator\n    response = gen.send(request)\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/datapipes/iter/callable.py\", line 123, in __iter__\n    yield self._apply_fn(data)\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/datapipes/iter/callable.py\", line 88, in _apply_fn\n    return self.fn(data)\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 142, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 142, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/home/vivek/.virtualenvs/mask_rcnn-w0kK5vJa/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 162, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 1024, 1024] at entry 0 and [3, 4161, 1024] at entry 10\nThis exception is thrown by __iter__ of MapperIterDataPipe()\n"
     ]
    }
   ],
   "source": [
    "output_df = test_model(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wsi_name</th>\n",
       "      <th>actual_labels</th>\n",
       "      <th>pred_labels</th>\n",
       "      <th>scores</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XE16-033</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.7342130541801453, -0.30953988432884216, -0....</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XE16-033</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.39095649123191833, -0.3952394425868988, -0....</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XE16-033</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.7152571678161621, -0.23949187994003296, -0....</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XE16-033</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9912577867507935, -0.4821361303329468, -0.2...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XE16-033</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.8842447400093079, -0.4726897180080414, -0.3...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>XE14-004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.555978536605835, 0.005207183305174112, -0.3...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>XE14-004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.5898568034172058, -0.3283420503139496, -0.4...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>XE14-004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.6234608292579651, -0.195412740111351, -0.27...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>XE14-004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.454772412776947, -0.09624777734279633, -0.2...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>XE14-004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.7267531156539917, -0.16806404292583466, -0....</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      wsi_name  actual_labels  pred_labels  \\\n",
       "0     XE16-033              1            0   \n",
       "1     XE16-033              1            0   \n",
       "2     XE16-033              1            0   \n",
       "3     XE16-033              1            0   \n",
       "4     XE16-033              1            0   \n",
       "...        ...            ...          ...   \n",
       "1194  XE14-004              0            0   \n",
       "1195  XE14-004              0            0   \n",
       "1196  XE14-004              0            0   \n",
       "1197  XE14-004              0            0   \n",
       "1198  XE14-004              0            0   \n",
       "\n",
       "                                                 scores  correct  \n",
       "0     [0.7342130541801453, -0.30953988432884216, -0....    False  \n",
       "1     [0.39095649123191833, -0.3952394425868988, -0....    False  \n",
       "2     [0.7152571678161621, -0.23949187994003296, -0....    False  \n",
       "3     [0.9912577867507935, -0.4821361303329468, -0.2...    False  \n",
       "4     [0.8842447400093079, -0.4726897180080414, -0.3...    False  \n",
       "...                                                 ...      ...  \n",
       "1194  [0.555978536605835, 0.005207183305174112, -0.3...     True  \n",
       "1195  [0.5898568034172058, -0.3283420503139496, -0.4...     True  \n",
       "1196  [0.6234608292579651, -0.195412740111351, -0.27...     True  \n",
       "1197  [0.454772412776947, -0.09624777734279633, -0.2...     True  \n",
       "1198  [0.7267531156539917, -0.16806404292583466, -0....     True  \n",
       "\n",
       "[1199 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11426188490408674"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(output_df[\"actual_labels\"]==output_df[\"pred_labels\"]).sum()/len(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df[\"correct\"] = output_df[\"actual_labels\"]==output_df[\"pred_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wsi_name\n",
       "XE08-017    1.0\n",
       "XE11-027    0.0\n",
       "XE14-004    1.0\n",
       "XE16-033    0.0\n",
       "Name: correct, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.groupby([\"wsi_name\"])[\"correct\"].sum()/output_df.groupby([\"wsi_name\"])[\"correct\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Confusion Matrix for  XE16-033 -------\n",
      "[[  0   0]\n",
      " [428   0]]\n",
      "-----Confusion Matrix for  XE11-027 -------\n",
      "[[  0   0]\n",
      " [634   0]]\n",
      "-----Confusion Matrix for  XE08-017 -------\n",
      "[[10]]\n",
      "-----Confusion Matrix for  XE14-004 -------\n",
      "[[127]]\n"
     ]
    }
   ],
   "source": [
    "for wsi in output_df[\"wsi_name\"].unique():\n",
    "    print(\"-----Confusion Matrix for \", wsi, \"-------\")\n",
    "    actual = output_df[output_df[\"wsi_name\"]==wsi][\"actual_labels\"]\n",
    "    pred = output_df[output_df[\"wsi_name\"]==wsi][\"pred_labels\"]\n",
    "    print(confusion_matrix(actual, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kfold_amy_plaque1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
