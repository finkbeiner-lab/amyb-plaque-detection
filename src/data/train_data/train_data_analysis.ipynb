{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/kfold_amy_plaque1/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations\n",
      "  Downloading albumentations-1.4.13-py3-none-any.whl (171 kB)\n",
      "\u001b[K     |████████████████████████████████| 171 kB 31.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic>=2.7.0\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "\u001b[K     |████████████████████████████████| 423 kB 106.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions>=4.9.0\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Collecting albucore>=0.0.13\n",
      "  Downloading albucore-0.0.13-py3-none-any.whl (8.5 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 49.9 MB 103.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.24.4\n",
      "  Downloading numpy-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.5 MB 35.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting eval-type-backport\n",
      "  Downloading eval_type_backport-0.2.0-py3-none-any.whl (5.9 kB)\n",
      "Collecting scikit-image>=0.21.0\n",
      "  Downloading scikit_image-0.24.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.9 MB 31.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /root/miniconda3/envs/kfold_amy_plaque1/lib/python3.9/site-packages (from albumentations) (6.0)\n",
      "Collecting scipy>=1.10.0\n",
      "  Downloading scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 38.6 MB 31.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tomli>=2.0.1 in /root/miniconda3/envs/kfold_amy_plaque1/lib/python3.9/site-packages (from albucore>=0.0.13->albumentations) (2.0.1)\n",
      "Collecting numpy>=1.24.4\n",
      "  Downloading numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 18.2 MB 40.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic-core==2.20.1\n",
      "  Downloading pydantic_core-2.20.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 42.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /root/miniconda3/envs/kfold_amy_plaque1/lib/python3.9/site-packages (from pydantic>=2.7.0->albumentations) (0.6.0)\n",
      "Collecting tifffile>=2022.8.12\n",
      "  Downloading tifffile-2024.7.24-py3-none-any.whl (226 kB)\n",
      "\u001b[K     |████████████████████████████████| 226 kB 123.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=21 in /root/miniconda3/envs/kfold_amy_plaque1/lib/python3.9/site-packages (from scikit-image>=0.21.0->albumentations) (21.3)\n",
      "Requirement already satisfied: imageio>=2.33 in /root/miniconda3/envs/kfold_amy_plaque1/lib/python3.9/site-packages (from scikit-image>=0.21.0->albumentations) (2.34.0)\n",
      "Collecting pillow>=9.1\n",
      "  Downloading pillow-10.4.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.5 MB 58.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lazy-loader>=0.4\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Collecting networkx>=2.8\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 40.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /root/miniconda3/envs/kfold_amy_plaque1/lib/python3.9/site-packages (from packaging>=21->scikit-image>=0.21.0->albumentations) (3.0.4)\n",
      "Installing collected packages: typing-extensions, pillow, numpy, tifffile, scipy, pydantic-core, opencv-python-headless, networkx, lazy-loader, scikit-image, pydantic, eval-type-backport, albucore, albumentations\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.8.0\n",
      "    Uninstalling typing-extensions-4.8.0:\n",
      "      Successfully uninstalled typing-extensions-4.8.0\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 9.0.1\n",
      "    Uninstalling Pillow-9.0.1:\n",
      "      Successfully uninstalled Pillow-9.0.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.3\n",
      "    Uninstalling numpy-1.22.3:\n",
      "      Successfully uninstalled numpy-1.22.3\n",
      "  Attempting uninstall: tifffile\n",
      "    Found existing installation: tifffile 2020.10.1\n",
      "    Uninstalling tifffile-2020.10.1:\n",
      "      Successfully uninstalled tifffile-2020.10.1\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.9.3\n",
      "    Uninstalling scipy-1.9.3:\n",
      "      Successfully uninstalled scipy-1.9.3\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic-core 2.10.1\n",
      "    Uninstalling pydantic-core-2.10.1:\n",
      "      Successfully uninstalled pydantic-core-2.10.1\n",
      "  Attempting uninstall: opencv-python-headless\n",
      "    Found existing installation: opencv-python-headless 4.7.0.68\n",
      "    Uninstalling opencv-python-headless-4.7.0.68:\n",
      "      Successfully uninstalled opencv-python-headless-4.7.0.68\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 2.7.1\n",
      "    Uninstalling networkx-2.7.1:\n",
      "      Successfully uninstalled networkx-2.7.1\n",
      "  Attempting uninstall: scikit-image\n",
      "    Found existing installation: scikit-image 0.19.2\n",
      "    Uninstalling scikit-image-0.19.2:\n",
      "      Successfully uninstalled scikit-image-0.19.2\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.4.2\n",
      "    Uninstalling pydantic-2.4.2:\n",
      "      Successfully uninstalled pydantic-2.4.2\n",
      "Successfully installed albucore-0.0.13 albumentations-1.4.13 eval-type-backport-0.2.0 lazy-loader-0.4 networkx-3.2.1 numpy-1.26.4 opencv-python-headless-4.10.0.84 pillow-10.4.0 pydantic-2.8.2 pydantic-core-2.20.1 scikit-image-0.24.0 scipy-1.13.1 tifffile-2024.7.24 typing-extensions-4.12.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/amy-def-mfg-jsons\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path = \"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/amy-def-mfg-test-jsons\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"json_path\":glob(os.path.join(path,\"*.json\"))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.DataFrame({\"json_path\":glob(os.path.join(val_path,\"*.json\"))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(l):\n",
    "    with open(l) as f:\n",
    "        data = json.load(f)\n",
    "    plaque_dict = {'Cored': 0, 'Diffuse': 0, 'Coarse-Grained': 0,'CAA': 0}\n",
    "    for tileId, ele in data.items():\n",
    "        for region in ele:\n",
    "            if \"label\" in region.keys():\n",
    "                if \"name\" in region['label'].keys():\n",
    "                    plaque_dict[region['label'][\"name\"]]=plaque_dict[region['label'][\"name\"]]+1\n",
    "    return plaque_dict\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in [\"Cored\",\"Diffuse\",\"Coarse-Grained\",\"CAA\"]:\n",
    "    df[cls] = df[\"json_path\"].apply(lambda l:get_count(l)[cls] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in [\"Cored\",\"Diffuse\",\"Coarse-Grained\",\"CAA\"]:\n",
    "    val_df[cls] = val_df[\"json_path\"].apply(lambda l:get_count(l)[cls] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"file_name\"] = df[\"json_path\"].apply(lambda l: l.split(\"/\")[-1].split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[\"file_name\"] = val_df[\"json_path\"].apply(lambda l: l.split(\"/\")[-1].split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>json_path</th>\n",
       "      <th>Cored</th>\n",
       "      <th>Diffuse</th>\n",
       "      <th>Coarse-Grained</th>\n",
       "      <th>CAA</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>XE07-047_1_AmyB_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>XE18-066_1_AmyB_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>XE07-064_1_AmyB_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>XE17-004_1_AmyB_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>XE15-039_1_AmyB_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>XE19-037_1_AmyB_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>XE17-039_1_AmyB_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>27</td>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>XE07-048_1_AmyB_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>XE15-022_1_AmyB_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>XE10-045_1_AmyB_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>XE19-028_1_AmyB_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>XE19-010_1_AmyB_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>XE11-039_1_AmyB_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>XE12-016_1_AmyB_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XE18-003_1_AmyB_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>XE11-025_1_AmyB_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>XE07-049_1_AmyB_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>XE10-053_1_AmyB_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            json_path  Cored  Diffuse  \\\n",
       "0   /gladstone/finkbeiner/steve/work/data/npsad_da...     21       26   \n",
       "1   /gladstone/finkbeiner/steve/work/data/npsad_da...      5       34   \n",
       "2   /gladstone/finkbeiner/steve/work/data/npsad_da...     13       18   \n",
       "3   /gladstone/finkbeiner/steve/work/data/npsad_da...      2       27   \n",
       "4   /gladstone/finkbeiner/steve/work/data/npsad_da...     23       22   \n",
       "5   /gladstone/finkbeiner/steve/work/data/npsad_da...      1       20   \n",
       "6   /gladstone/finkbeiner/steve/work/data/npsad_da...     10       13   \n",
       "7   /gladstone/finkbeiner/steve/work/data/npsad_da...     27       97   \n",
       "8   /gladstone/finkbeiner/steve/work/data/npsad_da...     26       27   \n",
       "9   /gladstone/finkbeiner/steve/work/data/npsad_da...      6       20   \n",
       "10  /gladstone/finkbeiner/steve/work/data/npsad_da...     13       13   \n",
       "11  /gladstone/finkbeiner/steve/work/data/npsad_da...     43        7   \n",
       "12  /gladstone/finkbeiner/steve/work/data/npsad_da...      9        5   \n",
       "13  /gladstone/finkbeiner/steve/work/data/npsad_da...     10       28   \n",
       "14  /gladstone/finkbeiner/steve/work/data/npsad_da...      3        0   \n",
       "15  /gladstone/finkbeiner/steve/work/data/npsad_da...      5       27   \n",
       "16  /gladstone/finkbeiner/steve/work/data/npsad_da...      8       26   \n",
       "17  /gladstone/finkbeiner/steve/work/data/npsad_da...      8       14   \n",
       "\n",
       "    Coarse-Grained  CAA          file_name  \n",
       "0                3    0  XE07-047_1_AmyB_1  \n",
       "1                3    0  XE18-066_1_AmyB_1  \n",
       "2                4    8  XE07-064_1_AmyB_1  \n",
       "3                3    9  XE17-004_1_AmyB_1  \n",
       "4               14    0  XE15-039_1_AmyB_1  \n",
       "5                0    2  XE19-037_1_AmyB_1  \n",
       "6               10    9  XE17-039_1_AmyB_1  \n",
       "7                5    0  XE07-048_1_AmyB_1  \n",
       "8                6    6  XE15-022_1_AmyB_1  \n",
       "9               10    6  XE10-045_1_AmyB_1  \n",
       "10               7    4  XE19-028_1_AmyB_1  \n",
       "11              27    0  XE19-010_1_AmyB_1  \n",
       "12              16    5  XE11-039_1_AmyB_1  \n",
       "13               4    1  XE12-016_1_AmyB_1  \n",
       "14               0    0  XE18-003_1_AmyB_1  \n",
       "15               0    1  XE11-025_1_AmyB_1  \n",
       "16               3    8  XE07-049_1_AmyB_1  \n",
       "17               5    1  XE10-053_1_AmyB_1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files =  [x.split(\"/\")[-1] for x in glob(os.path.join(\"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/test\",\"*\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_files =  [x.split(\"/\")[-1] for x in glob(os.path.join(\"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/val\",\"*\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XE16-021_1_AmyB_1',\n",
       " 'XE17-059_1_AmyB_1',\n",
       " 'XE12-016_1_AmyB_1',\n",
       " 'XE14-004_1_AmyB_1',\n",
       " 'XE13-007_1_AmyB_1',\n",
       " 'XE17-030_1_AmyB_1',\n",
       " 'XE17-010_1_AmyB_1']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[\"flag\"] = val_df[\"file_name\"].apply(lambda l: \"val\" if l in val_files else \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"flag\"] = df[\"file_name\"].apply(lambda l: \"test\" if l in test_files else \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat([df,val_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cored</th>\n",
       "      <th>Diffuse</th>\n",
       "      <th>Coarse-Grained</th>\n",
       "      <th>CAA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flag</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>26</td>\n",
       "      <td>85</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>246</td>\n",
       "      <td>393</td>\n",
       "      <td>131</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>49</td>\n",
       "      <td>69</td>\n",
       "      <td>62</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cored  Diffuse  Coarse-Grained  CAA\n",
       "flag                                      \n",
       "test      26       85              22   15\n",
       "train    246      393             131   66\n",
       "val       49       69              62   13"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.groupby([\"flag\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>json_path</th>\n",
       "      <th>Cored</th>\n",
       "      <th>Diffuse</th>\n",
       "      <th>Coarse-Grained</th>\n",
       "      <th>CAA</th>\n",
       "      <th>file_name</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>XE07-047_1_AmyB_1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>XE18-066_1_AmyB_1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>XE07-064_1_AmyB_1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>XE17-004_1_AmyB_1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>XE15-039_1_AmyB_1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>XE19-037_1_AmyB_1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>XE17-039_1_AmyB_1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>27</td>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>XE07-048_1_AmyB_1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>XE15-022_1_AmyB_1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>XE10-045_1_AmyB_1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>XE19-028_1_AmyB_1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>XE19-010_1_AmyB_1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>XE11-039_1_AmyB_1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>XE12-016_1_AmyB_1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XE18-003_1_AmyB_1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>XE11-025_1_AmyB_1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>XE07-049_1_AmyB_1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>XE10-053_1_AmyB_1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>XE14-004_1_AmyB_1</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>XE17-010_1_AmyB_1</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XE17-030_1_AmyB_1</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>XE17-059_1_AmyB_1</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>XE16-021_1_AmyB_1</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>XE09-063_1_AmyB_1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>XE18-001_1_AmyB_1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>XE18-004_1_AmyB_1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>XE13-007_1_AmyB_1</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>/gladstone/finkbeiner/steve/work/data/npsad_da...</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>XE12-010_1_AmyB_1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            json_path  Cored  Diffuse  \\\n",
       "0   /gladstone/finkbeiner/steve/work/data/npsad_da...     21       26   \n",
       "1   /gladstone/finkbeiner/steve/work/data/npsad_da...      5       34   \n",
       "2   /gladstone/finkbeiner/steve/work/data/npsad_da...     13       18   \n",
       "3   /gladstone/finkbeiner/steve/work/data/npsad_da...      2       27   \n",
       "4   /gladstone/finkbeiner/steve/work/data/npsad_da...     23       22   \n",
       "5   /gladstone/finkbeiner/steve/work/data/npsad_da...      1       20   \n",
       "6   /gladstone/finkbeiner/steve/work/data/npsad_da...     10       13   \n",
       "7   /gladstone/finkbeiner/steve/work/data/npsad_da...     27       97   \n",
       "8   /gladstone/finkbeiner/steve/work/data/npsad_da...     26       27   \n",
       "9   /gladstone/finkbeiner/steve/work/data/npsad_da...      6       20   \n",
       "10  /gladstone/finkbeiner/steve/work/data/npsad_da...     13       13   \n",
       "11  /gladstone/finkbeiner/steve/work/data/npsad_da...     43        7   \n",
       "12  /gladstone/finkbeiner/steve/work/data/npsad_da...      9        5   \n",
       "13  /gladstone/finkbeiner/steve/work/data/npsad_da...     10       28   \n",
       "14  /gladstone/finkbeiner/steve/work/data/npsad_da...      3        0   \n",
       "15  /gladstone/finkbeiner/steve/work/data/npsad_da...      5       27   \n",
       "16  /gladstone/finkbeiner/steve/work/data/npsad_da...      8       26   \n",
       "17  /gladstone/finkbeiner/steve/work/data/npsad_da...      8       14   \n",
       "18  /gladstone/finkbeiner/steve/work/data/npsad_da...      3        6   \n",
       "19  /gladstone/finkbeiner/steve/work/data/npsad_da...      5       13   \n",
       "20  /gladstone/finkbeiner/steve/work/data/npsad_da...      0        0   \n",
       "21  /gladstone/finkbeiner/steve/work/data/npsad_da...     14        3   \n",
       "22  /gladstone/finkbeiner/steve/work/data/npsad_da...      5       13   \n",
       "23  /gladstone/finkbeiner/steve/work/data/npsad_da...     10       29   \n",
       "24  /gladstone/finkbeiner/steve/work/data/npsad_da...      1        2   \n",
       "25  /gladstone/finkbeiner/steve/work/data/npsad_da...      3        0   \n",
       "26  /gladstone/finkbeiner/steve/work/data/npsad_da...     22       34   \n",
       "27  /gladstone/finkbeiner/steve/work/data/npsad_da...     25       23   \n",
       "\n",
       "    Coarse-Grained  CAA          file_name   flag  \n",
       "0                3    0  XE07-047_1_AmyB_1  train  \n",
       "1                3    0  XE18-066_1_AmyB_1   test  \n",
       "2                4    8  XE07-064_1_AmyB_1  train  \n",
       "3                3    9  XE17-004_1_AmyB_1  train  \n",
       "4               14    0  XE15-039_1_AmyB_1  train  \n",
       "5                0    2  XE19-037_1_AmyB_1   test  \n",
       "6               10    9  XE17-039_1_AmyB_1  train  \n",
       "7                5    0  XE07-048_1_AmyB_1  train  \n",
       "8                6    6  XE15-022_1_AmyB_1  train  \n",
       "9               10    6  XE10-045_1_AmyB_1  train  \n",
       "10               7    4  XE19-028_1_AmyB_1  train  \n",
       "11              27    0  XE19-010_1_AmyB_1  train  \n",
       "12              16    5  XE11-039_1_AmyB_1   test  \n",
       "13               4    1  XE12-016_1_AmyB_1  train  \n",
       "14               0    0  XE18-003_1_AmyB_1   test  \n",
       "15               0    1  XE11-025_1_AmyB_1  train  \n",
       "16               3    8  XE07-049_1_AmyB_1   test  \n",
       "17               5    1  XE10-053_1_AmyB_1  train  \n",
       "18              22    0  XE14-004_1_AmyB_1    val  \n",
       "19               9    0  XE17-010_1_AmyB_1    val  \n",
       "20               0    0  XE17-030_1_AmyB_1    val  \n",
       "21              17    4  XE17-059_1_AmyB_1    val  \n",
       "22              10    9  XE16-021_1_AmyB_1    val  \n",
       "23              25    0  XE09-063_1_AmyB_1  train  \n",
       "24               4    0  XE18-001_1_AmyB_1  train  \n",
       "25               2    0  XE18-004_1_AmyB_1  train  \n",
       "26               4    0  XE13-007_1_AmyB_1    val  \n",
       "27               2   21  XE12-010_1_AmyB_1  train  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = glob(os.path.join(\"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/train/images/\",'*.png'))\n",
    "all_masks = glob(os.path.join(\"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/train/labels/\",'*.png'))\n",
    "\n",
    "all_images.sort()\n",
    "all_masks.sort()\n",
    "\n",
    "cored_images, cored_masks, diffuse_images, diffuse_masks, cg_images,cg_masks, caa_images, caa_masks  = [],[],[],[],[],[],[],[]\n",
    "for image, mask in zip(all_images,all_masks):\n",
    "    found = np.unique(np.array(Image.open(mask)))\n",
    "    if 50 in found:\n",
    "        cored_images.append(image)\n",
    "        cored_masks.append(mask)\n",
    "    if 100 in found:\n",
    "        diffuse_images.append(image)\n",
    "        diffuse_masks.append(mask)\n",
    "    if 150 in found:\n",
    "        cg_images.append(image)\n",
    "        cg_masks.append(mask)\n",
    "    if 200 in found:\n",
    "        caa_images.append(image)\n",
    "        caa_masks.append(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "471"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213, 206, 106, 52)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cored_images),  len(diffuse_images), len(cg_images), len(caa_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms  = A.Compose([ A.VerticalFlip(p=0.5),\n",
    "                            A.HorizontalFlip(p=0.5),\n",
    "                            A.Blur(blur_limit=1,p=0.2),\n",
    "                            A.RandomRotate90(),\n",
    "                        ])\n",
    "\n",
    "def get_randimages_dataug(total_imgs, image_filenames, label_filenames):\n",
    "    image_filenames.sort()\n",
    "    label_filenames.sort()\n",
    "    random_image_file = []\n",
    "    random_label_file = []\n",
    "    for i in range(total_imgs):\n",
    "        random.seed(i)\n",
    "        random_image_file.append(random.choice(image_filenames))\n",
    "        random.seed(i)\n",
    "        random_label_file.append(random.choice(label_filenames))\n",
    "    return [random_image_file, random_label_file]\n",
    "\n",
    "def upsample_dataset(dataset_base_dir, random_img_filenames, rand_label_filenames, variations, transforms, dest_img_folder_name, dest_label_folder_name):\n",
    "    i = 0\n",
    "    aug_img_files = []\n",
    "    aug_mask_files = []\n",
    "    # random.seed(500)\n",
    "\n",
    "    # Make dir where tha augmented file will reside\n",
    "    aug_img_dir = os.path.join(dataset_base_dir, dest_img_folder_name)\n",
    "    if not os.path.exists(aug_img_dir):\n",
    "            os.makedirs(aug_img_dir)\n",
    "            print(\"Augmented Directory '%s' created\" %aug_img_dir)\n",
    "    \n",
    "    aug_mask_dir = os.path.join(dataset_base_dir, dest_label_folder_name)\n",
    "    if not os.path.exists(aug_mask_dir):\n",
    "            os.makedirs(aug_mask_dir)\n",
    "            print(\"Augmented Directory '%s' created\" %aug_mask_dir)\n",
    "\n",
    "    print(os.listdir(dataset_base_dir))\n",
    "    print(\"\\nData Augmentation in Progress ...\")\n",
    "    total_imgs = len(random_img_filenames)\n",
    "    \n",
    "    for i in range(total_imgs):\n",
    "        # load the image\n",
    "        img = Image.open(random_img_filenames[i]).convert(\"RGB\")\n",
    "        img = np.array(img)\n",
    "        mask = Image.open(rand_label_filenames[i]).convert('P')\n",
    "        mask = np.array(mask)\n",
    "\n",
    "        for j in range(variations):\n",
    "                transformed = transforms(image=img, mask=mask)\n",
    "                transformed_img = transformed[\"image\"]\n",
    "                transformed_img = Image.fromarray(transformed_img)\n",
    "\n",
    "                #To rename the file with prefix A_\n",
    "                filename = os.path.basename(random_img_filenames[i])\n",
    "                filepath = os.path.dirname(random_img_filenames[i])\n",
    "\n",
    "                aug_file_name = \"A_\" + str(i) + \"_\" + str(j) + \"_\" + filename\n",
    "                new_file = os.path.join(dataset_base_dir,dest_img_folder_name,\n",
    "                                        aug_file_name)\n",
    "                transformed_img.save(new_file)\n",
    "                aug_img_files.append(new_file)\n",
    "\n",
    "                transformed_mask = transformed[\"mask\"]\n",
    "                transformed_mask = Image.fromarray(transformed_mask)\n",
    "\n",
    "                #To rename the file with prefix A_\n",
    "                filename = os.path.basename(rand_label_filenames[i])\n",
    "                filepath = os.path.dirname(rand_label_filenames[i])\n",
    "                aug_file_name = \"A_\" + str(i) + \"_\" + str(j) + \"_\" + filename\n",
    "                new_file = os.path.join(dataset_base_dir, dest_label_folder_name,\n",
    "                                        aug_file_name)\n",
    "                transformed_mask.save(new_file)\n",
    "                aug_mask_files.append(new_file)\n",
    "    return aug_img_files, aug_mask_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['labels', '.DS_Store', 'images']\n",
      "\n",
      "Data Augmentation in Progress ...\n"
     ]
    }
   ],
   "source": [
    "aug_value = 100\n",
    "rand_image_filenames, rand_label_filenames = get_randimages_dataug(aug_value, cg_images, cg_masks)\n",
    "dataset_base_dir = \"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/train\"\n",
    "aug_img_files, aug_mask_files = upsample_dataset(dataset_base_dir, rand_image_filenames, rand_label_filenames, 1, transforms, \"images\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['labels', '.DS_Store', 'images']\n",
      "\n",
      "Data Augmentation in Progress ...\n"
     ]
    }
   ],
   "source": [
    "aug_value = 150\n",
    "rand_image_filenames, rand_label_filenames = get_randimages_dataug(aug_value, caa_images, caa_masks)\n",
    "dataset_base_dir = \"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/train\"\n",
    "aug_img_files, aug_mask_files = upsample_dataset(dataset_base_dir, rand_image_filenames, rand_label_filenames, 1, transforms, \"images\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = glob(os.path.join(\"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/train/images/\",'*.png'))\n",
    "all_masks = glob(os.path.join(\"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/train/labels/\",'*.png'))\n",
    "\n",
    "all_images.sort()\n",
    "all_masks.sort()\n",
    "\n",
    "cored_images, cored_masks, diffuse_images, diffuse_masks, cg_images,cg_masks, caa_images, caa_masks  = [],[],[],[],[],[],[],[]\n",
    "for image, mask in zip(all_images,all_masks):\n",
    "    found = np.unique(np.array(Image.open(mask)))\n",
    "    if 50 in found:\n",
    "        cored_images.append(image)\n",
    "        cored_masks.append(mask)\n",
    "    if 100 in found:\n",
    "        diffuse_images.append(image)\n",
    "        diffuse_masks.append(mask)\n",
    "    if 150 in found:\n",
    "        cg_images.append(image)\n",
    "        cg_masks.append(mask)\n",
    "    if 200 in found:\n",
    "        caa_images.append(image)\n",
    "        caa_masks.append(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 273, 212, 206)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cored_images),  len(diffuse_images), len(cg_images), len(caa_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = glob(os.path.join(\"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/train/images/\",'*.png'))\n",
    "all_masks = glob(os.path.join(\"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/train/labels/\",'*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images.sort()\n",
    "all_masks.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in zip(all_images,all_masks):\n",
    "    found = np.unique(np.array(Image.open(mask)))\n",
    "    if len(found)<=1:\n",
    "        print(image)\n",
    "        os.remove(image)\n",
    "        os.remove(mask)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images.sort()\n",
    "all_masks.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_masks_img = [x.split(\"/\")[-1] for x in all_masks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/train/images/XE12-010_1_AmyB_1_30926x_157422y_image.png\n",
      "/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/train/images/XE17-004_1_AmyB_1_71704x_156347y_image.png\n",
      "/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/train/images/XE19-010_1_AmyB_1_47110x_109293y_image.png\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for image in all_images:\n",
    "    #print(image.split(\"/\")[-1].replace(\"image\",\"mask\"))\n",
    "    if image.split(\"/\")[-1].replace(\"image\",\"mask\") not in all_masks_img:\n",
    "        counter=counter+1\n",
    "        print(image)\n",
    "        os.remove(image)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_mask = [x.split(\"/\")[-1] for x in all_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/train/labels/A_118_0_XE17-039_1_AmyB_1_36877x_104249y_mask.png\n",
      "/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/train/labels/XE07-047_1_AmyB_1_29885x_105470y_mask.png\n",
      "/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/train/labels/XE07-047_1_AmyB_1_54461x_139262y_mask.png\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for mask in all_masks:\n",
    "    #print(image.split(\"/\")[-1].replace(\"image\",\"mask\"))\n",
    "    if mask.split(\"/\")[-1].replace(\"mask\",\"image\") not in all_images_mask:\n",
    "        counter=counter+1\n",
    "        print(mask)\n",
    "        os.remove(mask)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = glob(os.path.join(\"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/val/images/\",'*.png'))\n",
    "all_masks = glob(os.path.join(\"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/val/labels/\",'*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/val/images/XE13-007_1_AmyB_1_37037x_114458y_image.png\n",
      "/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/val/images/XE13-007_1_AmyB_1_88237x_142106y_image.png\n"
     ]
    }
   ],
   "source": [
    "all_images.sort()\n",
    "all_masks.sort()\n",
    "for image, mask in zip(all_images,all_masks):\n",
    "    found = np.unique(np.array(Image.open(mask)))\n",
    "    if len(found)<=1:\n",
    "        print(image)\n",
    "        os.remove(image)\n",
    "        os.remove(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data augmentations (in runpod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = glob(os.path.join(\"/workspace/Projects/Amyb_plaque_detection/Datasets/train/images/\",'*.png'))\n",
    "all_masks = glob(os.path.join(\"/workspace/Projects/Amyb_plaque_detection/Datasets/train/labels/\",'*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images.sort()\n",
    "all_masks.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms  = A.Compose([A.VerticalFlip(p=0.5),\n",
    "                            A.HorizontalFlip(p=0.5),\n",
    "                            A.Blur(blur_limit=1,p=0.1),\n",
    "                            A.OpticalDistortion(p=0.25),\n",
    "                            A.HueSaturationValue(hue_shift_limit=1, sat_shift_limit=2, val_shift_limit=1, p=0.25),\n",
    "                            A.RandomRotate90(p=0.5),\n",
    "                            A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.25)\n",
    "                        ])\n",
    "\n",
    "\n",
    "def get_randimages_dataug(total_imgs, image_filenames, label_filenames):\n",
    "    image_filenames.sort()\n",
    "    label_filenames.sort()\n",
    "    random_image_file = []\n",
    "    random_label_file = []\n",
    "    for i in range(total_imgs):\n",
    "        random.seed(i)\n",
    "        random_image_file.append(random.choice(image_filenames))\n",
    "        random.seed(i)\n",
    "        random_label_file.append(random.choice(label_filenames))\n",
    "    return [random_image_file, random_label_file]\n",
    "\n",
    "def upsample_dataset(dataset_base_dir, random_img_filenames, rand_label_filenames, variations, transforms, dest_img_folder_name, dest_label_folder_name):\n",
    "    i = 0\n",
    "    aug_img_files = []\n",
    "    aug_mask_files = []\n",
    "    # random.seed(500)\n",
    "\n",
    "    # Make dir where tha augmented file will reside\n",
    "    aug_img_dir = os.path.join(dataset_base_dir, dest_img_folder_name)\n",
    "    if not os.path.exists(aug_img_dir):\n",
    "            os.makedirs(aug_img_dir)\n",
    "            print(\"Augmented Directory '%s' created\" %aug_img_dir)\n",
    "    \n",
    "    aug_mask_dir = os.path.join(dataset_base_dir, dest_label_folder_name)\n",
    "    if not os.path.exists(aug_mask_dir):\n",
    "            os.makedirs(aug_mask_dir)\n",
    "            print(\"Augmented Directory '%s' created\" %aug_mask_dir)\n",
    "\n",
    "    print(os.listdir(dataset_base_dir))\n",
    "    print(\"\\nData Augmentation in Progress ...\")\n",
    "    total_imgs = len(random_img_filenames)\n",
    "    \n",
    "    for i in range(total_imgs):\n",
    "        # load the image\n",
    "        img = Image.open(random_img_filenames[i]).convert(\"RGB\")\n",
    "        img = np.array(img)\n",
    "        mask = Image.open(rand_label_filenames[i]).convert('P')\n",
    "        mask = np.array(mask)\n",
    "\n",
    "        for j in range(variations):\n",
    "                #transformed = transforms(image=img, mask=mask)\n",
    "                #transformed_img = transformed[\"image\"]\n",
    "                #transformed_img = Image.fromarray(transformed_img)\n",
    "                transformed_img = Image.fromarray(img) \n",
    "                #To rename the file with prefix A_\n",
    "                filename = os.path.basename(random_img_filenames[i])\n",
    "                filepath = os.path.dirname(random_img_filenames[i])\n",
    "\n",
    "                #aug_file_name = \"A_\" + str(i) + \"_\" + str(j) + \"_\" + filename\n",
    "                aug_file_name = filename\n",
    "                new_file = os.path.join(dataset_base_dir,dest_img_folder_name,\n",
    "                                        aug_file_name)\n",
    "\n",
    "                transformed_img.save(new_file)\n",
    "                aug_img_files.append(new_file)\n",
    "\n",
    "                #transformed_mask = transformed[\"mask\"]\n",
    "                #transformed_mask = Image.fromarray(transformed_mask)\n",
    "                transformed_mask = Image.fromarray(mask)  \n",
    "            \n",
    "                #To rename the file with prefix A_\n",
    "                filename = os.path.basename(rand_label_filenames[i])\n",
    "                filepath = os.path.dirname(rand_label_filenames[i])\n",
    "                #aug_file_name = \"A_\" + str(i) + \"_\" + str(j) + \"_\" + filename\n",
    "                aug_file_name = filename\n",
    "                new_file = os.path.join(dataset_base_dir, dest_label_folder_name,\n",
    "                                        aug_file_name)\n",
    "                transformed_mask.save(new_file)\n",
    "                aug_mask_files.append(new_file)\n",
    "    return aug_img_files, aug_mask_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cored_images, cored_masks, diffuse_images, diffuse_masks, cg_images,cg_masks, caa_images, caa_masks  = [],[],[],[],[],[],[],[]\n",
    "for image, mask in zip(all_images,all_masks):\n",
    "    found = np.unique(np.array(Image.open(mask)))\n",
    "    if 50 in found:\n",
    "        cored_images.append(image)\n",
    "        cored_masks.append(mask)\n",
    "    if 100 in found:\n",
    "        diffuse_images.append(image)\n",
    "        diffuse_masks.append(mask)\n",
    "    if 150 in found:\n",
    "        cg_images.append(image)\n",
    "        cg_masks.append(mask)\n",
    "    if 200 in found:\n",
    "        caa_images.append(image)\n",
    "        caa_masks.append(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 202, 178, 72)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cored_images),  len(diffuse_images), len(cg_images), len(caa_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "618"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "166 + 202 + 178 + 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_value = 100\n",
    "rand_image_filenames, rand_label_filenames = get_randimages_dataug(aug_value, caa_images, caa_masks)\n",
    "dataset_base_dir = \"/workspace/Projects/Amyb_plaque_detection/Datasets/train\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rand_image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images', '.DS_Store', 'labels']\n",
      "\n",
      "Data Augmentation in Progress ...\n"
     ]
    }
   ],
   "source": [
    "aug_img_files, aug_mask_files = upsample_dataset(dataset_base_dir, rand_image_filenames, rand_label_filenames, 1, transforms, \"images\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = glob(os.path.join(\"/workspace/Projects/Amyb_plaque_detection/Datasets/train/images/\",'*.png'))\n",
    "all_masks = glob(os.path.join(\"/workspace/Projects/Amyb_plaque_detection/Datasets/train/labels/\",'*.png'))\n",
    "all_images.sort()\n",
    "all_masks.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(586, 586)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_images),  len(all_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images', '.DS_Store', 'labels']\n",
      "\n",
      "Data Augmentation in Progress ...\n"
     ]
    }
   ],
   "source": [
    "dataset_base_dir = \"/workspace/Projects/Amyb_plaque_detection/Datasets/train\"\n",
    "aug_img_files, aug_mask_files = upsample_dataset(dataset_base_dir, all_images, all_masks, 5, transforms, \"images\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = glob(os.path.join(\"/workspace/Projects/Amyb_plaque_detection/Datasets/train/images/\",'*.png'))\n",
    "all_masks = glob(os.path.join(\"/workspace/Projects/Amyb_plaque_detection/Datasets/train/labels/\",'*.png'))\n",
    "all_images.sort()\n",
    "all_masks.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in zip(all_images,all_masks):\n",
    "    found = np.unique(np.array(Image.open(mask)))\n",
    "    if len(found)<=1:\n",
    "        print(image)\n",
    "        print(mask)\n",
    "        os.remove(image)\n",
    "        os.remove(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data augmentations (in runpod) VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = glob(os.path.join(\"/workspace/Projects/Amyb_plaque_detection/Datasets/val/images/\",'*.png'))\n",
    "all_masks = glob(os.path.join(\"/workspace/Projects/Amyb_plaque_detection/Datasets/val/labels/\",'*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images.sort()\n",
    "all_masks.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cored_images, cored_masks, diffuse_images, diffuse_masks, cg_images,cg_masks, caa_images, caa_masks  = [],[],[],[],[],[],[],[]\n",
    "for image, mask in zip(all_images,all_masks):\n",
    "    found = np.unique(np.array(Image.open(mask)))\n",
    "    if 50 in found:\n",
    "        cored_images.append(image)\n",
    "        cored_masks.append(mask)\n",
    "    if 100 in found:\n",
    "        diffuse_images.append(image)\n",
    "        diffuse_masks.append(mask)\n",
    "    if 150 in found:\n",
    "        cg_images.append(image)\n",
    "        cg_masks.append(mask)\n",
    "    if 200 in found:\n",
    "        caa_images.append(image)\n",
    "        caa_masks.append(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 103, 43, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cored_images),  len(diffuse_images), len(cg_images), len(caa_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images', 'labels']\n",
      "\n",
      "Data Augmentation in Progress ...\n"
     ]
    }
   ],
   "source": [
    "dataset_base_dir = \"/workspace/Projects/Amyb_plaque_detection/Datasets/val\"\n",
    "aug_img_files, aug_mask_files = upsample_dataset(dataset_base_dir, all_images, all_masks, 5, transforms, \"images\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = glob(os.path.join(\"/workspace/Projects/Amyb_plaque_detection/Datasets/val/images/\",'*.png'))\n",
    "all_masks = glob(os.path.join(\"/workspace/Projects/Amyb_plaque_detection/Datasets/val/labels/\",'*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = glob(os.path.join(\"/workspace/Projects/Amyb_plaque_detection/Datasets/test\",'*/images/*.png'))\n",
    "all_masks = glob(os.path.join(\"/workspace/Projects/Amyb_plaque_detection/Datasets/test\",'*/labels/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images.sort()\n",
    "all_masks.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['labels', 'images', 'XE18-066_1_AmyB_1', 'XE07-049_1_AmyB_1', 'XE11-039_1_AmyB_1', 'XE18-003_1_AmyB_1', 'XE19-037_1_AmyB_1', '.DS_Store']\n",
      "\n",
      "Data Augmentation in Progress ...\n"
     ]
    }
   ],
   "source": [
    "dataset_base_dir = \"/workspace/Projects/Amyb_plaque_detection/Datasets/test\"\n",
    "aug_img_files, aug_mask_files = upsample_dataset(dataset_base_dir, all_images, all_masks, 5, transforms, \"images\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['labels', 'images', 'XE18-066_1_AmyB_1', 'XE07-049_1_AmyB_1', 'XE11-039_1_AmyB_1', 'XE18-003_1_AmyB_1', 'XE19-037_1_AmyB_1', '.DS_Store']\n",
      "\n",
      "Data Augmentation in Progress ...\n"
     ]
    }
   ],
   "source": [
    "dataset_base_dir = \"/workspace/Projects/Amyb_plaque_detection/Datasets/test\"\n",
    "aug_img_files, aug_mask_files = upsample_dataset(dataset_base_dir, all_images, all_masks, 1, transforms, \"images\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kfold_amy_plaque1",
   "language": "python",
   "name": "kfold_amy_plaque1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
