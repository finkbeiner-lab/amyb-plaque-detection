mkdir: cannot create directory '/tmp/lock-gpu2': File exists
Successfully started process watches.
Successfully started recording stats for 2283466.
W&B offline. Running your script from this directory will only write metadata locally. Use wandb disabled to completely turn off W&B.
wandb: Tracking run with wandb version 0.13.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
/wynton/home/finkbeiner/vgramas/.conda/envs/amyb/lib/python3.9/site-packages/torchvision/transforms/functional.py:165: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  img = torch.as_tensor(np.asarray(pic))
/wynton/home/finkbeiner/vgramas/.conda/envs/amyb/lib/python3.9/site-packages/torchvision/transforms/functional.py:165: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  img = torch.as_tensor(np.asarray(pic))
/wynton/home/finkbeiner/vgramas/.conda/envs/amyb/lib/python3.9/site-packages/torchvision/transforms/functional.py:165: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  img = torch.as_tensor(np.asarray(pic))
/wynton/home/finkbeiner/vgramas/.conda/envs/amyb/lib/python3.9/site-packages/torchvision/transforms/functional.py:165: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  img = torch.as_tensor(np.asarray(pic))
/wynton/home/finkbeiner/vgramas/.conda/envs/amyb/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/wynton/home/finkbeiner/vgramas/.conda/envs/amyb/lib/python3.9/site-packages/torchvision/transforms/functional.py:165: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  img = torch.as_tensor(np.asarray(pic))
epoch no : 0, batch no : 0, total loss : 3.3399782180786133,  classifier :1.5724525451660156, mask: 1.0666559934616089 ===================
epoch no : 0, batch no : 1, total loss : 2.713754177093506,  classifier :1.3805369138717651, mask: 0.6017799377441406 ===================
epoch no : 0, batch no : 2, total loss : 2.542773723602295,  classifier :1.212493896484375, mask: 0.6301148533821106 ===================
epoch no : 0, batch no : 3, total loss : 2.326754570007324,  classifier :0.9127494692802429, mask: 0.7060221433639526 ===================
epoch no : 0, batch no : 4, total loss : 1.9841456413269043,  classifier :0.6875032186508179, mask: 0.6193856000900269 ===================
epoch no : 0, batch no : 5, total loss : 1.895689845085144,  classifier :0.3637915253639221, mask: 0.7301986217498779 ===================
epoch no : 0, batch no : 6, total loss : 2.0290660858154297,  classifier :0.24828223884105682, mask: 0.9884982109069824 ===================
epoch no : 0, batch no : 7, total loss : 2.0991322994232178,  classifier :0.3056653141975403, mask: 0.9290133714675903 ===================
epoch no : 0, batch no : 8, total loss : 1.9290082454681396,  classifier :0.21816010773181915, mask: 0.8821691274642944 ===================
epoch no : 0, batch no : 9, total loss : 1.6188971996307373,  classifier :0.13967810571193695, mask: 0.7158340811729431 ===================
epoch no : 0, batch no : 10, total loss : 1.4361366033554077,  classifier :0.1175103709101677, mask: 0.6634236574172974 ===================
epoch no : 0, batch no : 11, total loss : 1.3820855617523193,  classifier :0.12829627096652985, mask: 0.6351038217544556 ===================
epoch no : 0, batch no : 12, total loss : 1.5481643676757812,  classifier :0.13251982629299164, mask: 0.8979997038841248 ===================
epoch no : 0, batch no : 13, total loss : 1.5871164798736572,  classifier :0.23637300729751587, mask: 0.7160362601280212 ===================
epoch no : 0, batch no : 14, total loss : 1.3886679410934448,  classifier :0.12586311995983124, mask: 0.7216767072677612 ===================
epoch no : 0, batch no : 15, total loss : 1.4783679246902466,  classifier :0.14704853296279907, mask: 0.5880604386329651 ===================
epoch no : 0, batch no : 16, total loss : 1.1908726692199707,  classifier :0.11118186265230179, mask: 0.5561015009880066 ===================
epoch no : 0, batch no : 17, total loss : 1.1373263597488403,  classifier :0.10251670330762863, mask: 0.574747622013092 ===================
epoch no : 0, batch no : 18, total loss : 1.7719199657440186,  classifier :0.15219664573669434, mask: 1.0937618017196655 ===================
epoch no : 0, batch no : 19, total loss : 1.8616019487380981,  classifier :0.45133960247039795, mask: 0.6798664927482605 ===================
epoch no : 0, batch no : 20, total loss : 1.4954320192337036,  classifier :0.1481514424085617, mask: 0.7279404401779175 ===================
epoch no : 0, batch no : 21, total loss : 1.3673709630966187,  classifier :0.1598779857158661, mask: 0.5390375852584839 ===================
epoch no : 0, batch no : 22, total loss : 1.326153039932251,  classifier :0.13603998720645905, mask: 0.5965240001678467 ===================
epoch no : 0, batch no : 23, total loss : 1.128446102142334,  classifier :0.11932100355625153, mask: 0.5049094557762146 ===================
epoch no : 0, batch no : 24, total loss : 1.3654016256332397,  classifier :0.1364695131778717, mask: 0.7405738234519958 ===================
epoch no : 0, batch no : 25, total loss : 1.804608702659607,  classifier :0.1977599412202835, mask: 1.1070924997329712 ===================
epoch no : 0, batch no : 26, total loss : 1.3624815940856934,  classifier :0.13550014793872833, mask: 0.6493794322013855 ===================
epoch no : 0, batch no : 27, total loss : 1.2769978046417236,  classifier :0.11974334716796875, mask: 0.6387953758239746 ===================
epoch no : 0, batch no : 28, total loss : 1.2440177202224731,  classifier :0.13487273454666138, mask: 0.5274125337600708 ===================
epoch no : 0, batch no : 29, total loss : 1.1619839668273926,  classifier :0.11565117537975311, mask: 0.5226612091064453 ===================
epoch no : 0, batch no : 30, total loss : 1.0775412321090698,  classifier :0.10996024310588837, mask: 0.4979681372642517 ===================
epoch no : 0, batch no : 31, total loss : 1.160607099533081,  classifier :0.12803608179092407, mask: 0.51646888256073 ===================
epoch no : 0, batch no : 32, total loss : 1.1943378448486328,  classifier :0.13408754765987396, mask: 0.49646833539009094 ===================
epoch no : 0, batch no : 33, total loss : 1.1169999837875366,  classifier :0.1347336769104004, mask: 0.4190129339694977 ===================
epoch no : 0, batch no : 34, total loss : 1.0355782508850098,  classifier :0.12057703733444214, mask: 0.43692275881767273 ===================
epoch no : 0, batch no : 35, total loss : 1.0145758390426636,  classifier :0.12009651958942413, mask: 0.4167897403240204 ===================
epoch no : 0, batch no : 36, total loss : 1.1799209117889404,  classifier :0.11682549118995667, mask: 0.5013049840927124 ===================
epoch no : 0, batch no : 37, total loss : 1.0983954668045044,  classifier :0.12202740460634232, mask: 0.4201834499835968 ===================
epoch no : 0, batch no : 38, total loss : 1.0056469440460205,  classifier :0.10747295618057251, mask: 0.4154771864414215 ===================
epoch no : 0, batch no : 39, total loss : 0.9809149503707886,  classifier :0.10934596508741379, mask: 0.3432301878929138 ===================
epoch no : 0, batch no : 40, total loss : 0.9801749587059021,  classifier :0.10770972818136215, mask: 0.4035532772541046 ===================
epoch no : 0, batch no : 41, total loss : 1.1156731843948364,  classifier :0.12227512151002884, mask: 0.424592524766922 ===================
epoch no : 0, batch no : 42, total loss : 1.4433751106262207,  classifier :0.1635809689760208, mask: 0.7053577899932861 ===================
epoch no : 0, batch no : 43, total loss : 1.0658259391784668,  classifier :0.11373862624168396, mask: 0.4394909739494324 ===================
epoch no : 0, batch no : 44, total loss : 1.005380392074585,  classifier :0.11105469614267349, mask: 0.37610363960266113 ===================
epoch no : 0, batch no : 45, total loss : 0.988523542881012,  classifier :0.10349737107753754, mask: 0.396309494972229 ===================
epoch no : 0, batch no : 46, total loss : 1.2291789054870605,  classifier :0.155282661318779, mask: 0.6194561123847961 ===================
epoch no : 0, batch no : 47, total loss : 1.3620949983596802,  classifier :0.17736054956912994, mask: 0.5576661825180054 ===================
epoch no : 0, batch no : 48, total loss : 1.1546242237091064,  classifier :0.09882042557001114, mask: 0.5943467020988464 ===================
epoch no : 0, batch no : 49, total loss : 1.1521252393722534,  classifier :0.13420279324054718, mask: 0.5075076222419739 ===================
epoch no : 0, batch no : 50, total loss : 0.9463663697242737,  classifier :0.11128168553113937, mask: 0.3456283211708069 ===================
epoch no : 0, batch no : 51, total loss : 0.9198343753814697,  classifier :0.10362360626459122, mask: 0.3808760344982147 ===================
epoch no : 0, batch no : 52, total loss : 1.020084261894226,  classifier :0.12387076020240784, mask: 0.37700968980789185 ===================
epoch no : 0, batch no : 53, total loss : 0.9530487656593323,  classifier :0.11030609905719757, mask: 0.3768952190876007 ===================
epoch no : 0, batch no : 54, total loss : 0.8779857158660889,  classifier :0.10218577831983566, mask: 0.3441368639469147 ===================
epoch no : 0, batch no : 55, total loss : 0.9722785353660583,  classifier :0.11247141659259796, mask: 0.3574894070625305 ===================
epoch no : 0, batch no : 56, total loss : 1.09608793258667,  classifier :0.10547149181365967, mask: 0.4344361424446106 ===================
epoch no : 0, batch no : 57, total loss : 0.9012242555618286,  classifier :0.09247011691331863, mask: 0.3760451376438141 ===================
epoch no : 0, batch no : 58, total loss : 0.9441934823989868,  classifier :0.13308657705783844, mask: 0.2893114686012268 ===================
epoch no : 0, batch no : 59, total loss : 0.8954512476921082,  classifier :0.09960304945707321, mask: 0.3120420277118683 ===================
epoch no : 0, batch no : 60, total loss : 0.8614829182624817,  classifier :0.10249427706003189, mask: 0.26864662766456604 ===================
epoch no : 0, batch no : 61, total loss : 0.8644744157791138,  classifier :0.12817393243312836, mask: 0.2746356129646301 ===================
epoch no : 0, batch no : 62, total loss : 0.8079555034637451,  classifier :0.10247284173965454, mask: 0.2848875820636749 ===================
epoch no : 0, batch no : 63, total loss : 0.8412733674049377,  classifier :0.12507620453834534, mask: 0.29180145263671875 ===================
epoch no : 0, batch no : 64, total loss : 0.8863354325294495,  classifier :0.10496208071708679, mask: 0.3380303680896759 ===================
epoch no : 0, batch no : 65, total loss : 1.0012712478637695,  classifier :0.11348216980695724, mask: 0.3159054219722748 ===================
epoch no : 0, batch no : 66, total loss : 0.9291357398033142,  classifier :0.11612404137849808, mask: 0.23936276137828827 ===================
epoch no : 0, batch no : 67, total loss : 0.9282727837562561,  classifier :0.10599380731582642, mask: 0.2776023745536804 ===================
epoch no : 0, batch no : 68, total loss : 0.8423432111740112,  classifier :0.11030365526676178, mask: 0.27135661244392395 ===================
epoch no : 0, batch no : 69, total loss : 0.845453143119812,  classifier :0.11698979139328003, mask: 0.282177209854126 ===================
epoch no : 0, batch no : 70, total loss : 0.9015554189682007,  classifier :0.10900656878948212, mask: 0.37511396408081055 ===================
epoch no : 0, batch no : 71, total loss : 1.2005836963653564,  classifier :0.11969836056232452, mask: 0.5651680827140808 ===================
epoch no : 0, batch no : 72, total loss : 1.2209367752075195,  classifier :0.1658109426498413, mask: 0.5197878479957581 ===================
epoch no : 0, batch no : 73, total loss : 1.098041296005249,  classifier :0.15341401100158691, mask: 0.4802989363670349 ===================
epoch no : 0, batch no : 74, total loss : 0.9036108255386353,  classifier :0.10480062663555145, mask: 0.26234838366508484 ===================
epoch no : 0, batch no : 75, total loss : 0.990534245967865,  classifier :0.12840160727500916, mask: 0.2974827289581299 ===================
epoch no : 0, batch no : 76, total loss : 0.8243659138679504,  classifier :0.11514401435852051, mask: 0.2542887032032013 ===================
epoch no : 0, batch no : 77, total loss : 0.7316862344741821,  classifier :0.1068139523267746, mask: 0.2424171268939972 ===================
epoch no : 0, batch no : 78, total loss : 0.765667200088501,  classifier :0.1147623285651207, mask: 0.2434956431388855 ===================
epoch no : 0, batch no : 79, total loss : 0.8381156325340271,  classifier :0.11366888880729675, mask: 0.3162992298603058 ===================
epoch no : 0, batch no : 80, total loss : 1.0164315700531006,  classifier :0.1062878742814064, mask: 0.4595390260219574 ===================
epoch no : 0, batch no : 81, total loss : 0.9665140509605408,  classifier :0.12389475107192993, mask: 0.41478613018989563 ===================
epoch no : 0, batch no : 82, total loss : 0.8671157956123352,  classifier :0.1288735568523407, mask: 0.32082030177116394 ===================
epoch no : 0, batch no : 83, total loss : 0.8565637469291687,  classifier :0.10571139305830002, mask: 0.2845676839351654 ===================
epoch no : 0, batch no : 84, total loss : 0.8625617623329163,  classifier :0.11444180458784103, mask: 0.2707284986972809 ===================
epoch no : 0, batch no : 85, total loss : 0.7913792729377747,  classifier :0.10921180993318558, mask: 0.27970319986343384 ===================
epoch no : 0, batch no : 86, total loss : 0.8250311613082886,  classifier :0.11451691389083862, mask: 0.2338712364435196 ===================
epoch no : 0, batch no : 87, total loss : 0.8324514031410217,  classifier :0.11249101907014847, mask: 0.22048790752887726 ===================
epoch no : 0, batch no : 88, total loss : 0.6429744958877563,  classifier :0.09418247640132904, mask: 0.1821536421775818 ===================
epoch no : 0, batch no : 89, total loss : 0.8498636484146118,  classifier :0.09270893782377243, mask: 0.33917906880378723 ===================
epoch no : 0, batch no : 90, total loss : 0.827565610408783,  classifier :0.10303494334220886, mask: 0.3269251585006714 ===================
epoch no : 0, batch no : 91, total loss : 0.771956205368042,  classifier :0.09982120245695114, mask: 0.21006347239017487 ===================
epoch no : 0, batch no : 92, total loss : 0.8362504243850708,  classifier :0.11248210817575455, mask: 0.31464987993240356 ===================
epoch no : 0, batch no : 93, total loss : 0.9564589262008667,  classifier :0.11657198518514633, mask: 0.4218901991844177 ===================
epoch no : 0, batch no : 94, total loss : 0.7627314329147339,  classifier :0.09793447703123093, mask: 0.33353695273399353 ===================
epoch no : 0, batch no : 95, total loss : 0.8101085424423218,  classifier :0.09616842865943909, mask: 0.25577396154403687 ===================
epoch no : 0, batch no : 96, total loss : 0.7545509338378906,  classifier :0.09963954240083694, mask: 0.27602052688598633 ===================
epoch no : 0, batch no : 97, total loss : 0.7270752191543579,  classifier :0.10236062109470367, mask: 0.2522735893726349 ===================
epoch no : 0, batch no : 98, total loss : 0.742311954498291,  classifier :0.09714241325855255, mask: 0.22333557903766632 ===================
epoch no : 0, batch no : 99, total loss : 0.7026471495628357,  classifier :0.10361868888139725, mask: 0.20231901109218597 ===================
epoch no : 0, batch no : 100, total loss : 0.802438497543335,  classifier :0.10952042043209076, mask: 0.2878493666648865 ===================
epoch no : 0, batch no : 101, total loss : 0.8312399983406067,  classifier :0.11459715664386749, mask: 0.28322505950927734 ===================
epoch no : 0, batch no : 102, total loss : 0.9715798497200012,  classifier :0.1031821072101593, mask: 0.44041958451271057 ===================
epoch no : 0, batch no : 103, total loss : 1.0675466060638428,  classifier :0.13350236415863037, mask: 0.4949217736721039 ===================
epoch no : 0, batch no : 104, total loss : 0.8901134729385376,  classifier :0.1219581663608551, mask: 0.40126508474349976 ===================
epoch no : 0, batch no : 105, total loss : 0.7922049164772034,  classifier :0.10217466950416565, mask: 0.29098883271217346 ===================
epoch no : 0, batch no : 106, total loss : 0.7716634273529053,  classifier :0.10273206233978271, mask: 0.24556565284729004 ===================
epoch no : 0, batch no : 107, total loss : 0.7397429347038269,  classifier :0.10362450778484344, mask: 0.24069227278232574 ===================
epoch no : 0, batch no : 108, total loss : 0.7391065955162048,  classifier :0.11106522381305695, mask: 0.2557447850704193 ===================
epoch no : 0, batch no : 109, total loss : 0.9138859510421753,  classifier :0.10134293884038925, mask: 0.38757985830307007 ===================
epoch no : 0, batch no : 110, total loss : 0.8871678113937378,  classifier :0.12370660901069641, mask: 0.32797476649284363 ===================
epoch no : 0, batch no : 111, total loss : 0.8133814930915833,  classifier :0.10542431473731995, mask: 0.26712745428085327 ===================
epoch no : 0, batch no : 112, total loss : 0.7680122256278992,  classifier :0.10788843780755997, mask: 0.24473388493061066 ===================
epoch no : 0, batch no : 113, total loss : 0.6655725240707397,  classifier :0.1006055399775505, mask: 0.1870085448026657 ===================
epoch no : 0, batch no : 114, total loss : 0.692227840423584,  classifier :0.0935322493314743, mask: 0.2125720977783203 ===================
epoch no : 0, batch no : 115, total loss : 0.6828388571739197,  classifier :0.09802579134702682, mask: 0.25072142481803894 ===================
epoch no : 0, batch no : 116, total loss : 0.5897267460823059,  classifier :0.08759456872940063, mask: 0.2236369401216507 ===================
epoch no : 0, batch no : 117, total loss : 0.6951130628585815,  classifier :0.1014280766248703, mask: 0.2062629759311676 ===================
epoch no : 0, batch no : 118, total loss : 0.6787614226341248,  classifier :0.0774846002459526, mask: 0.2658419609069824 ===================
epoch no : 0, batch no : 119, total loss : 0.7735408544540405,  classifier :0.1004384383559227, mask: 0.2809481620788574 ===================
epoch no : 0, batch no : 120, total loss : 0.7325066924095154,  classifier :0.11036785691976547, mask: 0.2421460747718811 ===================
epoch no : 0, batch no : 121, total loss : 0.6954677104949951,  classifier :0.0873800739645958, mask: 0.2283509522676468 ===================
epoch no : 0, batch no : 122, total loss : 0.665849506855011,  classifier :0.10657262057065964, mask: 0.2066216766834259 ===================
epoch no : 0, batch no : 123, total loss : 0.6668520569801331,  classifier :0.09564776718616486, mask: 0.22716760635375977 ===================
epoch no : 0, batch no : 124, total loss : 0.6167700290679932,  classifier :0.10540977120399475, mask: 0.19802333414554596 ===================
epoch no : 0, batch no : 125, total loss : 0.7384911775588989,  classifier :0.09964483976364136, mask: 0.2803683280944824 ===================
epoch no : 0, batch no : 126, total loss : 0.6174593567848206,  classifier :0.10186772048473358, mask: 0.23855313658714294 ===================
epoch no : 0, batch no : 127, total loss : 0.5911135077476501,  classifier :0.0863957405090332, mask: 0.19270311295986176 ===================
epoch no : 0, batch no : 128, total loss : 0.7095093727111816,  classifier :0.09227597713470459, mask: 0.19298408925533295 ===================
epoch no : 0, batch no : 129, total loss : 0.7593005895614624,  classifier :0.09993641078472137, mask: 0.30671146512031555 ===================
epoch no : 0, batch no : 130, total loss : 0.6570897102355957,  classifier :0.0801273062825203, mask: 0.2615935802459717 ===================
epoch no : 0, batch no : 131, total loss : 0.7371143102645874,  classifier :0.08557192981243134, mask: 0.2476842850446701 ===================
epoch no : 0, batch no : 132, total loss : 0.6180485486984253,  classifier :0.09412847459316254, mask: 0.18832115828990936 ===================
epoch no : 0, batch no : 133, total loss : 0.6522544622421265,  classifier :0.09364359825849533, mask: 0.24362321197986603 ===================
epoch no : 0, batch no : 134, total loss : 0.5779358148574829,  classifier :0.08335160464048386, mask: 0.20273470878601074 ===================
epoch no : 0, batch no : 135, total loss : 0.6021966338157654,  classifier :0.0918245017528534, mask: 0.19258368015289307 ===================
epoch no : 0, batch no : 136, total loss : 0.6597108840942383,  classifier :0.10821014642715454, mask: 0.21018826961517334 ===================
epoch no : 0, batch no : 137, total loss : 0.6335099935531616,  classifier :0.08866013586521149, mask: 0.2272450178861618 ===================
epoch no : 0, batch no : 138, total loss : 0.7716017365455627,  classifier :0.09960698336362839, mask: 0.32169783115386963 ===================
epoch no : 0, batch no : 139, total loss : 0.7316243648529053,  classifier :0.0927986204624176, mask: 0.3253497779369354 ===================
epoch no : 0, batch no : 140, total loss : 0.7538394927978516,  classifier :0.09210226684808731, mask: 0.2953355610370636 ===================
epoch no : 0, batch no : 141, total loss : 0.587246298789978,  classifier :0.08656816184520721, mask: 0.22768454253673553 ===================
epoch no : 0, batch no : 142, total loss : 0.557643473148346,  classifier :0.0913650393486023, mask: 0.1494103968143463 ===================
epoch no : 0, batch no : 143, total loss : 0.6147670149803162,  classifier :0.10341788083314896, mask: 0.20881669223308563 ===================
epoch no : 0, batch no : 144, total loss : 0.5605135560035706,  classifier :0.08715956658124924, mask: 0.2321251481771469 ===================
epoch no : 0, batch no : 145, total loss : 0.7105947732925415,  classifier :0.08995863050222397, mask: 0.2989799976348877 ===================
epoch no : 0, batch no : 146, total loss : 0.5660474896430969,  classifier :0.0873042643070221, mask: 0.20183290541172028 ===================
epoch no : 0, batch no : 147, total loss : 0.6041222810745239,  classifier :0.0917297974228859, mask: 0.18571709096431732 ===================
epoch no : 0, batch no : 148, total loss : 0.577295184135437,  classifier :0.09064318984746933, mask: 0.18379323184490204 ===================
epoch no : 0, batch no : 149, total loss : 0.6343739032745361,  classifier :0.09766826778650284, mask: 0.23564974963665009 ===================
epoch no : 0, batch no : 150, total loss : 0.5427217483520508,  classifier :0.08791334182024002, mask: 0.18111060559749603 ===================
epoch no : 0, batch no : 151, total loss : 0.8734245896339417,  classifier :0.09585753828287125, mask: 0.38627052307128906 ===================
epoch no : 0, batch no : 152, total loss : 1.11281418800354,  classifier :0.13763880729675293, mask: 0.5915473699569702 ===================
epoch no : 0, batch no : 153, total loss : 0.9844511151313782,  classifier :0.09936853498220444, mask: 0.44717976450920105 ===================
epoch no : 0, batch no : 154, total loss : 0.8733128905296326,  classifier :0.10628223419189453, mask: 0.3465273082256317 ===================
epoch no : 0, batch no : 155, total loss : 0.581159770488739,  classifier :0.0863829180598259, mask: 0.20859463512897491 ===================
epoch no : 0, batch no : 156, total loss : 0.6844265460968018,  classifier :0.09818805754184723, mask: 0.2648560702800751 ===================
epoch no : 0, batch no : 157, total loss : 0.525503933429718,  classifier :0.07343297451734543, mask: 0.20910027623176575 ===================
epoch no : 0, batch no : 158, total loss : 0.5618577003479004,  classifier :0.08673641085624695, mask: 0.19875343143939972 ===================
epoch no : 0, batch no : 159, total loss : 0.5959596037864685,  classifier :0.10118120163679123, mask: 0.20500226318836212 ===================
epoch no : 0, batch no : 160, total loss : 0.7266631126403809,  classifier :0.10696037113666534, mask: 0.2880704700946808 ===================
epoch no : 0, batch no : 161, total loss : 0.5508790016174316,  classifier :0.08541393280029297, mask: 0.18525561690330505 ===================
epoch no : 0, batch no : 162, total loss : 0.6175135374069214,  classifier :0.07834319025278091, mask: 0.2801946699619293 ===================
epoch no : 0, batch no : 163, total loss : 0.7197756171226501,  classifier :0.10937243700027466, mask: 0.28458908200263977 ===================
epoch no : 0, batch no : 164, total loss : 0.7595751285552979,  classifier :0.10561101883649826, mask: 0.3388812839984894 ===================
epoch no : 0, batch no : 165, total loss : 0.6611751317977905,  classifier :0.10075320303440094, mask: 0.20694270730018616 ===================
epoch no : 0, batch no : 166, total loss : 0.5251757502555847,  classifier :0.08835684508085251, mask: 0.16881756484508514 ===================
epoch no : 0, batch no : 167, total loss : 0.6440094709396362,  classifier :0.08844716846942902, mask: 0.22548726201057434 ===================
epoch no : 0, batch no : 168, total loss : 0.6523123383522034,  classifier :0.08957721292972565, mask: 0.25043120980262756 ===================
epoch no : 0, batch no : 169, total loss : 0.7376707792282104,  classifier :0.09254871308803558, mask: 0.26773133873939514 ===================
epoch no : 0, batch no : 170, total loss : 0.6203343272209167,  classifier :0.09505920112133026, mask: 0.26178306341171265 ===================
epoch no : 0, batch no : 171, total loss : 0.71113121509552,  classifier :0.0901452824473381, mask: 0.2184632569551468 ===================
epoch no : 0, batch no : 172, total loss : 0.6336755752563477,  classifier :0.0936879813671112, mask: 0.20135076344013214 ===================
epoch no : 0, batch no : 173, total loss : 0.5701709985733032,  classifier :0.07849553972482681, mask: 0.17294029891490936 ===================
epoch no : 0, batch no : 174, total loss : 0.608970582485199,  classifier :0.08829659223556519, mask: 0.2004474252462387 ===================
epoch no : 0, batch no : 175, total loss : 0.5126339197158813,  classifier :0.08610804378986359, mask: 0.1622987538576126 ===================
epoch no : 0, batch no : 176, total loss : 0.5212031602859497,  classifier :0.07717989385128021, mask: 0.16310688853263855 ===================
epoch no : 0, batch no : 177, total loss : 0.6602337956428528,  classifier :0.0904577448964119, mask: 0.22482603788375854 ===================
epoch no : 0, batch no : 178, total loss : 0.7234649658203125,  classifier :0.08947652578353882, mask: 0.321654736995697 ===================
epoch no : 0, batch no : 179, total loss : 0.7786841988563538,  classifier :0.09325507283210754, mask: 0.39952996373176575 ===================
epoch no : 0, batch no : 180, total loss : 0.6621778011322021,  classifier :0.11563505232334137, mask: 0.26213133335113525 ===================
epoch no : 0, batch no : 181, total loss : 0.5058524012565613,  classifier :0.0819186195731163, mask: 0.19461816549301147 ===================
epoch no : 0, batch no : 182, total loss : 0.8267176747322083,  classifier :0.1018521785736084, mask: 0.25489115715026855 ===================
epoch no : 0, batch no : 183, total loss : 0.6988673806190491,  classifier :0.08786849677562714, mask: 0.25229230523109436 ===================
epoch no : 0, batch no : 184, total loss : 0.5961888432502747,  classifier :0.08162008225917816, mask: 0.2217780351638794 ===================
epoch no : 0, batch no : 185, total loss : 0.7029193043708801,  classifier :0.08828043937683105, mask: 0.25376662611961365 ===================
epoch no : 0, batch no : 186, total loss : 0.6589542031288147,  classifier :0.08454591035842896, mask: 0.25197088718414307 ===================
epoch no : 0, batch no : 187, total loss : 0.5898760557174683,  classifier :0.08635320514440536, mask: 0.24070242047309875 ===================
epoch no : 0, batch no : 188, total loss : 0.5382899641990662,  classifier :0.0792088732123375, mask: 0.17594023048877716 ===================
epoch no : 0, batch no : 189, total loss : 0.5726451873779297,  classifier :0.089737668633461, mask: 0.19619588553905487 ===================
epoch no : 0, batch no : 190, total loss : 0.5774180889129639,  classifier :0.07896913588047028, mask: 0.2067151665687561 ===================
epoch no : 0, batch no : 191, total loss : 0.700032651424408,  classifier :0.07515910267829895, mask: 0.31540095806121826 ===================
epoch no : 0, batch no : 192, total loss : 0.6606676578521729,  classifier :0.08944934606552124, mask: 0.25696325302124023 ===================
epoch no : 0, batch no : 193, total loss : 0.5026383399963379,  classifier :0.0835433304309845, mask: 0.1820618361234665 ===================
epoch no : 0, batch no : 194, total loss : 0.5359325408935547,  classifier :0.07551275938749313, mask: 0.2677883207798004 ===================
epoch no : 0, batch no : 195, total loss : 0.6573070883750916,  classifier :0.10227116197347641, mask: 0.21868476271629333 ===================
epoch no : 0, batch no : 196, total loss : 0.5160744786262512,  classifier :0.06902329623699188, mask: 0.18704137206077576 ===================
epoch no : 0, batch no : 197, total loss : 0.4783896505832672,  classifier :0.0832800418138504, mask: 0.15618789196014404 ===================
epoch no : 0, batch no : 198, total loss : 0.5265025496482849,  classifier :0.08112969994544983, mask: 0.18515317142009735 ===================
epoch no : 0, batch no : 199, total loss : 0.45627760887145996,  classifier :0.075614333152771, mask: 0.17863500118255615 ===================
epoch no : 0, batch no : 200, total loss : 0.521281898021698,  classifier :0.07878981530666351, mask: 0.18454527854919434 ===================
epoch no : 0, batch no : 201, total loss : 0.5877373218536377,  classifier :0.08261974155902863, mask: 0.22546188533306122 ===================
epoch no : 0, batch no : 202, total loss : 0.6102954745292664,  classifier :0.09943436831235886, mask: 0.17839695513248444 ===================
epoch no : 0, batch no : 203, total loss : 0.692671000957489,  classifier :0.08381029963493347, mask: 0.29034560918807983 ===================
epoch no : 0, batch no : 204, total loss : 0.5736052393913269,  classifier :0.09071590006351471, mask: 0.1803542673587799 ===================
epoch no : 0, batch no : 205, total loss : 0.6299643516540527,  classifier :0.07859423756599426, mask: 0.24323219060897827 ===================
epoch no : 0, batch no : 206, total loss : 0.6261174082756042,  classifier :0.09062810987234116, mask: 0.22234724462032318 ===================
epoch no : 0, batch no : 207, total loss : 0.6382538676261902,  classifier :0.08322098851203918, mask: 0.2533607482910156 ===================
epoch no : 0, batch no : 208, total loss : 0.5357081294059753,  classifier :0.08227323740720749, mask: 0.1777600347995758 ===================
epoch no : 0, batch no : 209, total loss : 0.5384533405303955,  classifier :0.07269689440727234, mask: 0.2090981900691986 ===================
epoch no : 0, batch no : 210, total loss : 0.5295657515525818,  classifier :0.06872738897800446, mask: 0.24423930048942566 ===================
epoch no : 0, batch no : 211, total loss : 0.7411646246910095,  classifier :0.08480337262153625, mask: 0.33187198638916016 ===================
epoch no : 0, batch no : 212, total loss : 0.5763152241706848,  classifier :0.07855507731437683, mask: 0.24686908721923828 ===================
epoch no : 0, batch no : 213, total loss : 0.5786034464836121,  classifier :0.0689651146531105, mask: 0.22207407653331757 ===================
epoch no : 0, batch no : 214, total loss : 0.5137887597084045,  classifier :0.07145021855831146, mask: 0.1986611783504486 ===================
epoch no : 0, batch no : 215, total loss : 0.531949520111084,  classifier :0.08807241171598434, mask: 0.1712847501039505 ===================
epoch no : 0, batch no : 216, total loss : 0.5202538371086121,  classifier :0.07951078563928604, mask: 0.19494369626045227 ===================
epoch no : 0, batch no : 217, total loss : 0.5795134902000427,  classifier :0.08378329128026962, mask: 0.21997126936912537 ===================
epoch no : 0, batch no : 218, total loss : 0.4517122209072113,  classifier :0.07626569271087646, mask: 0.15779367089271545 ===================
epoch no : 0, batch no : 219, total loss : 0.46552175283432007,  classifier :0.08308569341897964, mask: 0.15080347657203674 ===================
epoch no : 0, batch no : 220, total loss : 0.5018413066864014,  classifier :0.07184948027133942, mask: 0.18474344909191132 ===================
epoch no : 0, batch no : 221, total loss : 0.6996124982833862,  classifier :0.08521835505962372, mask: 0.2712400257587433 ===================
epoch no : 0, batch no : 222, total loss : 0.48011890053749084,  classifier :0.07724792510271072, mask: 0.15095525979995728 ===================
epoch no : 0, batch no : 223, total loss : 0.569246232509613,  classifier :0.06910141557455063, mask: 0.22646179795265198 ===================
epoch no : 0, batch no : 224, total loss : 0.5388070344924927,  classifier :0.09155111759901047, mask: 0.19578270614147186 ===================
epoch no : 0, batch no : 225, total loss : 0.5153577923774719,  classifier :0.07788192480802536, mask: 0.18243829905986786 ===================
epoch no : 0, batch no : 226, total loss : 0.6182798743247986,  classifier :0.0859307274222374, mask: 0.2590155005455017 ===================
epoch no : 0, batch no : 227, total loss : 0.6487948298454285,  classifier :0.10156676918268204, mask: 0.23807787895202637 ===================
epoch no : 0, batch no : 228, total loss : 0.6762552261352539,  classifier :0.09358452260494232, mask: 0.309908926486969 ===================
epoch no : 0, batch no : 229, total loss : 0.6202278137207031,  classifier :0.0842403993010521, mask: 0.24990570545196533 ===================
epoch no : 0, batch no : 230, total loss : 0.5702111721038818,  classifier :0.08537737280130386, mask: 0.17977482080459595 ===================
epoch no : 0, batch no : 231, total loss : 0.5625830888748169,  classifier :0.07943277806043625, mask: 0.18282268941402435 ===================
epoch no : 0, batch no : 232, total loss : 0.6548105478286743,  classifier :0.081566721200943, mask: 0.21135558187961578 ===================
epoch no : 0, batch no : 233, total loss : 0.5866100788116455,  classifier :0.07559119164943695, mask: 0.2107183337211609 ===================
epoch no : 0, batch no : 234, total loss : 0.5088944435119629,  classifier :0.0792122483253479, mask: 0.2076224833726883 ===================
epoch no : 0, batch no : 235, total loss : 0.48989543318748474,  classifier :0.07651377469301224, mask: 0.14852982759475708 ===================
epoch no : 0, batch no : 236, total loss : 0.3773036599159241,  classifier :0.06716547161340714, mask: 0.15064096450805664 ===================
epoch no : 0, batch no : 237, total loss : 0.6320915222167969,  classifier :0.09782898426055908, mask: 0.26387307047843933 ===================
epoch no : 0, batch no : 238, total loss : 0.5162065625190735,  classifier :0.0699555054306984, mask: 0.22146767377853394 ===================
epoch no : 0, batch no : 239, total loss : 0.5084909796714783,  classifier :0.07573418319225311, mask: 0.2071356177330017 ===================
epoch no : 0, batch no : 240, total loss : 0.4492977559566498,  classifier :0.06262156367301941, mask: 0.17661432921886444 ===================
epoch no : 0, batch no : 241, total loss : 0.4978076219558716,  classifier :0.08693273365497589, mask: 0.17722156643867493 ===================
epoch no : 0, batch no : 242, total loss : 0.4174329936504364,  classifier :0.06993652880191803, mask: 0.15459559857845306 ===================
epoch no : 0, batch no : 243, total loss : 0.6628801822662354,  classifier :0.09445954114198685, mask: 0.23113076388835907 ===================
epoch no : 0, batch no : 244, total loss : 0.527608335018158,  classifier :0.08276546746492386, mask: 0.1889372169971466 ===================
epoch no : 0, batch no : 245, total loss : 0.623825192451477,  classifier :0.07724584639072418, mask: 0.22006505727767944 ===================
epoch no : 0, batch no : 246, total loss : 0.5390229821205139,  classifier :0.08751184493303299, mask: 0.1834612935781479 ===================
epoch no : 0, batch no : 247, total loss : 0.48014920949935913,  classifier :0.08296406269073486, mask: 0.14590923488140106 ===================
epoch no : 0, batch no : 248, total loss : 0.5345779657363892,  classifier :0.0797477662563324, mask: 0.17378725111484528 ===================
epoch no : 0, batch no : 249, total loss : 0.5143079161643982,  classifier :0.07720036059617996, mask: 0.17249514162540436 ===================
epoch no : 0, batch no : 250, total loss : 0.7401880025863647,  classifier :0.08773926645517349, mask: 0.29002106189727783 ===================
epoch no : 0, batch no : 251, total loss : 0.6948398947715759,  classifier :0.07985327392816544, mask: 0.244179829955101 ===================
epoch no : 0, batch no : 252, total loss : 0.5266135334968567,  classifier :0.07942545413970947, mask: 0.1939699947834015 ===================
epoch no : 0, batch no : 253, total loss : 0.619773268699646,  classifier :0.08978031575679779, mask: 0.23922377824783325 ===================
epoch no : 0, batch no : 254, total loss : 0.53823322057724,  classifier :0.07383842766284943, mask: 0.1860983818769455 ===================
epoch no : 0, batch no : 255, total loss : 0.6387021541595459,  classifier :0.0863833948969841, mask: 0.2514192759990692 ===================
epoch no : 0, batch no : 256, total loss : 0.5037456154823303,  classifier :0.08177729696035385, mask: 0.18122512102127075 ===================
epoch no : 0, batch no : 257, total loss : 0.500998318195343,  classifier :0.08423619717359543, mask: 0.17323225736618042 ===================
epoch no : 0, batch no : 258, total loss : 0.4937466084957123,  classifier :0.08109313994646072, mask: 0.15200011432170868 ===================
epoch no : 0, batch no : 259, total loss : 0.635773241519928,  classifier :0.07287581264972687, mask: 0.31881219148635864 ===================
epoch no : 0, batch no : 260, total loss : 0.6417385935783386,  classifier :0.06422723829746246, mask: 0.32350724935531616 ===================
epoch no : 0, batch no : 261, total loss : 0.5831324458122253,  classifier :0.07846568524837494, mask: 0.21888184547424316 ===================
epoch no : 0, batch no : 262, total loss : 0.4949571192264557,  classifier :0.07215236872434616, mask: 0.18279974162578583 ===================
epoch no : 0, batch no : 263, total loss : 0.4853931963443756,  classifier :0.07739708572626114, mask: 0.1839655339717865 ===================
epoch no : 0, batch no : 264, total loss : 0.4671739935874939,  classifier :0.08867069333791733, mask: 0.15165993571281433 ===================
epoch no : 0, batch no : 265, total loss : 0.5944139361381531,  classifier :0.0770130380988121, mask: 0.21811148524284363 ===================
epoch no : 0, batch no : 266, total loss : 0.494924932718277,  classifier :0.082484170794487, mask: 0.15547983348369598 ===================
epoch no : 0, batch no : 267, total loss : 0.5063040852546692,  classifier :0.08146163076162338, mask: 0.1789008378982544 ===================
epoch no : 0, batch no : 268, total loss : 0.5640241503715515,  classifier :0.07828468829393387, mask: 0.1815989762544632 ===================
epoch no : 0, batch no : 269, total loss : 0.574160099029541,  classifier :0.07638629525899887, mask: 0.23157627880573273 ===================
epoch no : 0, batch no : 270, total loss : 0.5888862609863281,  classifier :0.08675216138362885, mask: 0.18088534474372864 ===================
epoch no : 0, batch no : 271, total loss : 0.4605799913406372,  classifier :0.06469530612230301, mask: 0.17065110802650452 ===================
epoch no : 0, batch no : 272, total loss : 0.5296553373336792,  classifier :0.07460841536521912, mask: 0.21600404381752014 ===================
epoch no : 0, batch no : 273, total loss : 0.5292617678642273,  classifier :0.08720605820417404, mask: 0.18076784908771515 ===================
epoch no : 0, batch no : 274, total loss : 0.4366677403450012,  classifier :0.07807076722383499, mask: 0.15623386204242706 ===================
epoch no : 0, batch no : 275, total loss : 0.5325413942337036,  classifier :0.07801253348588943, mask: 0.19293048977851868 ===================
epoch no : 0, batch no : 276, total loss : 0.6805046200752258,  classifier :0.0797182098031044, mask: 0.2841537594795227 ===================
epoch no : 0, batch no : 277, total loss : 0.5051507949829102,  classifier :0.07677211612462997, mask: 0.17067432403564453 ===================
epoch no : 0, batch no : 278, total loss : 0.5093122720718384,  classifier :0.07509360462427139, mask: 0.17202875018119812 ===================
epoch no : 0, batch no : 279, total loss : 0.46281224489212036,  classifier :0.08583302050828934, mask: 0.15540620684623718 ===================
epoch no : 0, batch no : 280, total loss : 0.5215979218482971,  classifier :0.07436740398406982, mask: 0.19812500476837158 ===================
epoch no : 0, batch no : 281, total loss : 0.5028544664382935,  classifier :0.07596372812986374, mask: 0.18437643349170685 ===================
epoch no : 0, batch no : 282, total loss : 0.44941312074661255,  classifier :0.07588224112987518, mask: 0.18830737471580505 ===================
epoch no : 0, batch no : 283, total loss : 0.5432233214378357,  classifier :0.09219895303249359, mask: 0.16807110607624054 ===================
epoch no : 0, batch no : 284, total loss : 0.5435778498649597,  classifier :0.07771458476781845, mask: 0.1921924501657486 ===================
epoch no : 0, batch no : 285, total loss : 0.5710434913635254,  classifier :0.07788798213005066, mask: 0.23791153728961945 ===================
epoch no : 0, batch no : 286, total loss : 0.8209717869758606,  classifier :0.07892551273107529, mask: 0.3252880871295929 ===================
epoch no : 0, batch no : 287, total loss : 0.494144469499588,  classifier :0.07963749766349792, mask: 0.17060261964797974 ===================
epoch no : 0, batch no : 288, total loss : 0.5494794845581055,  classifier :0.09616538882255554, mask: 0.18616406619548798 ===================
epoch no : 0, batch no : 289, total loss : 0.5813180804252625,  classifier :0.07836805284023285, mask: 0.17406600713729858 ===================
epoch no : 0, batch no : 290, total loss : 0.713293731212616,  classifier :0.08146323263645172, mask: 0.27447834610939026 ===================
epoch no : 0, batch no : 291, total loss : 0.5753798484802246,  classifier :0.08156408369541168, mask: 0.20164722204208374 ===================
epoch no : 0, batch no : 292, total loss : 0.5948464870452881,  classifier :0.08812851458787918, mask: 0.20641227066516876 ===================
epoch no : 0, batch no : 293, total loss : 0.6663749814033508,  classifier :0.08881749212741852, mask: 0.25920599699020386 ===================
epoch no : 0, batch no : 294, total loss : 0.5845123529434204,  classifier :0.07630785554647446, mask: 0.2508717179298401 ===================
epoch no : 0, batch no : 295, total loss : 0.4647868275642395,  classifier :0.08046814054250717, mask: 0.1561882644891739 ===================
epoch no : 0, batch no : 296, total loss : 0.4775224030017853,  classifier :0.06987231969833374, mask: 0.17387473583221436 ===================
epoch no : 0, batch no : 297, total loss : 0.6462134122848511,  classifier :0.08342473953962326, mask: 0.21608366072177887 ===================
epoch no : 0, batch no : 298, total loss : 0.4670245945453644,  classifier :0.07843475788831711, mask: 0.16273143887519836 ===================
epoch no : 0, batch no : 299, total loss : 0.553435206413269,  classifier :0.0868111252784729, mask: 0.21218322217464447 ===================
epoch no : 0, batch no : 300, total loss : 0.6395414471626282,  classifier :0.08454903215169907, mask: 0.24307075142860413 ===================
epoch no : 0, batch no : 301, total loss : 0.5649664402008057,  classifier :0.07815586030483246, mask: 0.20070812106132507 ===================
epoch no : 0, batch no : 302, total loss : 0.5080138444900513,  classifier :0.066978819668293, mask: 0.1744357943534851 ===================
epoch no : 0, batch no : 303, total loss : 0.4326150417327881,  classifier :0.07800372689962387, mask: 0.1476026475429535 ===================
epoch no : 0, batch no : 304, total loss : 0.5053651928901672,  classifier :0.07674600183963776, mask: 0.15904901921749115 ===================
epoch no : 0, batch no : 305, total loss : 0.45716726779937744,  classifier :0.07555955648422241, mask: 0.16691821813583374 ===================
epoch no : 0, batch no : 306, total loss : 0.5210310220718384,  classifier :0.0844939649105072, mask: 0.17693185806274414 ===================
epoch no : 0, batch no : 307, total loss : 0.5057600140571594,  classifier :0.07708181440830231, mask: 0.18715575337409973 ===================
epoch no : 0, batch no : 308, total loss : 0.5838794708251953,  classifier :0.0850701704621315, mask: 0.17109596729278564 ===================
epoch no : 0, batch no : 309, total loss : 0.55490642786026,  classifier :0.07581871002912521, mask: 0.20540353655815125 ===================
epoch no : 0, batch no : 310, total loss : 0.6839972138404846,  classifier :0.09194348752498627, mask: 0.24296994507312775 ===================
epoch no : 0, batch no : 311, total loss : 0.49090147018432617,  classifier :0.08281061053276062, mask: 0.15547677874565125 ===================
epoch no : 0, batch no : 312, total loss : 0.4781755208969116,  classifier :0.08413510769605637, mask: 0.14709025621414185 ===================
epoch no : 0, batch no : 313, total loss : 0.5117566585540771,  classifier :0.09602810442447662, mask: 0.15690813958644867 ===================
epoch no : 0, batch no : 314, total loss : 0.5534844398498535,  classifier :0.07058671861886978, mask: 0.21015766263008118 ===================
epoch no : 0, batch no : 315, total loss : 0.47030505537986755,  classifier :0.08135508000850677, mask: 0.16327261924743652 ===================
epoch no : 0, batch no : 316, total loss : 0.5489374399185181,  classifier :0.07564383000135422, mask: 0.18332253396511078 ===================
epoch no : 0, batch no : 317, total loss : 0.6618144512176514,  classifier :0.09184154868125916, mask: 0.31595733761787415 ===================
epoch no : 0, batch no : 318, total loss : 0.5400636196136475,  classifier :0.08544743061065674, mask: 0.2069896161556244 ===================
epoch no : 0, batch no : 319, total loss : 0.7164480686187744,  classifier :0.08749372512102127, mask: 0.2304583489894867 ===================
epoch no : 0, batch no : 320, total loss : 0.4414497911930084,  classifier :0.07898113131523132, mask: 0.15214796364307404 ===================
epoch no : 0, batch no : 321, total loss : 0.6426800489425659,  classifier :0.07810194045305252, mask: 0.2450607866048813 ===================
epoch no : 0, batch no : 322, total loss : 0.5568197965621948,  classifier :0.08315448462963104, mask: 0.19752874970436096 ===================
epoch no : 0, batch no : 323, total loss : 0.5015279054641724,  classifier :0.07935231924057007, mask: 0.1907469630241394 ===================
epoch no : 0, batch no : 324, total loss : 0.6706501841545105,  classifier :0.07633692026138306, mask: 0.26880350708961487 ===================
epoch no : 0, batch no : 325, total loss : 0.49589112401008606,  classifier :0.07613590359687805, mask: 0.17047937214374542 ===================
epoch no : 0, batch no : 326, total loss : 0.5307601094245911,  classifier :0.0785498172044754, mask: 0.19466225802898407 ===================
epoch no : 0, batch no : 327, total loss : 0.5418998003005981,  classifier :0.07504940778017044, mask: 0.21644653379917145 ===================
epoch no : 0, batch no : 328, total loss : 0.5970884561538696,  classifier :0.06725883483886719, mask: 0.245827779173851 ===================
epoch no : 0, batch no : 329, total loss : 0.6522995829582214,  classifier :0.07964294403791428, mask: 0.24814815819263458 ===================
epoch no : 0, batch no : 330, total loss : 0.5487120151519775,  classifier :0.08235643059015274, mask: 0.17916052043437958 ===================
epoch no : 0, batch no : 331, total loss : 0.5240318775177002,  classifier :0.08271512389183044, mask: 0.18717600405216217 ===================
epoch no : 0, batch no : 332, total loss : 0.47445952892303467,  classifier :0.07528825104236603, mask: 0.17277228832244873 ===================
epoch no : 0, batch no : 333, total loss : 0.472326397895813,  classifier :0.0921824499964714, mask: 0.15348991751670837 ===================
epoch no : 0, batch no : 334, total loss : 0.5543689131736755,  classifier :0.0942208543419838, mask: 0.17764917016029358 ===================
epoch no : 0, batch no : 335, total loss : 0.4968869090080261,  classifier :0.07878945767879486, mask: 0.19254235923290253 ===================
epoch no : 0, batch no : 336, total loss : 0.5787511467933655,  classifier :0.07994560152292252, mask: 0.18625357747077942 ===================
epoch no : 0, batch no : 337, total loss : 0.5572255253791809,  classifier :0.08419132977724075, mask: 0.1880837380886078 ===================
epoch no : 0, batch no : 338, total loss : 0.5515502691268921,  classifier :0.07417494803667068, mask: 0.20689716935157776 ===================
epoch no : 0, batch no : 339, total loss : 0.4975012242794037,  classifier :0.09005128592252731, mask: 0.16651199758052826 ===================
epoch no : 0, batch no : 340, total loss : 0.5081955194473267,  classifier :0.05908867344260216, mask: 0.20407730340957642 ===================
epoch no : 0, batch no : 341, total loss : 0.5424754023551941,  classifier :0.06588114798069, mask: 0.2084178477525711 ===================
epoch no : 0, batch no : 342, total loss : 0.5143021941184998,  classifier :0.07526019960641861, mask: 0.18679335713386536 ===================
epoch no : 0, batch no : 343, total loss : 0.5632874369621277,  classifier :0.07913316041231155, mask: 0.22226840257644653 ===================
epoch no : 0, batch no : 344, total loss : 0.4531111419200897,  classifier :0.07938388735055923, mask: 0.13900363445281982 ===================
epoch no : 0, batch no : 345, total loss : 0.49755141139030457,  classifier :0.07983437180519104, mask: 0.17644861340522766 ===================
epoch no : 0, batch no : 346, total loss : 0.4940098524093628,  classifier :0.06970079988241196, mask: 0.18085446953773499 ===================
epoch no : 0, batch no : 347, total loss : 0.6179831027984619,  classifier :0.09013078361749649, mask: 0.24398158490657806 ===================
epoch no : 0, batch no : 348, total loss : 0.5126827359199524,  classifier :0.08051255345344543, mask: 0.18164290487766266 ===================
epoch no : 0, batch no : 349, total loss : 0.5254743695259094,  classifier :0.08582271635532379, mask: 0.1875227987766266 ===================
epoch no : 0, batch no : 350, total loss : 0.6089126467704773,  classifier :0.08543626964092255, mask: 0.2146306186914444 ===================
epoch no : 0, batch no : 351, total loss : 0.48014718294143677,  classifier :0.08564233779907227, mask: 0.15096674859523773 ===================
epoch no : 0, batch no : 352, total loss : 0.4753998816013336,  classifier :0.07103167474269867, mask: 0.1734093725681305 ===================
epoch no : 0, batch no : 353, total loss : 0.4721269905567169,  classifier :0.07800053805112839, mask: 0.1622236669063568 ===================
epoch no : 0, batch no : 354, total loss : 0.4761592745780945,  classifier :0.08910883218050003, mask: 0.16793718934059143 ===================
epoch no : 0, batch no : 355, total loss : 0.47091391682624817,  classifier :0.07620081305503845, mask: 0.17137548327445984 ===================
epoch no : 0, batch no : 356, total loss : 0.45530006289482117,  classifier :0.08034897595643997, mask: 0.1456097662448883 ===================
epoch no : 0, batch no : 357, total loss : 0.48924267292022705,  classifier :0.08980362862348557, mask: 0.17924728989601135 ===================
epoch no : 0, batch no : 358, total loss : 0.4700472950935364,  classifier :0.06579900532960892, mask: 0.18985997140407562 ===================
epoch no : 0, batch no : 359, total loss : 0.5241662263870239,  classifier :0.0717136561870575, mask: 0.19228971004486084 ===================
epoch no : 0, batch no : 360, total loss : 0.39958658814430237,  classifier :0.06749475747346878, mask: 0.14347733557224274 ===================
epoch no : 0, batch no : 361, total loss : 0.5122174620628357,  classifier :0.07764120399951935, mask: 0.1588798612356186 ===================
epoch no : 0, batch no : 362, total loss : 0.4462808668613434,  classifier :0.062438901513814926, mask: 0.15368200838565826 ===================
epoch no : 0, batch no : 363, total loss : 0.573527455329895,  classifier :0.08571186661720276, mask: 0.23455959558486938 ===================
epoch no : 0, batch no : 364, total loss : 0.5466526746749878,  classifier :0.07088641822338104, mask: 0.2303827404975891 ===================
epoch no : 0, batch no : 365, total loss : 0.5013933777809143,  classifier :0.0648140087723732, mask: 0.18319860100746155 ===================
epoch no : 0, batch no : 366, total loss : 0.5237262845039368,  classifier :0.06795345991849899, mask: 0.22390571236610413 ===================
epoch no : 0, batch no : 367, total loss : 0.508996307849884,  classifier :0.07712341845035553, mask: 0.1685599386692047 ===================
epoch no : 0, batch no : 368, total loss : 0.5838512778282166,  classifier :0.08549053966999054, mask: 0.1845044493675232 ===================
epoch no : 0, batch no : 369, total loss : 0.4967515468597412,  classifier :0.07664992660284042, mask: 0.18567906320095062 ===================
epoch no : 0, batch no : 370, total loss : 0.5687586069107056,  classifier :0.06597612798213959, mask: 0.19407446682453156 ===================
epoch no : 0, batch no : 371, total loss : 0.4998134970664978,  classifier :0.08838585019111633, mask: 0.16183768212795258 ===================
epoch no : 0, batch no : 372, total loss : 0.4378381371498108,  classifier :0.06347981840372086, mask: 0.12767449021339417 ===================
epoch no : 0, batch no : 373, total loss : 0.5803436636924744,  classifier :0.08771158754825592, mask: 0.19202294945716858 ===================
epoch no : 0, batch no : 374, total loss : 0.48299258947372437,  classifier :0.07530691474676132, mask: 0.1727113276720047 ===================
epoch no : 0, batch no : 375, total loss : 0.5754868388175964,  classifier :0.0879792869091034, mask: 0.225428968667984 ===================
epoch no : 0, batch no : 376, total loss : 0.5767484307289124,  classifier :0.08707632124423981, mask: 0.22465555369853973 ===================
epoch no : 0, batch no : 377, total loss : 0.4805843234062195,  classifier :0.08067210018634796, mask: 0.1542673408985138 ===================
epoch no : 0, batch no : 378, total loss : 0.5312153100967407,  classifier :0.07630676031112671, mask: 0.197723850607872 ===================
epoch no : 0, batch no : 379, total loss : 0.4471295475959778,  classifier :0.07338937371969223, mask: 0.1675020158290863 ===================
epoch no : 0, batch no : 380, total loss : 0.5247952938079834,  classifier :0.08052629977464676, mask: 0.21717983484268188 ===================
epoch no : 0, batch no : 381, total loss : 0.46439218521118164,  classifier :0.07886026799678802, mask: 0.15320229530334473 ===================
epoch no : 0, batch no : 382, total loss : 0.5438862442970276,  classifier :0.07389628887176514, mask: 0.16715086996555328 ===================
epoch no : 0, batch no : 383, total loss : 0.6102770566940308,  classifier :0.09155474603176117, mask: 0.23489394783973694 ===================
epoch no : 0, batch no : 384, total loss : 0.6298984885215759,  classifier :0.10772448778152466, mask: 0.22339944541454315 ===================
epoch no : 0, batch no : 385, total loss : 0.5490663051605225,  classifier :0.07594138383865356, mask: 0.1971866339445114 ===================
epoch no : 0, batch no : 386, total loss : 0.4236615300178528,  classifier :0.06911958009004593, mask: 0.13399596512317657 ===================
epoch no : 0, batch no : 387, total loss : 0.5366227626800537,  classifier :0.07746242731809616, mask: 0.16732874512672424 ===================
epoch no : 0, batch no : 388, total loss : 0.48746147751808167,  classifier :0.06646916270256042, mask: 0.15848253667354584 ===================
epoch no : 0, batch no : 389, total loss : 0.5848904252052307,  classifier :0.08242262899875641, mask: 0.21708990633487701 ===================
epoch no : 0, batch no : 390, total loss : 0.49998247623443604,  classifier :0.07566343992948532, mask: 0.16607528924942017 ===================
epoch no : 0, batch no : 391, total loss : 0.5905681848526001,  classifier :0.0837026983499527, mask: 0.19977723062038422 ===================
epoch no : 0, batch no : 392, total loss : 0.5087805390357971,  classifier :0.10037004947662354, mask: 0.14544114470481873 ===================
epoch no : 0, batch no : 393, total loss : 0.4826403856277466,  classifier :0.07317531853914261, mask: 0.1893928200006485 ===================
epoch no : 0, batch no : 394, total loss : 0.4566948115825653,  classifier :0.06900358945131302, mask: 0.17010429501533508 ===================
epoch no : 0, batch no : 395, total loss : 0.42685452103614807,  classifier :0.06753996014595032, mask: 0.1516486257314682 ===================
epoch no : 0, batch no : 396, total loss : 0.41601890325546265,  classifier :0.0711110532283783, mask: 0.1354929655790329 ===================
epoch no : 0, batch no : 397, total loss : 0.45755088329315186,  classifier :0.06217639893293381, mask: 0.15578944981098175 ===================
epoch no : 0, batch no : 398, total loss : 0.6543341875076294,  classifier :0.07834025472402573, mask: 0.250440776348114 ===================
creating index...
index created!
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
Test:  [   0/3188]  eta: 0:48:03  model_time: 0.2743 (0.2743)  evaluator_time: 0.1321 (0.1321)  time: 0.9044  data: 0.2724  max mem: 9499
Test:  [ 100/3188]  eta: 0:17:07  model_time: 0.1214 (0.1433)  evaluator_time: 0.0315 (0.0472)  time: 0.2954  data: 0.0047  max mem: 9499
Test:  [ 200/3188]  eta: 0:17:17  model_time: 0.1429 (0.1505)  evaluator_time: 0.0458 (0.0519)  time: 0.3766  data: 0.0044  max mem: 9499
Test:  [ 300/3188]  eta: 0:15:48  model_time: 0.1251 (0.1428)  evaluator_time: 0.0336 (0.0468)  time: 0.2999  data: 0.0049  max mem: 9499
Test:  [ 400/3188]  eta: 0:15:06  model_time: 0.1207 (0.1415)  evaluator_time: 0.0354 (0.0461)  time: 0.3036  data: 0.0046  max mem: 9499
Test:  [ 500/3188]  eta: 0:14:24  model_time: 0.1260 (0.1401)  evaluator_time: 0.0351 (0.0451)  time: 0.3629  data: 0.0045  max mem: 9499
Test:  [ 600/3188]  eta: 0:14:09  model_time: 0.1188 (0.1430)  evaluator_time: 0.0298 (0.0468)  time: 0.2999  data: 0.0044  max mem: 9499
Test:  [ 700/3188]  eta: 0:13:41  model_time: 0.1150 (0.1439)  evaluator_time: 0.0297 (0.0474)  time: 0.3027  data: 0.0044  max mem: 9499
Test:  [ 800/3188]  eta: 0:13:01  model_time: 0.1132 (0.1427)  evaluator_time: 0.0241 (0.0467)  time: 0.2698  data: 0.0045  max mem: 9499
Test:  [ 900/3188]  eta: 0:12:29  model_time: 0.1201 (0.1427)  evaluator_time: 0.0297 (0.0470)  time: 0.3864  data: 0.0044  max mem: 9499
Test:  [1000/3188]  eta: 0:11:58  model_time: 0.1162 (0.1430)  evaluator_time: 0.0294 (0.0473)  time: 0.2745  data: 0.0046  max mem: 9499
Test:  [1100/3188]  eta: 0:11:28  model_time: 0.1263 (0.1437)  evaluator_time: 0.0332 (0.0475)  time: 0.3082  data: 0.0046  max mem: 9499
Test:  [1200/3188]  eta: 0:10:58  model_time: 0.1241 (0.1443)  evaluator_time: 0.0351 (0.0478)  time: 0.3801  data: 0.0044  max mem: 9499
Test:  [1300/3188]  eta: 0:10:21  model_time: 0.1164 (0.1434)  evaluator_time: 0.0411 (0.0475)  time: 0.3145  data: 0.0047  max mem: 9499
Test:  [1400/3188]  eta: 0:09:53  model_time: 0.1149 (0.1444)  evaluator_time: 0.0331 (0.0484)  time: 0.2860  data: 0.0044  max mem: 9499
Test:  [1500/3188]  eta: 0:09:17  model_time: 0.1096 (0.1437)  evaluator_time: 0.0291 (0.0479)  time: 0.3512  data: 0.0047  max mem: 9499
Test:  [1600/3188]  eta: 0:08:47  model_time: 0.1032 (0.1446)  evaluator_time: 0.0208 (0.0480)  time: 0.2831  data: 0.0044  max mem: 9499
Test:  [1700/3188]  eta: 0:08:08  model_time: 0.1013 (0.1433)  evaluator_time: 0.0191 (0.0468)  time: 0.2442  data: 0.0048  max mem: 9499
Test:  [1800/3188]  eta: 0:07:37  model_time: 0.1229 (0.1438)  evaluator_time: 0.0268 (0.0467)  time: 0.3470  data: 0.0043  max mem: 9499
Test:  [1900/3188]  eta: 0:07:06  model_time: 0.1214 (0.1447)  evaluator_time: 0.0254 (0.0468)  time: 0.3419  data: 0.0046  max mem: 9499
Test:  [2000/3188]  eta: 0:06:33  model_time: 0.1469 (0.1449)  evaluator_time: 0.0316 (0.0466)  time: 0.3243  data: 0.0045  max mem: 9499
Test:  [2100/3188]  eta: 0:05:57  model_time: 0.1165 (0.1441)  evaluator_time: 0.0259 (0.0459)  time: 0.2738  data: 0.0044  max mem: 9499
Test:  [2200/3188]  eta: 0:05:24  model_time: 0.1278 (0.1438)  evaluator_time: 0.0300 (0.0455)  time: 0.3551  data: 0.0047  max mem: 9499
Test:  [2300/3188]  eta: 0:04:51  model_time: 0.1220 (0.1441)  evaluator_time: 0.0297 (0.0455)  time: 0.3908  data: 0.0045  max mem: 9499
Test:  [2400/3188]  eta: 0:04:19  model_time: 0.1140 (0.1446)  evaluator_time: 0.0234 (0.0456)  time: 0.3510  data: 0.0043  max mem: 9499
Test:  [2500/3188]  eta: 0:03:46  model_time: 0.1309 (0.1444)  evaluator_time: 0.0332 (0.0452)  time: 0.3719  data: 0.0044  max mem: 9499
Test:  [2600/3188]  eta: 0:03:12  model_time: 0.1159 (0.1440)  evaluator_time: 0.0233 (0.0448)  time: 0.2602  data: 0.0046  max mem: 9499
Test:  [2700/3188]  eta: 0:02:39  model_time: 0.1509 (0.1441)  evaluator_time: 0.0388 (0.0446)  time: 0.3332  data: 0.0045  max mem: 9499
Test:  [2800/3188]  eta: 0:02:07  model_time: 0.1249 (0.1449)  evaluator_time: 0.0267 (0.0448)  time: 0.3943  data: 0.0046  max mem: 9499
Test:  [2900/3188]  eta: 0:01:34  model_time: 0.1278 (0.1449)  evaluator_time: 0.0291 (0.0446)  time: 0.2999  data: 0.0046  max mem: 9499
Test:  [3000/3188]  eta: 0:01:02  model_time: 0.1242 (0.1453)  evaluator_time: 0.0287 (0.0447)  time: 0.3888  data: 0.0161  max mem: 9499
Test:  [3100/3188]  eta: 0:00:28  model_time: 0.1353 (0.1447)  evaluator_time: 0.0288 (0.0442)  time: 0.3144  data: 0.0048  max mem: 9499
Test:  [3187/3188]  eta: 0:00:00  model_time: 0.1238 (0.1451)  evaluator_time: 0.0277 (0.0443)  time: 0.3014  data: 0.0046  max mem: 9499
Test: Total time: 0:17:29 (0.3292 s / it)
Averaged stats: model_time: 0.1238 (0.1451)  evaluator_time: 0.0277 (0.0443)
Accumulating evaluation results...
DONE-test (t=2.64s).
Accumulating evaluation results...
DONE-test (t=2.33s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.388
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.618
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.460
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.388
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.662
IoU metric: segm
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.625
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.539
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.444
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.684
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.733
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.734
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.734
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch no : 1, batch no : 0, total loss : 0.5613616108894348,  classifier :0.08137406408786774, mask: 0.2353312224149704 ===================
epoch no : 1, batch no : 1, total loss : 0.648551881313324,  classifier :0.099205881357193, mask: 0.2756999135017395 ===================
epoch no : 1, batch no : 2, total loss : 0.5408444404602051,  classifier :0.08434019982814789, mask: 0.18208050727844238 ===================
epoch no : 1, batch no : 3, total loss : 0.45006054639816284,  classifier :0.08389217406511307, mask: 0.1368422955274582 ===================
epoch no : 1, batch no : 4, total loss : 0.41607144474983215,  classifier :0.07918937504291534, mask: 0.136694073677063 ===================
epoch no : 1, batch no : 5, total loss : 0.5269423127174377,  classifier :0.09236522763967514, mask: 0.176746666431427 ===================
epoch no : 1, batch no : 6, total loss : 0.4750271141529083,  classifier :0.07253424823284149, mask: 0.16176770627498627 ===================
epoch no : 1, batch no : 7, total loss : 0.5051022171974182,  classifier :0.08857192099094391, mask: 0.20606647431850433 ===================
epoch no : 1, batch no : 8, total loss : 0.4751552939414978,  classifier :0.0829351469874382, mask: 0.15058434009552002 ===================
epoch no : 1, batch no : 9, total loss : 0.5893669724464417,  classifier :0.08912298828363419, mask: 0.20134292542934418 ===================
epoch no : 1, batch no : 10, total loss : 0.4945865869522095,  classifier :0.07020838558673859, mask: 0.1944296956062317 ===================
epoch no : 1, batch no : 11, total loss : 0.49282780289649963,  classifier :0.07275895029306412, mask: 0.18327079713344574 ===================
epoch no : 1, batch no : 12, total loss : 0.4272288680076599,  classifier :0.0744541734457016, mask: 0.1696506142616272 ===================
epoch no : 1, batch no : 13, total loss : 0.4786580801010132,  classifier :0.07744103670120239, mask: 0.16035234928131104 ===================
epoch no : 1, batch no : 14, total loss : 0.44971388578414917,  classifier :0.07452251762151718, mask: 0.15516218543052673 ===================
epoch no : 1, batch no : 15, total loss : 0.45540934801101685,  classifier :0.06896284967660904, mask: 0.18327666819095612 ===================
epoch no : 1, batch no : 16, total loss : 0.5182364583015442,  classifier :0.07924503087997437, mask: 0.1941927820444107 ===================
epoch no : 1, batch no : 17, total loss : 0.39575761556625366,  classifier :0.06842002272605896, mask: 0.15009836852550507 ===================
epoch no : 1, batch no : 18, total loss : 0.46702009439468384,  classifier :0.0684138759970665, mask: 0.17888468503952026 ===================
epoch no : 1, batch no : 19, total loss : 0.4629949927330017,  classifier :0.06846098601818085, mask: 0.1706485003232956 ===================
epoch no : 1, batch no : 20, total loss : 0.4657841622829437,  classifier :0.06879570335149765, mask: 0.1602298766374588 ===================
epoch no : 1, batch no : 21, total loss : 0.5185284614562988,  classifier :0.06824083626270294, mask: 0.17243051528930664 ===================
epoch no : 1, batch no : 22, total loss : 0.45634377002716064,  classifier :0.07646340876817703, mask: 0.15870437026023865 ===================
epoch no : 1, batch no : 23, total loss : 0.47934433817863464,  classifier :0.07596416026353836, mask: 0.15696106851100922 ===================
epoch no : 1, batch no : 24, total loss : 0.5472615361213684,  classifier :0.08470079302787781, mask: 0.17537952959537506 ===================
epoch no : 1, batch no : 25, total loss : 0.4013912081718445,  classifier :0.06953117996454239, mask: 0.16188183426856995 ===================
epoch no : 1, batch no : 26, total loss : 0.4594096839427948,  classifier :0.07762376219034195, mask: 0.17606675624847412 ===================
epoch no : 1, batch no : 27, total loss : 0.5369636416435242,  classifier :0.08635767549276352, mask: 0.21070240437984467 ===================
epoch no : 1, batch no : 28, total loss : 0.5153922438621521,  classifier :0.08397752046585083, mask: 0.19567419588565826 ===================
epoch no : 1, batch no : 29, total loss : 0.5580639839172363,  classifier :0.07749342918395996, mask: 0.19831086695194244 ===================
epoch no : 1, batch no : 30, total loss : 0.42707955837249756,  classifier :0.07227256894111633, mask: 0.15476855635643005 ===================
epoch no : 1, batch no : 31, total loss : 0.5436554551124573,  classifier :0.08208246529102325, mask: 0.1835934817790985 ===================
epoch no : 1, batch no : 32, total loss : 0.4690045714378357,  classifier :0.07248920202255249, mask: 0.18630647659301758 ===================
epoch no : 1, batch no : 33, total loss : 0.4332546293735504,  classifier :0.07168705761432648, mask: 0.13932180404663086 ===================
epoch no : 1, batch no : 34, total loss : 0.4261150658130646,  classifier :0.08207320421934128, mask: 0.16026939451694489 ===================
epoch no : 1, batch no : 35, total loss : 0.3888072967529297,  classifier :0.07390710711479187, mask: 0.1406654715538025 ===================
epoch no : 1, batch no : 36, total loss : 0.39706605672836304,  classifier :0.07763809710741043, mask: 0.14103397727012634 ===================
epoch no : 1, batch no : 37, total loss : 0.5456523895263672,  classifier :0.07294409722089767, mask: 0.26337021589279175 ===================
epoch no : 1, batch no : 38, total loss : 0.4900962710380554,  classifier :0.07423701882362366, mask: 0.15700745582580566 ===================
epoch no : 1, batch no : 39, total loss : 0.5428138375282288,  classifier :0.07508422434329987, mask: 0.18404588103294373 ===================
epoch no : 1, batch no : 40, total loss : 0.45964691042900085,  classifier :0.07879190891981125, mask: 0.15064699947834015 ===================
epoch no : 1, batch no : 41, total loss : 0.5339186787605286,  classifier :0.0663379579782486, mask: 0.18437281250953674 ===================
epoch no : 1, batch no : 42, total loss : 0.5221831798553467,  classifier :0.07591874897480011, mask: 0.1837974190711975 ===================
epoch no : 1, batch no : 43, total loss : 0.49033862352371216,  classifier :0.08198371529579163, mask: 0.17027859389781952 ===================
epoch no : 1, batch no : 44, total loss : 0.44968143105506897,  classifier :0.07697834074497223, mask: 0.142595112323761 ===================
epoch no : 1, batch no : 45, total loss : 0.48328694701194763,  classifier :0.07954573631286621, mask: 0.1535256952047348 ===================
epoch no : 1, batch no : 46, total loss : 0.5770096182823181,  classifier :0.08058080822229385, mask: 0.18919344246387482 ===================
epoch no : 1, batch no : 47, total loss : 0.5574058890342712,  classifier :0.08403036743402481, mask: 0.1706494688987732 ===================
epoch no : 1, batch no : 48, total loss : 0.5271538496017456,  classifier :0.08557150512933731, mask: 0.17044256627559662 ===================
epoch no : 1, batch no : 49, total loss : 0.600752592086792,  classifier :0.09320016205310822, mask: 0.234776109457016 ===================
epoch no : 1, batch no : 50, total loss : 0.45487546920776367,  classifier :0.07552874088287354, mask: 0.14475740492343903 ===================
epoch no : 1, batch no : 51, total loss : 0.45765846967697144,  classifier :0.08026870340108871, mask: 0.16080765426158905 ===================
epoch no : 1, batch no : 52, total loss : 0.44801998138427734,  classifier :0.07420472055673599, mask: 0.15068957209587097 ===================
epoch no : 1, batch no : 53, total loss : 0.44443196058273315,  classifier :0.06836255639791489, mask: 0.16115432977676392 ===================
epoch no : 1, batch no : 54, total loss : 0.4593793749809265,  classifier :0.07637017965316772, mask: 0.14615432918071747 ===================
epoch no : 1, batch no : 55, total loss : 0.4112469255924225,  classifier :0.06490518152713776, mask: 0.15845747292041779 ===================
epoch no : 1, batch no : 56, total loss : 0.4361441731452942,  classifier :0.065098837018013, mask: 0.15849605202674866 ===================
epoch no : 1, batch no : 57, total loss : 0.5429800152778625,  classifier :0.09063050150871277, mask: 0.18524819612503052 ===================
epoch no : 1, batch no : 58, total loss : 0.5772454142570496,  classifier :0.07218074053525925, mask: 0.2109135389328003 ===================
epoch no : 1, batch no : 59, total loss : 0.5026987195014954,  classifier :0.0680067241191864, mask: 0.1924056112766266 ===================
epoch no : 1, batch no : 60, total loss : 0.49741557240486145,  classifier :0.07937800139188766, mask: 0.16443705558776855 ===================
epoch no : 1, batch no : 61, total loss : 0.47819873690605164,  classifier :0.07353100180625916, mask: 0.15590150654315948 ===================
epoch no : 1, batch no : 62, total loss : 0.526634156703949,  classifier :0.08381544798612595, mask: 0.18349780142307281 ===================
epoch no : 1, batch no : 63, total loss : 0.48112988471984863,  classifier :0.08325757086277008, mask: 0.17556503415107727 ===================
epoch no : 1, batch no : 64, total loss : 0.41794705390930176,  classifier :0.07149922102689743, mask: 0.1396666318178177 ===================
epoch no : 1, batch no : 65, total loss : 0.5515051484107971,  classifier :0.07247249037027359, mask: 0.2036655694246292 ===================
epoch no : 1, batch no : 66, total loss : 0.46817928552627563,  classifier :0.06966468691825867, mask: 0.16036643087863922 ===================
epoch no : 1, batch no : 67, total loss : 0.4657459855079651,  classifier :0.07083496451377869, mask: 0.16802996397018433 ===================
epoch no : 1, batch no : 68, total loss : 0.5458943843841553,  classifier :0.07888217270374298, mask: 0.18989619612693787 ===================
epoch no : 1, batch no : 69, total loss : 0.4673018753528595,  classifier :0.07799166440963745, mask: 0.15989984571933746 ===================
epoch no : 1, batch no : 70, total loss : 0.5321179628372192,  classifier :0.08256984502077103, mask: 0.18095535039901733 ===================
epoch no : 1, batch no : 71, total loss : 0.5699906349182129,  classifier :0.09593012183904648, mask: 0.2136169970035553 ===================
epoch no : 1, batch no : 72, total loss : 0.42755240201950073,  classifier :0.0699019655585289, mask: 0.14645133912563324 ===================
epoch no : 1, batch no : 73, total loss : 0.4906739890575409,  classifier :0.07105687260627747, mask: 0.1641620546579361 ===================
epoch no : 1, batch no : 74, total loss : 0.555321455001831,  classifier :0.08848152309656143, mask: 0.20383422076702118 ===================
epoch no : 1, batch no : 75, total loss : 0.47009265422821045,  classifier :0.07799514383077621, mask: 0.1515013426542282 ===================
epoch no : 1, batch no : 76, total loss : 0.5587624311447144,  classifier :0.06734193116426468, mask: 0.19986683130264282 ===================
epoch no : 1, batch no : 77, total loss : 0.5494086742401123,  classifier :0.0639704093337059, mask: 0.2301291823387146 ===================
epoch no : 1, batch no : 78, total loss : 0.44609156250953674,  classifier :0.07821334898471832, mask: 0.13719038665294647 ===================
epoch no : 1, batch no : 79, total loss : 0.5339335799217224,  classifier :0.0739898756146431, mask: 0.20276255905628204 ===================
epoch no : 1, batch no : 80, total loss : 0.39702844619750977,  classifier :0.07550742477178574, mask: 0.14719325304031372 ===================
epoch no : 1, batch no : 81, total loss : 0.4477970004081726,  classifier :0.06034901365637779, mask: 0.16736911237239838 ===================
epoch no : 1, batch no : 82, total loss : 0.5708398222923279,  classifier :0.08402805030345917, mask: 0.18127946555614471 ===================
epoch no : 1, batch no : 83, total loss : 0.6143988370895386,  classifier :0.10246951878070831, mask: 0.22008167207241058 ===================
epoch no : 1, batch no : 84, total loss : 0.5325301885604858,  classifier :0.07165413349866867, mask: 0.20594385266304016 ===================
epoch no : 1, batch no : 85, total loss : 0.5198023915290833,  classifier :0.07366126775741577, mask: 0.2008506804704666 ===================
epoch no : 1, batch no : 86, total loss : 0.45350944995880127,  classifier :0.07907985895872116, mask: 0.17485761642456055 ===================
epoch no : 1, batch no : 87, total loss : 0.5475477576255798,  classifier :0.06851962953805923, mask: 0.22638873755931854 ===================
epoch no : 1, batch no : 88, total loss : 0.5509403347969055,  classifier :0.07212027907371521, mask: 0.17214760184288025 ===================
epoch no : 1, batch no : 89, total loss : 0.4570900797843933,  classifier :0.07135187089443207, mask: 0.15602971613407135 ===================
epoch no : 1, batch no : 90, total loss : 0.545930027961731,  classifier :0.08880407363176346, mask: 0.17055292427539825 ===================
epoch no : 1, batch no : 91, total loss : 0.37290483713150024,  classifier :0.055482346564531326, mask: 0.13534291088581085 ===================
epoch no : 1, batch no : 92, total loss : 0.42052412033081055,  classifier :0.06968915462493896, mask: 0.15133163332939148 ===================
epoch no : 1, batch no : 93, total loss : 0.5122189521789551,  classifier :0.07242780178785324, mask: 0.1772514283657074 ===================
epoch no : 1, batch no : 94, total loss : 0.42756861448287964,  classifier :0.07003924250602722, mask: 0.13881051540374756 ===================
epoch no : 1, batch no : 95, total loss : 0.500831127166748,  classifier :0.06688716262578964, mask: 0.21189045906066895 ===================
epoch no : 1, batch no : 96, total loss : 0.49680325388908386,  classifier :0.081636443734169, mask: 0.18837082386016846 ===================
epoch no : 1, batch no : 97, total loss : 0.52557772397995,  classifier :0.07518065720796585, mask: 0.1999187171459198 ===================
epoch no : 1, batch no : 98, total loss : 0.40111783146858215,  classifier :0.06693744659423828, mask: 0.13900278508663177 ===================
epoch no : 1, batch no : 99, total loss : 0.4257495701313019,  classifier :0.07282635569572449, mask: 0.15117387473583221 ===================
epoch no : 1, batch no : 100, total loss : 0.48253384232521057,  classifier :0.08645991235971451, mask: 0.187997967004776 ===================
epoch no : 1, batch no : 101, total loss : 0.5001169443130493,  classifier :0.055893369019031525, mask: 0.21496687829494476 ===================
epoch no : 1, batch no : 102, total loss : 0.4482048451900482,  classifier :0.0794675201177597, mask: 0.15082840621471405 ===================
epoch no : 1, batch no : 103, total loss : 0.47401466965675354,  classifier :0.07381444424390793, mask: 0.16504666209220886 ===================
epoch no : 1, batch no : 104, total loss : 0.41852909326553345,  classifier :0.06404750794172287, mask: 0.13532423973083496 ===================
epoch no : 1, batch no : 105, total loss : 0.4580810070037842,  classifier :0.06700129806995392, mask: 0.14233069121837616 ===================
epoch no : 1, batch no : 106, total loss : 0.35458090901374817,  classifier :0.06392677873373032, mask: 0.13842563331127167 ===================
epoch no : 1, batch no : 107, total loss : 0.4008485674858093,  classifier :0.07102537155151367, mask: 0.1446896195411682 ===================
epoch no : 1, batch no : 108, total loss : 0.46558502316474915,  classifier :0.08845916390419006, mask: 0.13424499332904816 ===================
epoch no : 1, batch no : 109, total loss : 0.522930383682251,  classifier :0.08326511830091476, mask: 0.20159786939620972 ===================
epoch no : 1, batch no : 110, total loss : 0.4314756691455841,  classifier :0.061780184507369995, mask: 0.1489015817642212 ===================
epoch no : 1, batch no : 111, total loss : 0.47223570942878723,  classifier :0.061547257006168365, mask: 0.20804373919963837 ===================
epoch no : 1, batch no : 112, total loss : 0.3992554545402527,  classifier :0.06364808231592178, mask: 0.14175856113433838 ===================
epoch no : 1, batch no : 113, total loss : 0.4314427971839905,  classifier :0.07008569687604904, mask: 0.13030605018138885 ===================
epoch no : 1, batch no : 114, total loss : 0.49789857864379883,  classifier :0.06324794143438339, mask: 0.2109525501728058 ===================
epoch no : 1, batch no : 115, total loss : 0.5155717134475708,  classifier :0.08148622512817383, mask: 0.1722712218761444 ===================
epoch no : 1, batch no : 116, total loss : 0.5209243893623352,  classifier :0.06007777899503708, mask: 0.21006610989570618 ===================
epoch no : 1, batch no : 117, total loss : 0.5371819734573364,  classifier :0.05799049139022827, mask: 0.1972791701555252 ===================
epoch no : 1, batch no : 118, total loss : 0.45065927505493164,  classifier :0.0718049556016922, mask: 0.15298330783843994 ===================
epoch no : 1, batch no : 119, total loss : 0.4791431427001953,  classifier :0.08586163073778152, mask: 0.16659778356552124 ===================
epoch no : 1, batch no : 120, total loss : 0.5193011164665222,  classifier :0.08324678242206573, mask: 0.20112349092960358 ===================
epoch no : 1, batch no : 121, total loss : 0.5938331484794617,  classifier :0.07580943405628204, mask: 0.2399325668811798 ===================
epoch no : 1, batch no : 122, total loss : 0.6308736205101013,  classifier :0.06989424675703049, mask: 0.26733359694480896 ===================
epoch no : 1, batch no : 123, total loss : 0.5636700987815857,  classifier :0.08523328602313995, mask: 0.18348446488380432 ===================
epoch no : 1, batch no : 124, total loss : 0.4819575548171997,  classifier :0.07492424547672272, mask: 0.14642639458179474 ===================
epoch no : 1, batch no : 125, total loss : 0.4328134059906006,  classifier :0.06873616576194763, mask: 0.1372869908809662 ===================
epoch no : 1, batch no : 126, total loss : 0.4616745710372925,  classifier :0.07383502274751663, mask: 0.1673857569694519 ===================
epoch no : 1, batch no : 127, total loss : 0.5202218294143677,  classifier :0.0692305937409401, mask: 0.21446160972118378 ===================
epoch no : 1, batch no : 128, total loss : 0.375237375497818,  classifier :0.07809408009052277, mask: 0.1421562284231186 ===================
epoch no : 1, batch no : 129, total loss : 0.5426145195960999,  classifier :0.07617656886577606, mask: 0.1954408884048462 ===================
epoch no : 1, batch no : 130, total loss : 0.515041708946228,  classifier :0.07347635924816132, mask: 0.18977589905261993 ===================
epoch no : 1, batch no : 131, total loss : 0.6741997003555298,  classifier :0.10452117025852203, mask: 0.23232978582382202 ===================
epoch no : 1, batch no : 132, total loss : 0.5969041585922241,  classifier :0.06685945391654968, mask: 0.22718481719493866 ===================
epoch no : 1, batch no : 133, total loss : 0.378923624753952,  classifier :0.05751704052090645, mask: 0.13982927799224854 ===================
epoch no : 1, batch no : 134, total loss : 0.42014363408088684,  classifier :0.06610891222953796, mask: 0.13704559206962585 ===================
epoch no : 1, batch no : 135, total loss : 0.4674434959888458,  classifier :0.07642636448144913, mask: 0.15044847130775452 ===================
epoch no : 1, batch no : 136, total loss : 0.41516196727752686,  classifier :0.06671924889087677, mask: 0.17290203273296356 ===================
epoch no : 1, batch no : 137, total loss : 0.41013312339782715,  classifier :0.06940322369337082, mask: 0.1519184112548828 ===================
epoch no : 1, batch no : 138, total loss : 0.5441907644271851,  classifier :0.08314397931098938, mask: 0.20782823860645294 ===================
epoch no : 1, batch no : 139, total loss : 0.3973914384841919,  classifier :0.05824541673064232, mask: 0.13783769309520721 ===================
epoch no : 1, batch no : 140, total loss : 0.3896361291408539,  classifier :0.058818064630031586, mask: 0.1470634490251541 ===================
epoch no : 1, batch no : 141, total loss : 0.47288978099823,  classifier :0.06796478480100632, mask: 0.18041905760765076 ===================
epoch no : 1, batch no : 142, total loss : 0.5419870615005493,  classifier :0.07777480781078339, mask: 0.16637885570526123 ===================
epoch no : 1, batch no : 143, total loss : 0.4005303680896759,  classifier :0.07241590321063995, mask: 0.13211926817893982 ===================
epoch no : 1, batch no : 144, total loss : 0.5050312876701355,  classifier :0.08950532227754593, mask: 0.16458089649677277 ===================
epoch no : 1, batch no : 145, total loss : 0.47567418217658997,  classifier :0.07061935216188431, mask: 0.14234711229801178 ===================
epoch no : 1, batch no : 146, total loss : 0.5233447551727295,  classifier :0.07669011503458023, mask: 0.1621285080909729 ===================
epoch no : 1, batch no : 147, total loss : 0.6214002966880798,  classifier :0.08343041688203812, mask: 0.2177933305501938 ===================
epoch no : 1, batch no : 148, total loss : 0.463557630777359,  classifier :0.08164209872484207, mask: 0.15064536035060883 ===================
epoch no : 1, batch no : 149, total loss : 0.4974139630794525,  classifier :0.07135874778032303, mask: 0.214952290058136 ===================
epoch no : 1, batch no : 150, total loss : 0.5533517003059387,  classifier :0.08364159613847733, mask: 0.18525463342666626 ===================
epoch no : 1, batch no : 151, total loss : 0.4636071026325226,  classifier :0.07388646900653839, mask: 0.18960575759410858 ===================
epoch no : 1, batch no : 152, total loss : 0.4288930594921112,  classifier :0.06748532503843307, mask: 0.12494254857301712 ===================
epoch no : 1, batch no : 153, total loss : 0.553432285785675,  classifier :0.0643310472369194, mask: 0.217570960521698 ===================
epoch no : 1, batch no : 154, total loss : 0.3758201599121094,  classifier :0.06082572415471077, mask: 0.12889006733894348 ===================
epoch no : 1, batch no : 155, total loss : 0.5792076587677002,  classifier :0.07614398747682571, mask: 0.2175299972295761 ===================
epoch no : 1, batch no : 156, total loss : 0.5174671411514282,  classifier :0.09044704586267471, mask: 0.17797034978866577 ===================
epoch no : 1, batch no : 157, total loss : 0.4674323797225952,  classifier :0.06898342072963715, mask: 0.20161037147045135 ===================
epoch no : 1, batch no : 158, total loss : 0.5113608241081238,  classifier :0.07530780136585236, mask: 0.1812925487756729 ===================
epoch no : 1, batch no : 159, total loss : 0.3890114426612854,  classifier :0.06120195612311363, mask: 0.1504426747560501 ===================
epoch no : 1, batch no : 160, total loss : 0.36635252833366394,  classifier :0.060864657163619995, mask: 0.13374552130699158 ===================
epoch no : 1, batch no : 161, total loss : 0.540773332118988,  classifier :0.0701146200299263, mask: 0.18738330900669098 ===================
epoch no : 1, batch no : 162, total loss : 0.4524381756782532,  classifier :0.08053166419267654, mask: 0.14320529997348785 ===================
epoch no : 1, batch no : 163, total loss : 0.48264482617378235,  classifier :0.081624835729599, mask: 0.1934405267238617 ===================
epoch no : 1, batch no : 164, total loss : 0.41441404819488525,  classifier :0.070103220641613, mask: 0.14702504873275757 ===================
epoch no : 1, batch no : 165, total loss : 0.5296872854232788,  classifier :0.0707348957657814, mask: 0.21562178432941437 ===================
epoch no : 1, batch no : 166, total loss : 0.633984386920929,  classifier :0.0819016844034195, mask: 0.22870534658432007 ===================
epoch no : 1, batch no : 167, total loss : 0.46789875626564026,  classifier :0.060035090893507004, mask: 0.16489295661449432 ===================
epoch no : 1, batch no : 168, total loss : 0.3770575225353241,  classifier :0.0720025822520256, mask: 0.1328756958246231 ===================
epoch no : 1, batch no : 169, total loss : 0.44741371273994446,  classifier :0.07609187066555023, mask: 0.14418043196201324 ===================
epoch no : 1, batch no : 170, total loss : 0.3962453007698059,  classifier :0.06728221476078033, mask: 0.13987214863300323 ===================
epoch no : 1, batch no : 171, total loss : 0.3957284688949585,  classifier :0.06493940204381943, mask: 0.1359807550907135 ===================
epoch no : 1, batch no : 172, total loss : 0.46595826745033264,  classifier :0.08533082902431488, mask: 0.14563773572444916 ===================
epoch no : 1, batch no : 173, total loss : 0.5816825032234192,  classifier :0.0778757631778717, mask: 0.17360660433769226 ===================
epoch no : 1, batch no : 174, total loss : 0.45993030071258545,  classifier :0.08688392490148544, mask: 0.14937171339988708 ===================
epoch no : 1, batch no : 175, total loss : 0.45844796299934387,  classifier :0.07284622639417648, mask: 0.15930306911468506 ===================
epoch no : 1, batch no : 176, total loss : 0.4772109091281891,  classifier :0.08365583419799805, mask: 0.18557804822921753 ===================
epoch no : 1, batch no : 177, total loss : 0.5015480518341064,  classifier :0.06623201817274094, mask: 0.19652964174747467 ===================
epoch no : 1, batch no : 178, total loss : 0.4681868553161621,  classifier :0.0782519206404686, mask: 0.1464398354291916 ===================
epoch no : 1, batch no : 179, total loss : 0.48685288429260254,  classifier :0.06622032821178436, mask: 0.196150541305542 ===================
epoch no : 1, batch no : 180, total loss : 0.4686603844165802,  classifier :0.08510618656873703, mask: 0.1587887853384018 ===================
epoch no : 1, batch no : 181, total loss : 0.4917012155056,  classifier :0.07200620323419571, mask: 0.14967335760593414 ===================
epoch no : 1, batch no : 182, total loss : 0.5111406445503235,  classifier :0.07365959882736206, mask: 0.170964777469635 ===================
epoch no : 1, batch no : 183, total loss : 0.5062793493270874,  classifier :0.059492986649274826, mask: 0.20581087470054626 ===================
epoch no : 1, batch no : 184, total loss : 0.4474387466907501,  classifier :0.07533301413059235, mask: 0.15144973993301392 ===================
epoch no : 1, batch no : 185, total loss : 0.4549458920955658,  classifier :0.0674235075712204, mask: 0.1560150384902954 ===================
epoch no : 1, batch no : 186, total loss : 0.504464328289032,  classifier :0.07156714051961899, mask: 0.18094958364963531 ===================
epoch no : 1, batch no : 187, total loss : 0.43768927454948425,  classifier :0.06790445744991302, mask: 0.15333203971385956 ===================
epoch no : 1, batch no : 188, total loss : 0.48076382279396057,  classifier :0.08136212825775146, mask: 0.16007186472415924 ===================
epoch no : 1, batch no : 189, total loss : 0.45330244302749634,  classifier :0.08516953885555267, mask: 0.13370175659656525 ===================
epoch no : 1, batch no : 190, total loss : 0.5145497918128967,  classifier :0.07867557555437088, mask: 0.16948583722114563 ===================
epoch no : 1, batch no : 191, total loss : 0.45021408796310425,  classifier :0.06871359795331955, mask: 0.17984087765216827 ===================
epoch no : 1, batch no : 192, total loss : 0.4584785997867584,  classifier :0.09588176012039185, mask: 0.17037999629974365 ===================
epoch no : 1, batch no : 193, total loss : 0.4568459689617157,  classifier :0.06498129665851593, mask: 0.163204163312912 ===================
epoch no : 1, batch no : 194, total loss : 0.6079495549201965,  classifier :0.087235227227211, mask: 0.21882034838199615 ===================
epoch no : 1, batch no : 195, total loss : 0.48576459288597107,  classifier :0.07346710562705994, mask: 0.19553950428962708 ===================
epoch no : 1, batch no : 196, total loss : 0.4729193449020386,  classifier :0.05536958947777748, mask: 0.1764451116323471 ===================
epoch no : 1, batch no : 197, total loss : 0.48562848567962646,  classifier :0.08021857589483261, mask: 0.16848313808441162 ===================
epoch no : 1, batch no : 198, total loss : 0.4473881423473358,  classifier :0.07278026640415192, mask: 0.1474446803331375 ===================
epoch no : 1, batch no : 199, total loss : 0.3266841769218445,  classifier :0.053869832307100296, mask: 0.11994750797748566 ===================
epoch no : 1, batch no : 200, total loss : 0.4553928077220917,  classifier :0.06737026572227478, mask: 0.16626201570034027 ===================
epoch no : 1, batch no : 201, total loss : 0.4404110908508301,  classifier :0.07835983484983444, mask: 0.14479725062847137 ===================
epoch no : 1, batch no : 202, total loss : 0.448269784450531,  classifier :0.06696423888206482, mask: 0.17675158381462097 ===================
epoch no : 1, batch no : 203, total loss : 0.467559814453125,  classifier :0.07678670436143875, mask: 0.1605762243270874 ===================
epoch no : 1, batch no : 204, total loss : 0.37522441148757935,  classifier :0.061038535088300705, mask: 0.13494475185871124 ===================
epoch no : 1, batch no : 205, total loss : 0.5012938976287842,  classifier :0.0919819101691246, mask: 0.18174651265144348 ===================
epoch no : 1, batch no : 206, total loss : 0.47510677576065063,  classifier :0.06586772203445435, mask: 0.14754071831703186 ===================
epoch no : 1, batch no : 207, total loss : 0.46455323696136475,  classifier :0.060188017785549164, mask: 0.1510019600391388 ===================
epoch no : 1, batch no : 208, total loss : 0.40502163767814636,  classifier :0.0837034359574318, mask: 0.15326908230781555 ===================
epoch no : 1, batch no : 209, total loss : 0.5180153846740723,  classifier :0.09771762788295746, mask: 0.16175910830497742 ===================
epoch no : 1, batch no : 210, total loss : 0.6041509509086609,  classifier :0.08389303088188171, mask: 0.1846667230129242 ===================
epoch no : 1, batch no : 211, total loss : 0.44436314702033997,  classifier :0.06139222905039787, mask: 0.16295886039733887 ===================
epoch no : 1, batch no : 212, total loss : 0.49181386828422546,  classifier :0.07137348502874374, mask: 0.188208669424057 ===================
epoch no : 1, batch no : 213, total loss : 0.5352199673652649,  classifier :0.06224290281534195, mask: 0.1879798173904419 ===================
epoch no : 1, batch no : 214, total loss : 0.4620301127433777,  classifier :0.06042028218507767, mask: 0.14560461044311523 ===================
epoch no : 1, batch no : 215, total loss : 0.4763545095920563,  classifier :0.07509371638298035, mask: 0.1523960530757904 ===================
epoch no : 1, batch no : 216, total loss : 0.3636040985584259,  classifier :0.0802006870508194, mask: 0.12774032354354858 ===================
epoch no : 1, batch no : 217, total loss : 0.5094184279441833,  classifier :0.07100523263216019, mask: 0.16697156429290771 ===================
epoch no : 1, batch no : 218, total loss : 0.5233947038650513,  classifier :0.06935214251279831, mask: 0.15549075603485107 ===================
epoch no : 1, batch no : 219, total loss : 0.4941936731338501,  classifier :0.08108853548765182, mask: 0.19044731557369232 ===================
epoch no : 1, batch no : 220, total loss : 0.4217674136161804,  classifier :0.07398337870836258, mask: 0.14736954867839813 ===================
epoch no : 1, batch no : 221, total loss : 0.455556720495224,  classifier :0.07836657762527466, mask: 0.1645692139863968 ===================
epoch no : 1, batch no : 222, total loss : 0.4207742512226105,  classifier :0.07037916034460068, mask: 0.16583988070487976 ===================
epoch no : 1, batch no : 223, total loss : 0.513929545879364,  classifier :0.07325482368469238, mask: 0.17925046384334564 ===================
epoch no : 1, batch no : 224, total loss : 0.415044903755188,  classifier :0.07350083440542221, mask: 0.1291714757680893 ===================
epoch no : 1, batch no : 225, total loss : 0.4552997946739197,  classifier :0.06458750367164612, mask: 0.18214727938175201 ===================
epoch no : 1, batch no : 226, total loss : 0.3424197733402252,  classifier :0.06827758252620697, mask: 0.10844773054122925 ===================
epoch no : 1, batch no : 227, total loss : 0.47598499059677124,  classifier :0.060511209070682526, mask: 0.14864419400691986 ===================
epoch no : 1, batch no : 228, total loss : 0.5770524740219116,  classifier :0.08211097866296768, mask: 0.19977226853370667 ===================
epoch no : 1, batch no : 229, total loss : 0.4216214716434479,  classifier :0.07918859273195267, mask: 0.1455455720424652 ===================
epoch no : 1, batch no : 230, total loss : 0.4791375398635864,  classifier :0.06690437346696854, mask: 0.16234762966632843 ===================
epoch no : 1, batch no : 231, total loss : 0.7413521409034729,  classifier :0.08961214870214462, mask: 0.2765924334526062 ===================
epoch no : 1, batch no : 232, total loss : 0.48487958312034607,  classifier :0.0782138854265213, mask: 0.18750202655792236 ===================
epoch no : 1, batch no : 233, total loss : 0.43569445610046387,  classifier :0.06799594312906265, mask: 0.1308557540178299 ===================
epoch no : 1, batch no : 234, total loss : 0.48537230491638184,  classifier :0.07784423232078552, mask: 0.15810441970825195 ===================
epoch no : 1, batch no : 235, total loss : 0.36821359395980835,  classifier :0.06878003478050232, mask: 0.126926451921463 ===================
epoch no : 1, batch no : 236, total loss : 0.4665008783340454,  classifier :0.05894061177968979, mask: 0.16740559041500092 ===================
epoch no : 1, batch no : 237, total loss : 0.353100448846817,  classifier :0.057880617678165436, mask: 0.13185058534145355 ===================
epoch no : 1, batch no : 238, total loss : 0.4363354742527008,  classifier :0.07041598856449127, mask: 0.1520983725786209 ===================
epoch no : 1, batch no : 239, total loss : 0.48745864629745483,  classifier :0.07755006104707718, mask: 0.17167839407920837 ===================
epoch no : 1, batch no : 240, total loss : 0.47258642315864563,  classifier :0.062273066490888596, mask: 0.13930995762348175 ===================
epoch no : 1, batch no : 241, total loss : 0.5260833501815796,  classifier :0.059263650327920914, mask: 0.22908560931682587 ===================
epoch no : 1, batch no : 242, total loss : 0.3701770305633545,  classifier :0.060971058905124664, mask: 0.12255540490150452 ===================
epoch no : 1, batch no : 243, total loss : 0.49058157205581665,  classifier :0.06638967990875244, mask: 0.19319458305835724 ===================
epoch no : 1, batch no : 244, total loss : 0.62664794921875,  classifier :0.07665842771530151, mask: 0.22722558677196503 ===================
epoch no : 1, batch no : 245, total loss : 0.6196033358573914,  classifier :0.07384716719388962, mask: 0.237514466047287 ===================
epoch no : 1, batch no : 246, total loss : 0.4234338104724884,  classifier :0.06224137544631958, mask: 0.1387118697166443 ===================
epoch no : 1, batch no : 247, total loss : 0.3482026755809784,  classifier :0.0682176798582077, mask: 0.12397738546133041 ===================
epoch no : 1, batch no : 248, total loss : 0.4110715389251709,  classifier :0.059620801359415054, mask: 0.15776830911636353 ===================
epoch no : 1, batch no : 249, total loss : 0.4245072603225708,  classifier :0.06221458688378334, mask: 0.13732248544692993 ===================
epoch no : 1, batch no : 250, total loss : 0.4250338673591614,  classifier :0.056114312261343, mask: 0.17319467663764954 ===================
epoch no : 1, batch no : 251, total loss : 0.3836160898208618,  classifier :0.07240009307861328, mask: 0.1418016403913498 ===================
epoch no : 1, batch no : 252, total loss : 0.4619414806365967,  classifier :0.06357264518737793, mask: 0.16958492994308472 ===================
epoch no : 1, batch no : 253, total loss : 0.45308566093444824,  classifier :0.0598660483956337, mask: 0.15286926925182343 ===================
epoch no : 1, batch no : 254, total loss : 0.3523806035518646,  classifier :0.07694966346025467, mask: 0.13576896488666534 ===================
epoch no : 1, batch no : 255, total loss : 0.48696017265319824,  classifier :0.07413912564516068, mask: 0.14354680478572845 ===================
epoch no : 1, batch no : 256, total loss : 0.43108034133911133,  classifier :0.07065271586179733, mask: 0.14410841464996338 ===================
epoch no : 1, batch no : 257, total loss : 0.5320184230804443,  classifier :0.07341647893190384, mask: 0.15787526965141296 ===================
epoch no : 1, batch no : 258, total loss : 0.6630119681358337,  classifier :0.08622661232948303, mask: 0.23258578777313232 ===================
epoch no : 1, batch no : 259, total loss : 0.402142196893692,  classifier :0.0743376612663269, mask: 0.13940463960170746 ===================
epoch no : 1, batch no : 260, total loss : 0.5323200225830078,  classifier :0.06425230950117111, mask: 0.21344555914402008 ===================
epoch no : 1, batch no : 261, total loss : 0.6097095012664795,  classifier :0.06150505691766739, mask: 0.2986912727355957 ===================
epoch no : 1, batch no : 262, total loss : 0.6756030917167664,  classifier :0.08774736523628235, mask: 0.29460713267326355 ===================
epoch no : 1, batch no : 263, total loss : 0.4064042568206787,  classifier :0.057746805250644684, mask: 0.1454574316740036 ===================
epoch no : 1, batch no : 264, total loss : 0.37670665979385376,  classifier :0.06294084340333939, mask: 0.13063405454158783 ===================
epoch no : 1, batch no : 265, total loss : 0.4884603023529053,  classifier :0.08109325170516968, mask: 0.16210892796516418 ===================
epoch no : 1, batch no : 266, total loss : 0.5196928977966309,  classifier :0.09833633154630661, mask: 0.1717236340045929 ===================
epoch no : 1, batch no : 267, total loss : 0.4574217200279236,  classifier :0.07798135280609131, mask: 0.16442199051380157 ===================
epoch no : 1, batch no : 268, total loss : 0.47919416427612305,  classifier :0.058549996465444565, mask: 0.15604716539382935 ===================
epoch no : 1, batch no : 269, total loss : 0.5101419687271118,  classifier :0.06876587867736816, mask: 0.149215430021286 ===================
epoch no : 1, batch no : 270, total loss : 0.48003748059272766,  classifier :0.06879603117704391, mask: 0.16677606105804443 ===================
epoch no : 1, batch no : 271, total loss : 0.47088611125946045,  classifier :0.05741015821695328, mask: 0.2184668481349945 ===================
epoch no : 1, batch no : 272, total loss : 0.40383321046829224,  classifier :0.06833217293024063, mask: 0.14383535087108612 ===================
epoch no : 1, batch no : 273, total loss : 0.45814934372901917,  classifier :0.057244956493377686, mask: 0.17316709458827972 ===================
epoch no : 1, batch no : 274, total loss : 0.4192604720592499,  classifier :0.054352130740880966, mask: 0.17502568662166595 ===================
epoch no : 1, batch no : 275, total loss : 0.44813621044158936,  classifier :0.06290169805288315, mask: 0.17512547969818115 ===================
epoch no : 1, batch no : 276, total loss : 0.6276870369911194,  classifier :0.08783894777297974, mask: 0.18958406150341034 ===================
epoch no : 1, batch no : 277, total loss : 0.6794184446334839,  classifier :0.09226322919130325, mask: 0.23863686621189117 ===================
epoch no : 1, batch no : 278, total loss : 0.5032618045806885,  classifier :0.0733165591955185, mask: 0.15422695875167847 ===================
epoch no : 1, batch no : 279, total loss : 0.46506139636039734,  classifier :0.06099887937307358, mask: 0.16274413466453552 ===================
epoch no : 1, batch no : 280, total loss : 0.4430111050605774,  classifier :0.061776258051395416, mask: 0.19164176285266876 ===================
epoch no : 1, batch no : 281, total loss : 0.42760583758354187,  classifier :0.07215089350938797, mask: 0.15187959372997284 ===================
epoch no : 1, batch no : 282, total loss : 0.39962562918663025,  classifier :0.06800605356693268, mask: 0.1491161733865738 ===================
epoch no : 1, batch no : 283, total loss : 0.4225682318210602,  classifier :0.06730122864246368, mask: 0.15599896013736725 ===================
epoch no : 1, batch no : 284, total loss : 0.5432888865470886,  classifier :0.09007774293422699, mask: 0.18483269214630127 ===================
epoch no : 1, batch no : 285, total loss : 0.3836933374404907,  classifier :0.06793241947889328, mask: 0.14090745151042938 ===================
epoch no : 1, batch no : 286, total loss : 0.4624694287776947,  classifier :0.0754164606332779, mask: 0.17493966221809387 ===================
epoch no : 1, batch no : 287, total loss : 0.515651524066925,  classifier :0.0721609890460968, mask: 0.23957639932632446 ===================
epoch no : 1, batch no : 288, total loss : 0.6073264479637146,  classifier :0.09618338197469711, mask: 0.20657357573509216 ===================
epoch no : 1, batch no : 289, total loss : 0.5123625993728638,  classifier :0.07903425395488739, mask: 0.16716647148132324 ===================
epoch no : 1, batch no : 290, total loss : 0.3678835332393646,  classifier :0.0679977759718895, mask: 0.13864366710186005 ===================
epoch no : 1, batch no : 291, total loss : 0.4253081977367401,  classifier :0.07614070922136307, mask: 0.15590573847293854 ===================
epoch no : 1, batch no : 292, total loss : 0.486229807138443,  classifier :0.06212399899959564, mask: 0.1573888212442398 ===================
epoch no : 1, batch no : 293, total loss : 0.43657490611076355,  classifier :0.06825597584247589, mask: 0.1271350383758545 ===================
epoch no : 1, batch no : 294, total loss : 0.4311079680919647,  classifier :0.06393865495920181, mask: 0.15135763585567474 ===================
epoch no : 1, batch no : 295, total loss : 0.538902223110199,  classifier :0.061861760914325714, mask: 0.1930207461118698 ===================
epoch no : 1, batch no : 296, total loss : 0.4567561447620392,  classifier :0.05860591679811478, mask: 0.16134943068027496 ===================
epoch no : 1, batch no : 297, total loss : 0.41357794404029846,  classifier :0.07138704508543015, mask: 0.13248823583126068 ===================
epoch no : 1, batch no : 298, total loss : 0.387825071811676,  classifier :0.0694495141506195, mask: 0.12082275748252869 ===================
epoch no : 1, batch no : 299, total loss : 0.47282087802886963,  classifier :0.06488615274429321, mask: 0.1792433112859726 ===================
epoch no : 1, batch no : 300, total loss : 0.5227225422859192,  classifier :0.06515636295080185, mask: 0.19685208797454834 ===================
epoch no : 1, batch no : 301, total loss : 0.3603443503379822,  classifier :0.05640573427081108, mask: 0.13702552020549774 ===================
epoch no : 1, batch no : 302, total loss : 0.48060452938079834,  classifier :0.07029437273740768, mask: 0.1577570140361786 ===================
epoch no : 1, batch no : 303, total loss : 0.4858528971672058,  classifier :0.06409253180027008, mask: 0.16089379787445068 ===================
epoch no : 1, batch no : 304, total loss : 0.5345779061317444,  classifier :0.07098731398582458, mask: 0.19201289117336273 ===================
epoch no : 1, batch no : 305, total loss : 0.4795535206794739,  classifier :0.06992536783218384, mask: 0.1993342638015747 ===================
epoch no : 1, batch no : 306, total loss : 0.4056796431541443,  classifier :0.07203122228384018, mask: 0.1459890604019165 ===================
epoch no : 1, batch no : 307, total loss : 0.4638482332229614,  classifier :0.07066676020622253, mask: 0.13332051038742065 ===================
epoch no : 1, batch no : 308, total loss : 0.5970900654792786,  classifier :0.09073203802108765, mask: 0.20395231246948242 ===================
epoch no : 1, batch no : 309, total loss : 0.5115798115730286,  classifier :0.07732482254505157, mask: 0.17501139640808105 ===================
epoch no : 1, batch no : 310, total loss : 0.3901841640472412,  classifier :0.061815641820430756, mask: 0.14009924232959747 ===================
epoch no : 1, batch no : 311, total loss : 0.4087798297405243,  classifier :0.06360532343387604, mask: 0.14091910421848297 ===================
epoch no : 1, batch no : 312, total loss : 0.42157769203186035,  classifier :0.06805509328842163, mask: 0.1296728253364563 ===================
epoch no : 1, batch no : 313, total loss : 0.5259997248649597,  classifier :0.0749012678861618, mask: 0.17328260838985443 ===================
epoch no : 1, batch no : 314, total loss : 0.41873323917388916,  classifier :0.05249229073524475, mask: 0.12992119789123535 ===================
epoch no : 1, batch no : 315, total loss : 0.5294017195701599,  classifier :0.07769464701414108, mask: 0.1817738115787506 ===================
epoch no : 1, batch no : 316, total loss : 0.5030518174171448,  classifier :0.07723123580217361, mask: 0.2012438029050827 ===================
epoch no : 1, batch no : 317, total loss : 0.48634615540504456,  classifier :0.07946974784135818, mask: 0.14412786066532135 ===================
epoch no : 1, batch no : 318, total loss : 0.3507867753505707,  classifier :0.06705500185489655, mask: 0.1206124871969223 ===================
epoch no : 1, batch no : 319, total loss : 0.4769873321056366,  classifier :0.06017905846238136, mask: 0.21285897493362427 ===================
epoch no : 1, batch no : 320, total loss : 0.4151158332824707,  classifier :0.05713970214128494, mask: 0.15640254318714142 ===================
epoch no : 1, batch no : 321, total loss : 0.48432615399360657,  classifier :0.054700784385204315, mask: 0.14545387029647827 ===================
epoch no : 1, batch no : 322, total loss : 0.4325033724308014,  classifier :0.07191839814186096, mask: 0.15143714845180511 ===================
epoch no : 1, batch no : 323, total loss : 0.4473007917404175,  classifier :0.07254397124052048, mask: 0.14802147448062897 ===================
epoch no : 1, batch no : 324, total loss : 0.5933389067649841,  classifier :0.07409738004207611, mask: 0.2297256588935852 ===================
epoch no : 1, batch no : 325, total loss : 0.6998711228370667,  classifier :0.06843198090791702, mask: 0.35252827405929565 ===================
epoch no : 1, batch no : 326, total loss : 0.6276826858520508,  classifier :0.06611508131027222, mask: 0.3175802230834961 ===================
epoch no : 1, batch no : 327, total loss : 0.4593569338321686,  classifier :0.07278021425008774, mask: 0.1509837657213211 ===================
epoch no : 1, batch no : 328, total loss : 0.4606375992298126,  classifier :0.06681762635707855, mask: 0.14636632800102234 ===================
epoch no : 1, batch no : 329, total loss : 0.49930500984191895,  classifier :0.07328018546104431, mask: 0.13879291713237762 ===================
epoch no : 1, batch no : 330, total loss : 0.4512535631656647,  classifier :0.0809379518032074, mask: 0.158566415309906 ===================
epoch no : 1, batch no : 331, total loss : 0.44795703887939453,  classifier :0.08443772792816162, mask: 0.14789116382598877 ===================
epoch no : 1, batch no : 332, total loss : 0.45743513107299805,  classifier :0.06891099363565445, mask: 0.13751447200775146 ===================
epoch no : 1, batch no : 333, total loss : 0.5310318470001221,  classifier :0.0760226622223854, mask: 0.18833132088184357 ===================
epoch no : 1, batch no : 334, total loss : 0.5189644694328308,  classifier :0.09080638736486435, mask: 0.17687638103961945 ===================
epoch no : 1, batch no : 335, total loss : 0.49470701813697815,  classifier :0.0777461901307106, mask: 0.18306758999824524 ===================
epoch no : 1, batch no : 336, total loss : 0.47011062502861023,  classifier :0.0735723227262497, mask: 0.1888686567544937 ===================
epoch no : 1, batch no : 337, total loss : 0.4698696732521057,  classifier :0.07737952470779419, mask: 0.15016157925128937 ===================
epoch no : 1, batch no : 338, total loss : 0.4164789915084839,  classifier :0.06363678723573685, mask: 0.1531301587820053 ===================
epoch no : 1, batch no : 339, total loss : 0.3840745687484741,  classifier :0.05235420539975166, mask: 0.1395086944103241 ===================
epoch no : 1, batch no : 340, total loss : 0.3502790033817291,  classifier :0.07007458060979843, mask: 0.11649658530950546 ===================
epoch no : 1, batch no : 341, total loss : 0.4608508348464966,  classifier :0.07774604111909866, mask: 0.12944206595420837 ===================
epoch no : 1, batch no : 342, total loss : 0.4816325008869171,  classifier :0.06367457658052444, mask: 0.15076248347759247 ===================
epoch no : 1, batch no : 343, total loss : 0.6082900166511536,  classifier :0.05873963609337807, mask: 0.251891165971756 ===================
epoch no : 1, batch no : 344, total loss : 0.5715166926383972,  classifier :0.07650744169950485, mask: 0.18749001622200012 ===================
epoch no : 1, batch no : 345, total loss : 0.4111330807209015,  classifier :0.06237797811627388, mask: 0.1411529779434204 ===================
epoch no : 1, batch no : 346, total loss : 0.4403949975967407,  classifier :0.059349022805690765, mask: 0.13362948596477509 ===================
epoch no : 1, batch no : 347, total loss : 0.45139825344085693,  classifier :0.0675528272986412, mask: 0.171695277094841 ===================
epoch no : 1, batch no : 348, total loss : 0.4431021511554718,  classifier :0.06359167397022247, mask: 0.18129460513591766 ===================
epoch no : 1, batch no : 349, total loss : 0.5018236041069031,  classifier :0.07260715216398239, mask: 0.19320233166217804 ===================
epoch no : 1, batch no : 350, total loss : 0.5196631550788879,  classifier :0.09159767627716064, mask: 0.14833296835422516 ===================
epoch no : 1, batch no : 351, total loss : 0.4502633213996887,  classifier :0.06053328514099121, mask: 0.17581363022327423 ===================
epoch no : 1, batch no : 352, total loss : 0.3913279175758362,  classifier :0.054160624742507935, mask: 0.13507431745529175 ===================
epoch no : 1, batch no : 353, total loss : 0.45903968811035156,  classifier :0.06922347843647003, mask: 0.16912047564983368 ===================
epoch no : 1, batch no : 354, total loss : 0.49990665912628174,  classifier :0.0631134882569313, mask: 0.18651214241981506 ===================
epoch no : 1, batch no : 355, total loss : 0.5332871675491333,  classifier :0.06543495506048203, mask: 0.19585317373275757 ===================
epoch no : 1, batch no : 356, total loss : 0.3938548266887665,  classifier :0.0644422322511673, mask: 0.13879024982452393 ===================
epoch no : 1, batch no : 357, total loss : 0.4108123183250427,  classifier :0.05525590479373932, mask: 0.1561153531074524 ===================
epoch no : 1, batch no : 358, total loss : 0.43908339738845825,  classifier :0.05871126800775528, mask: 0.12982577085494995 ===================
epoch no : 1, batch no : 359, total loss : 0.3294106721878052,  classifier :0.057544924318790436, mask: 0.10752837359905243 ===================
epoch no : 1, batch no : 360, total loss : 0.41203880310058594,  classifier :0.06781680136919022, mask: 0.11703865975141525 ===================
epoch no : 1, batch no : 361, total loss : 0.4672163426876068,  classifier :0.07540146261453629, mask: 0.18227440118789673 ===================
epoch no : 1, batch no : 362, total loss : 0.5226379632949829,  classifier :0.076245978474617, mask: 0.209978848695755 ===================
epoch no : 1, batch no : 363, total loss : 0.5041387677192688,  classifier :0.07198353856801987, mask: 0.18906879425048828 ===================
epoch no : 1, batch no : 364, total loss : 0.3864956498146057,  classifier :0.06634950637817383, mask: 0.1538417786359787 ===================
epoch no : 1, batch no : 365, total loss : 0.5031840205192566,  classifier :0.05647488310933113, mask: 0.20120812952518463 ===================
epoch no : 1, batch no : 366, total loss : 0.5492282509803772,  classifier :0.06890132278203964, mask: 0.19516651332378387 ===================
epoch no : 1, batch no : 367, total loss : 0.3976074755191803,  classifier :0.06568042933940887, mask: 0.12716500461101532 ===================
epoch no : 1, batch no : 368, total loss : 0.3815310299396515,  classifier :0.06417173892259598, mask: 0.1432497203350067 ===================
epoch no : 1, batch no : 369, total loss : 0.39652952551841736,  classifier :0.0802721232175827, mask: 0.14334014058113098 ===================
epoch no : 1, batch no : 370, total loss : 0.4283778667449951,  classifier :0.06310119479894638, mask: 0.1765970140695572 ===================
epoch no : 1, batch no : 371, total loss : 0.4211810827255249,  classifier :0.051362719386816025, mask: 0.1618884801864624 ===================
epoch no : 1, batch no : 372, total loss : 0.5114637613296509,  classifier :0.07228390872478485, mask: 0.18996119499206543 ===================
epoch no : 1, batch no : 373, total loss : 0.5168845057487488,  classifier :0.06284290552139282, mask: 0.21001668274402618 ===================
epoch no : 1, batch no : 374, total loss : 0.4664817750453949,  classifier :0.05884627625346184, mask: 0.1918027102947235 ===================
epoch no : 1, batch no : 375, total loss : 0.4593788683414459,  classifier :0.06723113358020782, mask: 0.18429800868034363 ===================
epoch no : 1, batch no : 376, total loss : 0.4966824948787689,  classifier :0.07066767662763596, mask: 0.194878950715065 ===================
epoch no : 1, batch no : 377, total loss : 0.4633990228176117,  classifier :0.06502379477024078, mask: 0.1645815372467041 ===================
epoch no : 1, batch no : 378, total loss : 0.47290298342704773,  classifier :0.07472006976604462, mask: 0.16705697774887085 ===================
epoch no : 1, batch no : 379, total loss : 0.46143224835395813,  classifier :0.06771914660930634, mask: 0.16911587119102478 ===================
epoch no : 1, batch no : 380, total loss : 0.42633694410324097,  classifier :0.068295419216156, mask: 0.1555858999490738 ===================
epoch no : 1, batch no : 381, total loss : 0.4678809344768524,  classifier :0.05575663968920708, mask: 0.18128614127635956 ===================
epoch no : 1, batch no : 382, total loss : 0.5661077499389648,  classifier :0.09878794848918915, mask: 0.17740611732006073 ===================
epoch no : 1, batch no : 383, total loss : 0.3933352828025818,  classifier :0.04767521098256111, mask: 0.17590580880641937 ===================
epoch no : 1, batch no : 384, total loss : 0.5351117849349976,  classifier :0.08186427503824234, mask: 0.16539892554283142 ===================
epoch no : 1, batch no : 385, total loss : 0.582791268825531,  classifier :0.08593729138374329, mask: 0.20599371194839478 ===================
epoch no : 1, batch no : 386, total loss : 0.4792926609516144,  classifier :0.06127922236919403, mask: 0.2371475249528885 ===================
epoch no : 1, batch no : 387, total loss : 0.34080830216407776,  classifier :0.05262792482972145, mask: 0.1265794038772583 ===================
epoch no : 1, batch no : 388, total loss : 0.4526379704475403,  classifier :0.058241188526153564, mask: 0.1815134882926941 ===================
epoch no : 1, batch no : 389, total loss : 0.38218954205513,  classifier :0.05933002009987831, mask: 0.15025170147418976 ===================
epoch no : 1, batch no : 390, total loss : 0.49020373821258545,  classifier :0.051677726209163666, mask: 0.18477852642536163 ===================
epoch no : 1, batch no : 391, total loss : 0.3708641529083252,  classifier :0.06514321267604828, mask: 0.11988658457994461 ===================
epoch no : 1, batch no : 392, total loss : 0.41027674078941345,  classifier :0.07373031973838806, mask: 0.1413075029850006 ===================
epoch no : 1, batch no : 393, total loss : 0.5519251227378845,  classifier :0.07015547901391983, mask: 0.19179069995880127 ===================
epoch no : 1, batch no : 394, total loss : 0.3933011293411255,  classifier :0.06368300318717957, mask: 0.1331973671913147 ===================
epoch no : 1, batch no : 395, total loss : 0.35056424140930176,  classifier :0.0659475326538086, mask: 0.14552247524261475 ===================
epoch no : 1, batch no : 396, total loss : 0.37037381529808044,  classifier :0.05790415778756142, mask: 0.1371544897556305 ===================
epoch no : 1, batch no : 397, total loss : 0.3501606583595276,  classifier :0.047092005610466, mask: 0.14181910455226898 ===================
epoch no : 1, batch no : 398, total loss : 0.4831705689430237,  classifier :0.060798030346632004, mask: 0.197874516248703 ===================
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch no : 2, batch no : 0, total loss : 0.5125123858451843,  classifier :0.07939401268959045, mask: 0.14678889513015747 ===================
epoch no : 2, batch no : 1, total loss : 0.45542529225349426,  classifier :0.05650576576590538, mask: 0.16585132479667664 ===================
epoch no : 2, batch no : 2, total loss : 0.3815111815929413,  classifier :0.06390399485826492, mask: 0.14910940825939178 ===================
epoch no : 2, batch no : 3, total loss : 0.4219333529472351,  classifier :0.06736543774604797, mask: 0.16160164773464203 ===================
epoch no : 2, batch no : 4, total loss : 0.48698005080223083,  classifier :0.07426117360591888, mask: 0.19057004153728485 ===================
epoch no : 2, batch no : 5, total loss : 0.4803098440170288,  classifier :0.0693553015589714, mask: 0.17214332520961761 ===================
epoch no : 2, batch no : 6, total loss : 0.46902287006378174,  classifier :0.07878302782773972, mask: 0.15870685875415802 ===================
epoch no : 2, batch no : 7, total loss : 0.5305805802345276,  classifier :0.07625006884336472, mask: 0.17259104549884796 ===================
epoch no : 2, batch no : 8, total loss : 0.44234031438827515,  classifier :0.0806703269481659, mask: 0.14145712554454803 ===================
epoch no : 2, batch no : 9, total loss : 0.456630140542984,  classifier :0.062255118042230606, mask: 0.15367186069488525 ===================
epoch no : 2, batch no : 10, total loss : 0.4238041043281555,  classifier :0.0534052737057209, mask: 0.1466131955385208 ===================
epoch no : 2, batch no : 11, total loss : 0.4669852554798126,  classifier :0.06474687904119492, mask: 0.17096076905727386 ===================
epoch no : 2, batch no : 12, total loss : 0.5058791041374207,  classifier :0.06248876079916954, mask: 0.18762116134166718 ===================
epoch no : 2, batch no : 13, total loss : 0.4069594144821167,  classifier :0.06575515866279602, mask: 0.1453791707754135 ===================
epoch no : 2, batch no : 14, total loss : 0.3770293593406677,  classifier :0.05636775493621826, mask: 0.1253655105829239 ===================
epoch no : 2, batch no : 15, total loss : 0.35700860619544983,  classifier :0.058483000844717026, mask: 0.12968195974826813 ===================
epoch no : 2, batch no : 16, total loss : 0.427752822637558,  classifier :0.06957566738128662, mask: 0.15336363017559052 ===================
epoch no : 2, batch no : 17, total loss : 0.6289628744125366,  classifier :0.09151285886764526, mask: 0.24264831840991974 ===================
epoch no : 2, batch no : 18, total loss : 0.4957115352153778,  classifier :0.07969460636377335, mask: 0.1629570722579956 ===================
epoch no : 2, batch no : 19, total loss : 0.43836092948913574,  classifier :0.05046951770782471, mask: 0.17423050105571747 ===================
epoch no : 2, batch no : 20, total loss : 0.3912905156612396,  classifier :0.0608886256814003, mask: 0.12957699596881866 ===================
epoch no : 2, batch no : 21, total loss : 0.3778875470161438,  classifier :0.058916717767715454, mask: 0.10893601924180984 ===================
epoch no : 2, batch no : 22, total loss : 0.40665972232818604,  classifier :0.0680689811706543, mask: 0.12515076994895935 ===================
epoch no : 2, batch no : 23, total loss : 0.4583546221256256,  classifier :0.05942347273230553, mask: 0.1525215357542038 ===================
epoch no : 2, batch no : 24, total loss : 0.442977637052536,  classifier :0.05306678265333176, mask: 0.14428170025348663 ===================
epoch no : 2, batch no : 25, total loss : 0.34173405170440674,  classifier :0.06277652084827423, mask: 0.12179042398929596 ===================
epoch no : 2, batch no : 26, total loss : 0.46175092458724976,  classifier :0.0508221872150898, mask: 0.16056998074054718 ===================
epoch no : 2, batch no : 27, total loss : 0.41677969694137573,  classifier :0.061900585889816284, mask: 0.1483292579650879 ===================
epoch no : 2, batch no : 28, total loss : 0.46481576561927795,  classifier :0.0687042772769928, mask: 0.19965019822120667 ===================
epoch no : 2, batch no : 29, total loss : 0.39614126086235046,  classifier :0.054996058344841, mask: 0.15703395009040833 ===================
epoch no : 2, batch no : 30, total loss : 0.4109717011451721,  classifier :0.05897220969200134, mask: 0.14802004396915436 ===================
epoch no : 2, batch no : 31, total loss : 0.49117618799209595,  classifier :0.04941997677087784, mask: 0.21576924622058868 ===================
epoch no : 2, batch no : 32, total loss : 0.38273781538009644,  classifier :0.05697861686348915, mask: 0.163732647895813 ===================
epoch no : 2, batch no : 33, total loss : 0.5397493243217468,  classifier :0.08285626769065857, mask: 0.17796508967876434 ===================
epoch no : 2, batch no : 34, total loss : 0.4592534899711609,  classifier :0.058543235063552856, mask: 0.21527895331382751 ===================
epoch no : 2, batch no : 35, total loss : 0.3674897849559784,  classifier :0.055187471210956573, mask: 0.12919603288173676 ===================
epoch no : 2, batch no : 36, total loss : 0.517888069152832,  classifier :0.08389369398355484, mask: 0.1582537740468979 ===================
epoch no : 2, batch no : 37, total loss : 0.4816182255744934,  classifier :0.06475590169429779, mask: 0.17299994826316833 ===================
epoch no : 2, batch no : 38, total loss : 0.5002874732017517,  classifier :0.05989489704370499, mask: 0.18872831761837006 ===================
epoch no : 2, batch no : 39, total loss : 0.3994660973548889,  classifier :0.044641539454460144, mask: 0.15471896529197693 ===================
epoch no : 2, batch no : 40, total loss : 0.44358721375465393,  classifier :0.08297968655824661, mask: 0.1566302329301834 ===================
epoch no : 2, batch no : 41, total loss : 0.41763174533843994,  classifier :0.062452320009469986, mask: 0.1462261825799942 ===================
epoch no : 2, batch no : 42, total loss : 0.4423873722553253,  classifier :0.068688303232193, mask: 0.13352057337760925 ===================
epoch no : 2, batch no : 43, total loss : 0.41662201285362244,  classifier :0.06014480069279671, mask: 0.1203351840376854 ===================
epoch no : 2, batch no : 44, total loss : 0.4580087959766388,  classifier :0.06220244616270065, mask: 0.14408645033836365 ===================
epoch no : 2, batch no : 45, total loss : 0.4271734952926636,  classifier :0.05787795037031174, mask: 0.15105733275413513 ===================
epoch no : 2, batch no : 46, total loss : 0.4343288540840149,  classifier :0.06256622076034546, mask: 0.1237921416759491 ===================
epoch no : 2, batch no : 47, total loss : 0.46946030855178833,  classifier :0.06793465465307236, mask: 0.1763053834438324 ===================
epoch no : 2, batch no : 48, total loss : 0.3687485456466675,  classifier :0.0672430470585823, mask: 0.10450365394353867 ===================
epoch no : 2, batch no : 49, total loss : 0.42324039340019226,  classifier :0.0616360604763031, mask: 0.1582164466381073 ===================
epoch no : 2, batch no : 50, total loss : 0.49959248304367065,  classifier :0.05662529915571213, mask: 0.1940585821866989 ===================
epoch no : 2, batch no : 51, total loss : 0.38403066992759705,  classifier :0.06699983030557632, mask: 0.13699126243591309 ===================
epoch no : 2, batch no : 52, total loss : 0.4129714369773865,  classifier :0.0656425952911377, mask: 0.12957613170146942 ===================
epoch no : 2, batch no : 53, total loss : 0.36720964312553406,  classifier :0.05559956282377243, mask: 0.10769017785787582 ===================
epoch no : 2, batch no : 54, total loss : 0.3733527660369873,  classifier :0.05117591470479965, mask: 0.11180422455072403 ===================
epoch no : 2, batch no : 55, total loss : 0.35087522864341736,  classifier :0.06677413731813431, mask: 0.12362097948789597 ===================
epoch no : 2, batch no : 56, total loss : 0.43489858508110046,  classifier :0.04913916066288948, mask: 0.1599987894296646 ===================
epoch no : 2, batch no : 57, total loss : 0.3900620937347412,  classifier :0.06060481444001198, mask: 0.1332656294107437 ===================
epoch no : 2, batch no : 58, total loss : 0.44534510374069214,  classifier :0.06385268270969391, mask: 0.13621455430984497 ===================
epoch no : 2, batch no : 59, total loss : 0.43951869010925293,  classifier :0.07549308240413666, mask: 0.16029350459575653 ===================
epoch no : 2, batch no : 60, total loss : 0.5929713845252991,  classifier :0.07045159488916397, mask: 0.22747105360031128 ===================
epoch no : 2, batch no : 61, total loss : 0.4515755772590637,  classifier :0.06658703833818436, mask: 0.14782018959522247 ===================
epoch no : 2, batch no : 62, total loss : 0.39161381125450134,  classifier :0.06873080134391785, mask: 0.150241881608963 ===================
epoch no : 2, batch no : 63, total loss : 0.4964567720890045,  classifier :0.06502246856689453, mask: 0.17053265869617462 ===================
epoch no : 2, batch no : 64, total loss : 0.3606342673301697,  classifier :0.05204550549387932, mask: 0.13548246026039124 ===================
epoch no : 2, batch no : 65, total loss : 0.3585362136363983,  classifier :0.04384351149201393, mask: 0.127624049782753 ===================
epoch no : 2, batch no : 66, total loss : 0.4511507451534271,  classifier :0.04561302438378334, mask: 0.1707008332014084 ===================
epoch no : 2, batch no : 67, total loss : 0.3958897888660431,  classifier :0.06245967373251915, mask: 0.14436404407024384 ===================
epoch no : 2, batch no : 68, total loss : 0.37525251507759094,  classifier :0.0583154559135437, mask: 0.1316530555486679 ===================
epoch no : 2, batch no : 69, total loss : 0.4270554184913635,  classifier :0.05780389904975891, mask: 0.1663694828748703 ===================
epoch no : 2, batch no : 70, total loss : 0.44903072714805603,  classifier :0.07869387418031693, mask: 0.17987984418869019 ===================
epoch no : 2, batch no : 71, total loss : 0.4026448130607605,  classifier :0.05470103770494461, mask: 0.15225844085216522 ===================
epoch no : 2, batch no : 72, total loss : 0.36257535219192505,  classifier :0.06103365868330002, mask: 0.15180233120918274 ===================
epoch no : 2, batch no : 73, total loss : 0.48048827052116394,  classifier :0.06570915132761002, mask: 0.1707073152065277 ===================
epoch no : 2, batch no : 74, total loss : 0.35401925444602966,  classifier :0.05825437977910042, mask: 0.12030765414237976 ===================
epoch no : 2, batch no : 75, total loss : 0.4341399073600769,  classifier :0.05906194821000099, mask: 0.15866784751415253 ===================
epoch no : 2, batch no : 76, total loss : 0.4366506040096283,  classifier :0.05950076878070831, mask: 0.14030446112155914 ===================
epoch no : 2, batch no : 77, total loss : 0.3836165964603424,  classifier :0.06207135319709778, mask: 0.1152765229344368 ===================
epoch no : 2, batch no : 78, total loss : 0.4597826600074768,  classifier :0.06004120409488678, mask: 0.1491745114326477 ===================
epoch no : 2, batch no : 79, total loss : 0.38552841544151306,  classifier :0.06486375629901886, mask: 0.1426319032907486 ===================
epoch no : 2, batch no : 80, total loss : 0.34357118606567383,  classifier :0.05627571418881416, mask: 0.1321037858724594 ===================
epoch no : 2, batch no : 81, total loss : 0.4004894495010376,  classifier :0.05378873646259308, mask: 0.14632770419120789 ===================
epoch no : 2, batch no : 82, total loss : 0.38276466727256775,  classifier :0.05621633306145668, mask: 0.13730739057064056 ===================
epoch no : 2, batch no : 83, total loss : 0.4148004353046417,  classifier :0.06935422867536545, mask: 0.16578449308872223 ===================
epoch no : 2, batch no : 84, total loss : 0.36026981472969055,  classifier :0.05510038509964943, mask: 0.14583618938922882 ===================
epoch no : 2, batch no : 85, total loss : 0.3029824197292328,  classifier :0.06303853541612625, mask: 0.1045437678694725 ===================
epoch no : 2, batch no : 86, total loss : 0.38291388750076294,  classifier :0.05383990705013275, mask: 0.14341817796230316 ===================
epoch no : 2, batch no : 87, total loss : 0.3702419698238373,  classifier :0.06222950294613838, mask: 0.13610032200813293 ===================
epoch no : 2, batch no : 88, total loss : 0.41461512446403503,  classifier :0.0577889084815979, mask: 0.17384850978851318 ===================
epoch no : 2, batch no : 89, total loss : 0.417844295501709,  classifier :0.0600062757730484, mask: 0.14817194640636444 ===================
epoch no : 2, batch no : 90, total loss : 0.4405081868171692,  classifier :0.058359090238809586, mask: 0.1502033919095993 ===================
epoch no : 2, batch no : 91, total loss : 0.3844135105609894,  classifier :0.05662040412425995, mask: 0.11598791182041168 ===================
epoch no : 2, batch no : 92, total loss : 0.37329497933387756,  classifier :0.04820696637034416, mask: 0.1529700756072998 ===================
epoch no : 2, batch no : 93, total loss : 0.3205532133579254,  classifier :0.04725028574466705, mask: 0.11457382887601852 ===================
epoch no : 2, batch no : 94, total loss : 0.34396424889564514,  classifier :0.05301918089389801, mask: 0.1427956372499466 ===================
epoch no : 2, batch no : 95, total loss : 0.36342453956604004,  classifier :0.050237737596035004, mask: 0.11949063092470169 ===================
epoch no : 2, batch no : 96, total loss : 0.38535672426223755,  classifier :0.055657509714365005, mask: 0.1434508115053177 ===================
epoch no : 2, batch no : 97, total loss : 0.4280426800251007,  classifier :0.04943670332431793, mask: 0.19819533824920654 ===================
epoch no : 2, batch no : 98, total loss : 0.43495914340019226,  classifier :0.06172461435198784, mask: 0.1411779373884201 ===================
epoch no : 2, batch no : 99, total loss : 0.38540875911712646,  classifier :0.04981469735503197, mask: 0.13879850506782532 ===================
epoch no : 2, batch no : 100, total loss : 0.44693121314048767,  classifier :0.07619719207286835, mask: 0.15379749238491058 ===================
epoch no : 2, batch no : 101, total loss : 0.3842703104019165,  classifier :0.05615723878145218, mask: 0.14162321388721466 ===================
epoch no : 2, batch no : 102, total loss : 0.4363521337509155,  classifier :0.0503840409219265, mask: 0.1960081309080124 ===================
epoch no : 2, batch no : 103, total loss : 0.4136810600757599,  classifier :0.07495663315057755, mask: 0.13793061673641205 ===================
epoch no : 2, batch no : 104, total loss : 0.3442859351634979,  classifier :0.07134369015693665, mask: 0.13350634276866913 ===================
epoch no : 2, batch no : 105, total loss : 0.39952823519706726,  classifier :0.05572861060500145, mask: 0.10790510475635529 ===================
epoch no : 2, batch no : 106, total loss : 0.5115768313407898,  classifier :0.08353421837091446, mask: 0.1765623539686203 ===================
epoch no : 2, batch no : 107, total loss : 0.42559051513671875,  classifier :0.06850123405456543, mask: 0.15655921399593353 ===================
epoch no : 2, batch no : 108, total loss : 0.37396320700645447,  classifier :0.055910687893629074, mask: 0.12703032791614532 ===================
epoch no : 2, batch no : 109, total loss : 0.4496126174926758,  classifier :0.05976857617497444, mask: 0.14724963903427124 ===================
epoch no : 2, batch no : 110, total loss : 0.5345155000686646,  classifier :0.08931359648704529, mask: 0.17043091356754303 ===================
epoch no : 2, batch no : 111, total loss : 0.4099852442741394,  classifier :0.06426048278808594, mask: 0.14746540784835815 ===================
epoch no : 2, batch no : 112, total loss : 0.4623739421367645,  classifier :0.06166916340589523, mask: 0.1825607866048813 ===================
epoch no : 2, batch no : 113, total loss : 0.36757993698120117,  classifier :0.04374249279499054, mask: 0.13151489198207855 ===================
epoch no : 2, batch no : 114, total loss : 0.3378058671951294,  classifier :0.05596143379807472, mask: 0.13770358264446259 ===================
epoch no : 2, batch no : 115, total loss : 0.5191640853881836,  classifier :0.07309749722480774, mask: 0.18998627364635468 ===================
epoch no : 2, batch no : 116, total loss : 0.4895487129688263,  classifier :0.06857044994831085, mask: 0.22415626049041748 ===================
epoch no : 2, batch no : 117, total loss : 0.3309061825275421,  classifier :0.051394980400800705, mask: 0.13800901174545288 ===================
epoch no : 2, batch no : 118, total loss : 0.34933504462242126,  classifier :0.054538924247026443, mask: 0.1349121332168579 ===================
epoch no : 2, batch no : 119, total loss : 0.37098193168640137,  classifier :0.059593554586172104, mask: 0.13199663162231445 ===================
epoch no : 2, batch no : 120, total loss : 0.505431592464447,  classifier :0.07949728518724442, mask: 0.1838287115097046 ===================
epoch no : 2, batch no : 121, total loss : 0.40085121989250183,  classifier :0.07330180704593658, mask: 0.13983368873596191 ===================
epoch no : 2, batch no : 122, total loss : 0.49024757742881775,  classifier :0.06194679066538811, mask: 0.1677980124950409 ===================
epoch no : 2, batch no : 123, total loss : 0.4069029986858368,  classifier :0.048644550144672394, mask: 0.1709291934967041 ===================
epoch no : 2, batch no : 124, total loss : 0.4753607213497162,  classifier :0.07877054810523987, mask: 0.15675276517868042 ===================
epoch no : 2, batch no : 125, total loss : 0.40824759006500244,  classifier :0.054181940853595734, mask: 0.15259817242622375 ===================
epoch no : 2, batch no : 126, total loss : 0.4393988847732544,  classifier :0.05715712159872055, mask: 0.15795955061912537 ===================
epoch no : 2, batch no : 127, total loss : 0.38884904980659485,  classifier :0.051978450268507004, mask: 0.14937539398670197 ===================
epoch no : 2, batch no : 128, total loss : 0.4092373251914978,  classifier :0.06533117592334747, mask: 0.14541155099868774 ===================
epoch no : 2, batch no : 129, total loss : 0.3809460997581482,  classifier :0.053479697555303574, mask: 0.1406911015510559 ===================
epoch no : 2, batch no : 130, total loss : 0.3970576226711273,  classifier :0.05873465910553932, mask: 0.14036570489406586 ===================
epoch no : 2, batch no : 131, total loss : 0.36161503195762634,  classifier :0.04933035746216774, mask: 0.13971924781799316 ===================
epoch no : 2, batch no : 132, total loss : 0.427982896566391,  classifier :0.05531809478998184, mask: 0.15272516012191772 ===================
epoch no : 2, batch no : 133, total loss : 0.43247219920158386,  classifier :0.05326949432492256, mask: 0.17451885342597961 ===================
epoch no : 2, batch no : 134, total loss : 0.3941889703273773,  classifier :0.048504579812288284, mask: 0.14687961339950562 ===================
epoch no : 2, batch no : 135, total loss : 0.3145630657672882,  classifier :0.04792691767215729, mask: 0.1159219816327095 ===================
epoch no : 2, batch no : 136, total loss : 0.35927391052246094,  classifier :0.047211531549692154, mask: 0.1311953365802765 ===================
epoch no : 2, batch no : 137, total loss : 0.43952056765556335,  classifier :0.05102545768022537, mask: 0.17057032883167267 ===================
epoch no : 2, batch no : 138, total loss : 0.38748592138290405,  classifier :0.044632893055677414, mask: 0.14005319774150848 ===================
epoch no : 2, batch no : 139, total loss : 0.40048325061798096,  classifier :0.049543384462594986, mask: 0.14124621450901031 ===================
epoch no : 2, batch no : 140, total loss : 0.3837434947490692,  classifier :0.05420791730284691, mask: 0.1481388956308365 ===================
epoch no : 2, batch no : 141, total loss : 0.3611017167568207,  classifier :0.0521734245121479, mask: 0.1430823802947998 ===================
epoch no : 2, batch no : 142, total loss : 0.4052450656890869,  classifier :0.05541534349322319, mask: 0.14048802852630615 ===================
epoch no : 2, batch no : 143, total loss : 0.4423717260360718,  classifier :0.04874119162559509, mask: 0.17201478779315948 ===================
epoch no : 2, batch no : 144, total loss : 0.3812108337879181,  classifier :0.05224129930138588, mask: 0.13997559249401093 ===================
epoch no : 2, batch no : 145, total loss : 0.4139411151409149,  classifier :0.06807761639356613, mask: 0.13795635104179382 ===================
epoch no : 2, batch no : 146, total loss : 0.46715909242630005,  classifier :0.06349343806505203, mask: 0.1786203682422638 ===================
epoch no : 2, batch no : 147, total loss : 0.37807703018188477,  classifier :0.04919726401567459, mask: 0.13831588625907898 ===================
epoch no : 2, batch no : 148, total loss : 0.4116758108139038,  classifier :0.062180500477552414, mask: 0.13330328464508057 ===================
epoch no : 2, batch no : 149, total loss : 0.5008422136306763,  classifier :0.04977875575423241, mask: 0.1473010629415512 ===================
epoch no : 2, batch no : 150, total loss : 0.43212565779685974,  classifier :0.05387236177921295, mask: 0.15649797022342682 ===================
epoch no : 2, batch no : 151, total loss : 0.43704915046691895,  classifier :0.07521536946296692, mask: 0.17125998437404633 ===================
epoch no : 2, batch no : 152, total loss : 0.4151487648487091,  classifier :0.046769581735134125, mask: 0.17105884850025177 ===================
epoch no : 2, batch no : 153, total loss : 0.40412694215774536,  classifier :0.05424831807613373, mask: 0.14022529125213623 ===================
epoch no : 2, batch no : 154, total loss : 0.5662059187889099,  classifier :0.06433623284101486, mask: 0.2160889357328415 ===================
epoch no : 2, batch no : 155, total loss : 0.6256449818611145,  classifier :0.07332593202590942, mask: 0.2392241507768631 ===================
epoch no : 2, batch no : 156, total loss : 0.41165852546691895,  classifier :0.05913880839943886, mask: 0.13470089435577393 ===================
epoch no : 2, batch no : 157, total loss : 0.46518927812576294,  classifier :0.07619736343622208, mask: 0.15212328732013702 ===================
epoch no : 2, batch no : 158, total loss : 0.4438486099243164,  classifier :0.06297744065523148, mask: 0.16376493871212006 ===================
epoch no : 2, batch no : 159, total loss : 0.4065328538417816,  classifier :0.053387828171253204, mask: 0.13437755405902863 ===================
epoch no : 2, batch no : 160, total loss : 0.5098651647567749,  classifier :0.09058617800474167, mask: 0.1675988733768463 ===================
epoch no : 2, batch no : 161, total loss : 0.5288073420524597,  classifier :0.07190225273370743, mask: 0.2033766210079193 ===================
epoch no : 2, batch no : 162, total loss : 0.34217333793640137,  classifier :0.048439402133226395, mask: 0.15138712525367737 ===================
epoch no : 2, batch no : 163, total loss : 0.408176988363266,  classifier :0.05432406812906265, mask: 0.13918396830558777 ===================
epoch no : 2, batch no : 164, total loss : 0.34642118215560913,  classifier :0.046971291303634644, mask: 0.11698869615793228 ===================
epoch no : 2, batch no : 165, total loss : 0.39535751938819885,  classifier :0.056072335690259933, mask: 0.1389789879322052 ===================
epoch no : 2, batch no : 166, total loss : 0.42035409808158875,  classifier :0.06679646670818329, mask: 0.1537093073129654 ===================
epoch no : 2, batch no : 167, total loss : 0.39985305070877075,  classifier :0.05270539969205856, mask: 0.14314325153827667 ===================
epoch no : 2, batch no : 168, total loss : 0.4785490036010742,  classifier :0.06518156081438065, mask: 0.17627054452896118 ===================
epoch no : 2, batch no : 169, total loss : 0.3506848216056824,  classifier :0.060313016176223755, mask: 0.11827892065048218 ===================
epoch no : 2, batch no : 170, total loss : 0.4714992940425873,  classifier :0.08275718241930008, mask: 0.1476920247077942 ===================
epoch no : 2, batch no : 171, total loss : 0.37395375967025757,  classifier :0.05658108741044998, mask: 0.15028084814548492 ===================
epoch no : 2, batch no : 172, total loss : 0.32389622926712036,  classifier :0.04944561794400215, mask: 0.12309063971042633 ===================
epoch no : 2, batch no : 173, total loss : 0.49201709032058716,  classifier :0.07586058229207993, mask: 0.177564799785614 ===================
epoch no : 2, batch no : 174, total loss : 0.42249730229377747,  classifier :0.05962962284684181, mask: 0.15685340762138367 ===================
epoch no : 2, batch no : 175, total loss : 0.43393436074256897,  classifier :0.0539836660027504, mask: 0.1575748175382614 ===================
epoch no : 2, batch no : 176, total loss : 0.38086387515068054,  classifier :0.05432480573654175, mask: 0.14882655441761017 ===================
epoch no : 2, batch no : 177, total loss : 0.40195441246032715,  classifier :0.05285001918673515, mask: 0.14978744089603424 ===================
epoch no : 2, batch no : 178, total loss : 0.45383742451667786,  classifier :0.04644813388586044, mask: 0.18985290825366974 ===================
epoch no : 2, batch no : 179, total loss : 0.418125718832016,  classifier :0.05537593737244606, mask: 0.15735407173633575 ===================
epoch no : 2, batch no : 180, total loss : 0.5128380656242371,  classifier :0.048253290355205536, mask: 0.21157921850681305 ===================
epoch no : 2, batch no : 181, total loss : 0.4190507233142853,  classifier :0.04924215376377106, mask: 0.18055617809295654 ===================
epoch no : 2, batch no : 182, total loss : 0.3639466464519501,  classifier :0.06344027817249298, mask: 0.11818214505910873 ===================
epoch no : 2, batch no : 183, total loss : 0.38274022936820984,  classifier :0.06341765820980072, mask: 0.1254592388868332 ===================
epoch no : 2, batch no : 184, total loss : 0.391144335269928,  classifier :0.0453978031873703, mask: 0.15385012328624725 ===================
epoch no : 2, batch no : 185, total loss : 0.48880523443222046,  classifier :0.06263788044452667, mask: 0.15990537405014038 ===================
epoch no : 2, batch no : 186, total loss : 0.39181649684906006,  classifier :0.05547843873500824, mask: 0.14477844536304474 ===================
epoch no : 2, batch no : 187, total loss : 0.35661613941192627,  classifier :0.051657840609550476, mask: 0.1286536157131195 ===================
epoch no : 2, batch no : 188, total loss : 0.3853481113910675,  classifier :0.046935997903347015, mask: 0.1166725605726242 ===================
epoch no : 2, batch no : 189, total loss : 0.4529327154159546,  classifier :0.06016939878463745, mask: 0.1844848245382309 ===================
epoch no : 2, batch no : 190, total loss : 0.4373740553855896,  classifier :0.06576281040906906, mask: 0.17848484218120575 ===================
epoch no : 2, batch no : 191, total loss : 0.30151909589767456,  classifier :0.05531178414821625, mask: 0.10328599065542221 ===================
epoch no : 2, batch no : 192, total loss : 0.35556456446647644,  classifier :0.048938777297735214, mask: 0.1314280778169632 ===================
epoch no : 2, batch no : 193, total loss : 0.4280696213245392,  classifier :0.0555468313395977, mask: 0.14265915751457214 ===================
epoch no : 2, batch no : 194, total loss : 0.36980196833610535,  classifier :0.04776214808225632, mask: 0.13918082416057587 ===================
epoch no : 2, batch no : 195, total loss : 0.4372653663158417,  classifier :0.05921346694231033, mask: 0.1647748500108719 ===================
epoch no : 2, batch no : 196, total loss : 0.44202107191085815,  classifier :0.059506580233573914, mask: 0.1351614147424698 ===================
epoch no : 2, batch no : 197, total loss : 0.41867250204086304,  classifier :0.049488749355077744, mask: 0.17155104875564575 ===================
epoch no : 2, batch no : 198, total loss : 0.4156007766723633,  classifier :0.06113255023956299, mask: 0.1629757583141327 ===================
epoch no : 2, batch no : 199, total loss : 0.44879284501075745,  classifier :0.0589459165930748, mask: 0.1713506430387497 ===================
epoch no : 2, batch no : 200, total loss : 0.4814929664134979,  classifier :0.05052781477570534, mask: 0.17225471138954163 ===================
epoch no : 2, batch no : 201, total loss : 0.3915272057056427,  classifier :0.053320277482271194, mask: 0.14533257484436035 ===================
epoch no : 2, batch no : 202, total loss : 0.3661600649356842,  classifier :0.06334447115659714, mask: 0.14738018810749054 ===================
epoch no : 2, batch no : 203, total loss : 0.4698137044906616,  classifier :0.047924432903528214, mask: 0.20161545276641846 ===================
epoch no : 2, batch no : 204, total loss : 0.3262975215911865,  classifier :0.048223622143268585, mask: 0.11307784914970398 ===================
epoch no : 2, batch no : 205, total loss : 0.3704308867454529,  classifier :0.06011102348566055, mask: 0.10574956983327866 ===================
epoch no : 2, batch no : 206, total loss : 0.3311142027378082,  classifier :0.05542977154254913, mask: 0.11535897105932236 ===================
epoch no : 2, batch no : 207, total loss : 0.4856117367744446,  classifier :0.06296830624341965, mask: 0.22758018970489502 ===================
epoch no : 2, batch no : 208, total loss : 0.4175730049610138,  classifier :0.05963212251663208, mask: 0.15591217577457428 ===================
epoch no : 2, batch no : 209, total loss : 0.3481186628341675,  classifier :0.058695435523986816, mask: 0.11993148922920227 ===================
epoch no : 2, batch no : 210, total loss : 0.3606424629688263,  classifier :0.04717835783958435, mask: 0.11070240288972855 ===================
epoch no : 2, batch no : 211, total loss : 0.39175939559936523,  classifier :0.05083964392542839, mask: 0.1375395655632019 ===================
epoch no : 2, batch no : 212, total loss : 0.49713847041130066,  classifier :0.05847648158669472, mask: 0.17425155639648438 ===================
epoch no : 2, batch no : 213, total loss : 0.4302707314491272,  classifier :0.03998114541172981, mask: 0.1521010398864746 ===================
epoch no : 2, batch no : 214, total loss : 0.37866026163101196,  classifier :0.04643421992659569, mask: 0.142477884888649 ===================
epoch no : 2, batch no : 215, total loss : 0.36819466948509216,  classifier :0.058845411986112595, mask: 0.141520157456398 ===================
epoch no : 2, batch no : 216, total loss : 0.40436843037605286,  classifier :0.055971842259168625, mask: 0.1725306361913681 ===================
epoch no : 2, batch no : 217, total loss : 0.4086419343948364,  classifier :0.05675734207034111, mask: 0.15324553847312927 ===================
epoch no : 2, batch no : 218, total loss : 0.4214288592338562,  classifier :0.054949868470430374, mask: 0.14179876446723938 ===================
epoch no : 2, batch no : 219, total loss : 0.46070849895477295,  classifier :0.047743555158376694, mask: 0.18476325273513794 ===================
epoch no : 2, batch no : 220, total loss : 0.500056803226471,  classifier :0.060551535338163376, mask: 0.15060186386108398 ===================
epoch no : 2, batch no : 221, total loss : 0.3900618851184845,  classifier :0.05682451277971268, mask: 0.14102314412593842 ===================
epoch no : 2, batch no : 222, total loss : 0.4516250491142273,  classifier :0.05247975513339043, mask: 0.20677034556865692 ===================
epoch no : 2, batch no : 223, total loss : 0.44284456968307495,  classifier :0.047614097595214844, mask: 0.17019344866275787 ===================
epoch no : 2, batch no : 224, total loss : 0.420366495847702,  classifier :0.06753088533878326, mask: 0.1684100329875946 ===================
epoch no : 2, batch no : 225, total loss : 0.5923842191696167,  classifier :0.10556136816740036, mask: 0.21945269405841827 ===================
epoch no : 2, batch no : 226, total loss : 0.4233509600162506,  classifier :0.05944298952817917, mask: 0.16827289760112762 ===================
epoch no : 2, batch no : 227, total loss : 0.41212204098701477,  classifier :0.05864003673195839, mask: 0.190568745136261 ===================
epoch no : 2, batch no : 228, total loss : 0.4523146152496338,  classifier :0.05891040712594986, mask: 0.18903222680091858 ===================
epoch no : 2, batch no : 229, total loss : 0.4073485732078552,  classifier :0.05271773785352707, mask: 0.12684498727321625 ===================
epoch no : 2, batch no : 230, total loss : 0.462494820356369,  classifier :0.06557445973157883, mask: 0.1524287611246109 ===================
epoch no : 2, batch no : 231, total loss : 0.497936487197876,  classifier :0.07265737652778625, mask: 0.16352291405200958 ===================
epoch no : 2, batch no : 232, total loss : 0.41528865694999695,  classifier :0.056020062416791916, mask: 0.14911608397960663 ===================
epoch no : 2, batch no : 233, total loss : 0.4054180979728699,  classifier :0.052777595818042755, mask: 0.13538812100887299 ===================
epoch no : 2, batch no : 234, total loss : 0.38264068961143494,  classifier :0.05253611132502556, mask: 0.15490449965000153 ===================
epoch no : 2, batch no : 235, total loss : 0.3788866400718689,  classifier :0.04631452634930611, mask: 0.15989311039447784 ===================
epoch no : 2, batch no : 236, total loss : 0.3681139051914215,  classifier :0.06998411566019058, mask: 0.14481021463871002 ===================
epoch no : 2, batch no : 237, total loss : 0.3327016532421112,  classifier :0.04302266985177994, mask: 0.1261242777109146 ===================
epoch no : 2, batch no : 238, total loss : 0.4600822925567627,  classifier :0.07157079875469208, mask: 0.1644076555967331 ===================
epoch no : 2, batch no : 239, total loss : 0.434408575296402,  classifier :0.04752688109874725, mask: 0.18412111699581146 ===================
epoch no : 2, batch no : 240, total loss : 0.4226635992527008,  classifier :0.05243830010294914, mask: 0.17582431435585022 ===================
epoch no : 2, batch no : 241, total loss : 0.373035192489624,  classifier :0.041622094810009, mask: 0.14163421094417572 ===================
epoch no : 2, batch no : 242, total loss : 0.4190792441368103,  classifier :0.05829720199108124, mask: 0.1473044455051422 ===================
epoch no : 2, batch no : 243, total loss : 0.5420123338699341,  classifier :0.06694606691598892, mask: 0.2053202986717224 ===================
epoch no : 2, batch no : 244, total loss : 0.43334370851516724,  classifier :0.05603022500872612, mask: 0.1321658492088318 ===================
epoch no : 2, batch no : 245, total loss : 0.47041767835617065,  classifier :0.062248170375823975, mask: 0.19162581861019135 ===================
epoch no : 2, batch no : 246, total loss : 0.3753328025341034,  classifier :0.05856357887387276, mask: 0.13268668949604034 ===================
epoch no : 2, batch no : 247, total loss : 0.35474544763565063,  classifier :0.04844212532043457, mask: 0.1454821527004242 ===================
epoch no : 2, batch no : 248, total loss : 0.4134020507335663,  classifier :0.05066516622900963, mask: 0.16704347729682922 ===================
epoch no : 2, batch no : 249, total loss : 0.3859400153160095,  classifier :0.052320484071969986, mask: 0.1478729099035263 ===================
epoch no : 2, batch no : 250, total loss : 0.43970656394958496,  classifier :0.05387674272060394, mask: 0.16646528244018555 ===================
epoch no : 2, batch no : 251, total loss : 0.30941805243492126,  classifier :0.05436883494257927, mask: 0.11083146929740906 ===================
epoch no : 2, batch no : 252, total loss : 0.33079689741134644,  classifier :0.045692041516304016, mask: 0.12779158353805542 ===================
epoch no : 2, batch no : 253, total loss : 0.3872474431991577,  classifier :0.05874756723642349, mask: 0.15528208017349243 ===================
epoch no : 2, batch no : 254, total loss : 0.3907322883605957,  classifier :0.056923139840364456, mask: 0.16044855117797852 ===================
epoch no : 2, batch no : 255, total loss : 0.3916822075843811,  classifier :0.051759324967861176, mask: 0.18304352462291718 ===================
epoch no : 2, batch no : 256, total loss : 0.41509559750556946,  classifier :0.04952530562877655, mask: 0.16376693546772003 ===================
epoch no : 2, batch no : 257, total loss : 0.43653619289398193,  classifier :0.055576324462890625, mask: 0.14262434840202332 ===================
epoch no : 2, batch no : 258, total loss : 0.42914795875549316,  classifier :0.0431646890938282, mask: 0.14326582849025726 ===================
epoch no : 2, batch no : 259, total loss : 0.35875770449638367,  classifier :0.049251459538936615, mask: 0.1418655961751938 ===================
epoch no : 2, batch no : 260, total loss : 0.3689590096473694,  classifier :0.05115136504173279, mask: 0.14076469838619232 ===================
epoch no : 2, batch no : 261, total loss : 0.42322152853012085,  classifier :0.06444205343723297, mask: 0.14867255091667175 ===================
epoch no : 2, batch no : 262, total loss : 0.5287522673606873,  classifier :0.049491036683321, mask: 0.2361999750137329 ===================
epoch no : 2, batch no : 263, total loss : 0.3526570796966553,  classifier :0.05333337560296059, mask: 0.1401311755180359 ===================
epoch no : 2, batch no : 264, total loss : 0.4006471335887909,  classifier :0.05514449626207352, mask: 0.1437617391347885 ===================
epoch no : 2, batch no : 265, total loss : 0.3527783751487732,  classifier :0.05850294232368469, mask: 0.10950452089309692 ===================
epoch no : 2, batch no : 266, total loss : 0.2910598814487457,  classifier :0.05159797891974449, mask: 0.1071145310997963 ===================
epoch no : 2, batch no : 267, total loss : 0.39433807134628296,  classifier :0.03629294037818909, mask: 0.14786072075366974 ===================
epoch no : 2, batch no : 268, total loss : 0.49875837564468384,  classifier :0.06322118639945984, mask: 0.17102953791618347 ===================
epoch no : 2, batch no : 269, total loss : 0.3484228551387787,  classifier :0.049458447843790054, mask: 0.13328111171722412 ===================
epoch no : 2, batch no : 270, total loss : 0.3718016743659973,  classifier :0.04732951894402504, mask: 0.14192458987236023 ===================
epoch no : 2, batch no : 271, total loss : 0.4090956747531891,  classifier :0.05139075964689255, mask: 0.15191738307476044 ===================
epoch no : 2, batch no : 272, total loss : 0.36457279324531555,  classifier :0.049821678549051285, mask: 0.1392507702112198 ===================
epoch no : 2, batch no : 273, total loss : 0.4197496771812439,  classifier :0.058652114123106, mask: 0.14950606226921082 ===================
epoch no : 2, batch no : 274, total loss : 0.38265261054039,  classifier :0.043601810932159424, mask: 0.17276456952095032 ===================
epoch no : 2, batch no : 275, total loss : 0.4766494631767273,  classifier :0.0588824562728405, mask: 0.18754105269908905 ===================
epoch no : 2, batch no : 276, total loss : 0.3600716292858124,  classifier :0.05460844933986664, mask: 0.12650161981582642 ===================
epoch no : 2, batch no : 277, total loss : 0.39914780855178833,  classifier :0.04534846544265747, mask: 0.1883762776851654 ===================
epoch no : 2, batch no : 278, total loss : 0.3686999976634979,  classifier :0.059970445930957794, mask: 0.13197161257266998 ===================
epoch no : 2, batch no : 279, total loss : 0.3373444080352783,  classifier :0.054224222898483276, mask: 0.09334953874349594 ===================
epoch no : 2, batch no : 280, total loss : 0.3660229742527008,  classifier :0.0462896004319191, mask: 0.13095572590827942 ===================
epoch no : 2, batch no : 281, total loss : 0.3088223338127136,  classifier :0.032549239695072174, mask: 0.128461554646492 ===================
epoch no : 2, batch no : 282, total loss : 0.33497175574302673,  classifier :0.048464056104421616, mask: 0.1333826184272766 ===================
epoch no : 2, batch no : 283, total loss : 0.32215434312820435,  classifier :0.04770316928625107, mask: 0.12542827427387238 ===================
epoch no : 2, batch no : 284, total loss : 0.4541041851043701,  classifier :0.049725644290447235, mask: 0.20752958953380585 ===================
epoch no : 2, batch no : 285, total loss : 0.3913104832172394,  classifier :0.05137071758508682, mask: 0.1625707745552063 ===================
epoch no : 2, batch no : 286, total loss : 0.4436057507991791,  classifier :0.047242555767297745, mask: 0.1815744787454605 ===================
epoch no : 2, batch no : 287, total loss : 0.39967721700668335,  classifier :0.06419139355421066, mask: 0.13754703104496002 ===================
epoch no : 2, batch no : 288, total loss : 0.4459494948387146,  classifier :0.047472309321165085, mask: 0.18083417415618896 ===================
epoch no : 2, batch no : 289, total loss : 0.30084118247032166,  classifier :0.038569238036870956, mask: 0.11315549910068512 ===================
epoch no : 2, batch no : 290, total loss : 0.39210543036460876,  classifier :0.05736829712986946, mask: 0.14554107189178467 ===================
epoch no : 2, batch no : 291, total loss : 0.39757776260375977,  classifier :0.05346623808145523, mask: 0.14667156338691711 ===================
epoch no : 2, batch no : 292, total loss : 0.5161619186401367,  classifier :0.055943381041288376, mask: 0.19932280480861664 ===================
epoch no : 2, batch no : 293, total loss : 0.5094209909439087,  classifier :0.06667046993970871, mask: 0.22406934201717377 ===================
epoch no : 2, batch no : 294, total loss : 0.4641737639904022,  classifier :0.054824165999889374, mask: 0.1599806696176529 ===================
epoch no : 2, batch no : 295, total loss : 0.4079691469669342,  classifier :0.04649415239691734, mask: 0.17715223133563995 ===================
epoch no : 2, batch no : 296, total loss : 0.33354586362838745,  classifier :0.05335988476872444, mask: 0.125362828373909 ===================
epoch no : 2, batch no : 297, total loss : 0.4025298058986664,  classifier :0.05637451633810997, mask: 0.1665119230747223 ===================
epoch no : 2, batch no : 298, total loss : 0.4069150686264038,  classifier :0.04220627248287201, mask: 0.15880461037158966 ===================
epoch no : 2, batch no : 299, total loss : 0.36472365260124207,  classifier :0.048975180834531784, mask: 0.14430488646030426 ===================
epoch no : 2, batch no : 300, total loss : 0.36137545108795166,  classifier :0.0491621196269989, mask: 0.14390818774700165 ===================
epoch no : 2, batch no : 301, total loss : 0.43303194642066956,  classifier :0.04280182346701622, mask: 0.18694309890270233 ===================
epoch no : 2, batch no : 302, total loss : 0.4372093379497528,  classifier :0.04754188284277916, mask: 0.21919101476669312 ===================
epoch no : 2, batch no : 303, total loss : 0.38431090116500854,  classifier :0.042239271104335785, mask: 0.14198069274425507 ===================
epoch no : 2, batch no : 304, total loss : 0.40402549505233765,  classifier :0.05149897560477257, mask: 0.13334505259990692 ===================
epoch no : 2, batch no : 305, total loss : 0.39116835594177246,  classifier :0.05538875237107277, mask: 0.1361061930656433 ===================
epoch no : 2, batch no : 306, total loss : 0.31249696016311646,  classifier :0.04423009976744652, mask: 0.11881899833679199 ===================
epoch no : 2, batch no : 307, total loss : 0.40862563252449036,  classifier :0.045350950211286545, mask: 0.12392819672822952 ===================
epoch no : 2, batch no : 308, total loss : 0.4528714418411255,  classifier :0.046149808913469315, mask: 0.11153280735015869 ===================
epoch no : 2, batch no : 309, total loss : 0.37774789333343506,  classifier :0.043280232697725296, mask: 0.15961481630802155 ===================
epoch no : 2, batch no : 310, total loss : 0.396424263715744,  classifier :0.05848076567053795, mask: 0.13822314143180847 ===================
epoch no : 2, batch no : 311, total loss : 0.4499976933002472,  classifier :0.05043310672044754, mask: 0.1885872781276703 ===================
epoch no : 2, batch no : 312, total loss : 0.3202883303165436,  classifier :0.04031456261873245, mask: 0.11904224753379822 ===================
epoch no : 2, batch no : 313, total loss : 0.42301586270332336,  classifier :0.034584760665893555, mask: 0.14869530498981476 ===================
epoch no : 2, batch no : 314, total loss : 0.524319589138031,  classifier :0.05356258153915405, mask: 0.20031684637069702 ===================
epoch no : 2, batch no : 315, total loss : 0.6157287955284119,  classifier :0.04710307717323303, mask: 0.2390672266483307 ===================
epoch no : 2, batch no : 316, total loss : 0.4548342227935791,  classifier :0.05558200925588608, mask: 0.1498633474111557 ===================
epoch no : 2, batch no : 317, total loss : 0.5184940695762634,  classifier :0.08516800403594971, mask: 0.19042955338954926 ===================
epoch no : 2, batch no : 318, total loss : 0.374786376953125,  classifier :0.04130030795931816, mask: 0.1444457322359085 ===================
epoch no : 2, batch no : 319, total loss : 0.4842798709869385,  classifier :0.045285534113645554, mask: 0.1887536197900772 ===================
epoch no : 2, batch no : 320, total loss : 0.4339430630207062,  classifier :0.07490691542625427, mask: 0.1542998105287552 ===================
epoch no : 2, batch no : 321, total loss : 0.4275153577327728,  classifier :0.04632061719894409, mask: 0.15512558817863464 ===================
epoch no : 2, batch no : 322, total loss : 0.4077514111995697,  classifier :0.05147303268313408, mask: 0.16082191467285156 ===================
epoch no : 2, batch no : 323, total loss : 0.337881475687027,  classifier :0.05868919566273689, mask: 0.13578014075756073 ===================
epoch no : 2, batch no : 324, total loss : 0.39420804381370544,  classifier :0.047950342297554016, mask: 0.16167931258678436 ===================
epoch no : 2, batch no : 325, total loss : 0.35627153515815735,  classifier :0.046052996069192886, mask: 0.15294265747070312 ===================
epoch no : 2, batch no : 326, total loss : 0.28963372111320496,  classifier :0.04828229546546936, mask: 0.1175868958234787 ===================
epoch no : 2, batch no : 327, total loss : 0.3031441569328308,  classifier :0.05725330486893654, mask: 0.10931798815727234 ===================
epoch no : 2, batch no : 328, total loss : 0.511157214641571,  classifier :0.07350180298089981, mask: 0.15328237414360046 ===================
epoch no : 2, batch no : 329, total loss : 0.4649133086204529,  classifier :0.052057817578315735, mask: 0.18130064010620117 ===================
epoch no : 2, batch no : 330, total loss : 0.5941721796989441,  classifier :0.07958965003490448, mask: 0.27184203267097473 ===================
epoch no : 2, batch no : 331, total loss : 0.38726720213890076,  classifier :0.04914236068725586, mask: 0.16352561116218567 ===================
epoch no : 2, batch no : 332, total loss : 0.3287563920021057,  classifier :0.050787799060344696, mask: 0.11282839626073837 ===================
epoch no : 2, batch no : 333, total loss : 0.3901602327823639,  classifier :0.05218277871608734, mask: 0.13046647608280182 ===================
epoch no : 2, batch no : 334, total loss : 0.4888928532600403,  classifier :0.07008949667215347, mask: 0.1829037219285965 ===================
epoch no : 2, batch no : 335, total loss : 0.4221744239330292,  classifier :0.05051659792661667, mask: 0.15715749561786652 ===================
epoch no : 2, batch no : 336, total loss : 0.34971973299980164,  classifier :0.045299045741558075, mask: 0.14912912249565125 ===================
epoch no : 2, batch no : 337, total loss : 0.47320258617401123,  classifier :0.05682867020368576, mask: 0.20301669836044312 ===================
epoch no : 2, batch no : 338, total loss : 0.3080480694770813,  classifier :0.05525254085659981, mask: 0.1077730804681778 ===================
epoch no : 2, batch no : 339, total loss : 0.3111542761325836,  classifier :0.039980582892894745, mask: 0.11203010380268097 ===================
epoch no : 2, batch no : 340, total loss : 0.32217076420783997,  classifier :0.046002164483070374, mask: 0.11805208027362823 ===================
epoch no : 2, batch no : 341, total loss : 0.3339158892631531,  classifier :0.06194522976875305, mask: 0.12270938605070114 ===================
epoch no : 2, batch no : 342, total loss : 0.3008323609828949,  classifier :0.04195662587881088, mask: 0.1365482658147812 ===================
epoch no : 2, batch no : 343, total loss : 0.33241212368011475,  classifier :0.05627462640404701, mask: 0.1306440681219101 ===================
epoch no : 2, batch no : 344, total loss : 0.46600982546806335,  classifier :0.038961052894592285, mask: 0.1676637977361679 ===================
epoch no : 2, batch no : 345, total loss : 0.46810996532440186,  classifier :0.06060182303190231, mask: 0.1608409732580185 ===================
epoch no : 2, batch no : 346, total loss : 0.40160560607910156,  classifier :0.06958507746458054, mask: 0.13065147399902344 ===================
epoch no : 2, batch no : 347, total loss : 0.4102743864059448,  classifier :0.0498976893723011, mask: 0.13561680912971497 ===================
epoch no : 2, batch no : 348, total loss : 0.4480515718460083,  classifier :0.0605044849216938, mask: 0.14454880356788635 ===================
epoch no : 2, batch no : 349, total loss : 0.37986958026885986,  classifier :0.047293130308389664, mask: 0.13427987694740295 ===================
epoch no : 2, batch no : 350, total loss : 0.2704000174999237,  classifier :0.051271647214889526, mask: 0.10190831124782562 ===================
epoch no : 2, batch no : 351, total loss : 0.4674968123435974,  classifier :0.054606739431619644, mask: 0.17275702953338623 ===================
epoch no : 2, batch no : 352, total loss : 0.3805510103702545,  classifier :0.05366874858736992, mask: 0.13220679759979248 ===================
epoch no : 2, batch no : 353, total loss : 0.3648659884929657,  classifier :0.04332582280039787, mask: 0.1122983917593956 ===================
epoch no : 2, batch no : 354, total loss : 0.35951605439186096,  classifier :0.041401155292987823, mask: 0.1563478261232376 ===================
epoch no : 2, batch no : 355, total loss : 0.41027942299842834,  classifier :0.044034019112586975, mask: 0.1443149298429489 ===================
epoch no : 2, batch no : 356, total loss : 0.4274752736091614,  classifier :0.05002622678875923, mask: 0.13572914898395538 ===================
epoch no : 2, batch no : 357, total loss : 0.3737553060054779,  classifier :0.046689651906490326, mask: 0.147541344165802 ===================
epoch no : 2, batch no : 358, total loss : 0.31353700160980225,  classifier :0.041547991335392, mask: 0.11214123666286469 ===================
epoch no : 2, batch no : 359, total loss : 0.269864022731781,  classifier :0.04332033917307854, mask: 0.09928473085165024 ===================
epoch no : 2, batch no : 360, total loss : 0.3682841360569,  classifier :0.06491610407829285, mask: 0.10168268531560898 ===================
epoch no : 2, batch no : 361, total loss : 0.30816686153411865,  classifier :0.04007045552134514, mask: 0.1125904843211174 ===================
epoch no : 2, batch no : 362, total loss : 0.3166804909706116,  classifier :0.039594586938619614, mask: 0.12389423698186874 ===================
epoch no : 2, batch no : 363, total loss : 0.40381619334220886,  classifier :0.061429161578416824, mask: 0.15142105519771576 ===================
epoch no : 2, batch no : 364, total loss : 0.40504685044288635,  classifier :0.060160424560308456, mask: 0.16307130455970764 ===================
epoch no : 2, batch no : 365, total loss : 0.4416266977787018,  classifier :0.048797283321619034, mask: 0.15669295191764832 ===================
epoch no : 2, batch no : 366, total loss : 0.3539585769176483,  classifier :0.040388163179159164, mask: 0.14625529944896698 ===================
epoch no : 2, batch no : 367, total loss : 0.3719535171985626,  classifier :0.0529412105679512, mask: 0.14255395531654358 ===================
epoch no : 2, batch no : 368, total loss : 0.3995332717895508,  classifier :0.04703881964087486, mask: 0.1512843817472458 ===================
epoch no : 2, batch no : 369, total loss : 0.4054960608482361,  classifier :0.04704437032341957, mask: 0.14257249236106873 ===================
epoch no : 2, batch no : 370, total loss : 0.35778576135635376,  classifier :0.05679162219166756, mask: 0.12196150422096252 ===================
epoch no : 2, batch no : 371, total loss : 0.49070918560028076,  classifier :0.05752911791205406, mask: 0.2400742620229721 ===================
epoch no : 2, batch no : 372, total loss : 0.5753124356269836,  classifier :0.048295456916093826, mask: 0.21072356402873993 ===================
epoch no : 2, batch no : 373, total loss : 0.44105586409568787,  classifier :0.03867329657077789, mask: 0.15064623951911926 ===================
epoch no : 2, batch no : 374, total loss : 0.3941446840763092,  classifier :0.06221107766032219, mask: 0.13862337172031403 ===================
epoch no : 2, batch no : 375, total loss : 0.46366897225379944,  classifier :0.07172399759292603, mask: 0.1586441844701767 ===================
epoch no : 2, batch no : 376, total loss : 0.45423832535743713,  classifier :0.05504554882645607, mask: 0.14340999722480774 ===================
epoch no : 2, batch no : 377, total loss : 0.4614006578922272,  classifier :0.054559800773859024, mask: 0.15998303890228271 ===================
epoch no : 2, batch no : 378, total loss : 0.40480804443359375,  classifier :0.04493819922208786, mask: 0.14507360756397247 ===================
epoch no : 2, batch no : 379, total loss : 0.3163791000843048,  classifier :0.05188479274511337, mask: 0.1234331950545311 ===================
epoch no : 2, batch no : 380, total loss : 0.3769441545009613,  classifier :0.041961826384067535, mask: 0.16449634730815887 ===================
epoch no : 2, batch no : 381, total loss : 0.34863126277923584,  classifier :0.05345124751329422, mask: 0.12660451233386993 ===================
epoch no : 2, batch no : 382, total loss : 0.30394238233566284,  classifier :0.04788631573319435, mask: 0.1045336052775383 ===================
epoch no : 2, batch no : 383, total loss : 0.3738095164299011,  classifier :0.04984220862388611, mask: 0.14891240000724792 ===================
epoch no : 2, batch no : 384, total loss : 0.47708410024642944,  classifier :0.06776446849107742, mask: 0.20594286918640137 ===================
epoch no : 2, batch no : 385, total loss : 0.33607447147369385,  classifier :0.03547818958759308, mask: 0.1299392282962799 ===================
epoch no : 2, batch no : 386, total loss : 0.3221012055873871,  classifier :0.05846720188856125, mask: 0.13064856827259064 ===================
epoch no : 2, batch no : 387, total loss : 0.39633455872535706,  classifier :0.05270642042160034, mask: 0.13455134630203247 ===================
epoch no : 2, batch no : 388, total loss : 0.36337634921073914,  classifier :0.03765080124139786, mask: 0.15267089009284973 ===================
epoch no : 2, batch no : 389, total loss : 0.5206016898155212,  classifier :0.08082316815853119, mask: 0.16988930106163025 ===================
epoch no : 2, batch no : 390, total loss : 0.4179207980632782,  classifier :0.042279161512851715, mask: 0.17563071846961975 ===================
epoch no : 2, batch no : 391, total loss : 0.4307902753353119,  classifier :0.05465418100357056, mask: 0.17385563254356384 ===================
epoch no : 2, batch no : 392, total loss : 0.35544154047966003,  classifier :0.05897872895002365, mask: 0.1271928995847702 ===================
epoch no : 2, batch no : 393, total loss : 0.40439191460609436,  classifier :0.06630154699087143, mask: 0.14054298400878906 ===================
epoch no : 2, batch no : 394, total loss : 0.4050382673740387,  classifier :0.051806263625621796, mask: 0.15761850774288177 ===================
epoch no : 2, batch no : 395, total loss : 0.34872445464134216,  classifier :0.05122166499495506, mask: 0.1392422616481781 ===================
epoch no : 2, batch no : 396, total loss : 0.4043087959289551,  classifier :0.05017045885324478, mask: 0.13999556005001068 ===================
epoch no : 2, batch no : 397, total loss : 0.44266095757484436,  classifier :0.05437575280666351, mask: 0.16536052525043488 ===================
epoch no : 2, batch no : 398, total loss : 0.3568703830242157,  classifier :0.041498053818941116, mask: 0.1345759481191635 ===================
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch no : 3, batch no : 0, total loss : 0.4687137305736542,  classifier :0.040028590708971024, mask: 0.16828154027462006 ===================
epoch no : 3, batch no : 1, total loss : 0.4156985282897949,  classifier :0.043265774846076965, mask: 0.17240607738494873 ===================
epoch no : 3, batch no : 2, total loss : 0.37479859590530396,  classifier :0.05840887501835823, mask: 0.1280895322561264 ===================
epoch no : 3, batch no : 3, total loss : 0.34965619444847107,  classifier :0.0311331357806921, mask: 0.15923036634922028 ===================
epoch no : 3, batch no : 4, total loss : 0.46338003873825073,  classifier :0.05877353996038437, mask: 0.17526280879974365 ===================
epoch no : 3, batch no : 5, total loss : 0.513130247592926,  classifier :0.06844586133956909, mask: 0.2132350504398346 ===================
epoch no : 3, batch no : 6, total loss : 0.3858543038368225,  classifier :0.05139784887433052, mask: 0.13291625678539276 ===================
epoch no : 3, batch no : 7, total loss : 0.3708176016807556,  classifier :0.052072301506996155, mask: 0.13536134362220764 ===================
epoch no : 3, batch no : 8, total loss : 0.42448076605796814,  classifier :0.05750443413853645, mask: 0.16743887960910797 ===================
epoch no : 3, batch no : 9, total loss : 0.43411675095558167,  classifier :0.05284437537193298, mask: 0.1759437620639801 ===================
epoch no : 3, batch no : 10, total loss : 0.46691712737083435,  classifier :0.06305151432752609, mask: 0.16281872987747192 ===================
epoch no : 3, batch no : 11, total loss : 0.3980252742767334,  classifier :0.049172695726156235, mask: 0.1851590871810913 ===================
epoch no : 3, batch no : 12, total loss : 0.3565801978111267,  classifier :0.03711051121354103, mask: 0.14221186935901642 ===================
epoch no : 3, batch no : 13, total loss : 0.3700122535228729,  classifier :0.041437942534685135, mask: 0.137922465801239 ===================
epoch no : 3, batch no : 14, total loss : 0.4022669196128845,  classifier :0.04779859632253647, mask: 0.1418401449918747 ===================
epoch no : 3, batch no : 15, total loss : 0.36716771125793457,  classifier :0.045985788106918335, mask: 0.14303429424762726 ===================
epoch no : 3, batch no : 16, total loss : 0.3338187336921692,  classifier :0.0456007681787014, mask: 0.12099166959524155 ===================
epoch no : 3, batch no : 17, total loss : 0.2939510941505432,  classifier :0.04295232519507408, mask: 0.11720362305641174 ===================
epoch no : 3, batch no : 18, total loss : 0.3923192024230957,  classifier :0.041904788464307785, mask: 0.1693117767572403 ===================
epoch no : 3, batch no : 19, total loss : 0.37434157729148865,  classifier :0.05140548199415207, mask: 0.16505546867847443 ===================
epoch no : 3, batch no : 20, total loss : 0.3492852449417114,  classifier :0.04342716559767723, mask: 0.13901405036449432 ===================
epoch no : 3, batch no : 21, total loss : 0.40263867378234863,  classifier :0.06333088129758835, mask: 0.13923317193984985 ===================
epoch no : 3, batch no : 22, total loss : 0.26804691553115845,  classifier :0.043393008410930634, mask: 0.10471680760383606 ===================
epoch no : 3, batch no : 23, total loss : 0.37757304310798645,  classifier :0.0442395955324173, mask: 0.1604800969362259 ===================
epoch no : 3, batch no : 24, total loss : 0.26260411739349365,  classifier :0.03161577880382538, mask: 0.12086532264947891 ===================
epoch no : 3, batch no : 25, total loss : 0.4216814637184143,  classifier :0.05834478512406349, mask: 0.1316068321466446 ===================
epoch no : 3, batch no : 26, total loss : 0.35805755853652954,  classifier :0.03954225033521652, mask: 0.11855612695217133 ===================
epoch no : 3, batch no : 27, total loss : 0.3050006628036499,  classifier :0.05139331519603729, mask: 0.11712834984064102 ===================
epoch no : 3, batch no : 28, total loss : 0.4530814290046692,  classifier :0.04102442041039467, mask: 0.18569380044937134 ===================
epoch no : 3, batch no : 29, total loss : 0.44323641061782837,  classifier :0.041045837104320526, mask: 0.15166015923023224 ===================
epoch no : 3, batch no : 30, total loss : 0.3881111145019531,  classifier :0.039882346987724304, mask: 0.1496964693069458 ===================
epoch no : 3, batch no : 31, total loss : 0.33881327509880066,  classifier :0.04540953412652016, mask: 0.14536213874816895 ===================
epoch no : 3, batch no : 32, total loss : 0.4525813162326813,  classifier :0.05608004704117775, mask: 0.17555256187915802 ===================
epoch no : 3, batch no : 33, total loss : 0.3520663380622864,  classifier :0.06117519736289978, mask: 0.108731210231781 ===================
epoch no : 3, batch no : 34, total loss : 0.36322763562202454,  classifier :0.038764432072639465, mask: 0.11522488296031952 ===================
epoch no : 3, batch no : 35, total loss : 0.48597681522369385,  classifier :0.04633865877985954, mask: 0.19032983481884003 ===================
epoch no : 3, batch no : 36, total loss : 0.38358044624328613,  classifier :0.04716122895479202, mask: 0.136389821767807 ===================
epoch no : 3, batch no : 37, total loss : 0.3349883556365967,  classifier :0.04041951894760132, mask: 0.13494420051574707 ===================
epoch no : 3, batch no : 38, total loss : 0.338345468044281,  classifier :0.034508008509874344, mask: 0.16277585923671722 ===================
epoch no : 3, batch no : 39, total loss : 0.3463847041130066,  classifier :0.04720962420105934, mask: 0.13514134287834167 ===================
epoch no : 3, batch no : 40, total loss : 0.28627943992614746,  classifier :0.040965486317873, mask: 0.12812122702598572 ===================
epoch no : 3, batch no : 41, total loss : 0.36478644609451294,  classifier :0.04230025038123131, mask: 0.15588968992233276 ===================
epoch no : 3, batch no : 42, total loss : 0.5380123853683472,  classifier :0.05984312295913696, mask: 0.1972200721502304 ===================
epoch no : 3, batch no : 43, total loss : 0.3575912117958069,  classifier :0.04770633205771446, mask: 0.13630272448062897 ===================
epoch no : 3, batch no : 44, total loss : 0.38232824206352234,  classifier :0.03941255062818527, mask: 0.1403384655714035 ===================
epoch no : 3, batch no : 45, total loss : 0.3339685797691345,  classifier :0.039933331310749054, mask: 0.12839233875274658 ===================
epoch no : 3, batch no : 46, total loss : 0.2960248589515686,  classifier :0.04154934361577034, mask: 0.11451266705989838 ===================
epoch no : 3, batch no : 47, total loss : 0.41456717252731323,  classifier :0.04888221621513367, mask: 0.15527822077274323 ===================
epoch no : 3, batch no : 48, total loss : 0.40347591042518616,  classifier :0.043259769678115845, mask: 0.14579622447490692 ===================
epoch no : 3, batch no : 49, total loss : 0.4159936010837555,  classifier :0.053066350519657135, mask: 0.16306322813034058 ===================
epoch no : 3, batch no : 50, total loss : 0.2550765573978424,  classifier :0.04331902787089348, mask: 0.12409137189388275 ===================
epoch no : 3, batch no : 51, total loss : 0.278399258852005,  classifier :0.03497305139899254, mask: 0.11201996356248856 ===================
epoch no : 3, batch no : 52, total loss : 0.3391379117965698,  classifier :0.048288244754076004, mask: 0.12501636147499084 ===================
epoch no : 3, batch no : 53, total loss : 0.40603935718536377,  classifier :0.055580317974090576, mask: 0.16160567104816437 ===================
epoch no : 3, batch no : 54, total loss : 0.4485642611980438,  classifier :0.06940052658319473, mask: 0.17274323105812073 ===================
epoch no : 3, batch no : 55, total loss : 0.4295652508735657,  classifier :0.05351624637842178, mask: 0.17078831791877747 ===================
epoch no : 3, batch no : 56, total loss : 0.3791261613368988,  classifier :0.04841151833534241, mask: 0.14522387087345123 ===================
epoch no : 3, batch no : 57, total loss : 0.3466384708881378,  classifier :0.043141525238752365, mask: 0.14341627061367035 ===================
epoch no : 3, batch no : 58, total loss : 0.3620915710926056,  classifier :0.054585251957178116, mask: 0.13973483443260193 ===================
epoch no : 3, batch no : 59, total loss : 0.3796294927597046,  classifier :0.0615762360394001, mask: 0.12170004099607468 ===================
epoch no : 3, batch no : 60, total loss : 0.3023933470249176,  classifier :0.041042301803827286, mask: 0.11541178822517395 ===================
epoch no : 3, batch no : 61, total loss : 0.36519163846969604,  classifier :0.039113886654376984, mask: 0.11792478710412979 ===================
epoch no : 3, batch no : 62, total loss : 0.43866482377052307,  classifier :0.058209002017974854, mask: 0.1496727615594864 ===================
epoch no : 3, batch no : 63, total loss : 0.3741713762283325,  classifier :0.04238305240869522, mask: 0.14522702991962433 ===================
epoch no : 3, batch no : 64, total loss : 0.3683038055896759,  classifier :0.04480692744255066, mask: 0.17075450718402863 ===================
epoch no : 3, batch no : 65, total loss : 0.2917947471141815,  classifier :0.046860471367836, mask: 0.12741634249687195 ===================
epoch no : 3, batch no : 66, total loss : 0.2905018925666809,  classifier :0.03130839020013809, mask: 0.11975156515836716 ===================
epoch no : 3, batch no : 67, total loss : 0.4039204716682434,  classifier :0.05005871504545212, mask: 0.12178902328014374 ===================
epoch no : 3, batch no : 68, total loss : 0.4718841016292572,  classifier :0.06541652232408524, mask: 0.17802074551582336 ===================
epoch no : 3, batch no : 69, total loss : 0.3007676601409912,  classifier :0.03953845053911209, mask: 0.11229601502418518 ===================
epoch no : 3, batch no : 70, total loss : 0.48179933428764343,  classifier :0.04088014364242554, mask: 0.20270907878875732 ===================
epoch no : 3, batch no : 71, total loss : 0.4365187883377075,  classifier :0.0520695336163044, mask: 0.14850154519081116 ===================
epoch no : 3, batch no : 72, total loss : 0.40762731432914734,  classifier :0.04136301204562187, mask: 0.16227981448173523 ===================
epoch no : 3, batch no : 73, total loss : 0.37232136726379395,  classifier :0.04652104526758194, mask: 0.13675051927566528 ===================
epoch no : 3, batch no : 74, total loss : 0.37931206822395325,  classifier :0.05918164923787117, mask: 0.1371835619211197 ===================
epoch no : 3, batch no : 75, total loss : 0.3598303198814392,  classifier :0.0409366674721241, mask: 0.14357253909111023 ===================
epoch no : 3, batch no : 76, total loss : 0.4415999948978424,  classifier :0.04738562926650047, mask: 0.17842711508274078 ===================
epoch no : 3, batch no : 77, total loss : 0.4565475285053253,  classifier :0.05719595029950142, mask: 0.14381647109985352 ===================
epoch no : 3, batch no : 78, total loss : 0.39688923954963684,  classifier :0.07238323241472244, mask: 0.12333449721336365 ===================
epoch no : 3, batch no : 79, total loss : 0.31153833866119385,  classifier :0.06011118367314339, mask: 0.1199253499507904 ===================
epoch no : 3, batch no : 80, total loss : 0.3103136718273163,  classifier :0.04136519134044647, mask: 0.10198338329792023 ===================
epoch no : 3, batch no : 81, total loss : 0.3642778992652893,  classifier :0.04517412558197975, mask: 0.12705430388450623 ===================
epoch no : 3, batch no : 82, total loss : 0.3630475699901581,  classifier :0.03913753107190132, mask: 0.12826994061470032 ===================
epoch no : 3, batch no : 83, total loss : 0.44656261801719666,  classifier :0.050412289798259735, mask: 0.1545848250389099 ===================
epoch no : 3, batch no : 84, total loss : 0.352117121219635,  classifier :0.046682484447956085, mask: 0.13237722218036652 ===================
epoch no : 3, batch no : 85, total loss : 0.3905011713504791,  classifier :0.045722123235464096, mask: 0.17204514145851135 ===================
epoch no : 3, batch no : 86, total loss : 0.3632873296737671,  classifier :0.04616545885801315, mask: 0.14159205555915833 ===================
epoch no : 3, batch no : 87, total loss : 0.38796377182006836,  classifier :0.040861014276742935, mask: 0.14363496005535126 ===================
epoch no : 3, batch no : 88, total loss : 0.3679753839969635,  classifier :0.04139392822980881, mask: 0.13402366638183594 ===================
epoch no : 3, batch no : 89, total loss : 0.3603358864784241,  classifier :0.04044629633426666, mask: 0.16157615184783936 ===================
epoch no : 3, batch no : 90, total loss : 0.33330878615379333,  classifier :0.044733162969350815, mask: 0.11594796180725098 ===================
epoch no : 3, batch no : 91, total loss : 0.35316815972328186,  classifier :0.0425613671541214, mask: 0.14301851391792297 ===================
epoch no : 3, batch no : 92, total loss : 0.419248104095459,  classifier :0.04137000814080238, mask: 0.15531183779239655 ===================
epoch no : 3, batch no : 93, total loss : 0.44492852687835693,  classifier :0.05144638940691948, mask: 0.154886394739151 ===================
epoch no : 3, batch no : 94, total loss : 0.35499492287635803,  classifier :0.03586453199386597, mask: 0.17982344329357147 ===================
epoch no : 3, batch no : 95, total loss : 0.28688687086105347,  classifier :0.05344659090042114, mask: 0.1307755708694458 ===================
epoch no : 3, batch no : 96, total loss : 0.3681327700614929,  classifier :0.052210792899131775, mask: 0.1600816696882248 ===================
epoch no : 3, batch no : 97, total loss : 0.31886643171310425,  classifier :0.05793820321559906, mask: 0.10333362966775894 ===================
epoch no : 3, batch no : 98, total loss : 0.360983669757843,  classifier :0.04243580996990204, mask: 0.1496797651052475 ===================
epoch no : 3, batch no : 99, total loss : 0.386220246553421,  classifier :0.06282773613929749, mask: 0.14427228271961212 ===================
epoch no : 3, batch no : 100, total loss : 0.3895733952522278,  classifier :0.03973391652107239, mask: 0.14058129489421844 ===================
epoch no : 3, batch no : 101, total loss : 0.37915921211242676,  classifier :0.04958526790142059, mask: 0.13304373621940613 ===================
epoch no : 3, batch no : 102, total loss : 0.38837283849716187,  classifier :0.0458366796374321, mask: 0.13055521249771118 ===================
epoch no : 3, batch no : 103, total loss : 0.34017276763916016,  classifier :0.0451255738735199, mask: 0.10489726811647415 ===================
epoch no : 3, batch no : 104, total loss : 0.3152466118335724,  classifier :0.04723234847187996, mask: 0.12314141541719437 ===================
epoch no : 3, batch no : 105, total loss : 0.32674193382263184,  classifier :0.02956511825323105, mask: 0.1244419664144516 ===================
epoch no : 3, batch no : 106, total loss : 0.5251039266586304,  classifier :0.06809819489717484, mask: 0.2328997701406479 ===================
epoch no : 3, batch no : 107, total loss : 0.4678695499897003,  classifier :0.04798825830221176, mask: 0.19849839806556702 ===================
epoch no : 3, batch no : 108, total loss : 0.49832549691200256,  classifier :0.05559932440519333, mask: 0.20484645664691925 ===================
epoch no : 3, batch no : 109, total loss : 0.2918355166912079,  classifier :0.0399322584271431, mask: 0.11397266387939453 ===================
epoch no : 3, batch no : 110, total loss : 0.3933022618293762,  classifier :0.043551791459321976, mask: 0.16266342997550964 ===================
epoch no : 3, batch no : 111, total loss : 0.32468682527542114,  classifier :0.03934948518872261, mask: 0.12369003891944885 ===================
epoch no : 3, batch no : 112, total loss : 0.3025059401988983,  classifier :0.04454110562801361, mask: 0.1147986501455307 ===================
epoch no : 3, batch no : 113, total loss : 0.3019300401210785,  classifier :0.04097986966371536, mask: 0.12110015749931335 ===================
epoch no : 3, batch no : 114, total loss : 0.5150148868560791,  classifier :0.061000045388936996, mask: 0.20339463651180267 ===================
epoch no : 3, batch no : 115, total loss : 0.3911900222301483,  classifier :0.061062537133693695, mask: 0.1540074199438095 ===================
epoch no : 3, batch no : 116, total loss : 0.4098450839519501,  classifier :0.040409475564956665, mask: 0.1840129941701889 ===================
epoch no : 3, batch no : 117, total loss : 0.30966565012931824,  classifier :0.03257210552692413, mask: 0.161505326628685 ===================
epoch no : 3, batch no : 118, total loss : 0.2770790457725525,  classifier :0.040488582104444504, mask: 0.10319577157497406 ===================
epoch no : 3, batch no : 119, total loss : 0.2830183506011963,  classifier :0.040933940559625626, mask: 0.11187601834535599 ===================
epoch no : 3, batch no : 120, total loss : 0.30620670318603516,  classifier :0.04878867417573929, mask: 0.12207532674074173 ===================
epoch no : 3, batch no : 121, total loss : 0.30025020241737366,  classifier :0.040099237114191055, mask: 0.11410240828990936 ===================
epoch no : 3, batch no : 122, total loss : 0.30240193009376526,  classifier :0.042833320796489716, mask: 0.11990083754062653 ===================
epoch no : 3, batch no : 123, total loss : 0.3435753881931305,  classifier :0.043167322874069214, mask: 0.11882945895195007 ===================
epoch no : 3, batch no : 124, total loss : 0.45320358872413635,  classifier :0.06717915832996368, mask: 0.13730375468730927 ===================
epoch no : 3, batch no : 125, total loss : 0.36755475401878357,  classifier :0.04711814597249031, mask: 0.13931290805339813 ===================
epoch no : 3, batch no : 126, total loss : 0.3604291081428528,  classifier :0.05379099398851395, mask: 0.14423808455467224 ===================
epoch no : 3, batch no : 127, total loss : 0.31928759813308716,  classifier :0.04924070090055466, mask: 0.1260330080986023 ===================
epoch no : 3, batch no : 128, total loss : 0.2757105231285095,  classifier :0.049991950392723083, mask: 0.11921727657318115 ===================
epoch no : 3, batch no : 129, total loss : 0.40387988090515137,  classifier :0.04379940778017044, mask: 0.18832118809223175 ===================
epoch no : 3, batch no : 130, total loss : 0.3935664892196655,  classifier :0.05248250067234039, mask: 0.20064881443977356 ===================
epoch no : 3, batch no : 131, total loss : 0.45217299461364746,  classifier :0.03401506319642067, mask: 0.21290114521980286 ===================
epoch no : 3, batch no : 132, total loss : 0.4167257845401764,  classifier :0.05151737481355667, mask: 0.15920935571193695 ===================
epoch no : 3, batch no : 133, total loss : 0.34920188784599304,  classifier :0.05517870560288429, mask: 0.11047915369272232 ===================
epoch no : 3, batch no : 134, total loss : 0.4282962679862976,  classifier :0.05182235315442085, mask: 0.16236689686775208 ===================
epoch no : 3, batch no : 135, total loss : 0.3846113383769989,  classifier :0.03539130091667175, mask: 0.1331663727760315 ===================
epoch no : 3, batch no : 136, total loss : 0.3303299844264984,  classifier :0.041819021105766296, mask: 0.12841521203517914 ===================
epoch no : 3, batch no : 137, total loss : 0.3956413269042969,  classifier :0.05818302556872368, mask: 0.1382133662700653 ===================
epoch no : 3, batch no : 138, total loss : 0.3476980924606323,  classifier :0.046437110751867294, mask: 0.15162017941474915 ===================
epoch no : 3, batch no : 139, total loss : 0.3572441637516022,  classifier :0.04441199451684952, mask: 0.13899487257003784 ===================
epoch no : 3, batch no : 140, total loss : 0.30815431475639343,  classifier :0.05548026040196419, mask: 0.11832111328840256 ===================
epoch no : 3, batch no : 141, total loss : 0.3706444501876831,  classifier :0.04855039715766907, mask: 0.128702312707901 ===================
epoch no : 3, batch no : 142, total loss : 0.4822869896888733,  classifier :0.07185236364603043, mask: 0.16622427105903625 ===================
epoch no : 3, batch no : 143, total loss : 0.6274616122245789,  classifier :0.061920419335365295, mask: 0.20160353183746338 ===================
epoch no : 3, batch no : 144, total loss : 0.37038421630859375,  classifier :0.04591812193393707, mask: 0.13802720606327057 ===================
epoch no : 3, batch no : 145, total loss : 0.3931976854801178,  classifier :0.058432918041944504, mask: 0.13626272976398468 ===================
epoch no : 3, batch no : 146, total loss : 0.35086187720298767,  classifier :0.042898498475551605, mask: 0.13004663586616516 ===================
epoch no : 3, batch no : 147, total loss : 0.5092487335205078,  classifier :0.04316195100545883, mask: 0.20431402325630188 ===================
epoch no : 3, batch no : 148, total loss : 0.45600685477256775,  classifier :0.05107391998171806, mask: 0.20898044109344482 ===================
epoch no : 3, batch no : 149, total loss : 0.47349172830581665,  classifier :0.0448521189391613, mask: 0.1866222321987152 ===================
epoch no : 3, batch no : 150, total loss : 0.3310466706752777,  classifier :0.04479428008198738, mask: 0.13718339800834656 ===================
epoch no : 3, batch no : 151, total loss : 0.30932480096817017,  classifier :0.04620649665594101, mask: 0.09856955707073212 ===================
epoch no : 3, batch no : 152, total loss : 0.3304300010204315,  classifier :0.046487048268318176, mask: 0.11996939033269882 ===================
epoch no : 3, batch no : 153, total loss : 0.36473047733306885,  classifier :0.04143216088414192, mask: 0.14867763221263885 ===================
epoch no : 3, batch no : 154, total loss : 0.32939162850379944,  classifier :0.034634437412023544, mask: 0.13791437447071075 ===================
epoch no : 3, batch no : 155, total loss : 0.34974369406700134,  classifier :0.03753365948796272, mask: 0.131669819355011 ===================
epoch no : 3, batch no : 156, total loss : 0.3925980031490326,  classifier :0.055417221039533615, mask: 0.127204030752182 ===================
epoch no : 3, batch no : 157, total loss : 0.2969697415828705,  classifier :0.041554830968379974, mask: 0.11087150126695633 ===================
epoch no : 3, batch no : 158, total loss : 0.4347977042198181,  classifier :0.05648709461092949, mask: 0.15570740401744843 ===================
epoch no : 3, batch no : 159, total loss : 0.3973757326602936,  classifier :0.046707917004823685, mask: 0.11455537378787994 ===================
epoch no : 3, batch no : 160, total loss : 0.3538670837879181,  classifier :0.041036441922187805, mask: 0.17596110701560974 ===================
epoch no : 3, batch no : 161, total loss : 0.36875036358833313,  classifier :0.047112010419368744, mask: 0.16530552506446838 ===================
epoch no : 3, batch no : 162, total loss : 0.31113770604133606,  classifier :0.04526133835315704, mask: 0.11264179646968842 ===================
epoch no : 3, batch no : 163, total loss : 0.3144259452819824,  classifier :0.05476014316082001, mask: 0.11723171174526215 ===================
epoch no : 3, batch no : 164, total loss : 0.3885743021965027,  classifier :0.04074631631374359, mask: 0.1480521261692047 ===================
epoch no : 3, batch no : 165, total loss : 0.40373262763023376,  classifier :0.05344553291797638, mask: 0.12569299340248108 ===================
epoch no : 3, batch no : 166, total loss : 0.3899437487125397,  classifier :0.0514647401869297, mask: 0.16736845672130585 ===================
epoch no : 3, batch no : 167, total loss : 0.31604552268981934,  classifier :0.042132411152124405, mask: 0.13006767630577087 ===================
epoch no : 3, batch no : 168, total loss : 0.31058618426322937,  classifier :0.04813847318291664, mask: 0.10907144099473953 ===================
epoch no : 3, batch no : 169, total loss : 0.40706220269203186,  classifier :0.05629530921578407, mask: 0.1234961599111557 ===================
epoch no : 3, batch no : 170, total loss : 0.39333611726760864,  classifier :0.040630415081977844, mask: 0.15477599203586578 ===================
epoch no : 3, batch no : 171, total loss : 0.37970057129859924,  classifier :0.04542161151766777, mask: 0.16644351184368134 ===================
epoch no : 3, batch no : 172, total loss : 0.38762184977531433,  classifier :0.042903587222099304, mask: 0.1537666767835617 ===================
epoch no : 3, batch no : 173, total loss : 0.4688871502876282,  classifier :0.06231522560119629, mask: 0.1763135939836502 ===================
epoch no : 3, batch no : 174, total loss : 0.37500330805778503,  classifier :0.04702270030975342, mask: 0.13051140308380127 ===================
epoch no : 3, batch no : 175, total loss : 0.4046223759651184,  classifier :0.06641079485416412, mask: 0.15913763642311096 ===================
epoch no : 3, batch no : 176, total loss : 0.35219883918762207,  classifier :0.05122903361916542, mask: 0.13023509085178375 ===================
epoch no : 3, batch no : 177, total loss : 0.32922160625457764,  classifier :0.05270539969205856, mask: 0.11068170517683029 ===================
epoch no : 3, batch no : 178, total loss : 0.3278138041496277,  classifier :0.04267020896077156, mask: 0.11791162192821503 ===================
epoch no : 3, batch no : 179, total loss : 0.32944682240486145,  classifier :0.04200046509504318, mask: 0.14487814903259277 ===================
epoch no : 3, batch no : 180, total loss : 0.3189682960510254,  classifier :0.043126288801431656, mask: 0.11704466491937637 ===================
epoch no : 3, batch no : 181, total loss : 0.2706264853477478,  classifier :0.049322329461574554, mask: 0.10457124561071396 ===================
epoch no : 3, batch no : 182, total loss : 0.3008444905281067,  classifier :0.041138797998428345, mask: 0.10868006944656372 ===================
epoch no : 3, batch no : 183, total loss : 0.3399660289287567,  classifier :0.04289333149790764, mask: 0.12853224575519562 ===================
epoch no : 3, batch no : 184, total loss : 0.383081316947937,  classifier :0.05328388884663582, mask: 0.1553620845079422 ===================
epoch no : 3, batch no : 185, total loss : 0.35318896174430847,  classifier :0.05361675098538399, mask: 0.14924262464046478 ===================
epoch no : 3, batch no : 186, total loss : 0.33950918912887573,  classifier :0.05783846974372864, mask: 0.13788297772407532 ===================
epoch no : 3, batch no : 187, total loss : 0.4834088683128357,  classifier :0.043157219886779785, mask: 0.20381294190883636 ===================
epoch no : 3, batch no : 188, total loss : 0.3624904453754425,  classifier :0.0480337031185627, mask: 0.140392005443573 ===================
epoch no : 3, batch no : 189, total loss : 0.26452499628067017,  classifier :0.03933945298194885, mask: 0.0881001204252243 ===================
epoch no : 3, batch no : 190, total loss : 0.3629258871078491,  classifier :0.05274290591478348, mask: 0.11782049387693405 ===================
epoch no : 3, batch no : 191, total loss : 0.3793078660964966,  classifier :0.047540828585624695, mask: 0.15657411515712738 ===================
epoch no : 3, batch no : 192, total loss : 0.34085872769355774,  classifier :0.04372869059443474, mask: 0.14611893892288208 ===================
epoch no : 3, batch no : 193, total loss : 0.2776920795440674,  classifier :0.029695745557546616, mask: 0.11987295746803284 ===================
epoch no : 3, batch no : 194, total loss : 0.2650044560432434,  classifier :0.03529629856348038, mask: 0.09911277145147324 ===================
epoch no : 3, batch no : 195, total loss : 0.38458654284477234,  classifier :0.03734925016760826, mask: 0.1549844592809677 ===================
epoch no : 3, batch no : 196, total loss : 0.44861897826194763,  classifier :0.04749071225523949, mask: 0.20421820878982544 ===================
epoch no : 3, batch no : 197, total loss : 0.3249533474445343,  classifier :0.04632203280925751, mask: 0.12532955408096313 ===================
epoch no : 3, batch no : 198, total loss : 0.36478114128112793,  classifier :0.05316738039255142, mask: 0.10837111622095108 ===================
epoch no : 3, batch no : 199, total loss : 0.3616936504840851,  classifier :0.046438075602054596, mask: 0.15300442278385162 ===================
epoch no : 3, batch no : 200, total loss : 0.2888116240501404,  classifier :0.04074595496058464, mask: 0.11621113866567612 ===================
epoch no : 3, batch no : 201, total loss : 0.2945295572280884,  classifier :0.038919948041439056, mask: 0.12036509066820145 ===================
epoch no : 3, batch no : 202, total loss : 0.3583081364631653,  classifier :0.05193039029836655, mask: 0.1379677951335907 ===================
epoch no : 3, batch no : 203, total loss : 0.4409024119377136,  classifier :0.0565071664750576, mask: 0.1822771579027176 ===================
epoch no : 3, batch no : 204, total loss : 0.5429564714431763,  classifier :0.04997152090072632, mask: 0.22708818316459656 ===================
epoch no : 3, batch no : 205, total loss : 0.42553895711898804,  classifier :0.043171610683202744, mask: 0.17410075664520264 ===================
epoch no : 3, batch no : 206, total loss : 0.35407954454421997,  classifier :0.05647869035601616, mask: 0.12949202954769135 ===================
epoch no : 3, batch no : 207, total loss : 0.44929376244544983,  classifier :0.07879359275102615, mask: 0.15487028658390045 ===================
epoch no : 3, batch no : 208, total loss : 0.40486931800842285,  classifier :0.08772994577884674, mask: 0.13626728951931 ===================
epoch no : 3, batch no : 209, total loss : 0.3259100914001465,  classifier :0.038041435182094574, mask: 0.11775375157594681 ===================
epoch no : 3, batch no : 210, total loss : 0.39493077993392944,  classifier :0.037182025611400604, mask: 0.18931804597377777 ===================
epoch no : 3, batch no : 211, total loss : 0.48848313093185425,  classifier :0.0701851099729538, mask: 0.18698541820049286 ===================
epoch no : 3, batch no : 212, total loss : 0.3358463943004608,  classifier :0.04062611609697342, mask: 0.1273960918188095 ===================
epoch no : 3, batch no : 213, total loss : 0.48658761382102966,  classifier :0.04263732209801674, mask: 0.17572444677352905 ===================
epoch no : 3, batch no : 214, total loss : 0.2970386743545532,  classifier :0.050496906042099, mask: 0.1131296157836914 ===================
epoch no : 3, batch no : 215, total loss : 0.32633519172668457,  classifier :0.04183361679315567, mask: 0.12635807693004608 ===================
epoch no : 3, batch no : 216, total loss : 0.2869677245616913,  classifier :0.027447449043393135, mask: 0.1307026445865631 ===================
epoch no : 3, batch no : 217, total loss : 0.3143002986907959,  classifier :0.04307253658771515, mask: 0.13102595508098602 ===================
epoch no : 3, batch no : 218, total loss : 0.3845266103744507,  classifier :0.053112469613552094, mask: 0.14188872277736664 ===================
epoch no : 3, batch no : 219, total loss : 0.4370929002761841,  classifier :0.041795581579208374, mask: 0.17796245217323303 ===================
epoch no : 3, batch no : 220, total loss : 0.3456784188747406,  classifier :0.04791508987545967, mask: 0.15028414130210876 ===================
epoch no : 3, batch no : 221, total loss : 0.3747888207435608,  classifier :0.05261632055044174, mask: 0.14133265614509583 ===================
epoch no : 3, batch no : 222, total loss : 0.38460156321525574,  classifier :0.041105300188064575, mask: 0.12267712503671646 ===================
epoch no : 3, batch no : 223, total loss : 0.2953958213329315,  classifier :0.036860935389995575, mask: 0.11851274967193604 ===================
epoch no : 3, batch no : 224, total loss : 0.3469291031360626,  classifier :0.03957061842083931, mask: 0.12670105695724487 ===================
epoch no : 3, batch no : 225, total loss : 0.3131009042263031,  classifier :0.034221526235342026, mask: 0.12508070468902588 ===================
epoch no : 3, batch no : 226, total loss : 0.31926658749580383,  classifier :0.033569660037755966, mask: 0.12478053569793701 ===================
epoch no : 3, batch no : 227, total loss : 0.3020533323287964,  classifier :0.0420941486954689, mask: 0.10472861677408218 ===================
epoch no : 3, batch no : 228, total loss : 0.38103756308555603,  classifier :0.04662877321243286, mask: 0.1421480029821396 ===================
epoch no : 3, batch no : 229, total loss : 0.28277766704559326,  classifier :0.03147159144282341, mask: 0.12850913405418396 ===================
epoch no : 3, batch no : 230, total loss : 0.34888309240341187,  classifier :0.050763607025146484, mask: 0.1307467371225357 ===================
epoch no : 3, batch no : 231, total loss : 0.2453925460577011,  classifier :0.04086022078990936, mask: 0.10305309295654297 ===================
epoch no : 3, batch no : 232, total loss : 0.2889234125614166,  classifier :0.04212915152311325, mask: 0.0904749184846878 ===================
epoch no : 3, batch no : 233, total loss : 0.3067474365234375,  classifier :0.04887564852833748, mask: 0.11543616652488708 ===================
epoch no : 3, batch no : 234, total loss : 0.3434479534626007,  classifier :0.04799363389611244, mask: 0.11860956996679306 ===================
epoch no : 3, batch no : 235, total loss : 0.3739553689956665,  classifier :0.039830565452575684, mask: 0.15015573799610138 ===================
epoch no : 3, batch no : 236, total loss : 0.29984429478645325,  classifier :0.03882618993520737, mask: 0.10103338211774826 ===================
epoch no : 3, batch no : 237, total loss : 0.3676885962486267,  classifier :0.04952089861035347, mask: 0.14019860327243805 ===================
epoch no : 3, batch no : 238, total loss : 0.3462367653846741,  classifier :0.04777536913752556, mask: 0.124901182949543 ===================
epoch no : 3, batch no : 239, total loss : 0.30791664123535156,  classifier :0.052200797945261, mask: 0.13456624746322632 ===================
epoch no : 3, batch no : 240, total loss : 0.34055599570274353,  classifier :0.041575003415346146, mask: 0.12757310271263123 ===================
epoch no : 3, batch no : 241, total loss : 0.41114479303359985,  classifier :0.030720215290784836, mask: 0.194879412651062 ===================
epoch no : 3, batch no : 242, total loss : 0.30411970615386963,  classifier :0.05601838231086731, mask: 0.11553867161273956 ===================
epoch no : 3, batch no : 243, total loss : 0.3269575238227844,  classifier :0.03452495113015175, mask: 0.1447228342294693 ===================
epoch no : 3, batch no : 244, total loss : 0.34618327021598816,  classifier :0.04152758792042732, mask: 0.12825928628444672 ===================
epoch no : 3, batch no : 245, total loss : 0.4071626365184784,  classifier :0.04887065663933754, mask: 0.14521847665309906 ===================
epoch no : 3, batch no : 246, total loss : 0.37996906042099,  classifier :0.030201749876141548, mask: 0.17602558434009552 ===================
epoch no : 3, batch no : 247, total loss : 0.283620148897171,  classifier :0.04894211143255234, mask: 0.1161428764462471 ===================
epoch no : 3, batch no : 248, total loss : 0.3253616988658905,  classifier :0.0415208600461483, mask: 0.13257932662963867 ===================
epoch no : 3, batch no : 249, total loss : 0.32279372215270996,  classifier :0.026364510878920555, mask: 0.15061596035957336 ===================
epoch no : 3, batch no : 250, total loss : 0.3203860819339752,  classifier :0.03607594966888428, mask: 0.12763811647891998 ===================
epoch no : 3, batch no : 251, total loss : 0.4048770070075989,  classifier :0.050782304257154465, mask: 0.17423135042190552 ===================
epoch no : 3, batch no : 252, total loss : 0.32638269662857056,  classifier :0.06742096692323685, mask: 0.10711508244276047 ===================
epoch no : 3, batch no : 253, total loss : 0.2475343942642212,  classifier :0.036909688264131546, mask: 0.09774493426084518 ===================
epoch no : 3, batch no : 254, total loss : 0.35626259446144104,  classifier :0.05136748030781746, mask: 0.12844370305538177 ===================
epoch no : 3, batch no : 255, total loss : 0.30171728134155273,  classifier :0.029070895165205002, mask: 0.13705961406230927 ===================
epoch no : 3, batch no : 256, total loss : 0.48856204748153687,  classifier :0.056869763880968094, mask: 0.1414017230272293 ===================
epoch no : 3, batch no : 257, total loss : 0.3589082360267639,  classifier :0.040399402379989624, mask: 0.15416134893894196 ===================
epoch no : 3, batch no : 258, total loss : 0.44015830755233765,  classifier :0.043981269001960754, mask: 0.2020791620016098 ===================
epoch no : 3, batch no : 259, total loss : 0.43861478567123413,  classifier :0.04074588045477867, mask: 0.15508852899074554 ===================
epoch no : 3, batch no : 260, total loss : 0.3938154876232147,  classifier :0.0498632974922657, mask: 0.14495082199573517 ===================
epoch no : 3, batch no : 261, total loss : 0.35638314485549927,  classifier :0.051309533417224884, mask: 0.135027214884758 ===================
epoch no : 3, batch no : 262, total loss : 0.2931537330150604,  classifier :0.04659920558333397, mask: 0.10678375512361526 ===================
epoch no : 3, batch no : 263, total loss : 0.38532084226608276,  classifier :0.049717292189598083, mask: 0.12606015801429749 ===================
epoch no : 3, batch no : 264, total loss : 0.3320733606815338,  classifier :0.05470648035407066, mask: 0.12309988588094711 ===================
epoch no : 3, batch no : 265, total loss : 0.35106247663497925,  classifier :0.05496469512581825, mask: 0.14080844819545746 ===================
epoch no : 3, batch no : 266, total loss : 0.30950891971588135,  classifier :0.05245964229106903, mask: 0.11985129117965698 ===================
epoch no : 3, batch no : 267, total loss : 0.40826550126075745,  classifier :0.043403007090091705, mask: 0.16043278574943542 ===================
epoch no : 3, batch no : 268, total loss : 0.28928980231285095,  classifier :0.039895497262477875, mask: 0.1032644733786583 ===================
epoch no : 3, batch no : 269, total loss : 0.2905435562133789,  classifier :0.05579337105154991, mask: 0.11120828241109848 ===================
epoch no : 3, batch no : 270, total loss : 0.3957495093345642,  classifier :0.0656965896487236, mask: 0.12661811709403992 ===================
epoch no : 3, batch no : 271, total loss : 0.30776742100715637,  classifier :0.04594404995441437, mask: 0.11491338163614273 ===================
epoch no : 3, batch no : 272, total loss : 0.3473736643791199,  classifier :0.04407205432653427, mask: 0.1393641233444214 ===================
epoch no : 3, batch no : 273, total loss : 0.34098145365715027,  classifier :0.04115559533238411, mask: 0.1342843919992447 ===================
epoch no : 3, batch no : 274, total loss : 0.35739630460739136,  classifier :0.03962540999054909, mask: 0.11338796466588974 ===================
epoch no : 3, batch no : 275, total loss : 0.4961506724357605,  classifier :0.04956651106476784, mask: 0.1996336579322815 ===================
epoch no : 3, batch no : 276, total loss : 0.33715173602104187,  classifier :0.03955940529704094, mask: 0.11811832338571548 ===================
epoch no : 3, batch no : 277, total loss : 0.29803651571273804,  classifier :0.039513882249593735, mask: 0.11921992152929306 ===================
epoch no : 3, batch no : 278, total loss : 0.32557591795921326,  classifier :0.03881433233618736, mask: 0.13939468562602997 ===================
epoch no : 3, batch no : 279, total loss : 0.3133508265018463,  classifier :0.03452170267701149, mask: 0.12347006052732468 ===================
epoch no : 3, batch no : 280, total loss : 0.3313520550727844,  classifier :0.03357605263590813, mask: 0.11903675645589828 ===================
epoch no : 3, batch no : 281, total loss : 0.3046119809150696,  classifier :0.039313070476055145, mask: 0.11591125279664993 ===================
epoch no : 3, batch no : 282, total loss : 0.24751345813274384,  classifier :0.04025103151798248, mask: 0.09864327311515808 ===================
epoch no : 3, batch no : 283, total loss : 0.3375386595726013,  classifier :0.05292004719376564, mask: 0.11896409094333649 ===================
epoch no : 3, batch no : 284, total loss : 0.3416711688041687,  classifier :0.05178740620613098, mask: 0.1507261097431183 ===================
epoch no : 3, batch no : 285, total loss : 0.3280709981918335,  classifier :0.05309963971376419, mask: 0.1267993301153183 ===================
epoch no : 3, batch no : 286, total loss : 0.3502214848995209,  classifier :0.037141721695661545, mask: 0.1569788008928299 ===================
epoch no : 3, batch no : 287, total loss : 0.3779716193675995,  classifier :0.04891686886548996, mask: 0.1504652351140976 ===================
epoch no : 3, batch no : 288, total loss : 0.37380242347717285,  classifier :0.04225306957960129, mask: 0.13490481674671173 ===================
epoch no : 3, batch no : 289, total loss : 0.37859123945236206,  classifier :0.03989097476005554, mask: 0.15062902867794037 ===================
epoch no : 3, batch no : 290, total loss : 0.36842772364616394,  classifier :0.03726418688893318, mask: 0.16442999243736267 ===================
epoch no : 3, batch no : 291, total loss : 0.36180248856544495,  classifier :0.04150613024830818, mask: 0.1363717019557953 ===================
epoch no : 3, batch no : 292, total loss : 0.3576812446117401,  classifier :0.04126357659697533, mask: 0.12509146332740784 ===================
epoch no : 3, batch no : 293, total loss : 0.3799039125442505,  classifier :0.0540425106883049, mask: 0.130009263753891 ===================
epoch no : 3, batch no : 294, total loss : 0.372147798538208,  classifier :0.048225171864032745, mask: 0.11591072380542755 ===================
epoch no : 3, batch no : 295, total loss : 0.37155085802078247,  classifier :0.035273827612400055, mask: 0.17408257722854614 ===================
epoch no : 3, batch no : 296, total loss : 0.2988748252391815,  classifier :0.0430276021361351, mask: 0.11340563744306564 ===================
epoch no : 3, batch no : 297, total loss : 0.3006109595298767,  classifier :0.04072365164756775, mask: 0.12206697463989258 ===================
epoch no : 3, batch no : 298, total loss : 0.4977678060531616,  classifier :0.052100084722042084, mask: 0.22056466341018677 ===================
epoch no : 3, batch no : 299, total loss : 0.39840036630630493,  classifier :0.04575489088892937, mask: 0.12653586268424988 ===================
epoch no : 3, batch no : 300, total loss : 0.3964618444442749,  classifier :0.05406545475125313, mask: 0.14687061309814453 ===================
epoch no : 3, batch no : 301, total loss : 0.29031404852867126,  classifier :0.028002828359603882, mask: 0.11722394078969955 ===================
epoch no : 3, batch no : 302, total loss : 0.2890733778476715,  classifier :0.05050734430551529, mask: 0.10219751298427582 ===================
epoch no : 3, batch no : 303, total loss : 0.393865704536438,  classifier :0.047715574502944946, mask: 0.14036093652248383 ===================
epoch no : 3, batch no : 304, total loss : 0.30869024991989136,  classifier :0.04521532356739044, mask: 0.12372525781393051 ===================
epoch no : 3, batch no : 305, total loss : 0.3451731204986572,  classifier :0.04246124252676964, mask: 0.11969982087612152 ===================
epoch no : 3, batch no : 306, total loss : 0.3901466131210327,  classifier :0.03393849730491638, mask: 0.1655646711587906 ===================
epoch no : 3, batch no : 307, total loss : 0.385141521692276,  classifier :0.041208665817976, mask: 0.1298411339521408 ===================
epoch no : 3, batch no : 308, total loss : 0.3404260575771332,  classifier :0.044508762657642365, mask: 0.11992347240447998 ===================
epoch no : 3, batch no : 309, total loss : 0.35756197571754456,  classifier :0.035954710096120834, mask: 0.15023618936538696 ===================
epoch no : 3, batch no : 310, total loss : 0.3558405935764313,  classifier :0.03630302473902702, mask: 0.14137814939022064 ===================
epoch no : 3, batch no : 311, total loss : 0.43398159742355347,  classifier :0.03983578085899353, mask: 0.17324285209178925 ===================
epoch no : 3, batch no : 312, total loss : 0.3417701721191406,  classifier :0.03843609616160393, mask: 0.14299745857715607 ===================
epoch no : 3, batch no : 313, total loss : 0.3238292634487152,  classifier :0.04458487033843994, mask: 0.13752256333827972 ===================
epoch no : 3, batch no : 314, total loss : 0.3518655598163605,  classifier :0.04105845466256142, mask: 0.15021400153636932 ===================
epoch no : 3, batch no : 315, total loss : 0.3377397358417511,  classifier :0.04231272265315056, mask: 0.1592288464307785 ===================
epoch no : 3, batch no : 316, total loss : 0.3908805549144745,  classifier :0.04545506462454796, mask: 0.17595668137073517 ===================
epoch no : 3, batch no : 317, total loss : 0.41540399193763733,  classifier :0.03460300341248512, mask: 0.17747865617275238 ===================
epoch no : 3, batch no : 318, total loss : 0.27298906445503235,  classifier :0.04683791473507881, mask: 0.10637083649635315 ===================
epoch no : 3, batch no : 319, total loss : 0.4578365087509155,  classifier :0.04610251262784004, mask: 0.19678866863250732 ===================
epoch no : 3, batch no : 320, total loss : 0.4463936984539032,  classifier :0.03583686426281929, mask: 0.15125449001789093 ===================
epoch no : 3, batch no : 321, total loss : 0.37788742780685425,  classifier :0.03602541983127594, mask: 0.14798171818256378 ===================
epoch no : 3, batch no : 322, total loss : 0.3864784836769104,  classifier :0.04385332390666008, mask: 0.1545153707265854 ===================
epoch no : 3, batch no : 323, total loss : 0.23862409591674805,  classifier :0.031193220987915993, mask: 0.09369964152574539 ===================
epoch no : 3, batch no : 324, total loss : 0.4013976752758026,  classifier :0.044856809079647064, mask: 0.15617051720619202 ===================
epoch no : 3, batch no : 325, total loss : 0.3525333106517792,  classifier :0.03368484228849411, mask: 0.1759176105260849 ===================
epoch no : 3, batch no : 326, total loss : 0.3190367817878723,  classifier :0.03977443277835846, mask: 0.118011474609375 ===================
epoch no : 3, batch no : 327, total loss : 0.3934812545776367,  classifier :0.04972267895936966, mask: 0.15618354082107544 ===================
epoch no : 3, batch no : 328, total loss : 0.36478641629219055,  classifier :0.04697804898023605, mask: 0.12701348960399628 ===================
epoch no : 3, batch no : 329, total loss : 0.3288253843784332,  classifier :0.052026163786649704, mask: 0.1234728991985321 ===================
epoch no : 3, batch no : 330, total loss : 0.28784456849098206,  classifier :0.053593505173921585, mask: 0.11659187823534012 ===================
epoch no : 3, batch no : 331, total loss : 0.3040355145931244,  classifier :0.045256420969963074, mask: 0.11118178069591522 ===================
epoch no : 3, batch no : 332, total loss : 0.3708033561706543,  classifier :0.046301692724227905, mask: 0.12022478133440018 ===================
epoch no : 3, batch no : 333, total loss : 0.3041434586048126,  classifier :0.036613114178180695, mask: 0.1173798143863678 ===================
epoch no : 3, batch no : 334, total loss : 0.3340371251106262,  classifier :0.031504757702350616, mask: 0.14098185300827026 ===================
epoch no : 3, batch no : 335, total loss : 0.3554641604423523,  classifier :0.02735133096575737, mask: 0.14732198417186737 ===================
epoch no : 3, batch no : 336, total loss : 0.40165480971336365,  classifier :0.03809055685997009, mask: 0.15363813936710358 ===================
epoch no : 3, batch no : 337, total loss : 0.387065052986145,  classifier :0.04675872251391411, mask: 0.17544998228549957 ===================
epoch no : 3, batch no : 338, total loss : 0.35261809825897217,  classifier :0.04822081699967384, mask: 0.1306462585926056 ===================
epoch no : 3, batch no : 339, total loss : 0.30021458864212036,  classifier :0.04106974974274635, mask: 0.12439993768930435 ===================
epoch no : 3, batch no : 340, total loss : 0.396004855632782,  classifier :0.06087006628513336, mask: 0.15663594007492065 ===================
epoch no : 3, batch no : 341, total loss : 0.42882677912712097,  classifier :0.05699077248573303, mask: 0.19606392085552216 ===================
epoch no : 3, batch no : 342, total loss : 0.39997750520706177,  classifier :0.06373390555381775, mask: 0.15253211557865143 ===================
epoch no : 3, batch no : 343, total loss : 0.36345547437667847,  classifier :0.03450631722807884, mask: 0.1637195497751236 ===================
epoch no : 3, batch no : 344, total loss : 0.29933926463127136,  classifier :0.03125125542283058, mask: 0.11794902384281158 ===================
epoch no : 3, batch no : 345, total loss : 0.34453973174095154,  classifier :0.044557735323905945, mask: 0.14514876902103424 ===================
epoch no : 3, batch no : 346, total loss : 0.3323764204978943,  classifier :0.033782850950956345, mask: 0.12933556735515594 ===================
epoch no : 3, batch no : 347, total loss : 0.3547680377960205,  classifier :0.03732246905565262, mask: 0.16203175485134125 ===================
epoch no : 3, batch no : 348, total loss : 0.3357025980949402,  classifier :0.029692815616726875, mask: 0.18212226033210754 ===================
epoch no : 3, batch no : 349, total loss : 0.36568233370780945,  classifier :0.04745352268218994, mask: 0.13244928419589996 ===================
epoch no : 3, batch no : 350, total loss : 0.3045986294746399,  classifier :0.037347279489040375, mask: 0.12228281795978546 ===================
epoch no : 3, batch no : 351, total loss : 0.36944150924682617,  classifier :0.03722163289785385, mask: 0.14708712697029114 ===================
epoch no : 3, batch no : 352, total loss : 0.4197266697883606,  classifier :0.03812447935342789, mask: 0.13791285455226898 ===================
epoch no : 3, batch no : 353, total loss : 0.4347659945487976,  classifier :0.0492631271481514, mask: 0.13948874175548553 ===================
epoch no : 3, batch no : 354, total loss : 0.39934903383255005,  classifier :0.05467942729592323, mask: 0.1550544947385788 ===================
epoch no : 3, batch no : 355, total loss : 0.31899553537368774,  classifier :0.04220364987850189, mask: 0.12561802566051483 ===================
epoch no : 3, batch no : 356, total loss : 0.30351752042770386,  classifier :0.041242942214012146, mask: 0.11714962124824524 ===================
epoch no : 3, batch no : 357, total loss : 0.34523043036460876,  classifier :0.03377233445644379, mask: 0.1381073147058487 ===================
epoch no : 3, batch no : 358, total loss : 0.3558632433414459,  classifier :0.04166952148079872, mask: 0.14820170402526855 ===================
epoch no : 3, batch no : 359, total loss : 0.3661348223686218,  classifier :0.03397293761372566, mask: 0.14537453651428223 ===================
epoch no : 3, batch no : 360, total loss : 0.3384309411048889,  classifier :0.03940310701727867, mask: 0.13930942118167877 ===================
epoch no : 3, batch no : 361, total loss : 0.27310287952423096,  classifier :0.03487817943096161, mask: 0.108490489423275 ===================
epoch no : 3, batch no : 362, total loss : 0.3862763047218323,  classifier :0.04498745873570442, mask: 0.12565277516841888 ===================
epoch no : 3, batch no : 363, total loss : 0.3473586142063141,  classifier :0.03778001293540001, mask: 0.12649662792682648 ===================
epoch no : 3, batch no : 364, total loss : 0.34956684708595276,  classifier :0.049839798361063004, mask: 0.13710668683052063 ===================
epoch no : 3, batch no : 365, total loss : 0.3460502624511719,  classifier :0.05488181114196777, mask: 0.11589602380990982 ===================
epoch no : 3, batch no : 366, total loss : 0.30527812242507935,  classifier :0.04011997580528259, mask: 0.12889869511127472 ===================
epoch no : 3, batch no : 367, total loss : 0.2225801944732666,  classifier :0.03325963765382767, mask: 0.0938982143998146 ===================
epoch no : 3, batch no : 368, total loss : 0.3885735273361206,  classifier :0.04370754957199097, mask: 0.15688902139663696 ===================
epoch no : 3, batch no : 369, total loss : 0.5530872941017151,  classifier :0.06375230848789215, mask: 0.23292256891727448 ===================
epoch no : 3, batch no : 370, total loss : 0.3419050872325897,  classifier :0.028276367112994194, mask: 0.16912730038166046 ===================
epoch no : 3, batch no : 371, total loss : 0.2857873737812042,  classifier :0.03307487443089485, mask: 0.13089588284492493 ===================
epoch no : 3, batch no : 372, total loss : 0.2999686598777771,  classifier :0.03430899605154991, mask: 0.12901878356933594 ===================
epoch no : 3, batch no : 373, total loss : 0.39611953496932983,  classifier :0.04476533085107803, mask: 0.1401563137769699 ===================
epoch no : 3, batch no : 374, total loss : 0.3726651966571808,  classifier :0.0391458235681057, mask: 0.13837577402591705 ===================
epoch no : 3, batch no : 375, total loss : 0.28335872292518616,  classifier :0.041388243436813354, mask: 0.12175227701663971 ===================
epoch no : 3, batch no : 376, total loss : 0.24178822338581085,  classifier :0.03347650170326233, mask: 0.09933056682348251 ===================
epoch no : 3, batch no : 377, total loss : 0.3171674609184265,  classifier :0.027008777484297752, mask: 0.12222430109977722 ===================
epoch no : 3, batch no : 378, total loss : 0.3809531331062317,  classifier :0.03695652261376381, mask: 0.13186828792095184 ===================
epoch no : 3, batch no : 379, total loss : 0.36336401104927063,  classifier :0.03936979919672012, mask: 0.16758127510547638 ===================
epoch no : 3, batch no : 380, total loss : 0.3274897634983063,  classifier :0.03219699114561081, mask: 0.12787503004074097 ===================
epoch no : 3, batch no : 381, total loss : 0.3297405540943146,  classifier :0.04224132373929024, mask: 0.1488964706659317 ===================
epoch no : 3, batch no : 382, total loss : 0.48184165358543396,  classifier :0.03910944238305092, mask: 0.21052584052085876 ===================
epoch no : 3, batch no : 383, total loss : 0.42473992705345154,  classifier :0.042420174926519394, mask: 0.14900745451450348 ===================
epoch no : 3, batch no : 384, total loss : 0.37313392758369446,  classifier :0.036708347499370575, mask: 0.14334507286548615 ===================
epoch no : 3, batch no : 385, total loss : 0.3343468904495239,  classifier :0.05627187341451645, mask: 0.1361026167869568 ===================
epoch no : 3, batch no : 386, total loss : 0.3261449337005615,  classifier :0.04232224076986313, mask: 0.1334194391965866 ===================
epoch no : 3, batch no : 387, total loss : 0.2612650394439697,  classifier :0.02776154689490795, mask: 0.11286475509405136 ===================
epoch no : 3, batch no : 388, total loss : 0.3119693100452423,  classifier :0.0443478599190712, mask: 0.13447336852550507 ===================
epoch no : 3, batch no : 389, total loss : 0.3171549439430237,  classifier :0.03767433017492294, mask: 0.15314093232154846 ===================
epoch no : 3, batch no : 390, total loss : 0.4593432545661926,  classifier :0.05968139320611954, mask: 0.1860090047121048 ===================
epoch no : 3, batch no : 391, total loss : 0.2784566581249237,  classifier :0.025663325563073158, mask: 0.1223263069987297 ===================
epoch no : 3, batch no : 392, total loss : 0.37785398960113525,  classifier :0.03137822821736336, mask: 0.15420177578926086 ===================
epoch no : 3, batch no : 393, total loss : 0.3004550337791443,  classifier :0.03534647077322006, mask: 0.13374336063861847 ===================
epoch no : 3, batch no : 394, total loss : 0.29691869020462036,  classifier :0.039715901017189026, mask: 0.11328381299972534 ===================
epoch no : 3, batch no : 395, total loss : 0.2999536991119385,  classifier :0.0325361005961895, mask: 0.10935822129249573 ===================
epoch no : 3, batch no : 396, total loss : 0.2589513957500458,  classifier :0.03712897747755051, mask: 0.10274773836135864 ===================
epoch no : 3, batch no : 397, total loss : 0.30285418033599854,  classifier :0.03350356966257095, mask: 0.12380577623844147 ===================
epoch no : 3, batch no : 398, total loss : 0.28109607100486755,  classifier :0.031068086624145508, mask: 0.13744716346263885 ===================
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch no : 4, batch no : 0, total loss : 0.3707021474838257,  classifier :0.04433390498161316, mask: 0.15303769707679749 ===================
epoch no : 4, batch no : 1, total loss : 0.370126336812973,  classifier :0.04607183858752251, mask: 0.1500794142484665 ===================
epoch no : 4, batch no : 2, total loss : 0.4349108636379242,  classifier :0.04506675899028778, mask: 0.15886852145195007 ===================
epoch no : 4, batch no : 3, total loss : 0.28525328636169434,  classifier :0.04334551841020584, mask: 0.09588994085788727 ===================
epoch no : 4, batch no : 4, total loss : 0.35728371143341064,  classifier :0.02990318275988102, mask: 0.1602461189031601 ===================
epoch no : 4, batch no : 5, total loss : 0.3196786642074585,  classifier :0.043056946247816086, mask: 0.12380214035511017 ===================
epoch no : 4, batch no : 6, total loss : 0.3921971321105957,  classifier :0.04079316183924675, mask: 0.17758648097515106 ===================
epoch no : 4, batch no : 7, total loss : 0.24768075346946716,  classifier :0.026467854157090187, mask: 0.12103752046823502 ===================
epoch no : 4, batch no : 8, total loss : 0.25743383169174194,  classifier :0.03380347788333893, mask: 0.09178187698125839 ===================
epoch no : 4, batch no : 9, total loss : 0.3079710602760315,  classifier :0.06024941802024841, mask: 0.1041765958070755 ===================
epoch no : 4, batch no : 10, total loss : 0.3149285614490509,  classifier :0.03857596963644028, mask: 0.13241276144981384 ===================
epoch no : 4, batch no : 11, total loss : 0.3633357286453247,  classifier :0.05297090858221054, mask: 0.15477760136127472 ===================
epoch no : 4, batch no : 12, total loss : 0.48512712121009827,  classifier :0.04828830808401108, mask: 0.19349434971809387 ===================
epoch no : 4, batch no : 13, total loss : 0.3574240207672119,  classifier :0.03718440234661102, mask: 0.12051926553249359 ===================
epoch no : 4, batch no : 14, total loss : 0.34278005361557007,  classifier :0.04941700026392937, mask: 0.138465017080307 ===================
epoch no : 4, batch no : 15, total loss : 0.44220712780952454,  classifier :0.07397548854351044, mask: 0.14841827750205994 ===================
epoch no : 4, batch no : 16, total loss : 0.3586428463459015,  classifier :0.031804975122213364, mask: 0.15392115712165833 ===================
epoch no : 4, batch no : 17, total loss : 0.27509233355522156,  classifier :0.03374417498707771, mask: 0.11615364253520966 ===================
epoch no : 4, batch no : 18, total loss : 0.2436450868844986,  classifier :0.02778858318924904, mask: 0.09872929751873016 ===================
epoch no : 4, batch no : 19, total loss : 0.38445088267326355,  classifier :0.03345533460378647, mask: 0.1703541874885559 ===================
epoch no : 4, batch no : 20, total loss : 0.3042599856853485,  classifier :0.03448940068483353, mask: 0.11960228532552719 ===================
epoch no : 4, batch no : 21, total loss : 0.4405311048030853,  classifier :0.056735869497060776, mask: 0.15643008053302765 ===================
epoch no : 4, batch no : 22, total loss : 0.2797480821609497,  classifier :0.039113495498895645, mask: 0.09818383306264877 ===================
epoch no : 4, batch no : 23, total loss : 0.3255208134651184,  classifier :0.037460703402757645, mask: 0.15689244866371155 ===================
epoch no : 4, batch no : 24, total loss : 0.45821458101272583,  classifier :0.04405973106622696, mask: 0.1944446861743927 ===================
epoch no : 4, batch no : 25, total loss : 0.31835034489631653,  classifier :0.04651777073740959, mask: 0.11460146307945251 ===================
epoch no : 4, batch no : 26, total loss : 0.28875142335891724,  classifier :0.03337227553129196, mask: 0.11578553915023804 ===================
epoch no : 4, batch no : 27, total loss : 0.35333243012428284,  classifier :0.05054410547018051, mask: 0.1420353651046753 ===================
epoch no : 4, batch no : 28, total loss : 0.28489983081817627,  classifier :0.03627137839794159, mask: 0.12437756359577179 ===================
epoch no : 4, batch no : 29, total loss : 0.33300572633743286,  classifier :0.03909756988286972, mask: 0.13329873979091644 ===================
epoch no : 4, batch no : 30, total loss : 0.4090796113014221,  classifier :0.04502398893237114, mask: 0.13349828124046326 ===================
epoch no : 4, batch no : 31, total loss : 0.3996845483779907,  classifier :0.03968696668744087, mask: 0.19277925789356232 ===================
epoch no : 4, batch no : 32, total loss : 0.36706995964050293,  classifier :0.042599815875291824, mask: 0.148906409740448 ===================
epoch no : 4, batch no : 33, total loss : 0.327534943819046,  classifier :0.04110796004533768, mask: 0.14231544733047485 ===================
epoch no : 4, batch no : 34, total loss : 0.34193918108940125,  classifier :0.042669057846069336, mask: 0.1408054232597351 ===================
epoch no : 4, batch no : 35, total loss : 0.33116480708122253,  classifier :0.05378525331616402, mask: 0.12478262186050415 ===================
epoch no : 4, batch no : 36, total loss : 0.26927560567855835,  classifier :0.028418995440006256, mask: 0.11760822683572769 ===================
epoch no : 4, batch no : 37, total loss : 0.348145455121994,  classifier :0.050696901977062225, mask: 0.1313493698835373 ===================
epoch no : 4, batch no : 38, total loss : 0.2648600935935974,  classifier :0.0394379161298275, mask: 0.10622792690992355 ===================
epoch no : 4, batch no : 39, total loss : 0.2615089416503906,  classifier :0.036118119955062866, mask: 0.1046280562877655 ===================
epoch no : 4, batch no : 40, total loss : 0.38594090938568115,  classifier :0.04579586535692215, mask: 0.1624288558959961 ===================
epoch no : 4, batch no : 41, total loss : 0.2885814905166626,  classifier :0.03727053850889206, mask: 0.11137168854475021 ===================
epoch no : 4, batch no : 42, total loss : 0.31353551149368286,  classifier :0.0432555228471756, mask: 0.09692630171775818 ===================
epoch no : 4, batch no : 43, total loss : 0.332737535238266,  classifier :0.04241309314966202, mask: 0.15836608409881592 ===================
epoch no : 4, batch no : 44, total loss : 0.3223276436328888,  classifier :0.03186464309692383, mask: 0.1533239185810089 ===================
epoch no : 4, batch no : 45, total loss : 0.29660138487815857,  classifier :0.04453875496983528, mask: 0.12753155827522278 ===================
epoch no : 4, batch no : 46, total loss : 0.42624714970588684,  classifier :0.03511664643883705, mask: 0.1624160259962082 ===================
epoch no : 4, batch no : 47, total loss : 0.2896862030029297,  classifier :0.029174260795116425, mask: 0.14481143653392792 ===================
epoch no : 4, batch no : 48, total loss : 0.2776307761669159,  classifier :0.04499615728855133, mask: 0.1160457655787468 ===================
epoch no : 4, batch no : 49, total loss : 0.36539605259895325,  classifier :0.03532494604587555, mask: 0.12667924165725708 ===================
epoch no : 4, batch no : 50, total loss : 0.29853129386901855,  classifier :0.03059956803917885, mask: 0.13676175475120544 ===================
epoch no : 4, batch no : 51, total loss : 0.2895028293132782,  classifier :0.029882540926337242, mask: 0.1359790712594986 ===================
epoch no : 4, batch no : 52, total loss : 0.3758105933666229,  classifier :0.031805358827114105, mask: 0.15344107151031494 ===================
epoch no : 4, batch no : 53, total loss : 0.27491360902786255,  classifier :0.045073021203279495, mask: 0.12258541584014893 ===================
epoch no : 4, batch no : 54, total loss : 0.3819393515586853,  classifier :0.058781519532203674, mask: 0.1383385956287384 ===================
epoch no : 4, batch no : 55, total loss : 0.3190787434577942,  classifier :0.04189161956310272, mask: 0.12286868691444397 ===================
epoch no : 4, batch no : 56, total loss : 0.3526633381843567,  classifier :0.03618580847978592, mask: 0.13720041513442993 ===================
epoch no : 4, batch no : 57, total loss : 0.2637765407562256,  classifier :0.03840365260839462, mask: 0.1073947623372078 ===================
epoch no : 4, batch no : 58, total loss : 0.3078022599220276,  classifier :0.050502192229032516, mask: 0.13222457468509674 ===================
epoch no : 4, batch no : 59, total loss : 0.31405967473983765,  classifier :0.04419466853141785, mask: 0.12406554073095322 ===================
epoch no : 4, batch no : 60, total loss : 0.3197097182273865,  classifier :0.04682758077979088, mask: 0.14059357345104218 ===================
epoch no : 4, batch no : 61, total loss : 0.3091854453086853,  classifier :0.036581527441740036, mask: 0.11671467870473862 ===================
epoch no : 4, batch no : 62, total loss : 0.28082525730133057,  classifier :0.03317438066005707, mask: 0.12310751527547836 ===================
epoch no : 4, batch no : 63, total loss : 0.3488612473011017,  classifier :0.029402833431959152, mask: 0.12306957691907883 ===================
epoch no : 4, batch no : 64, total loss : 0.45832929015159607,  classifier :0.05666397884488106, mask: 0.15365247428417206 ===================
epoch no : 4, batch no : 65, total loss : 0.3204177916049957,  classifier :0.03446854650974274, mask: 0.1658533364534378 ===================
epoch no : 4, batch no : 66, total loss : 0.37493231892585754,  classifier :0.04879069700837135, mask: 0.15640871226787567 ===================
epoch no : 4, batch no : 67, total loss : 0.30902373790740967,  classifier :0.03702566772699356, mask: 0.1319822520017624 ===================
epoch no : 4, batch no : 68, total loss : 0.5202091932296753,  classifier :0.0524769127368927, mask: 0.17849934101104736 ===================
epoch no : 4, batch no : 69, total loss : 0.34565451741218567,  classifier :0.0332997664809227, mask: 0.13408489525318146 ===================
epoch no : 4, batch no : 70, total loss : 0.3464926779270172,  classifier :0.045379605144262314, mask: 0.13462133705615997 ===================
epoch no : 4, batch no : 71, total loss : 0.2779732942581177,  classifier :0.0553581565618515, mask: 0.10808093100786209 ===================
epoch no : 4, batch no : 72, total loss : 0.380947470664978,  classifier :0.03904696926474571, mask: 0.15930208563804626 ===================
epoch no : 4, batch no : 73, total loss : 0.25714683532714844,  classifier :0.05143040418624878, mask: 0.10210084915161133 ===================
epoch no : 4, batch no : 74, total loss : 0.27634841203689575,  classifier :0.03592928871512413, mask: 0.11815057694911957 ===================
epoch no : 4, batch no : 75, total loss : 0.24578237533569336,  classifier :0.02794259786605835, mask: 0.1076902225613594 ===================
epoch no : 4, batch no : 76, total loss : 0.36277589201927185,  classifier :0.05964038893580437, mask: 0.11011548340320587 ===================
epoch no : 4, batch no : 77, total loss : 0.30468034744262695,  classifier :0.04604048654437065, mask: 0.11387436091899872 ===================
epoch no : 4, batch no : 78, total loss : 0.25973787903785706,  classifier :0.03285858780145645, mask: 0.09201942384243011 ===================
epoch no : 4, batch no : 79, total loss : 0.26690930128097534,  classifier :0.04894685745239258, mask: 0.0958196297287941 ===================
epoch no : 4, batch no : 80, total loss : 0.33967748284339905,  classifier :0.033036261796951294, mask: 0.11830617487430573 ===================
epoch no : 4, batch no : 81, total loss : 0.44136306643486023,  classifier :0.042459886521101, mask: 0.17160089313983917 ===================
epoch no : 4, batch no : 82, total loss : 0.3928765654563904,  classifier :0.041053514927625656, mask: 0.15035909414291382 ===================
epoch no : 4, batch no : 83, total loss : 0.3104887306690216,  classifier :0.031575024127960205, mask: 0.11337046325206757 ===================
epoch no : 4, batch no : 84, total loss : 0.42779234051704407,  classifier :0.041027795523405075, mask: 0.19491392374038696 ===================
epoch no : 4, batch no : 85, total loss : 0.4993860721588135,  classifier :0.05341838300228119, mask: 0.16197232902050018 ===================
epoch no : 4, batch no : 86, total loss : 0.31808316707611084,  classifier :0.039627689868211746, mask: 0.13201993703842163 ===================
epoch no : 4, batch no : 87, total loss : 0.24138273298740387,  classifier :0.04125133156776428, mask: 0.10412076860666275 ===================
epoch no : 4, batch no : 88, total loss : 0.29080188274383545,  classifier :0.030642716214060783, mask: 0.12873727083206177 ===================
epoch no : 4, batch no : 89, total loss : 0.3089812099933624,  classifier :0.03182176873087883, mask: 0.13552819192409515 ===================
epoch no : 4, batch no : 90, total loss : 0.2743575870990753,  classifier :0.03421742841601372, mask: 0.12641732394695282 ===================
epoch no : 4, batch no : 91, total loss : 0.35813549160957336,  classifier :0.03448051959276199, mask: 0.15839757025241852 ===================
epoch no : 4, batch no : 92, total loss : 0.2742565870285034,  classifier :0.030941514298319817, mask: 0.10327789932489395 ===================
epoch no : 4, batch no : 93, total loss : 0.2908584773540497,  classifier :0.034622542560100555, mask: 0.11167971789836884 ===================
epoch no : 4, batch no : 94, total loss : 0.3658573627471924,  classifier :0.029808662831783295, mask: 0.15989133715629578 ===================
epoch no : 4, batch no : 95, total loss : 0.4243103563785553,  classifier :0.05240096524357796, mask: 0.17721228301525116 ===================
epoch no : 4, batch no : 96, total loss : 0.3030308187007904,  classifier :0.028081974014639854, mask: 0.14349572360515594 ===================
epoch no : 4, batch no : 97, total loss : 0.31022536754608154,  classifier :0.0325501374900341, mask: 0.13586671650409698 ===================
epoch no : 4, batch no : 98, total loss : 0.4023495018482208,  classifier :0.028625383973121643, mask: 0.15995711088180542 ===================
epoch no : 4, batch no : 99, total loss : 0.2300442010164261,  classifier :0.03390003740787506, mask: 0.09299001842737198 ===================
epoch no : 4, batch no : 100, total loss : 0.26059669256210327,  classifier :0.03853479400277138, mask: 0.10280267149209976 ===================
epoch no : 4, batch no : 101, total loss : 0.23290526866912842,  classifier :0.034409355372190475, mask: 0.09861116856336594 ===================
epoch no : 4, batch no : 102, total loss : 0.2572600543498993,  classifier :0.04586731269955635, mask: 0.09538242220878601 ===================
epoch no : 4, batch no : 103, total loss : 0.30129408836364746,  classifier :0.0377940833568573, mask: 0.12350089102983475 ===================
epoch no : 4, batch no : 104, total loss : 0.3071228563785553,  classifier :0.03158170357346535, mask: 0.13456158339977264 ===================
epoch no : 4, batch no : 105, total loss : 0.42949578166007996,  classifier :0.05184367299079895, mask: 0.1787983477115631 ===================
epoch no : 4, batch no : 106, total loss : 0.2603306174278259,  classifier :0.033316656947135925, mask: 0.10282618552446365 ===================
epoch no : 4, batch no : 107, total loss : 0.2902694344520569,  classifier :0.043567731976509094, mask: 0.09972274303436279 ===================
epoch no : 4, batch no : 108, total loss : 0.3118964433670044,  classifier :0.025302182883024216, mask: 0.1127891018986702 ===================
epoch no : 4, batch no : 109, total loss : 0.28812509775161743,  classifier :0.032818976789712906, mask: 0.1040731742978096 ===================
epoch no : 4, batch no : 110, total loss : 0.36543741822242737,  classifier :0.05399273335933685, mask: 0.12882111966609955 ===================
epoch no : 4, batch no : 111, total loss : 0.2611304223537445,  classifier :0.03218494728207588, mask: 0.10408218950033188 ===================
epoch no : 4, batch no : 112, total loss : 0.4529430866241455,  classifier :0.06667274236679077, mask: 0.1771947592496872 ===================
epoch no : 4, batch no : 113, total loss : 0.2657177448272705,  classifier :0.02745409496128559, mask: 0.1172579675912857 ===================
epoch no : 4, batch no : 114, total loss : 0.25153815746307373,  classifier :0.03429773449897766, mask: 0.10470710694789886 ===================
epoch no : 4, batch no : 115, total loss : 0.27444443106651306,  classifier :0.03069278597831726, mask: 0.10577196627855301 ===================
epoch no : 4, batch no : 116, total loss : 0.3093990981578827,  classifier :0.03435836732387543, mask: 0.1357395499944687 ===================
epoch no : 4, batch no : 117, total loss : 0.3410676121711731,  classifier :0.03674048185348511, mask: 0.11216279864311218 ===================
epoch no : 4, batch no : 118, total loss : 0.40616291761398315,  classifier :0.04267090559005737, mask: 0.1550866961479187 ===================
epoch no : 4, batch no : 119, total loss : 0.35303065180778503,  classifier :0.03318792209029198, mask: 0.15320996940135956 ===================
epoch no : 4, batch no : 120, total loss : 0.33196958899497986,  classifier :0.03202323988080025, mask: 0.14521223306655884 ===================
epoch no : 4, batch no : 121, total loss : 0.2838590145111084,  classifier :0.03879857435822487, mask: 0.11499644070863724 ===================
epoch no : 4, batch no : 122, total loss : 0.2905121445655823,  classifier :0.031214114278554916, mask: 0.12025903910398483 ===================
epoch no : 4, batch no : 123, total loss : 0.28188303112983704,  classifier :0.02333599515259266, mask: 0.15248842537403107 ===================
epoch no : 4, batch no : 124, total loss : 0.2929891049861908,  classifier :0.03015953116118908, mask: 0.12275063991546631 ===================
epoch no : 4, batch no : 125, total loss : 0.24059945344924927,  classifier :0.02447924204170704, mask: 0.10507373511791229 ===================
epoch no : 4, batch no : 126, total loss : 0.3339008390903473,  classifier :0.029774265363812447, mask: 0.14024201035499573 ===================
epoch no : 4, batch no : 127, total loss : 0.3515194356441498,  classifier :0.038528382778167725, mask: 0.13029535114765167 ===================
epoch no : 4, batch no : 128, total loss : 0.3449013829231262,  classifier :0.03631836920976639, mask: 0.14619073271751404 ===================
epoch no : 4, batch no : 129, total loss : 0.32226428389549255,  classifier :0.03927198052406311, mask: 0.1332317292690277 ===================
epoch no : 4, batch no : 130, total loss : 0.48496317863464355,  classifier :0.04434196278452873, mask: 0.15556320548057556 ===================
epoch no : 4, batch no : 131, total loss : 0.3784683048725128,  classifier :0.03599395602941513, mask: 0.1307385265827179 ===================
epoch no : 4, batch no : 132, total loss : 0.26895254850387573,  classifier :0.03742671385407448, mask: 0.14187073707580566 ===================
epoch no : 4, batch no : 133, total loss : 0.27776846289634705,  classifier :0.043750256299972534, mask: 0.10605926811695099 ===================
epoch no : 4, batch no : 134, total loss : 0.22874820232391357,  classifier :0.029836107045412064, mask: 0.09576720744371414 ===================
epoch no : 4, batch no : 135, total loss : 0.31740063428878784,  classifier :0.03168341889977455, mask: 0.11918280273675919 ===================
epoch no : 4, batch no : 136, total loss : 0.36977580189704895,  classifier :0.04837840795516968, mask: 0.13294276595115662 ===================
epoch no : 4, batch no : 137, total loss : 0.43066638708114624,  classifier :0.049963925033807755, mask: 0.17985454201698303 ===================
epoch no : 4, batch no : 138, total loss : 0.34673622250556946,  classifier :0.0337926484644413, mask: 0.1424301117658615 ===================
epoch no : 4, batch no : 139, total loss : 0.3702711760997772,  classifier :0.036754027009010315, mask: 0.1165810227394104 ===================
epoch no : 4, batch no : 140, total loss : 0.37088438868522644,  classifier :0.04179926961660385, mask: 0.11642704159021378 ===================
epoch no : 4, batch no : 141, total loss : 0.3187110424041748,  classifier :0.0334797240793705, mask: 0.12450701743364334 ===================
epoch no : 4, batch no : 142, total loss : 0.3256562054157257,  classifier :0.042593229562044144, mask: 0.11708425730466843 ===================
epoch no : 4, batch no : 143, total loss : 0.355297327041626,  classifier :0.05607954040169716, mask: 0.15201549232006073 ===================
epoch no : 4, batch no : 144, total loss : 0.40452075004577637,  classifier :0.04748404026031494, mask: 0.1687602400779724 ===================
epoch no : 4, batch no : 145, total loss : 0.37658560276031494,  classifier :0.04710427299141884, mask: 0.1432931125164032 ===================
epoch no : 4, batch no : 146, total loss : 0.49086856842041016,  classifier :0.06431279331445694, mask: 0.20697811245918274 ===================
epoch no : 4, batch no : 147, total loss : 0.25375914573669434,  classifier :0.04943542554974556, mask: 0.09724398702383041 ===================
epoch no : 4, batch no : 148, total loss : 0.3042088449001312,  classifier :0.0449901781976223, mask: 0.12220039963722229 ===================
epoch no : 4, batch no : 149, total loss : 0.35966193675994873,  classifier :0.05849580094218254, mask: 0.12114731967449188 ===================
epoch no : 4, batch no : 150, total loss : 0.32665789127349854,  classifier :0.040718238800764084, mask: 0.14324989914894104 ===================
epoch no : 4, batch no : 151, total loss : 0.36157846450805664,  classifier :0.03878243267536163, mask: 0.15481968224048615 ===================
epoch no : 4, batch no : 152, total loss : 0.37007325887680054,  classifier :0.04109145328402519, mask: 0.15354672074317932 ===================
epoch no : 4, batch no : 153, total loss : 0.26462841033935547,  classifier :0.03488476946949959, mask: 0.10336649417877197 ===================
epoch no : 4, batch no : 154, total loss : 0.34652289748191833,  classifier :0.04289489984512329, mask: 0.12666666507720947 ===================
epoch no : 4, batch no : 155, total loss : 0.3388241231441498,  classifier :0.036965012550354004, mask: 0.12641212344169617 ===================
epoch no : 4, batch no : 156, total loss : 0.34781867265701294,  classifier :0.03291274607181549, mask: 0.14526301622390747 ===================
epoch no : 4, batch no : 157, total loss : 0.3637487590312958,  classifier :0.034010015428066254, mask: 0.12140119075775146 ===================
epoch no : 4, batch no : 158, total loss : 0.3564011752605438,  classifier :0.034257903695106506, mask: 0.14946609735488892 ===================
epoch no : 4, batch no : 159, total loss : 0.2572445273399353,  classifier :0.030086195096373558, mask: 0.11427972465753555 ===================
epoch no : 4, batch no : 160, total loss : 0.2669757306575775,  classifier :0.04067803919315338, mask: 0.10374078154563904 ===================
epoch no : 4, batch no : 161, total loss : 0.2905244827270508,  classifier :0.029792388901114464, mask: 0.14804162085056305 ===================
epoch no : 4, batch no : 162, total loss : 0.2670259475708008,  classifier :0.04047933593392372, mask: 0.11104914546012878 ===================
epoch no : 4, batch no : 163, total loss : 0.23685771226882935,  classifier :0.03792153298854828, mask: 0.09762764722108841 ===================
epoch no : 4, batch no : 164, total loss : 0.3440079092979431,  classifier :0.024307619780302048, mask: 0.15340721607208252 ===================
epoch no : 4, batch no : 165, total loss : 0.364654004573822,  classifier :0.05889180675148964, mask: 0.13583563268184662 ===================
epoch no : 4, batch no : 166, total loss : 0.33366477489471436,  classifier :0.046422168612480164, mask: 0.14863157272338867 ===================
epoch no : 4, batch no : 167, total loss : 0.3356834053993225,  classifier :0.03299080207943916, mask: 0.14083972573280334 ===================
epoch no : 4, batch no : 168, total loss : 0.3874858021736145,  classifier :0.04210177809000015, mask: 0.15372928977012634 ===================
epoch no : 4, batch no : 169, total loss : 0.44637584686279297,  classifier :0.04088209569454193, mask: 0.23181873559951782 ===================
epoch no : 4, batch no : 170, total loss : 0.3773519694805145,  classifier :0.04613037407398224, mask: 0.14057905972003937 ===================
epoch no : 4, batch no : 171, total loss : 0.423130601644516,  classifier :0.04212445020675659, mask: 0.1570155769586563 ===================
epoch no : 4, batch no : 172, total loss : 0.3715769648551941,  classifier :0.04671711474657059, mask: 0.14463195204734802 ===================
epoch no : 4, batch no : 173, total loss : 0.3240489363670349,  classifier :0.03085194155573845, mask: 0.11949284374713898 ===================
epoch no : 4, batch no : 174, total loss : 0.3419516086578369,  classifier :0.053201474249362946, mask: 0.11738047003746033 ===================
epoch no : 4, batch no : 175, total loss : 0.2748604416847229,  classifier :0.035570576786994934, mask: 0.10762715339660645 ===================
epoch no : 4, batch no : 176, total loss : 0.33165666460990906,  classifier :0.02969210594892502, mask: 0.14744997024536133 ===================
epoch no : 4, batch no : 177, total loss : 0.3559653162956238,  classifier :0.046483974903821945, mask: 0.14141292870044708 ===================
epoch no : 4, batch no : 178, total loss : 0.24403953552246094,  classifier :0.033774565905332565, mask: 0.08617376536130905 ===================
epoch no : 4, batch no : 179, total loss : 0.2791358232498169,  classifier :0.03812585771083832, mask: 0.12457873672246933 ===================
epoch no : 4, batch no : 180, total loss : 0.29973071813583374,  classifier :0.03653626888990402, mask: 0.11556798964738846 ===================
epoch no : 4, batch no : 181, total loss : 0.3382219970226288,  classifier :0.03442763537168503, mask: 0.13811974227428436 ===================
epoch no : 4, batch no : 182, total loss : 0.3608781695365906,  classifier :0.039175357669591904, mask: 0.14477716386318207 ===================
epoch no : 4, batch no : 183, total loss : 0.3186526298522949,  classifier :0.028229212388396263, mask: 0.11732613295316696 ===================
epoch no : 4, batch no : 184, total loss : 0.31122463941574097,  classifier :0.04258504509925842, mask: 0.12207598984241486 ===================
epoch no : 4, batch no : 185, total loss : 0.42460834980010986,  classifier :0.05934130772948265, mask: 0.17188760638237 ===================
epoch no : 4, batch no : 186, total loss : 0.30303117632865906,  classifier :0.04166771098971367, mask: 0.11089015007019043 ===================
epoch no : 4, batch no : 187, total loss : 0.3331800401210785,  classifier :0.03224608674645424, mask: 0.09785974025726318 ===================
epoch no : 4, batch no : 188, total loss : 0.2864939868450165,  classifier :0.04059586301445961, mask: 0.1019887775182724 ===================
epoch no : 4, batch no : 189, total loss : 0.3433072566986084,  classifier :0.02637474425137043, mask: 0.12188876420259476 ===================
epoch no : 4, batch no : 190, total loss : 0.34132078289985657,  classifier :0.030253684148192406, mask: 0.1544388085603714 ===================
epoch no : 4, batch no : 191, total loss : 0.2923688590526581,  classifier :0.027194228023290634, mask: 0.13726194202899933 ===================
epoch no : 4, batch no : 192, total loss : 0.2737133204936981,  classifier :0.02893892675638199, mask: 0.12420014292001724 ===================
epoch no : 4, batch no : 193, total loss : 0.4071314334869385,  classifier :0.05757616460323334, mask: 0.14683043956756592 ===================
epoch no : 4, batch no : 194, total loss : 0.38857364654541016,  classifier :0.03839196637272835, mask: 0.17083151638507843 ===================
epoch no : 4, batch no : 195, total loss : 0.3472515344619751,  classifier :0.03148936480283737, mask: 0.1532658040523529 ===================
epoch no : 4, batch no : 196, total loss : 0.3326244056224823,  classifier :0.03713156655430794, mask: 0.1311507523059845 ===================
epoch no : 4, batch no : 197, total loss : 0.2800273597240448,  classifier :0.04179350286722183, mask: 0.12080874294042587 ===================
epoch no : 4, batch no : 198, total loss : 0.29431554675102234,  classifier :0.037032514810562134, mask: 0.11104294657707214 ===================
epoch no : 4, batch no : 199, total loss : 0.30228400230407715,  classifier :0.0322604663670063, mask: 0.13018178939819336 ===================
epoch no : 4, batch no : 200, total loss : 0.2618345320224762,  classifier :0.039920538663864136, mask: 0.10185975581407547 ===================
epoch no : 4, batch no : 201, total loss : 0.25820356607437134,  classifier :0.027051081880927086, mask: 0.11774608492851257 ===================
epoch no : 4, batch no : 202, total loss : 0.2734193503856659,  classifier :0.02786330133676529, mask: 0.1142546609044075 ===================
epoch no : 4, batch no : 203, total loss : 0.301828533411026,  classifier :0.029444651678204536, mask: 0.12858153879642487 ===================
epoch no : 4, batch no : 204, total loss : 0.2999863922595978,  classifier :0.048673782497644424, mask: 0.12442688643932343 ===================
epoch no : 4, batch no : 205, total loss : 0.3298836052417755,  classifier :0.030775168910622597, mask: 0.13885021209716797 ===================
epoch no : 4, batch no : 206, total loss : 0.2647448480129242,  classifier :0.03826552629470825, mask: 0.10608189553022385 ===================
epoch no : 4, batch no : 207, total loss : 0.3129512071609497,  classifier :0.03472594916820526, mask: 0.11845579743385315 ===================
epoch no : 4, batch no : 208, total loss : 0.2822880446910858,  classifier :0.03569400683045387, mask: 0.12767009437084198 ===================
epoch no : 4, batch no : 209, total loss : 0.2808340787887573,  classifier :0.028700191527605057, mask: 0.11691451817750931 ===================
epoch no : 4, batch no : 210, total loss : 0.2719065248966217,  classifier :0.0391295850276947, mask: 0.10688941925764084 ===================
epoch no : 4, batch no : 211, total loss : 0.2891613245010376,  classifier :0.033167045563459396, mask: 0.10859809815883636 ===================
epoch no : 4, batch no : 212, total loss : 0.2516990303993225,  classifier :0.03544628247618675, mask: 0.11480612307786942 ===================
epoch no : 4, batch no : 213, total loss : 0.36328092217445374,  classifier :0.058319900184869766, mask: 0.15020087361335754 ===================
epoch no : 4, batch no : 214, total loss : 0.23151575028896332,  classifier :0.032582156360149384, mask: 0.10186800360679626 ===================
epoch no : 4, batch no : 215, total loss : 0.2742323875427246,  classifier :0.030940894037485123, mask: 0.14463339745998383 ===================
epoch no : 4, batch no : 216, total loss : 0.30381008982658386,  classifier :0.04991651326417923, mask: 0.13617351651191711 ===================
epoch no : 4, batch no : 217, total loss : 0.26268744468688965,  classifier :0.026738189160823822, mask: 0.13005034625530243 ===================
epoch no : 4, batch no : 218, total loss : 0.2999400496482849,  classifier :0.03088977560400963, mask: 0.12662039697170258 ===================
epoch no : 4, batch no : 219, total loss : 0.3488541543483734,  classifier :0.042237788438797, mask: 0.13230735063552856 ===================
epoch no : 4, batch no : 220, total loss : 0.30296754837036133,  classifier :0.03006492368876934, mask: 0.12518873810768127 ===================
epoch no : 4, batch no : 221, total loss : 0.33303773403167725,  classifier :0.04592236131429672, mask: 0.1248297393321991 ===================
epoch no : 4, batch no : 222, total loss : 0.37744253873825073,  classifier :0.0320739820599556, mask: 0.15308958292007446 ===================
epoch no : 4, batch no : 223, total loss : 0.29431894421577454,  classifier :0.033382806926965714, mask: 0.14554597437381744 ===================
epoch no : 4, batch no : 224, total loss : 0.35328564047813416,  classifier :0.029702119529247284, mask: 0.17227424681186676 ===================
epoch no : 4, batch no : 225, total loss : 0.27882570028305054,  classifier :0.02978145144879818, mask: 0.10375190526247025 ===================
epoch no : 4, batch no : 226, total loss : 0.254215270280838,  classifier :0.032647691667079926, mask: 0.11022923141717911 ===================
epoch no : 4, batch no : 227, total loss : 0.2853819727897644,  classifier :0.04341030493378639, mask: 0.1254776418209076 ===================
epoch no : 4, batch no : 228, total loss : 0.32367774844169617,  classifier :0.033097729086875916, mask: 0.16962172091007233 ===================
epoch no : 4, batch no : 229, total loss : 0.3563922643661499,  classifier :0.03872444108128548, mask: 0.14612451195716858 ===================
epoch no : 4, batch no : 230, total loss : 0.3356066346168518,  classifier :0.04635424539446831, mask: 0.14156830310821533 ===================
epoch no : 4, batch no : 231, total loss : 0.3349641263484955,  classifier :0.029243899509310722, mask: 0.1406349092721939 ===================
epoch no : 4, batch no : 232, total loss : 0.3282720446586609,  classifier :0.04490678384900093, mask: 0.14575842022895813 ===================
epoch no : 4, batch no : 233, total loss : 0.32141563296318054,  classifier :0.030101943761110306, mask: 0.13569316267967224 ===================
epoch no : 4, batch no : 234, total loss : 0.30014339089393616,  classifier :0.03358155116438866, mask: 0.12105225026607513 ===================
epoch no : 4, batch no : 235, total loss : 0.2659788131713867,  classifier :0.03193104267120361, mask: 0.10786132514476776 ===================
epoch no : 4, batch no : 236, total loss : 0.27303287386894226,  classifier :0.0393262580037117, mask: 0.09925780445337296 ===================
epoch no : 4, batch no : 237, total loss : 0.35445860028266907,  classifier :0.05101174861192703, mask: 0.15817265212535858 ===================
epoch no : 4, batch no : 238, total loss : 0.2310025542974472,  classifier :0.041876956820487976, mask: 0.09477915614843369 ===================
epoch no : 4, batch no : 239, total loss : 0.33797356486320496,  classifier :0.052743636071681976, mask: 0.131227508187294 ===================
epoch no : 4, batch no : 240, total loss : 0.3239400088787079,  classifier :0.043818674981594086, mask: 0.13549132645130157 ===================
epoch no : 4, batch no : 241, total loss : 0.42072197794914246,  classifier :0.047582630068063736, mask: 0.16192592680454254 ===================
epoch no : 4, batch no : 242, total loss : 0.3147190511226654,  classifier :0.04012024775147438, mask: 0.1108398288488388 ===================
epoch no : 4, batch no : 243, total loss : 0.3087608218193054,  classifier :0.039606787264347076, mask: 0.11254585534334183 ===================
epoch no : 4, batch no : 244, total loss : 0.3076920211315155,  classifier :0.026104388758540154, mask: 0.1238078698515892 ===================
epoch no : 4, batch no : 245, total loss : 0.4059430956840515,  classifier :0.03900176286697388, mask: 0.1770583540201187 ===================
epoch no : 4, batch no : 246, total loss : 0.4943981170654297,  classifier :0.04949222132563591, mask: 0.18982018530368805 ===================
epoch no : 4, batch no : 247, total loss : 0.41719329357147217,  classifier :0.037539612501859665, mask: 0.17863526940345764 ===================
epoch no : 4, batch no : 248, total loss : 0.31484296917915344,  classifier :0.03338147699832916, mask: 0.13164366781711578 ===================
epoch no : 4, batch no : 249, total loss : 0.33614587783813477,  classifier :0.03070000931620598, mask: 0.14202004671096802 ===================
epoch no : 4, batch no : 250, total loss : 0.24416705965995789,  classifier :0.037577755749225616, mask: 0.10298802703619003 ===================
epoch no : 4, batch no : 251, total loss : 0.32006046175956726,  classifier :0.03156806528568268, mask: 0.1362028867006302 ===================
epoch no : 4, batch no : 252, total loss : 0.31341636180877686,  classifier :0.030117163434624672, mask: 0.12422511726617813 ===================
epoch no : 4, batch no : 253, total loss : 0.36831581592559814,  classifier :0.04830775782465935, mask: 0.14977477490901947 ===================
epoch no : 4, batch no : 254, total loss : 0.2648056447505951,  classifier :0.03629840910434723, mask: 0.11280141770839691 ===================
epoch no : 4, batch no : 255, total loss : 0.4114113450050354,  classifier :0.03341927006840706, mask: 0.14445704221725464 ===================
epoch no : 4, batch no : 256, total loss : 0.28583088517189026,  classifier :0.02792554534971714, mask: 0.11657775938510895 ===================
epoch no : 4, batch no : 257, total loss : 0.29440706968307495,  classifier :0.026178531348705292, mask: 0.1208370104432106 ===================
epoch no : 4, batch no : 258, total loss : 0.3169330954551697,  classifier :0.04092033579945564, mask: 0.12515151500701904 ===================
epoch no : 4, batch no : 259, total loss : 0.28325751423835754,  classifier :0.02588077448308468, mask: 0.10745155811309814 ===================
epoch no : 4, batch no : 260, total loss : 0.2848648130893707,  classifier :0.026515718549489975, mask: 0.11825120449066162 ===================
epoch no : 4, batch no : 261, total loss : 0.29879891872406006,  classifier :0.03368059918284416, mask: 0.11786026507616043 ===================
epoch no : 4, batch no : 262, total loss : 0.24489299952983856,  classifier :0.03645914047956467, mask: 0.10800697654485703 ===================
epoch no : 4, batch no : 263, total loss : 0.3125517666339874,  classifier :0.029758986085653305, mask: 0.13007648289203644 ===================
epoch no : 4, batch no : 264, total loss : 0.2654082179069519,  classifier :0.03817830979824066, mask: 0.09501716494560242 ===================
epoch no : 4, batch no : 265, total loss : 0.31964150071144104,  classifier :0.04188937693834305, mask: 0.12600603699684143 ===================
epoch no : 4, batch no : 266, total loss : 0.2984831929206848,  classifier :0.04248938709497452, mask: 0.11116184294223785 ===================
epoch no : 4, batch no : 267, total loss : 0.27447593212127686,  classifier :0.03108939155936241, mask: 0.11522895842790604 ===================
epoch no : 4, batch no : 268, total loss : 0.26929208636283875,  classifier :0.04110069200396538, mask: 0.09339930862188339 ===================
epoch no : 4, batch no : 269, total loss : 0.310022234916687,  classifier :0.028824590146541595, mask: 0.11090513318777084 ===================
epoch no : 4, batch no : 270, total loss : 0.31016895174980164,  classifier :0.03537210449576378, mask: 0.13597382605075836 ===================
epoch no : 4, batch no : 271, total loss : 0.2586183547973633,  classifier :0.040995314717292786, mask: 0.10254643112421036 ===================
epoch no : 4, batch no : 272, total loss : 0.30562397837638855,  classifier :0.03525131195783615, mask: 0.13485302031040192 ===================
epoch no : 4, batch no : 273, total loss : 0.36149534583091736,  classifier :0.02602136880159378, mask: 0.13948246836662292 ===================
epoch no : 4, batch no : 274, total loss : 0.4736135005950928,  classifier :0.044235821813344955, mask: 0.1676783561706543 ===================
epoch no : 4, batch no : 275, total loss : 0.2794567942619324,  classifier :0.031069440767169, mask: 0.12371066957712173 ===================
epoch no : 4, batch no : 276, total loss : 0.2947222590446472,  classifier :0.03932882472872734, mask: 0.11485099047422409 ===================
epoch no : 4, batch no : 277, total loss : 0.32379305362701416,  classifier :0.03579997271299362, mask: 0.15268823504447937 ===================
epoch no : 4, batch no : 278, total loss : 0.29752105474472046,  classifier :0.03165142610669136, mask: 0.1206246018409729 ===================
epoch no : 4, batch no : 279, total loss : 0.29462021589279175,  classifier :0.03180103376507759, mask: 0.12118364870548248 ===================
epoch no : 4, batch no : 280, total loss : 0.28760865330696106,  classifier :0.02910429984331131, mask: 0.11602690070867538 ===================
epoch no : 4, batch no : 281, total loss : 0.38955727219581604,  classifier :0.0476163849234581, mask: 0.17605312168598175 ===================
epoch no : 4, batch no : 282, total loss : 0.3914746344089508,  classifier :0.03160355985164642, mask: 0.14674940705299377 ===================
epoch no : 4, batch no : 283, total loss : 0.4401750862598419,  classifier :0.048385657370090485, mask: 0.17307281494140625 ===================
epoch no : 4, batch no : 284, total loss : 0.31153053045272827,  classifier :0.047096360474824905, mask: 0.11788181215524673 ===================
epoch no : 4, batch no : 285, total loss : 0.34921300411224365,  classifier :0.051499709486961365, mask: 0.11661629378795624 ===================
epoch no : 4, batch no : 286, total loss : 0.3020496368408203,  classifier :0.03181784600019455, mask: 0.11919217556715012 ===================
epoch no : 4, batch no : 287, total loss : 0.25013166666030884,  classifier :0.03900910168886185, mask: 0.10315223783254623 ===================
epoch no : 4, batch no : 288, total loss : 0.30396097898483276,  classifier :0.021073199808597565, mask: 0.1266506165266037 ===================
epoch no : 4, batch no : 289, total loss : 0.4190655052661896,  classifier :0.054127540439367294, mask: 0.13945573568344116 ===================
epoch no : 4, batch no : 290, total loss : 0.2709013819694519,  classifier :0.031729526817798615, mask: 0.10590830445289612 ===================
epoch no : 4, batch no : 291, total loss : 0.28068143129348755,  classifier :0.03574245423078537, mask: 0.11844772845506668 ===================
epoch no : 4, batch no : 292, total loss : 0.30411162972450256,  classifier :0.03232160210609436, mask: 0.1565033197402954 ===================
epoch no : 4, batch no : 293, total loss : 0.3234022557735443,  classifier :0.03212327882647514, mask: 0.12835313379764557 ===================
epoch no : 4, batch no : 294, total loss : 0.2787841260433197,  classifier :0.030432764440774918, mask: 0.12686994671821594 ===================
epoch no : 4, batch no : 295, total loss : 0.23688344657421112,  classifier :0.029455842450261116, mask: 0.11616746336221695 ===================
epoch no : 4, batch no : 296, total loss : 0.2637515962123871,  classifier :0.0328778512775898, mask: 0.10367639362812042 ===================
epoch no : 4, batch no : 297, total loss : 0.23577114939689636,  classifier :0.032878320664167404, mask: 0.09148212522268295 ===================
epoch no : 4, batch no : 298, total loss : 0.3446497619152069,  classifier :0.04955407232046127, mask: 0.11411720514297485 ===================
epoch no : 4, batch no : 299, total loss : 0.3396352231502533,  classifier :0.03803069889545441, mask: 0.12727457284927368 ===================
epoch no : 4, batch no : 300, total loss : 0.36201778054237366,  classifier :0.04443581402301788, mask: 0.12275490164756775 ===================
epoch no : 4, batch no : 301, total loss : 0.30564790964126587,  classifier :0.02772757224738598, mask: 0.12790489196777344 ===================
epoch no : 4, batch no : 302, total loss : 0.3473408818244934,  classifier :0.04093810170888901, mask: 0.14583562314510345 ===================
epoch no : 4, batch no : 303, total loss : 0.3233921229839325,  classifier :0.03565651550889015, mask: 0.12385249137878418 ===================
epoch no : 4, batch no : 304, total loss : 0.41219332814216614,  classifier :0.02936442568898201, mask: 0.1700502634048462 ===================
epoch no : 4, batch no : 305, total loss : 0.31644657254219055,  classifier :0.033623214811086655, mask: 0.12255894392728806 ===================
epoch no : 4, batch no : 306, total loss : 0.35278332233428955,  classifier :0.037124838680028915, mask: 0.13479696214199066 ===================
epoch no : 4, batch no : 307, total loss : 0.35477307438850403,  classifier :0.03406623750925064, mask: 0.1498185247182846 ===================
epoch no : 4, batch no : 308, total loss : 0.25717952847480774,  classifier :0.038485944271087646, mask: 0.08394356817007065 ===================
epoch no : 4, batch no : 309, total loss : 0.33139267563819885,  classifier :0.030342603102326393, mask: 0.15425235033035278 ===================
epoch no : 4, batch no : 310, total loss : 0.3743404746055603,  classifier :0.025010470300912857, mask: 0.22087498009204865 ===================
epoch no : 4, batch no : 311, total loss : 0.556533694267273,  classifier :0.0443355068564415, mask: 0.26347509026527405 ===================
epoch no : 4, batch no : 312, total loss : 0.3702661693096161,  classifier :0.039332956075668335, mask: 0.17889726161956787 ===================
epoch no : 4, batch no : 313, total loss : 0.32399749755859375,  classifier :0.033186763525009155, mask: 0.14362509548664093 ===================
epoch no : 4, batch no : 314, total loss : 0.3227056860923767,  classifier :0.04757106304168701, mask: 0.12224786728620529 ===================
epoch no : 4, batch no : 315, total loss : 0.30225101113319397,  classifier :0.04224842041730881, mask: 0.12343376129865646 ===================
epoch no : 4, batch no : 316, total loss : 0.3457110822200775,  classifier :0.03099299781024456, mask: 0.1309206187725067 ===================
epoch no : 4, batch no : 317, total loss : 0.3049817979335785,  classifier :0.029974456876516342, mask: 0.12429080903530121 ===================
epoch no : 4, batch no : 318, total loss : 0.3122509717941284,  classifier :0.03598016873002052, mask: 0.14876241981983185 ===================
epoch no : 4, batch no : 319, total loss : 0.39738601446151733,  classifier :0.038394249975681305, mask: 0.14173638820648193 ===================
epoch no : 4, batch no : 320, total loss : 0.42071419954299927,  classifier :0.03544583544135094, mask: 0.15933579206466675 ===================
epoch no : 4, batch no : 321, total loss : 0.26313209533691406,  classifier :0.028426937758922577, mask: 0.11329200863838196 ===================
epoch no : 4, batch no : 322, total loss : 0.2908192276954651,  classifier :0.04057468846440315, mask: 0.12648414075374603 ===================
epoch no : 4, batch no : 323, total loss : 0.35304710268974304,  classifier :0.038662634789943695, mask: 0.15401004254817963 ===================
epoch no : 4, batch no : 324, total loss : 0.2759338617324829,  classifier :0.030041886493563652, mask: 0.1130116656422615 ===================
epoch no : 4, batch no : 325, total loss : 0.30742424726486206,  classifier :0.039528533816337585, mask: 0.1108902171254158 ===================
epoch no : 4, batch no : 326, total loss : 0.26362287998199463,  classifier :0.036191970109939575, mask: 0.11038719862699509 ===================
epoch no : 4, batch no : 327, total loss : 0.28178566694259644,  classifier :0.033397119492292404, mask: 0.0973680317401886 ===================
epoch no : 4, batch no : 328, total loss : 0.31119298934936523,  classifier :0.037906464189291, mask: 0.1150490790605545 ===================
epoch no : 4, batch no : 329, total loss : 0.3066902756690979,  classifier :0.03541639447212219, mask: 0.11190856993198395 ===================
epoch no : 4, batch no : 330, total loss : 0.3032769560813904,  classifier :0.02621900476515293, mask: 0.1390530914068222 ===================
epoch no : 4, batch no : 331, total loss : 0.30768606066703796,  classifier :0.04216500744223595, mask: 0.13385072350502014 ===================
epoch no : 4, batch no : 332, total loss : 0.26809781789779663,  classifier :0.03340711444616318, mask: 0.12148787081241608 ===================
epoch no : 4, batch no : 333, total loss : 0.3216365873813629,  classifier :0.03427080437541008, mask: 0.13771402835845947 ===================
epoch no : 4, batch no : 334, total loss : 0.3724552094936371,  classifier :0.057314686477184296, mask: 0.13248057663440704 ===================
epoch no : 4, batch no : 335, total loss : 0.26484107971191406,  classifier :0.026645204052329063, mask: 0.10433562844991684 ===================
epoch no : 4, batch no : 336, total loss : 0.3458843529224396,  classifier :0.03230811282992363, mask: 0.1384173482656479 ===================
epoch no : 4, batch no : 337, total loss : 0.37575528025627136,  classifier :0.03780319169163704, mask: 0.1759173721075058 ===================
epoch no : 4, batch no : 338, total loss : 0.30012843012809753,  classifier :0.031477417796850204, mask: 0.12340008467435837 ===================
epoch no : 4, batch no : 339, total loss : 0.27778324484825134,  classifier :0.03890896961092949, mask: 0.1157078742980957 ===================
epoch no : 4, batch no : 340, total loss : 0.24942603707313538,  classifier :0.031847648322582245, mask: 0.09650208055973053 ===================
epoch no : 4, batch no : 341, total loss : 0.36240947246551514,  classifier :0.0472690612077713, mask: 0.13429845869541168 ===================
epoch no : 4, batch no : 342, total loss : 0.2780188322067261,  classifier :0.03056410886347294, mask: 0.12104456126689911 ===================
epoch no : 4, batch no : 343, total loss : 0.33136624097824097,  classifier :0.04126688838005066, mask: 0.14113064110279083 ===================
epoch no : 4, batch no : 344, total loss : 0.26487165689468384,  classifier :0.027829157188534737, mask: 0.10899105668067932 ===================
epoch no : 4, batch no : 345, total loss : 0.33990737795829773,  classifier :0.029347863048315048, mask: 0.12003234028816223 ===================
epoch no : 4, batch no : 346, total loss : 0.2722836434841156,  classifier :0.034746818244457245, mask: 0.1065262109041214 ===================
epoch no : 4, batch no : 347, total loss : 0.33031168580055237,  classifier :0.04798677936196327, mask: 0.13012593984603882 ===================
epoch no : 4, batch no : 348, total loss : 0.32881054282188416,  classifier :0.03153236582875252, mask: 0.14409218728542328 ===================
epoch no : 4, batch no : 349, total loss : 0.42778438329696655,  classifier :0.04803156480193138, mask: 0.18746067583560944 ===================
epoch no : 4, batch no : 350, total loss : 0.6655025482177734,  classifier :0.06870454549789429, mask: 0.36015647649765015 ===================
epoch no : 4, batch no : 351, total loss : 0.5945925116539001,  classifier :0.08906423300504684, mask: 0.27253153920173645 ===================
epoch no : 4, batch no : 352, total loss : 0.4181109070777893,  classifier :0.03360152617096901, mask: 0.20214655995368958 ===================
epoch no : 4, batch no : 353, total loss : 0.41107580065727234,  classifier :0.052450116723775864, mask: 0.15878134965896606 ===================
epoch no : 4, batch no : 354, total loss : 0.2937011122703552,  classifier :0.030139749869704247, mask: 0.13096719980239868 ===================
epoch no : 4, batch no : 355, total loss : 0.3623947501182556,  classifier :0.039867911487817764, mask: 0.14880019426345825 ===================
epoch no : 4, batch no : 356, total loss : 0.3875395357608795,  classifier :0.0487789660692215, mask: 0.17722150683403015 ===================
epoch no : 4, batch no : 357, total loss : 0.44953128695487976,  classifier :0.058464184403419495, mask: 0.18888753652572632 ===================
epoch no : 4, batch no : 358, total loss : 0.37190186977386475,  classifier :0.04067022353410721, mask: 0.1431964784860611 ===================
epoch no : 4, batch no : 359, total loss : 0.3043740689754486,  classifier :0.03242684155702591, mask: 0.12109403312206268 ===================
epoch no : 4, batch no : 360, total loss : 0.2572816014289856,  classifier :0.03424772620201111, mask: 0.10251224786043167 ===================
epoch no : 4, batch no : 361, total loss : 0.3209686875343323,  classifier :0.03738204017281532, mask: 0.11880116909742355 ===================
epoch no : 4, batch no : 362, total loss : 0.32437458634376526,  classifier :0.047609519213438034, mask: 0.12502619624137878 ===================
epoch no : 4, batch no : 363, total loss : 0.30512112379074097,  classifier :0.0403716079890728, mask: 0.11293254047632217 ===================
epoch no : 4, batch no : 364, total loss : 0.25345054268836975,  classifier :0.02578476443886757, mask: 0.09972278773784637 ===================
epoch no : 4, batch no : 365, total loss : 0.29448339343070984,  classifier :0.03375551849603653, mask: 0.11332173645496368 ===================
epoch no : 4, batch no : 366, total loss : 0.4159325957298279,  classifier :0.043909408152103424, mask: 0.17291304469108582 ===================
epoch no : 4, batch no : 367, total loss : 0.28021812438964844,  classifier :0.030089670792222023, mask: 0.12796065211296082 ===================
epoch no : 4, batch no : 368, total loss : 0.26941415667533875,  classifier :0.0281035378575325, mask: 0.11903829127550125 ===================
epoch no : 4, batch no : 369, total loss : 0.3466549813747406,  classifier :0.04790069907903671, mask: 0.12369604408740997 ===================
epoch no : 4, batch no : 370, total loss : 0.29628241062164307,  classifier :0.03686083108186722, mask: 0.10604044049978256 ===================
epoch no : 4, batch no : 371, total loss : 0.3592025637626648,  classifier :0.033212896436452866, mask: 0.14991255104541779 ===================
epoch no : 4, batch no : 372, total loss : 0.2898746132850647,  classifier :0.028186263516545296, mask: 0.15156462788581848 ===================
epoch no : 4, batch no : 373, total loss : 0.34659355878829956,  classifier :0.03586919605731964, mask: 0.13705851137638092 ===================
epoch no : 4, batch no : 374, total loss : 0.3340836465358734,  classifier :0.03302060067653656, mask: 0.1332019418478012 ===================
epoch no : 4, batch no : 375, total loss : 0.4072886109352112,  classifier :0.04749652370810509, mask: 0.1457897424697876 ===================
epoch no : 4, batch no : 376, total loss : 0.3028101325035095,  classifier :0.032966431230306625, mask: 0.11087202280759811 ===================
epoch no : 4, batch no : 377, total loss : 0.25775235891342163,  classifier :0.03933506831526756, mask: 0.10268246382474899 ===================
epoch no : 4, batch no : 378, total loss : 0.29831820726394653,  classifier :0.02986348606646061, mask: 0.1187172532081604 ===================
epoch no : 4, batch no : 379, total loss : 0.25507473945617676,  classifier :0.028054075315594673, mask: 0.11877674609422684 ===================
epoch no : 4, batch no : 380, total loss : 0.33189406991004944,  classifier :0.03087533265352249, mask: 0.13967810571193695 ===================
epoch no : 4, batch no : 381, total loss : 0.24656005203723907,  classifier :0.03267670422792435, mask: 0.10046153515577316 ===================
epoch no : 4, batch no : 382, total loss : 0.32391804456710815,  classifier :0.049162156879901886, mask: 0.11235931515693665 ===================
epoch no : 4, batch no : 383, total loss : 0.2824742794036865,  classifier :0.03344997763633728, mask: 0.10707607865333557 ===================
epoch no : 4, batch no : 384, total loss : 0.3298201560974121,  classifier :0.03034316934645176, mask: 0.11673031002283096 ===================
epoch no : 4, batch no : 385, total loss : 0.38584375381469727,  classifier :0.03518292307853699, mask: 0.148534893989563 ===================
epoch no : 4, batch no : 386, total loss : 0.2875520884990692,  classifier :0.029743414372205734, mask: 0.14537492394447327 ===================
epoch no : 4, batch no : 387, total loss : 0.2728480100631714,  classifier :0.03032471053302288, mask: 0.11256084591150284 ===================
epoch no : 4, batch no : 388, total loss : 0.27036774158477783,  classifier :0.028928063809871674, mask: 0.12159662693738937 ===================
epoch no : 4, batch no : 389, total loss : 0.3187667429447174,  classifier :0.043865446001291275, mask: 0.13045819103717804 ===================
epoch no : 4, batch no : 390, total loss : 0.2745174169540405,  classifier :0.03486299514770508, mask: 0.11385680735111237 ===================
epoch no : 4, batch no : 391, total loss : 0.26738446950912476,  classifier :0.033218298107385635, mask: 0.09725979715585709 ===================
epoch no : 4, batch no : 392, total loss : 0.2894672155380249,  classifier :0.028826987370848656, mask: 0.11363871395587921 ===================
epoch no : 4, batch no : 393, total loss : 0.398721843957901,  classifier :0.04754351079463959, mask: 0.13650062680244446 ===================
epoch no : 4, batch no : 394, total loss : 0.44290992617607117,  classifier :0.037905190140008926, mask: 0.1522073596715927 ===================
epoch no : 4, batch no : 395, total loss : 0.2874630093574524,  classifier :0.05458183214068413, mask: 0.10002749413251877 ===================
epoch no : 4, batch no : 396, total loss : 0.3853289484977722,  classifier :0.037553571164608, mask: 0.1220046877861023 ===================
epoch no : 4, batch no : 397, total loss : 0.30648547410964966,  classifier :0.02971317060291767, mask: 0.11721713095903397 ===================
epoch no : 4, batch no : 398, total loss : 0.33855390548706055,  classifier :0.05360330268740654, mask: 0.13703885674476624 ===================
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch no : 5, batch no : 0, total loss : 0.40790805220603943,  classifier :0.04640522971749306, mask: 0.1366187334060669 ===================
epoch no : 5, batch no : 1, total loss : 0.3560483157634735,  classifier :0.037243328988552094, mask: 0.14797937870025635 ===================
epoch no : 5, batch no : 2, total loss : 0.31713542342185974,  classifier :0.027522966265678406, mask: 0.1629466563463211 ===================
epoch no : 5, batch no : 3, total loss : 0.2673119902610779,  classifier :0.04190730303525925, mask: 0.09605664014816284 ===================
epoch no : 5, batch no : 4, total loss : 0.34961074590682983,  classifier :0.0338684543967247, mask: 0.12027136236429214 ===================
epoch no : 5, batch no : 5, total loss : 0.3346894085407257,  classifier :0.04240180552005768, mask: 0.13559569418430328 ===================
epoch no : 5, batch no : 6, total loss : 0.34513676166534424,  classifier :0.05388151854276657, mask: 0.1364658623933792 ===================
epoch no : 5, batch no : 7, total loss : 0.2920014262199402,  classifier :0.03802690654993057, mask: 0.1258891075849533 ===================
epoch no : 5, batch no : 8, total loss : 0.2879216969013214,  classifier :0.03871695697307587, mask: 0.1257690042257309 ===================
epoch no : 5, batch no : 9, total loss : 0.30302077531814575,  classifier :0.033604927361011505, mask: 0.1195940300822258 ===================
epoch no : 5, batch no : 10, total loss : 0.2946898341178894,  classifier :0.03501017019152641, mask: 0.1360413134098053 ===================
epoch no : 5, batch no : 11, total loss : 0.33220264315605164,  classifier :0.04489368572831154, mask: 0.11969216912984848 ===================
epoch no : 5, batch no : 12, total loss : 0.25021159648895264,  classifier :0.04538166895508766, mask: 0.09268606454133987 ===================
epoch no : 5, batch no : 13, total loss : 0.2718985974788666,  classifier :0.028057219460606575, mask: 0.12129612267017365 ===================
epoch no : 5, batch no : 14, total loss : 0.3292771279811859,  classifier :0.04311549291014671, mask: 0.13453452289104462 ===================
epoch no : 5, batch no : 15, total loss : 0.33838123083114624,  classifier :0.042441610246896744, mask: 0.1115114763379097 ===================
epoch no : 5, batch no : 16, total loss : 0.3477637767791748,  classifier :0.030305534601211548, mask: 0.14024718105793 ===================
epoch no : 5, batch no : 17, total loss : 0.23969879746437073,  classifier :0.030192570760846138, mask: 0.10264503210783005 ===================
epoch no : 5, batch no : 18, total loss : 0.2993471324443817,  classifier :0.037561651319265366, mask: 0.12931281328201294 ===================
epoch no : 5, batch no : 19, total loss : 0.3216397166252136,  classifier :0.03784070536494255, mask: 0.12126680463552475 ===================
epoch no : 5, batch no : 20, total loss : 0.29410237073898315,  classifier :0.026826441287994385, mask: 0.15383829176425934 ===================
epoch no : 5, batch no : 21, total loss : 0.2629307210445404,  classifier :0.03911376744508743, mask: 0.11120838671922684 ===================
epoch no : 5, batch no : 22, total loss : 0.29736587405204773,  classifier :0.033170342445373535, mask: 0.10321283340454102 ===================
epoch no : 5, batch no : 23, total loss : 0.2544921636581421,  classifier :0.02688026800751686, mask: 0.09879368543624878 ===================
epoch no : 5, batch no : 24, total loss : 0.26270636916160583,  classifier :0.034909430891275406, mask: 0.10470311343669891 ===================
epoch no : 5, batch no : 25, total loss : 0.32542282342910767,  classifier :0.046203695237636566, mask: 0.15129733085632324 ===================
epoch no : 5, batch no : 26, total loss : 0.39176443219184875,  classifier :0.039746206253767014, mask: 0.176857128739357 ===================
epoch no : 5, batch no : 27, total loss : 0.38127243518829346,  classifier :0.05653585493564606, mask: 0.15905475616455078 ===================
epoch no : 5, batch no : 28, total loss : 0.24435676634311676,  classifier :0.034258197993040085, mask: 0.11194877326488495 ===================
epoch no : 5, batch no : 29, total loss : 0.3269488513469696,  classifier :0.03195482864975929, mask: 0.14986193180084229 ===================
epoch no : 5, batch no : 30, total loss : 0.2815774381160736,  classifier :0.02940189093351364, mask: 0.13610488176345825 ===================
epoch no : 5, batch no : 31, total loss : 0.30927959084510803,  classifier :0.0305093452334404, mask: 0.15210776031017303 ===================
epoch no : 5, batch no : 32, total loss : 0.3123585283756256,  classifier :0.03830228000879288, mask: 0.14573809504508972 ===================
epoch no : 5, batch no : 33, total loss : 0.2955145239830017,  classifier :0.03353459760546684, mask: 0.11136040836572647 ===================
epoch no : 5, batch no : 34, total loss : 0.2429133951663971,  classifier :0.0278695710003376, mask: 0.09714030474424362 ===================
epoch no : 5, batch no : 35, total loss : 0.32532551884651184,  classifier :0.02862529642879963, mask: 0.11679824441671371 ===================
epoch no : 5, batch no : 36, total loss : 0.3058527708053589,  classifier :0.022588888183236122, mask: 0.13323131203651428 ===================
epoch no : 5, batch no : 37, total loss : 0.30313417315483093,  classifier :0.038013555109500885, mask: 0.11897405982017517 ===================
epoch no : 5, batch no : 38, total loss : 0.3242262601852417,  classifier :0.02808886021375656, mask: 0.12318435311317444 ===================
epoch no : 5, batch no : 39, total loss : 0.4271353781223297,  classifier :0.03926587849855423, mask: 0.1982601433992386 ===================
epoch no : 5, batch no : 40, total loss : 0.3339748978614807,  classifier :0.04628342017531395, mask: 0.1281524896621704 ===================
epoch no : 5, batch no : 41, total loss : 0.27070942521095276,  classifier :0.026364872232079506, mask: 0.1449960470199585 ===================
epoch no : 5, batch no : 42, total loss : 0.3293358385562897,  classifier :0.0343041755259037, mask: 0.14010630548000336 ===================
epoch no : 5, batch no : 43, total loss : 0.31567755341529846,  classifier :0.039258923381567, mask: 0.1120990663766861 ===================
epoch no : 5, batch no : 44, total loss : 0.28724566102027893,  classifier :0.04789052903652191, mask: 0.11207529157400131 ===================
epoch no : 5, batch no : 45, total loss : 0.3006879687309265,  classifier :0.032789211720228195, mask: 0.13951337337493896 ===================
epoch no : 5, batch no : 46, total loss : 0.2660455107688904,  classifier :0.04096609726548195, mask: 0.11986085027456284 ===================
epoch no : 5, batch no : 47, total loss : 0.273702472448349,  classifier :0.04621843621134758, mask: 0.09726749360561371 ===================
epoch no : 5, batch no : 48, total loss : 0.2860587239265442,  classifier :0.026726657524704933, mask: 0.11325923353433609 ===================
epoch no : 5, batch no : 49, total loss : 0.33960169553756714,  classifier :0.03456490486860275, mask: 0.13388460874557495 ===================
epoch no : 5, batch no : 50, total loss : 0.2887422442436218,  classifier :0.02619105763733387, mask: 0.11191918700933456 ===================
epoch no : 5, batch no : 51, total loss : 0.302787721157074,  classifier :0.02965623512864113, mask: 0.12659570574760437 ===================
epoch no : 5, batch no : 52, total loss : 0.39901936054229736,  classifier :0.038356758654117584, mask: 0.15617024898529053 ===================
epoch no : 5, batch no : 53, total loss : 0.27549460530281067,  classifier :0.03725394234061241, mask: 0.10563601553440094 ===================
epoch no : 5, batch no : 54, total loss : 0.266767293214798,  classifier :0.02639652229845524, mask: 0.09941466897726059 ===================
epoch no : 5, batch no : 55, total loss : 0.30288854241371155,  classifier :0.03033846989274025, mask: 0.12936633825302124 ===================
epoch no : 5, batch no : 56, total loss : 0.32875216007232666,  classifier :0.03183792904019356, mask: 0.12493949383497238 ===================
epoch no : 5, batch no : 57, total loss : 0.3682030439376831,  classifier :0.04626253992319107, mask: 0.1506568342447281 ===================
epoch no : 5, batch no : 58, total loss : 0.34018805623054504,  classifier :0.03702515363693237, mask: 0.14722110331058502 ===================
epoch no : 5, batch no : 59, total loss : 0.3148277699947357,  classifier :0.02950298972427845, mask: 0.12740068137645721 ===================
epoch no : 5, batch no : 60, total loss : 0.26586824655532837,  classifier :0.03677177056670189, mask: 0.10660171508789062 ===================
epoch no : 5, batch no : 61, total loss : 0.30999207496643066,  classifier :0.03005652315914631, mask: 0.13525058329105377 ===================
epoch no : 5, batch no : 62, total loss : 0.28871145844459534,  classifier :0.029161447659134865, mask: 0.13604113459587097 ===================
epoch no : 5, batch no : 63, total loss : 0.24315835535526276,  classifier :0.03650926426053047, mask: 0.08629429340362549 ===================
epoch no : 5, batch no : 64, total loss : 0.2304045706987381,  classifier :0.030474988743662834, mask: 0.09847104549407959 ===================
epoch no : 5, batch no : 65, total loss : 0.2887398600578308,  classifier :0.031280603259801865, mask: 0.10294536501169205 ===================
epoch no : 5, batch no : 66, total loss : 0.315220445394516,  classifier :0.02649228274822235, mask: 0.14039766788482666 ===================
epoch no : 5, batch no : 67, total loss : 0.2730644941329956,  classifier :0.03828384727239609, mask: 0.11080899834632874 ===================
epoch no : 5, batch no : 68, total loss : 0.2618083655834198,  classifier :0.03399651125073433, mask: 0.10305600613355637 ===================
epoch no : 5, batch no : 69, total loss : 0.2944224178791046,  classifier :0.036886680871248245, mask: 0.11395356059074402 ===================
epoch no : 5, batch no : 70, total loss : 0.2929043471813202,  classifier :0.036109667271375656, mask: 0.12037599831819534 ===================
epoch no : 5, batch no : 71, total loss : 0.2759985029697418,  classifier :0.0418168343603611, mask: 0.10756777226924896 ===================
epoch no : 5, batch no : 72, total loss : 0.2800403833389282,  classifier :0.042983703315258026, mask: 0.11378375440835953 ===================
epoch no : 5, batch no : 73, total loss : 0.2797416150569916,  classifier :0.037898313254117966, mask: 0.1162920817732811 ===================
epoch no : 5, batch no : 74, total loss : 0.3869895040988922,  classifier :0.03370249643921852, mask: 0.1343831866979599 ===================
epoch no : 5, batch no : 75, total loss : 0.4101247787475586,  classifier :0.03766333684325218, mask: 0.16325914859771729 ===================
epoch no : 5, batch no : 76, total loss : 0.29248180985450745,  classifier :0.0311672892421484, mask: 0.12650936841964722 ===================
epoch no : 5, batch no : 77, total loss : 0.26775744557380676,  classifier :0.0328831747174263, mask: 0.11808900535106659 ===================
epoch no : 5, batch no : 78, total loss : 0.33783119916915894,  classifier :0.03462835028767586, mask: 0.19324155151844025 ===================
epoch no : 5, batch no : 79, total loss : 0.26595935225486755,  classifier :0.031279873102903366, mask: 0.11530458182096481 ===================
epoch no : 5, batch no : 80, total loss : 0.23759958148002625,  classifier :0.029241012409329414, mask: 0.10257717967033386 ===================
epoch no : 5, batch no : 81, total loss : 0.39402511715888977,  classifier :0.034034613519907, mask: 0.17478647828102112 ===================
epoch no : 5, batch no : 82, total loss : 0.2760905921459198,  classifier :0.03669552132487297, mask: 0.1182766854763031 ===================
epoch no : 5, batch no : 83, total loss : 0.2887994647026062,  classifier :0.035936884582042694, mask: 0.14351971447467804 ===================
epoch no : 5, batch no : 84, total loss : 0.24050040543079376,  classifier :0.02843969501554966, mask: 0.11534404009580612 ===================
epoch no : 5, batch no : 85, total loss : 0.2179231345653534,  classifier :0.021427864208817482, mask: 0.10433294624090195 ===================
epoch no : 5, batch no : 86, total loss : 0.26968979835510254,  classifier :0.033136047422885895, mask: 0.1150432676076889 ===================
epoch no : 5, batch no : 87, total loss : 0.3161393404006958,  classifier :0.03733832761645317, mask: 0.1429910510778427 ===================
epoch no : 5, batch no : 88, total loss : 0.4530070722103119,  classifier :0.027142401784658432, mask: 0.20218724012374878 ===================
epoch no : 5, batch no : 89, total loss : 0.4037972688674927,  classifier :0.04304884746670723, mask: 0.1432490199804306 ===================
epoch no : 5, batch no : 90, total loss : 0.38300609588623047,  classifier :0.05769459530711174, mask: 0.14490565657615662 ===================
epoch no : 5, batch no : 91, total loss : 0.33020979166030884,  classifier :0.03431610390543938, mask: 0.14962787926197052 ===================
epoch no : 5, batch no : 92, total loss : 0.2961289882659912,  classifier :0.03466285765171051, mask: 0.1281997263431549 ===================
epoch no : 5, batch no : 93, total loss : 0.26781582832336426,  classifier :0.038154590874910355, mask: 0.10166462510824203 ===================
epoch no : 5, batch no : 94, total loss : 0.28628844022750854,  classifier :0.030891668051481247, mask: 0.11371054500341415 ===================
epoch no : 5, batch no : 95, total loss : 0.27663588523864746,  classifier :0.028243327513337135, mask: 0.10585017502307892 ===================
epoch no : 5, batch no : 96, total loss : 0.30352526903152466,  classifier :0.041978757828474045, mask: 0.11723925918340683 ===================
epoch no : 5, batch no : 97, total loss : 0.3034726679325104,  classifier :0.025698982179164886, mask: 0.11986342072486877 ===================
epoch no : 5, batch no : 98, total loss : 0.22460663318634033,  classifier :0.031021857634186745, mask: 0.08587675541639328 ===================
epoch no : 5, batch no : 99, total loss : 0.30314165353775024,  classifier :0.026608355343341827, mask: 0.11023321747779846 ===================
epoch no : 5, batch no : 100, total loss : 0.34050267934799194,  classifier :0.03203458711504936, mask: 0.1590425968170166 ===================
epoch no : 5, batch no : 101, total loss : 0.3062583804130554,  classifier :0.031997594982385635, mask: 0.12567773461341858 ===================
epoch no : 5, batch no : 102, total loss : 0.34695422649383545,  classifier :0.03383495286107063, mask: 0.12119597941637039 ===================
epoch no : 5, batch no : 103, total loss : 0.27869611978530884,  classifier :0.041708964854478836, mask: 0.10765043646097183 ===================
epoch no : 5, batch no : 104, total loss : 0.278987318277359,  classifier :0.02965587005019188, mask: 0.11601099371910095 ===================
epoch no : 5, batch no : 105, total loss : 0.2926205098628998,  classifier :0.050832439213991165, mask: 0.10932932049036026 ===================
epoch no : 5, batch no : 106, total loss : 0.2958354949951172,  classifier :0.030946366488933563, mask: 0.13013437390327454 ===================
epoch no : 5, batch no : 107, total loss : 0.33871710300445557,  classifier :0.03640488162636757, mask: 0.1419466733932495 ===================
epoch no : 5, batch no : 108, total loss : 0.42594006657600403,  classifier :0.04595458135008812, mask: 0.14963312447071075 ===================
epoch no : 5, batch no : 109, total loss : 0.2846088111400604,  classifier :0.0350300557911396, mask: 0.11584828794002533 ===================
epoch no : 5, batch no : 110, total loss : 0.31607022881507874,  classifier :0.028220931068062782, mask: 0.12532426416873932 ===================
epoch no : 5, batch no : 111, total loss : 0.38208550214767456,  classifier :0.0368008017539978, mask: 0.14011164009571075 ===================
epoch no : 5, batch no : 112, total loss : 0.3824760913848877,  classifier :0.038384754210710526, mask: 0.1655702441930771 ===================
epoch no : 5, batch no : 113, total loss : 0.3175797760486603,  classifier :0.04389161244034767, mask: 0.11755292117595673 ===================
epoch no : 5, batch no : 114, total loss : 0.2647479176521301,  classifier :0.026437928900122643, mask: 0.13841475546360016 ===================
epoch no : 5, batch no : 115, total loss : 0.220592200756073,  classifier :0.02518530935049057, mask: 0.10688956081867218 ===================
epoch no : 5, batch no : 116, total loss : 0.27589115500450134,  classifier :0.04607204720377922, mask: 0.10403434187173843 ===================
epoch no : 5, batch no : 117, total loss : 0.3126769959926605,  classifier :0.03415240719914436, mask: 0.11557003855705261 ===================
epoch no : 5, batch no : 118, total loss : 0.3605848252773285,  classifier :0.027381977066397667, mask: 0.14708267152309418 ===================
epoch no : 5, batch no : 119, total loss : 0.217239648103714,  classifier :0.035886913537979126, mask: 0.08805429935455322 ===================
epoch no : 5, batch no : 120, total loss : 0.276125431060791,  classifier :0.03171826899051666, mask: 0.11623227596282959 ===================
epoch no : 5, batch no : 121, total loss : 0.3053031265735626,  classifier :0.027298949658870697, mask: 0.1221930980682373 ===================
epoch no : 5, batch no : 122, total loss : 0.39893704652786255,  classifier :0.04205459728837013, mask: 0.1324535310268402 ===================
epoch no : 5, batch no : 123, total loss : 0.27653491497039795,  classifier :0.031901925802230835, mask: 0.11936919391155243 ===================
epoch no : 5, batch no : 124, total loss : 0.2823184132575989,  classifier :0.033693864941596985, mask: 0.1050378754734993 ===================
epoch no : 5, batch no : 125, total loss : 0.23616212606430054,  classifier :0.030702216550707817, mask: 0.0979764461517334 ===================
epoch no : 5, batch no : 126, total loss : 0.3094838261604309,  classifier :0.025009285658597946, mask: 0.12712769210338593 ===================
epoch no : 5, batch no : 127, total loss : 0.273670494556427,  classifier :0.037073180079460144, mask: 0.12647640705108643 ===================
epoch no : 5, batch no : 128, total loss : 0.313421368598938,  classifier :0.03408311307430267, mask: 0.12866516411304474 ===================
epoch no : 5, batch no : 129, total loss : 0.3127518594264984,  classifier :0.054552797228097916, mask: 0.12054629623889923 ===================
epoch no : 5, batch no : 130, total loss : 0.3037329316139221,  classifier :0.03157362714409828, mask: 0.1269589364528656 ===================
epoch no : 5, batch no : 131, total loss : 0.2510722279548645,  classifier :0.04615049436688423, mask: 0.08993232250213623 ===================
epoch no : 5, batch no : 132, total loss : 0.31758227944374084,  classifier :0.045293863862752914, mask: 0.13569369912147522 ===================
epoch no : 5, batch no : 133, total loss : 0.2506141662597656,  classifier :0.03330973908305168, mask: 0.10147183388471603 ===================
epoch no : 5, batch no : 134, total loss : 0.31071043014526367,  classifier :0.03120332770049572, mask: 0.1540585309267044 ===================
epoch no : 5, batch no : 135, total loss : 0.2511855661869049,  classifier :0.025298329070210457, mask: 0.09722882509231567 ===================
epoch no : 5, batch no : 136, total loss : 0.30481359362602234,  classifier :0.03214942663908005, mask: 0.14227184653282166 ===================
epoch no : 5, batch no : 137, total loss : 0.26655980944633484,  classifier :0.030169585719704628, mask: 0.09830394387245178 ===================
epoch no : 5, batch no : 138, total loss : 0.28680619597435,  classifier :0.03383449837565422, mask: 0.1083344891667366 ===================
epoch no : 5, batch no : 139, total loss : 0.2357759177684784,  classifier :0.02714657410979271, mask: 0.10936669260263443 ===================
epoch no : 5, batch no : 140, total loss : 0.23196981847286224,  classifier :0.02434578537940979, mask: 0.11227189749479294 ===================
epoch no : 5, batch no : 141, total loss : 0.22790992259979248,  classifier :0.02640952169895172, mask: 0.10396233946084976 ===================
epoch no : 5, batch no : 142, total loss : 0.24867823719978333,  classifier :0.03201095759868622, mask: 0.09211323410272598 ===================
epoch no : 5, batch no : 143, total loss : 0.36626356840133667,  classifier :0.03955238312482834, mask: 0.13287895917892456 ===================
epoch no : 5, batch no : 144, total loss : 0.2889679968357086,  classifier :0.025342624634504318, mask: 0.127656951546669 ===================
epoch no : 5, batch no : 145, total loss : 0.3398382067680359,  classifier :0.03458893671631813, mask: 0.13890741765499115 ===================
epoch no : 5, batch no : 146, total loss : 0.2299288511276245,  classifier :0.026577869430184364, mask: 0.10481191426515579 ===================
epoch no : 5, batch no : 147, total loss : 0.2731153666973114,  classifier :0.032826196402311325, mask: 0.11270999908447266 ===================
epoch no : 5, batch no : 148, total loss : 0.27398431301116943,  classifier :0.03373901918530464, mask: 0.13897939026355743 ===================
epoch no : 5, batch no : 149, total loss : 0.36076390743255615,  classifier :0.03420157730579376, mask: 0.1647115796804428 ===================
epoch no : 5, batch no : 150, total loss : 0.36070936918258667,  classifier :0.024660736322402954, mask: 0.15816622972488403 ===================
epoch no : 5, batch no : 151, total loss : 0.33894652128219604,  classifier :0.02781476266682148, mask: 0.1544722616672516 ===================
epoch no : 5, batch no : 152, total loss : 0.39605236053466797,  classifier :0.02925257757306099, mask: 0.1641543060541153 ===================
epoch no : 5, batch no : 153, total loss : 0.3349391222000122,  classifier :0.023071253672242165, mask: 0.159194678068161 ===================
epoch no : 5, batch no : 154, total loss : 0.30012965202331543,  classifier :0.025352492928504944, mask: 0.14682579040527344 ===================
epoch no : 5, batch no : 155, total loss : 0.2220081239938736,  classifier :0.028403956443071365, mask: 0.09776902943849564 ===================
epoch no : 5, batch no : 156, total loss : 0.2610093653202057,  classifier :0.030611088499426842, mask: 0.12436854094266891 ===================
epoch no : 5, batch no : 157, total loss : 0.2883850634098053,  classifier :0.031112689524888992, mask: 0.11077377945184708 ===================
epoch no : 5, batch no : 158, total loss : 0.26486197113990784,  classifier :0.03455447033047676, mask: 0.10569104552268982 ===================
epoch no : 5, batch no : 159, total loss : 0.2947532832622528,  classifier :0.026124143972992897, mask: 0.14234469830989838 ===================
epoch no : 5, batch no : 160, total loss : 0.2681693434715271,  classifier :0.034750863909721375, mask: 0.11247330904006958 ===================
epoch no : 5, batch no : 161, total loss : 0.3190074563026428,  classifier :0.025041671469807625, mask: 0.1362685263156891 ===================
epoch no : 5, batch no : 162, total loss : 0.3913663327693939,  classifier :0.04298895597457886, mask: 0.14587587118148804 ===================
epoch no : 5, batch no : 163, total loss : 0.298911452293396,  classifier :0.028316544368863106, mask: 0.1323145478963852 ===================
epoch no : 5, batch no : 164, total loss : 0.2428961545228958,  classifier :0.03535396233201027, mask: 0.10587898641824722 ===================
epoch no : 5, batch no : 165, total loss : 0.2325606644153595,  classifier :0.029128270223736763, mask: 0.09151074290275574 ===================
epoch no : 5, batch no : 166, total loss : 0.24660414457321167,  classifier :0.0266428105533123, mask: 0.11540892720222473 ===================
epoch no : 5, batch no : 167, total loss : 0.28594857454299927,  classifier :0.03165478631854057, mask: 0.11168147623538971 ===================
epoch no : 5, batch no : 168, total loss : 0.32119160890579224,  classifier :0.027760932222008705, mask: 0.1532232165336609 ===================
epoch no : 5, batch no : 169, total loss : 0.2752857506275177,  classifier :0.020608261227607727, mask: 0.13034525513648987 ===================
epoch no : 5, batch no : 170, total loss : 0.3215186893939972,  classifier :0.029421057552099228, mask: 0.132086381316185 ===================
epoch no : 5, batch no : 171, total loss : 0.32341691851615906,  classifier :0.024377809837460518, mask: 0.17616869509220123 ===================
epoch no : 5, batch no : 172, total loss : 0.2537662088871002,  classifier :0.024345405399799347, mask: 0.1080259308218956 ===================
epoch no : 5, batch no : 173, total loss : 0.30363786220550537,  classifier :0.0410376712679863, mask: 0.12197542935609818 ===================
epoch no : 5, batch no : 174, total loss : 0.24549442529678345,  classifier :0.024028917774558067, mask: 0.10303813964128494 ===================
epoch no : 5, batch no : 175, total loss : 0.3124663829803467,  classifier :0.03321503475308418, mask: 0.12555839121341705 ===================
epoch no : 5, batch no : 176, total loss : 0.28389716148376465,  classifier :0.03757482022047043, mask: 0.1241203024983406 ===================
epoch no : 5, batch no : 177, total loss : 0.4198036789894104,  classifier :0.038739163428545, mask: 0.18731965124607086 ===================
epoch no : 5, batch no : 178, total loss : 0.40225648880004883,  classifier :0.032279182225465775, mask: 0.1638665795326233 ===================
epoch no : 5, batch no : 179, total loss : 0.26213306188583374,  classifier :0.03489166125655174, mask: 0.11378274112939835 ===================
epoch no : 5, batch no : 180, total loss : 0.31218940019607544,  classifier :0.03216403350234032, mask: 0.1306740641593933 ===================
epoch no : 5, batch no : 181, total loss : 0.24635747075080872,  classifier :0.026793157681822777, mask: 0.11506477743387222 ===================
epoch no : 5, batch no : 182, total loss : 0.24296720325946808,  classifier :0.03617967665195465, mask: 0.10498109459877014 ===================
epoch no : 5, batch no : 183, total loss : 0.2566503584384918,  classifier :0.024945024400949478, mask: 0.11248611658811569 ===================
epoch no : 5, batch no : 184, total loss : 0.25491005182266235,  classifier :0.03739103674888611, mask: 0.12177638709545135 ===================
epoch no : 5, batch no : 185, total loss : 0.22931165993213654,  classifier :0.02458965592086315, mask: 0.10586855560541153 ===================
epoch no : 5, batch no : 186, total loss : 0.2963399887084961,  classifier :0.03954862058162689, mask: 0.12047838419675827 ===================
epoch no : 5, batch no : 187, total loss : 0.5024891495704651,  classifier :0.08778638392686844, mask: 0.16921114921569824 ===================
epoch no : 5, batch no : 188, total loss : 0.3520652651786804,  classifier :0.02997608110308647, mask: 0.15267081558704376 ===================
epoch no : 5, batch no : 189, total loss : 0.3153938353061676,  classifier :0.036942142993211746, mask: 0.11639769375324249 ===================
epoch no : 5, batch no : 190, total loss : 0.25254523754119873,  classifier :0.029609601944684982, mask: 0.11045068502426147 ===================
epoch no : 5, batch no : 191, total loss : 0.4227716028690338,  classifier :0.02881307527422905, mask: 0.20918378233909607 ===================
epoch no : 5, batch no : 192, total loss : 0.3080176115036011,  classifier :0.030321361497044563, mask: 0.13234283030033112 ===================
epoch no : 5, batch no : 193, total loss : 0.2662476599216461,  classifier :0.03199077025055885, mask: 0.12667316198349 ===================
epoch no : 5, batch no : 194, total loss : 0.3114944398403168,  classifier :0.036426130682229996, mask: 0.130386620759964 ===================
epoch no : 5, batch no : 195, total loss : 0.4176570177078247,  classifier :0.05414201319217682, mask: 0.14782831072807312 ===================
epoch no : 5, batch no : 196, total loss : 0.32205888628959656,  classifier :0.038567859679460526, mask: 0.1508943736553192 ===================
epoch no : 5, batch no : 197, total loss : 0.27191925048828125,  classifier :0.043456126004457474, mask: 0.11404623836278915 ===================
epoch no : 5, batch no : 198, total loss : 0.22157303988933563,  classifier :0.027644922956824303, mask: 0.0830218717455864 ===================
epoch no : 5, batch no : 199, total loss : 0.33595937490463257,  classifier :0.045306406915187836, mask: 0.12711405754089355 ===================
epoch no : 5, batch no : 200, total loss : 0.24833425879478455,  classifier :0.026353981345891953, mask: 0.11349029093980789 ===================
epoch no : 5, batch no : 201, total loss : 0.2432447075843811,  classifier :0.03146596997976303, mask: 0.10194528847932816 ===================
epoch no : 5, batch no : 202, total loss : 0.27455055713653564,  classifier :0.033338285982608795, mask: 0.10341440141201019 ===================
epoch no : 5, batch no : 203, total loss : 0.4274021089076996,  classifier :0.030230864882469177, mask: 0.15990924835205078 ===================
epoch no : 5, batch no : 204, total loss : 0.3691125214099884,  classifier :0.038401853293180466, mask: 0.155131533741951 ===================
epoch no : 5, batch no : 205, total loss : 0.3138608932495117,  classifier :0.0343053936958313, mask: 0.11660048365592957 ===================
epoch no : 5, batch no : 206, total loss : 0.21226872503757477,  classifier :0.02540057897567749, mask: 0.08224904537200928 ===================
epoch no : 5, batch no : 207, total loss : 0.3023301959037781,  classifier :0.037687644362449646, mask: 0.1363530308008194 ===================
epoch no : 5, batch no : 208, total loss : 0.26381421089172363,  classifier :0.02647489309310913, mask: 0.11604879796504974 ===================
epoch no : 5, batch no : 209, total loss : 0.3628850281238556,  classifier :0.04107491672039032, mask: 0.15672066807746887 ===================
epoch no : 5, batch no : 210, total loss : 0.26551350951194763,  classifier :0.03196097910404205, mask: 0.12263982743024826 ===================
epoch no : 5, batch no : 211, total loss : 0.22375011444091797,  classifier :0.03615058586001396, mask: 0.10208821296691895 ===================
epoch no : 5, batch no : 212, total loss : 0.29617246985435486,  classifier :0.0465325303375721, mask: 0.0969695895910263 ===================
epoch no : 5, batch no : 213, total loss : 0.38521096110343933,  classifier :0.03332262858748436, mask: 0.1636839359998703 ===================
epoch no : 5, batch no : 214, total loss : 0.2478906512260437,  classifier :0.03856882452964783, mask: 0.09057945758104324 ===================
epoch no : 5, batch no : 215, total loss : 0.37599194049835205,  classifier :0.041326362639665604, mask: 0.1782124936580658 ===================
epoch no : 5, batch no : 216, total loss : 0.2704884707927704,  classifier :0.032280102372169495, mask: 0.11770505458116531 ===================
epoch no : 5, batch no : 217, total loss : 0.24620288610458374,  classifier :0.03611038625240326, mask: 0.08839747309684753 ===================
epoch no : 5, batch no : 218, total loss : 0.3275621235370636,  classifier :0.03242530673742294, mask: 0.14376148581504822 ===================
epoch no : 5, batch no : 219, total loss : 0.32009848952293396,  classifier :0.050912562757730484, mask: 0.11283671855926514 ===================
epoch no : 5, batch no : 220, total loss : 0.3229747414588928,  classifier :0.0638904720544815, mask: 0.13249222934246063 ===================
epoch no : 5, batch no : 221, total loss : 0.20249821245670319,  classifier :0.02429727464914322, mask: 0.08740925043821335 ===================
epoch no : 5, batch no : 222, total loss : 0.23233044147491455,  classifier :0.028210192918777466, mask: 0.1077553927898407 ===================
epoch no : 5, batch no : 223, total loss : 0.24924473464488983,  classifier :0.029876794666051865, mask: 0.09976515173912048 ===================
epoch no : 5, batch no : 224, total loss : 0.26369786262512207,  classifier :0.026729118078947067, mask: 0.09655247628688812 ===================
epoch no : 5, batch no : 225, total loss : 0.31446799635887146,  classifier :0.03652317449450493, mask: 0.11028154194355011 ===================
epoch no : 5, batch no : 226, total loss : 0.26035380363464355,  classifier :0.03074994869530201, mask: 0.11204388737678528 ===================
epoch no : 5, batch no : 227, total loss : 0.2226918637752533,  classifier :0.036318935453891754, mask: 0.10054949671030045 ===================
epoch no : 5, batch no : 228, total loss : 0.26818186044692993,  classifier :0.03989320248365402, mask: 0.12084857374429703 ===================
epoch no : 5, batch no : 229, total loss : 0.30580490827560425,  classifier :0.02707742154598236, mask: 0.16258303821086884 ===================
epoch no : 5, batch no : 230, total loss : 0.2496621012687683,  classifier :0.02697945386171341, mask: 0.10356869548559189 ===================
epoch no : 5, batch no : 231, total loss : 0.27671530842781067,  classifier :0.02985181100666523, mask: 0.11409462243318558 ===================
epoch no : 5, batch no : 232, total loss : 0.32188886404037476,  classifier :0.036985475569963455, mask: 0.13930931687355042 ===================
epoch no : 5, batch no : 233, total loss : 0.3111891448497772,  classifier :0.040804170072078705, mask: 0.11786622554063797 ===================
epoch no : 5, batch no : 234, total loss : 0.23250126838684082,  classifier :0.03554239869117737, mask: 0.09594202786684036 ===================
epoch no : 5, batch no : 235, total loss : 0.2563447952270508,  classifier :0.02771236002445221, mask: 0.11911063641309738 ===================
epoch no : 5, batch no : 236, total loss : 0.2490469068288803,  classifier :0.03650711849331856, mask: 0.09560022503137589 ===================
epoch no : 5, batch no : 237, total loss : 0.2505824565887451,  classifier :0.027110066264867783, mask: 0.11380844563245773 ===================
epoch no : 5, batch no : 238, total loss : 0.2283405065536499,  classifier :0.03168421611189842, mask: 0.09596647322177887 ===================
epoch no : 5, batch no : 239, total loss : 0.2641327381134033,  classifier :0.029277250170707703, mask: 0.10549098253250122 ===================
epoch no : 5, batch no : 240, total loss : 0.30548086762428284,  classifier :0.03604941815137863, mask: 0.12017732858657837 ===================
epoch no : 5, batch no : 241, total loss : 0.24446523189544678,  classifier :0.03329915925860405, mask: 0.11086279898881912 ===================
epoch no : 5, batch no : 242, total loss : 0.2746526598930359,  classifier :0.034420404583215714, mask: 0.1265197992324829 ===================
epoch no : 5, batch no : 243, total loss : 0.30942124128341675,  classifier :0.04538014903664589, mask: 0.11482985317707062 ===================
epoch no : 5, batch no : 244, total loss : 0.32955607771873474,  classifier :0.025677388533949852, mask: 0.1224108636379242 ===================
epoch no : 5, batch no : 245, total loss : 0.28938156366348267,  classifier :0.026275912299752235, mask: 0.13129596412181854 ===================
epoch no : 5, batch no : 246, total loss : 0.2889927327632904,  classifier :0.035795003175735474, mask: 0.12301603704690933 ===================
epoch no : 5, batch no : 247, total loss : 0.2536237835884094,  classifier :0.02157382108271122, mask: 0.10992760211229324 ===================
epoch no : 5, batch no : 248, total loss : 0.34513482451438904,  classifier :0.03066139481961727, mask: 0.1454702764749527 ===================
epoch no : 5, batch no : 249, total loss : 0.2893837094306946,  classifier :0.02297056093811989, mask: 0.12237756699323654 ===================
epoch no : 5, batch no : 250, total loss : 0.22280928492546082,  classifier :0.02783762477338314, mask: 0.09682836383581161 ===================
epoch no : 5, batch no : 251, total loss : 0.26805365085601807,  classifier :0.03126705065369606, mask: 0.10449882596731186 ===================
epoch no : 5, batch no : 252, total loss : 0.25193631649017334,  classifier :0.03449982404708862, mask: 0.11399692296981812 ===================
epoch no : 5, batch no : 253, total loss : 0.30065444111824036,  classifier :0.03798709437251091, mask: 0.1375187784433365 ===================
epoch no : 5, batch no : 254, total loss : 0.28622370958328247,  classifier :0.026190225034952164, mask: 0.1303262710571289 ===================
epoch no : 5, batch no : 255, total loss : 0.2656950056552887,  classifier :0.03682497888803482, mask: 0.11873754113912582 ===================
epoch no : 5, batch no : 256, total loss : 0.42191511392593384,  classifier :0.056038398295640945, mask: 0.1827803999185562 ===================
epoch no : 5, batch no : 257, total loss : 0.44983506202697754,  classifier :0.05247539281845093, mask: 0.18685677647590637 ===================
epoch no : 5, batch no : 258, total loss : 0.3215109705924988,  classifier :0.02136741764843464, mask: 0.1406349241733551 ===================
epoch no : 5, batch no : 259, total loss : 0.275921493768692,  classifier :0.03947571665048599, mask: 0.11206524819135666 ===================
epoch no : 5, batch no : 260, total loss : 0.29317089915275574,  classifier :0.03107336349785328, mask: 0.12582530081272125 ===================
epoch no : 5, batch no : 261, total loss : 0.3195962905883789,  classifier :0.04138345643877983, mask: 0.1396849900484085 ===================
epoch no : 5, batch no : 262, total loss : 0.288614422082901,  classifier :0.029137087985873222, mask: 0.11431638151407242 ===================
epoch no : 5, batch no : 263, total loss : 0.25126323103904724,  classifier :0.03123987838625908, mask: 0.10157740861177444 ===================
epoch no : 5, batch no : 264, total loss : 0.3021763563156128,  classifier :0.034522462636232376, mask: 0.1656423658132553 ===================
epoch no : 5, batch no : 265, total loss : 0.3066026270389557,  classifier :0.029179958626627922, mask: 0.09882151335477829 ===================
epoch no : 5, batch no : 266, total loss : 0.25394880771636963,  classifier :0.022660713642835617, mask: 0.10412941128015518 ===================
epoch no : 5, batch no : 267, total loss : 0.28804811835289,  classifier :0.02669152431190014, mask: 0.11575248837471008 ===================
epoch no : 5, batch no : 268, total loss : 0.40682560205459595,  classifier :0.03361033648252487, mask: 0.14691169559955597 ===================
epoch no : 5, batch no : 269, total loss : 0.2547333240509033,  classifier :0.030759984627366066, mask: 0.12689948081970215 ===================
epoch no : 5, batch no : 270, total loss : 0.2502785921096802,  classifier :0.042655233293771744, mask: 0.11190873384475708 ===================
epoch no : 5, batch no : 271, total loss : 0.24204504489898682,  classifier :0.027751412242650986, mask: 0.11146305501461029 ===================
epoch no : 5, batch no : 272, total loss : 0.22637349367141724,  classifier :0.024807563051581383, mask: 0.10836850106716156 ===================
epoch no : 5, batch no : 273, total loss : 0.3050048053264618,  classifier :0.04490421339869499, mask: 0.1263693869113922 ===================
epoch no : 5, batch no : 274, total loss : 0.24569660425186157,  classifier :0.03100360371172428, mask: 0.09821443259716034 ===================
epoch no : 5, batch no : 275, total loss : 0.3987034857273102,  classifier :0.03587505966424942, mask: 0.1672278344631195 ===================
epoch no : 5, batch no : 276, total loss : 0.31611892580986023,  classifier :0.02340555004775524, mask: 0.1303764432668686 ===================
epoch no : 5, batch no : 277, total loss : 0.3014791011810303,  classifier :0.02912670187652111, mask: 0.13563023507595062 ===================
epoch no : 5, batch no : 278, total loss : 0.3420222997665405,  classifier :0.03578289970755577, mask: 0.13377009332180023 ===================
epoch no : 5, batch no : 279, total loss : 0.40815380215644836,  classifier :0.04943350329995155, mask: 0.1548406332731247 ===================
epoch no : 5, batch no : 280, total loss : 0.4063932001590729,  classifier :0.0398428812623024, mask: 0.1497647911310196 ===================
epoch no : 5, batch no : 281, total loss : 0.3159884214401245,  classifier :0.03392008692026138, mask: 0.1405481994152069 ===================
epoch no : 5, batch no : 282, total loss : 0.30472850799560547,  classifier :0.03147003799676895, mask: 0.1332969069480896 ===================
epoch no : 5, batch no : 283, total loss : 0.2983804941177368,  classifier :0.03705823794007301, mask: 0.12856662273406982 ===================
epoch no : 5, batch no : 284, total loss : 0.3113214671611786,  classifier :0.029011547565460205, mask: 0.15238089859485626 ===================
epoch no : 5, batch no : 285, total loss : 0.41070249676704407,  classifier :0.06338614970445633, mask: 0.16331610083580017 ===================
epoch no : 5, batch no : 286, total loss : 0.25603750348091125,  classifier :0.02104954980313778, mask: 0.10342302918434143 ===================
epoch no : 5, batch no : 287, total loss : 0.22033068537712097,  classifier :0.02606041543185711, mask: 0.08899359405040741 ===================
epoch no : 5, batch no : 288, total loss : 0.2338002324104309,  classifier :0.022626586258411407, mask: 0.10729999840259552 ===================
epoch no : 5, batch no : 289, total loss : 0.26025915145874023,  classifier :0.02379656583070755, mask: 0.10833283513784409 ===================
epoch no : 5, batch no : 290, total loss : 0.23815971612930298,  classifier :0.032061584293842316, mask: 0.09944534301757812 ===================
epoch no : 5, batch no : 291, total loss : 0.27661675214767456,  classifier :0.02453482151031494, mask: 0.13299238681793213 ===================
epoch no : 5, batch no : 292, total loss : 0.2144748866558075,  classifier :0.023140907287597656, mask: 0.09145546704530716 ===================
epoch no : 5, batch no : 293, total loss : 0.23187439143657684,  classifier :0.030879242345690727, mask: 0.08697467297315598 ===================
epoch no : 5, batch no : 294, total loss : 0.30357882380485535,  classifier :0.03485577926039696, mask: 0.12528954446315765 ===================
epoch no : 5, batch no : 295, total loss : 0.3284294903278351,  classifier :0.03172283619642258, mask: 0.12966378033161163 ===================
epoch no : 5, batch no : 296, total loss : 0.38744446635246277,  classifier :0.03984598070383072, mask: 0.1470189392566681 ===================
epoch no : 5, batch no : 297, total loss : 0.2739388048648834,  classifier :0.02904580906033516, mask: 0.11332998424768448 ===================
epoch no : 5, batch no : 298, total loss : 0.31989312171936035,  classifier :0.032936614006757736, mask: 0.10726348310709 ===================
epoch no : 5, batch no : 299, total loss : 0.31198301911354065,  classifier :0.031168071553111076, mask: 0.11198209971189499 ===================
epoch no : 5, batch no : 300, total loss : 0.32274577021598816,  classifier :0.032186854630708694, mask: 0.13121719658374786 ===================
epoch no : 5, batch no : 301, total loss : 0.3534247577190399,  classifier :0.03209000080823898, mask: 0.15198948979377747 ===================
epoch no : 5, batch no : 302, total loss : 0.41039609909057617,  classifier :0.04394868016242981, mask: 0.1655745506286621 ===================
epoch no : 5, batch no : 303, total loss : 0.3436850607395172,  classifier :0.040678102523088455, mask: 0.14145170152187347 ===================
epoch no : 5, batch no : 304, total loss : 0.17699779570102692,  classifier :0.021336693316698074, mask: 0.08204232901334763 ===================
epoch no : 5, batch no : 305, total loss : 0.23546847701072693,  classifier :0.03730595484375954, mask: 0.09659029543399811 ===================
epoch no : 5, batch no : 306, total loss : 0.31980812549591064,  classifier :0.04277360066771507, mask: 0.10644751787185669 ===================
epoch no : 5, batch no : 307, total loss : 0.3181197941303253,  classifier :0.028807274997234344, mask: 0.16419853270053864 ===================
epoch no : 5, batch no : 308, total loss : 0.3577784299850464,  classifier :0.035851381719112396, mask: 0.13740234076976776 ===================
epoch no : 5, batch no : 309, total loss : 0.25633975863456726,  classifier :0.01865510083734989, mask: 0.1173240914940834 ===================
epoch no : 5, batch no : 310, total loss : 0.2955799698829651,  classifier :0.03396596759557724, mask: 0.11718648672103882 ===================
epoch no : 5, batch no : 311, total loss : 0.3728257715702057,  classifier :0.027899224311113358, mask: 0.1398131400346756 ===================
epoch no : 5, batch no : 312, total loss : 0.3025740683078766,  classifier :0.025827085599303246, mask: 0.11464938521385193 ===================
epoch no : 5, batch no : 313, total loss : 0.2620498836040497,  classifier :0.040289394557476044, mask: 0.10559757053852081 ===================
epoch no : 5, batch no : 314, total loss : 0.3656812906265259,  classifier :0.025518354028463364, mask: 0.17910811305046082 ===================
epoch no : 5, batch no : 315, total loss : 0.28680309653282166,  classifier :0.024788424372673035, mask: 0.127157524228096 ===================
epoch no : 5, batch no : 316, total loss : 0.34397614002227783,  classifier :0.029786257073283195, mask: 0.14005854725837708 ===================
epoch no : 5, batch no : 317, total loss : 0.23395219445228577,  classifier :0.023122191429138184, mask: 0.11874565482139587 ===================
epoch no : 5, batch no : 318, total loss : 0.250872939825058,  classifier :0.023108916357159615, mask: 0.12721014022827148 ===================
epoch no : 5, batch no : 319, total loss : 0.26740363240242004,  classifier :0.024486513808369637, mask: 0.12310531735420227 ===================
epoch no : 5, batch no : 320, total loss : 0.19630417227745056,  classifier :0.022279221564531326, mask: 0.08497156947851181 ===================
epoch no : 5, batch no : 321, total loss : 0.3335611820220947,  classifier :0.03791232407093048, mask: 0.12971316277980804 ===================
epoch no : 5, batch no : 322, total loss : 0.3250812590122223,  classifier :0.038543619215488434, mask: 0.12334839254617691 ===================
epoch no : 5, batch no : 323, total loss : 0.2628335654735565,  classifier :0.030668456107378006, mask: 0.11154533177614212 ===================
epoch no : 5, batch no : 324, total loss : 0.24510149657726288,  classifier :0.02508949115872383, mask: 0.10521438717842102 ===================
epoch no : 5, batch no : 325, total loss : 0.23453320562839508,  classifier :0.024166597053408623, mask: 0.11426421999931335 ===================
epoch no : 5, batch no : 326, total loss : 0.23401737213134766,  classifier :0.029826724901795387, mask: 0.10970794409513474 ===================
epoch no : 5, batch no : 327, total loss : 0.260653555393219,  classifier :0.04396883025765419, mask: 0.0889015644788742 ===================
epoch no : 5, batch no : 328, total loss : 0.24555093050003052,  classifier :0.03220845386385918, mask: 0.09879213571548462 ===================
epoch no : 5, batch no : 329, total loss : 0.24177733063697815,  classifier :0.02801770530641079, mask: 0.09715882688760757 ===================
epoch no : 5, batch no : 330, total loss : 0.28712546825408936,  classifier :0.03284182399511337, mask: 0.12594440579414368 ===================
epoch no : 5, batch no : 331, total loss : 0.31460073590278625,  classifier :0.0322096012532711, mask: 0.13409268856048584 ===================
epoch no : 5, batch no : 332, total loss : 0.3235262632369995,  classifier :0.025852564722299576, mask: 0.12865667045116425 ===================
epoch no : 5, batch no : 333, total loss : 0.28172436356544495,  classifier :0.023250116035342216, mask: 0.12807698547840118 ===================
epoch no : 5, batch no : 334, total loss : 0.39933666586875916,  classifier :0.03504383936524391, mask: 0.19325169920921326 ===================
epoch no : 5, batch no : 335, total loss : 0.2326892763376236,  classifier :0.024629518389701843, mask: 0.10515936464071274 ===================
epoch no : 5, batch no : 336, total loss : 0.286692351102829,  classifier :0.031676601618528366, mask: 0.11774051189422607 ===================
epoch no : 5, batch no : 337, total loss : 0.25952017307281494,  classifier :0.023813538253307343, mask: 0.10004724562168121 ===================
epoch no : 5, batch no : 338, total loss : 0.23223599791526794,  classifier :0.02738008089363575, mask: 0.08688583970069885 ===================
epoch no : 5, batch no : 339, total loss : 0.25995776057243347,  classifier :0.03735332563519478, mask: 0.10553055256605148 ===================
epoch no : 5, batch no : 340, total loss : 0.3567007780075073,  classifier :0.03991727530956268, mask: 0.12115416675806046 ===================
epoch no : 5, batch no : 341, total loss : 0.3121800422668457,  classifier :0.026093071326613426, mask: 0.14852771162986755 ===================
epoch no : 5, batch no : 342, total loss : 0.3026486039161682,  classifier :0.021970966830849648, mask: 0.13710889220237732 ===================
epoch no : 5, batch no : 343, total loss : 0.21727298200130463,  classifier :0.029988771304488182, mask: 0.08267045766115189 ===================
epoch no : 5, batch no : 344, total loss : 0.22781679034233093,  classifier :0.03866282477974892, mask: 0.09281492978334427 ===================
epoch no : 5, batch no : 345, total loss : 0.3069177269935608,  classifier :0.03273065760731697, mask: 0.09922102838754654 ===================
epoch no : 5, batch no : 346, total loss : 0.2523927688598633,  classifier :0.02678186260163784, mask: 0.08815117180347443 ===================
epoch no : 5, batch no : 347, total loss : 0.2618872821331024,  classifier :0.033478375524282455, mask: 0.09558863192796707 ===================
epoch no : 5, batch no : 348, total loss : 0.32840439677238464,  classifier :0.02623647078871727, mask: 0.15076008439064026 ===================
epoch no : 5, batch no : 349, total loss : 0.20390141010284424,  classifier :0.02217232808470726, mask: 0.07803555577993393 ===================
epoch no : 5, batch no : 350, total loss : 0.2907368838787079,  classifier :0.019883273169398308, mask: 0.12736563384532928 ===================
epoch no : 5, batch no : 351, total loss : 0.2794732451438904,  classifier :0.027444038540124893, mask: 0.12714554369449615 ===================
epoch no : 5, batch no : 352, total loss : 0.30869314074516296,  classifier :0.021628884598612785, mask: 0.12836585938930511 ===================
epoch no : 5, batch no : 353, total loss : 0.2523368299007416,  classifier :0.02465137094259262, mask: 0.13098447024822235 ===================
epoch no : 5, batch no : 354, total loss : 0.2542775273323059,  classifier :0.026952818036079407, mask: 0.12583346664905548 ===================
epoch no : 5, batch no : 355, total loss : 0.22137190401554108,  classifier :0.03379974141716957, mask: 0.09497863799333572 ===================
epoch no : 5, batch no : 356, total loss : 0.27727434039115906,  classifier :0.027870524674654007, mask: 0.11435066908597946 ===================
epoch no : 5, batch no : 357, total loss : 0.23971381783485413,  classifier :0.021459655836224556, mask: 0.09450752288103104 ===================
epoch no : 5, batch no : 358, total loss : 0.255774587392807,  classifier :0.03439322113990784, mask: 0.09521115571260452 ===================
epoch no : 5, batch no : 359, total loss : 0.2789442241191864,  classifier :0.046397723257541656, mask: 0.10979340970516205 ===================
epoch no : 5, batch no : 360, total loss : 0.25171706080436707,  classifier :0.025877444073557854, mask: 0.10844456404447556 ===================
epoch no : 5, batch no : 361, total loss : 0.27107083797454834,  classifier :0.030021384358406067, mask: 0.12454826384782791 ===================
epoch no : 5, batch no : 362, total loss : 0.30967289209365845,  classifier :0.03246287629008293, mask: 0.152053102850914 ===================
epoch no : 5, batch no : 363, total loss : 0.33470091223716736,  classifier :0.03407026827335358, mask: 0.11430677771568298 ===================
epoch no : 5, batch no : 364, total loss : 0.3454574644565582,  classifier :0.03873497620224953, mask: 0.14062894880771637 ===================
epoch no : 5, batch no : 365, total loss : 0.2447458654642105,  classifier :0.03035949543118477, mask: 0.092642642557621 ===================
epoch no : 5, batch no : 366, total loss : 0.26276904344558716,  classifier :0.03356485068798065, mask: 0.09776987135410309 ===================
epoch no : 5, batch no : 367, total loss : 0.24754595756530762,  classifier :0.03529985249042511, mask: 0.10089003294706345 ===================
epoch no : 5, batch no : 368, total loss : 0.2114669680595398,  classifier :0.029437297955155373, mask: 0.09170053899288177 ===================
epoch no : 5, batch no : 369, total loss : 0.2588164210319519,  classifier :0.03749481961131096, mask: 0.1068035140633583 ===================
epoch no : 5, batch no : 370, total loss : 0.31848108768463135,  classifier :0.03959086164832115, mask: 0.13044080138206482 ===================
epoch no : 5, batch no : 371, total loss : 0.317291259765625,  classifier :0.043636173009872437, mask: 0.12758120894432068 ===================
epoch no : 5, batch no : 372, total loss : 0.2677392065525055,  classifier :0.024480629712343216, mask: 0.11558792740106583 ===================
epoch no : 5, batch no : 373, total loss : 0.189188614487648,  classifier :0.02004903368651867, mask: 0.08613623678684235 ===================
epoch no : 5, batch no : 374, total loss : 0.24917688965797424,  classifier :0.016812419518828392, mask: 0.13160620629787445 ===================
epoch no : 5, batch no : 375, total loss : 0.2824375629425049,  classifier :0.03589076176285744, mask: 0.12644141912460327 ===================
epoch no : 5, batch no : 376, total loss : 0.2696615755558014,  classifier :0.03250645846128464, mask: 0.11235019564628601 ===================
epoch no : 5, batch no : 377, total loss : 0.24879197776317596,  classifier :0.028259575366973877, mask: 0.09213882684707642 ===================
epoch no : 5, batch no : 378, total loss : 0.39263615012168884,  classifier :0.045838095247745514, mask: 0.15171365439891815 ===================
epoch no : 5, batch no : 379, total loss : 0.2842518985271454,  classifier :0.03356333449482918, mask: 0.09309037774801254 ===================
epoch no : 5, batch no : 380, total loss : 0.30837035179138184,  classifier :0.03849917650222778, mask: 0.12678906321525574 ===================
epoch no : 5, batch no : 381, total loss : 0.39840948581695557,  classifier :0.0352761372923851, mask: 0.15104609727859497 ===================
epoch no : 5, batch no : 382, total loss : 0.4432254433631897,  classifier :0.03400256857275963, mask: 0.19591845571994781 ===================
epoch no : 5, batch no : 383, total loss : 0.2867032587528229,  classifier :0.040612637996673584, mask: 0.10821004211902618 ===================
epoch no : 5, batch no : 384, total loss : 0.34809231758117676,  classifier :0.04645437002182007, mask: 0.1273796111345291 ===================
epoch no : 5, batch no : 385, total loss : 0.2567175328731537,  classifier :0.029618147760629654, mask: 0.0949200764298439 ===================
epoch no : 5, batch no : 386, total loss : 0.26384595036506653,  classifier :0.028555145487189293, mask: 0.11454503983259201 ===================
epoch no : 5, batch no : 387, total loss : 0.3224656581878662,  classifier :0.04181375354528427, mask: 0.14133408665657043 ===================
epoch no : 5, batch no : 388, total loss : 0.3120039999485016,  classifier :0.02338460460305214, mask: 0.15851911902427673 ===================
epoch no : 5, batch no : 389, total loss : 0.30819979310035706,  classifier :0.04005078598856926, mask: 0.11383969336748123 ===================
epoch no : 5, batch no : 390, total loss : 0.23593458533287048,  classifier :0.032837238162755966, mask: 0.11150387674570084 ===================
epoch no : 5, batch no : 391, total loss : 0.2872264087200165,  classifier :0.041207071393728256, mask: 0.12187065184116364 ===================
epoch no : 5, batch no : 392, total loss : 0.30827584862709045,  classifier :0.026004651561379433, mask: 0.16683150827884674 ===================
epoch no : 5, batch no : 393, total loss : 0.22656814754009247,  classifier :0.02369273267686367, mask: 0.1013820469379425 ===================
epoch no : 5, batch no : 394, total loss : 0.3012576997280121,  classifier :0.028992680832743645, mask: 0.11285603046417236 ===================
epoch no : 5, batch no : 395, total loss : 0.3128608465194702,  classifier :0.03891032934188843, mask: 0.10769719630479813 ===================
epoch no : 5, batch no : 396, total loss : 0.3233349323272705,  classifier :0.042393382638692856, mask: 0.12935993075370789 ===================
epoch no : 5, batch no : 397, total loss : 0.3443116545677185,  classifier :0.041926488280296326, mask: 0.13729438185691833 ===================
epoch no : 5, batch no : 398, total loss : 0.31955409049987793,  classifier :0.058322012424468994, mask: 0.10338611155748367 ===================
creating index...
index created!
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
Test:  [   0/3188]  eta: 0:35:20  model_time: 0.1215 (0.1215)  evaluator_time: 0.0284 (0.0284)  time: 0.6650  data: 0.3567  max mem: 9499
Test:  [ 100/3188]  eta: 0:11:17  model_time: 0.0875 (0.0922)  evaluator_time: 0.0088 (0.0126)  time: 0.2100  data: 0.0045  max mem: 9499
Test:  [ 200/3188]  eta: 0:10:43  model_time: 0.0897 (0.0912)  evaluator_time: 0.0105 (0.0118)  time: 0.2156  data: 0.0045  max mem: 9499
Test:  [ 300/3188]  eta: 0:10:13  model_time: 0.0840 (0.0900)  evaluator_time: 0.0110 (0.0112)  time: 0.2060  data: 0.0051  max mem: 9499
Test:  [ 400/3188]  eta: 0:09:56  model_time: 0.0903 (0.0905)  evaluator_time: 0.0106 (0.0115)  time: 0.2163  data: 0.0052  max mem: 9499
Test:  [ 500/3188]  eta: 0:09:34  model_time: 0.0869 (0.0906)  evaluator_time: 0.0107 (0.0115)  time: 0.2157  data: 0.0049  max mem: 9499
Test:  [ 600/3188]  eta: 0:09:12  model_time: 0.0878 (0.0907)  evaluator_time: 0.0101 (0.0115)  time: 0.2096  data: 0.0043  max mem: 9499
Test:  [ 700/3188]  eta: 0:08:50  model_time: 0.0870 (0.0907)  evaluator_time: 0.0105 (0.0115)  time: 0.2144  data: 0.0045  max mem: 9499
Test:  [ 800/3188]  eta: 0:08:28  model_time: 0.0840 (0.0905)  evaluator_time: 0.0082 (0.0114)  time: 0.2001  data: 0.0044  max mem: 9499
Test:  [ 900/3188]  eta: 0:08:07  model_time: 0.0911 (0.0907)  evaluator_time: 0.0097 (0.0115)  time: 0.2249  data: 0.0043  max mem: 9499
Test:  [1000/3188]  eta: 0:07:46  model_time: 0.0845 (0.0907)  evaluator_time: 0.0096 (0.0116)  time: 0.2041  data: 0.0042  max mem: 9499
Test:  [1100/3188]  eta: 0:07:24  model_time: 0.0852 (0.0906)  evaluator_time: 0.0080 (0.0116)  time: 0.2066  data: 0.0044  max mem: 9499
Test:  [1200/3188]  eta: 0:07:03  model_time: 0.0894 (0.0907)  evaluator_time: 0.0109 (0.0117)  time: 0.2174  data: 0.0044  max mem: 9499
Test:  [1300/3188]  eta: 0:06:41  model_time: 0.0883 (0.0906)  evaluator_time: 0.0101 (0.0117)  time: 0.2070  data: 0.0047  max mem: 9499
Test:  [1400/3188]  eta: 0:06:20  model_time: 0.0862 (0.0906)  evaluator_time: 0.0113 (0.0118)  time: 0.2069  data: 0.0053  max mem: 9499
Test:  [1500/3188]  eta: 0:05:59  model_time: 0.0923 (0.0906)  evaluator_time: 0.0106 (0.0118)  time: 0.2130  data: 0.0045  max mem: 9499
Test:  [1600/3188]  eta: 0:05:38  model_time: 0.0856 (0.0906)  evaluator_time: 0.0082 (0.0117)  time: 0.2037  data: 0.0045  max mem: 9499
Test:  [1700/3188]  eta: 0:05:16  model_time: 0.0890 (0.0905)  evaluator_time: 0.0096 (0.0117)  time: 0.2020  data: 0.0049  max mem: 9499
Test:  [1800/3188]  eta: 0:04:54  model_time: 0.0835 (0.0904)  evaluator_time: 0.0094 (0.0117)  time: 0.1996  data: 0.0051  max mem: 9499
Test:  [1900/3188]  eta: 0:04:33  model_time: 0.0883 (0.0904)  evaluator_time: 0.0088 (0.0117)  time: 0.2111  data: 0.0046  max mem: 9499
Test:  [2000/3188]  eta: 0:04:12  model_time: 0.0864 (0.0905)  evaluator_time: 0.0082 (0.0117)  time: 0.2115  data: 0.0047  max mem: 9499
Test:  [2100/3188]  eta: 0:03:51  model_time: 0.0849 (0.0904)  evaluator_time: 0.0083 (0.0117)  time: 0.2128  data: 0.0046  max mem: 9499
Test:  [2200/3188]  eta: 0:03:29  model_time: 0.0871 (0.0904)  evaluator_time: 0.0139 (0.0117)  time: 0.2070  data: 0.0056  max mem: 9499
Test:  [2300/3188]  eta: 0:03:08  model_time: 0.0891 (0.0904)  evaluator_time: 0.0097 (0.0117)  time: 0.2325  data: 0.0044  max mem: 9499
Test:  [2400/3188]  eta: 0:02:47  model_time: 0.0861 (0.0904)  evaluator_time: 0.0089 (0.0117)  time: 0.2024  data: 0.0042  max mem: 9499
Test:  [2500/3188]  eta: 0:02:26  model_time: 0.0863 (0.0905)  evaluator_time: 0.0099 (0.0117)  time: 0.2098  data: 0.0051  max mem: 9499
Test:  [2600/3188]  eta: 0:02:04  model_time: 0.0858 (0.0905)  evaluator_time: 0.0099 (0.0116)  time: 0.2041  data: 0.0046  max mem: 9499
Test:  [2700/3188]  eta: 0:01:43  model_time: 0.0894 (0.0905)  evaluator_time: 0.0107 (0.0116)  time: 0.2163  data: 0.0045  max mem: 9499
Test:  [2800/3188]  eta: 0:01:22  model_time: 0.0890 (0.0905)  evaluator_time: 0.0115 (0.0117)  time: 0.2168  data: 0.0050  max mem: 9499
Test:  [2900/3188]  eta: 0:01:01  model_time: 0.0873 (0.0905)  evaluator_time: 0.0092 (0.0117)  time: 0.2021  data: 0.0044  max mem: 9499
Test:  [3000/3188]  eta: 0:00:39  model_time: 0.0904 (0.0905)  evaluator_time: 0.0094 (0.0117)  time: 0.2167  data: 0.0042  max mem: 9499
Test:  [3100/3188]  eta: 0:00:18  model_time: 0.0904 (0.0904)  evaluator_time: 0.0095 (0.0117)  time: 0.2112  data: 0.0045  max mem: 9499
Test:  [3187/3188]  eta: 0:00:00  model_time: 0.0866 (0.0905)  evaluator_time: 0.0098 (0.0117)  time: 0.2126  data: 0.0045  max mem: 9499
Test: Total time: 0:11:17 (0.2125 s / it)
Averaged stats: model_time: 0.0866 (0.0905)  evaluator_time: 0.0098 (0.0117)
Accumulating evaluation results...
DONE-test (t=1.48s).
Accumulating evaluation results...
DONE-test (t=1.63s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.707
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.888
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.857
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.707
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.799
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.823
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.823
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.823
IoU metric: segm
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.715
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.890
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.855
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.715
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.802
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.826
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.826
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.826
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch no : 6, batch no : 0, total loss : 0.35785529017448425,  classifier :0.03654351457953453, mask: 0.13018833100795746 ===================
epoch no : 6, batch no : 1, total loss : 0.4914921522140503,  classifier :0.05300796404480934, mask: 0.21521231532096863 ===================
epoch no : 6, batch no : 2, total loss : 0.33282914757728577,  classifier :0.04040947183966637, mask: 0.13642530143260956 ===================
epoch no : 6, batch no : 3, total loss : 0.32634419202804565,  classifier :0.028167465701699257, mask: 0.1643734574317932 ===================
epoch no : 6, batch no : 4, total loss : 0.2584080398082733,  classifier :0.029729146510362625, mask: 0.09879814088344574 ===================
epoch no : 6, batch no : 5, total loss : 0.25443798303604126,  classifier :0.030514394864439964, mask: 0.10576065629720688 ===================
epoch no : 6, batch no : 6, total loss : 0.3065144121646881,  classifier :0.03140327334403992, mask: 0.12480573356151581 ===================
epoch no : 6, batch no : 7, total loss : 0.27123942971229553,  classifier :0.02526768296957016, mask: 0.10529227554798126 ===================
epoch no : 6, batch no : 8, total loss : 0.28050801157951355,  classifier :0.04126089811325073, mask: 0.11017956584692001 ===================
epoch no : 6, batch no : 9, total loss : 0.26074138283729553,  classifier :0.025668734684586525, mask: 0.12420381605625153 ===================
epoch no : 6, batch no : 10, total loss : 0.24322813749313354,  classifier :0.04036719352006912, mask: 0.0961431935429573 ===================
epoch no : 6, batch no : 11, total loss : 0.32389840483665466,  classifier :0.04302110895514488, mask: 0.12536990642547607 ===================
epoch no : 6, batch no : 12, total loss : 0.20687103271484375,  classifier :0.04169740155339241, mask: 0.07606074213981628 ===================
epoch no : 6, batch no : 13, total loss : 0.2626803517341614,  classifier :0.023786673322319984, mask: 0.1257806420326233 ===================
epoch no : 6, batch no : 14, total loss : 0.25124120712280273,  classifier :0.023927778005599976, mask: 0.125026673078537 ===================
epoch no : 6, batch no : 15, total loss : 0.253097802400589,  classifier :0.030405528843402863, mask: 0.10334610193967819 ===================
epoch no : 6, batch no : 16, total loss : 0.23799721896648407,  classifier :0.03126052767038345, mask: 0.0874100998044014 ===================
epoch no : 6, batch no : 17, total loss : 0.2955262064933777,  classifier :0.027148684486746788, mask: 0.12273022532463074 ===================
epoch no : 6, batch no : 18, total loss : 0.24046960473060608,  classifier :0.030843250453472137, mask: 0.10100195556879044 ===================
epoch no : 6, batch no : 19, total loss : 0.24276520311832428,  classifier :0.027521919459104538, mask: 0.10423227399587631 ===================
epoch no : 6, batch no : 20, total loss : 0.26224398612976074,  classifier :0.03299493342638016, mask: 0.09329523146152496 ===================
epoch no : 6, batch no : 21, total loss : 0.35808098316192627,  classifier :0.026812618598341942, mask: 0.1302693486213684 ===================
epoch no : 6, batch no : 22, total loss : 0.3893167972564697,  classifier :0.03135063871741295, mask: 0.15780732035636902 ===================
epoch no : 6, batch no : 23, total loss : 0.36697158217430115,  classifier :0.03169265016913414, mask: 0.15408188104629517 ===================
epoch no : 6, batch no : 24, total loss : 0.2710053622722626,  classifier :0.04394112527370453, mask: 0.0959707647562027 ===================
epoch no : 6, batch no : 25, total loss : 0.24616293609142303,  classifier :0.02625550702214241, mask: 0.1033836230635643 ===================
epoch no : 6, batch no : 26, total loss : 0.25093454122543335,  classifier :0.04144731163978577, mask: 0.10517744719982147 ===================
epoch no : 6, batch no : 27, total loss : 0.1935957968235016,  classifier :0.02686329372227192, mask: 0.09111000597476959 ===================
epoch no : 6, batch no : 28, total loss : 0.2535627484321594,  classifier :0.037465374916791916, mask: 0.11162393540143967 ===================
epoch no : 6, batch no : 29, total loss : 0.30630335211753845,  classifier :0.03194308653473854, mask: 0.11385104805231094 ===================
epoch no : 6, batch no : 30, total loss : 0.23155833780765533,  classifier :0.02343418262898922, mask: 0.09159725159406662 ===================
epoch no : 6, batch no : 31, total loss : 0.2726585268974304,  classifier :0.030043859034776688, mask: 0.13244032859802246 ===================
epoch no : 6, batch no : 32, total loss : 0.2714047133922577,  classifier :0.017264708876609802, mask: 0.11712493747472763 ===================
epoch no : 6, batch no : 33, total loss : 0.29805442690849304,  classifier :0.025053570047020912, mask: 0.11907965689897537 ===================
epoch no : 6, batch no : 34, total loss : 0.2614697515964508,  classifier :0.023105647414922714, mask: 0.1018718034029007 ===================
epoch no : 6, batch no : 35, total loss : 0.2673635482788086,  classifier :0.039498042315244675, mask: 0.1006198301911354 ===================
epoch no : 6, batch no : 36, total loss : 0.2163114994764328,  classifier :0.02915949560701847, mask: 0.0972452387213707 ===================
epoch no : 6, batch no : 37, total loss : 0.2468772679567337,  classifier :0.03416019678115845, mask: 0.08761803060770035 ===================
epoch no : 6, batch no : 38, total loss : 0.42460212111473083,  classifier :0.052438635379076004, mask: 0.13342541456222534 ===================
epoch no : 6, batch no : 39, total loss : 0.23849670588970184,  classifier :0.021300068125128746, mask: 0.09247412532567978 ===================
epoch no : 6, batch no : 40, total loss : 0.2949961721897125,  classifier :0.026446526870131493, mask: 0.13441196084022522 ===================
epoch no : 6, batch no : 41, total loss : 0.2243935763835907,  classifier :0.037765197455883026, mask: 0.09024401009082794 ===================
epoch no : 6, batch no : 42, total loss : 0.216478630900383,  classifier :0.027770046144723892, mask: 0.08557242900133133 ===================
epoch no : 6, batch no : 43, total loss : 0.2655380368232727,  classifier :0.033832963556051254, mask: 0.12389461696147919 ===================
epoch no : 6, batch no : 44, total loss : 0.26325422525405884,  classifier :0.02844258025288582, mask: 0.12670525908470154 ===================
epoch no : 6, batch no : 45, total loss : 0.3636775612831116,  classifier :0.02448798343539238, mask: 0.1187068298459053 ===================
epoch no : 6, batch no : 46, total loss : 0.2628653943538666,  classifier :0.030828628689050674, mask: 0.11116969585418701 ===================
epoch no : 6, batch no : 47, total loss : 0.24090053141117096,  classifier :0.02216333895921707, mask: 0.11009092628955841 ===================
epoch no : 6, batch no : 48, total loss : 0.27409103512763977,  classifier :0.04773535206913948, mask: 0.11091804504394531 ===================
epoch no : 6, batch no : 49, total loss : 0.3622240722179413,  classifier :0.028323428705334663, mask: 0.1528392881155014 ===================
epoch no : 6, batch no : 50, total loss : 0.3183232247829437,  classifier :0.029479961842298508, mask: 0.14196264743804932 ===================
epoch no : 6, batch no : 51, total loss : 0.4353328049182892,  classifier :0.05552716553211212, mask: 0.1821264624595642 ===================
epoch no : 6, batch no : 52, total loss : 0.2670019567012787,  classifier :0.029205230996012688, mask: 0.14160418510437012 ===================
epoch no : 6, batch no : 53, total loss : 0.26176172494888306,  classifier :0.02793295495212078, mask: 0.1275351643562317 ===================
epoch no : 6, batch no : 54, total loss : 0.2531115412712097,  classifier :0.029976487159729004, mask: 0.11344984173774719 ===================
epoch no : 6, batch no : 55, total loss : 0.23140370845794678,  classifier :0.030198004096746445, mask: 0.09590935707092285 ===================
epoch no : 6, batch no : 56, total loss : 0.27166783809661865,  classifier :0.030937179923057556, mask: 0.1333334892988205 ===================
epoch no : 6, batch no : 57, total loss : 0.26255175471305847,  classifier :0.02291453257203102, mask: 0.1254323422908783 ===================
epoch no : 6, batch no : 58, total loss : 0.3298438787460327,  classifier :0.031094040721654892, mask: 0.12899233400821686 ===================
epoch no : 6, batch no : 59, total loss : 0.32862338423728943,  classifier :0.04194054380059242, mask: 0.12636388838291168 ===================
epoch no : 6, batch no : 60, total loss : 0.36906689405441284,  classifier :0.03325168043375015, mask: 0.17307700216770172 ===================
epoch no : 6, batch no : 61, total loss : 0.2591036558151245,  classifier :0.023400573059916496, mask: 0.13095764815807343 ===================
epoch no : 6, batch no : 62, total loss : 0.31550899147987366,  classifier :0.03845274820923805, mask: 0.15330861508846283 ===================
epoch no : 6, batch no : 63, total loss : 0.24909907579421997,  classifier :0.02492900751531124, mask: 0.11664526164531708 ===================
epoch no : 6, batch no : 64, total loss : 0.2974640130996704,  classifier :0.03431272879242897, mask: 0.13499826192855835 ===================
epoch no : 6, batch no : 65, total loss : 0.27053380012512207,  classifier :0.029149793088436127, mask: 0.10784070938825607 ===================
epoch no : 6, batch no : 66, total loss : 0.2550193965435028,  classifier :0.03279214724898338, mask: 0.08804021775722504 ===================
epoch no : 6, batch no : 67, total loss : 0.32719242572784424,  classifier :0.0413573794066906, mask: 0.1557285487651825 ===================
epoch no : 6, batch no : 68, total loss : 0.21946768462657928,  classifier :0.024061676114797592, mask: 0.08773750066757202 ===================
epoch no : 6, batch no : 69, total loss : 0.2242516577243805,  classifier :0.026941947638988495, mask: 0.09350494295358658 ===================
epoch no : 6, batch no : 70, total loss : 0.23566238582134247,  classifier :0.024061108008027077, mask: 0.11407236754894257 ===================
epoch no : 6, batch no : 71, total loss : 0.22755567729473114,  classifier :0.034757547080516815, mask: 0.08925068378448486 ===================
epoch no : 6, batch no : 72, total loss : 0.29357317090034485,  classifier :0.03217165917158127, mask: 0.1294817477464676 ===================
epoch no : 6, batch no : 73, total loss : 0.2289472222328186,  classifier :0.032228462398052216, mask: 0.10038457065820694 ===================
epoch no : 6, batch no : 74, total loss : 0.2702099680900574,  classifier :0.0260244719684124, mask: 0.11734589189291 ===================
epoch no : 6, batch no : 75, total loss : 0.3380937874317169,  classifier :0.03834526613354683, mask: 0.1419963240623474 ===================
epoch no : 6, batch no : 76, total loss : 0.29543712735176086,  classifier :0.024210626259446144, mask: 0.11671829968690872 ===================
epoch no : 6, batch no : 77, total loss : 0.3011432886123657,  classifier :0.027329221367836, mask: 0.13099464774131775 ===================
epoch no : 6, batch no : 78, total loss : 0.27203381061553955,  classifier :0.03452328220009804, mask: 0.10040058195590973 ===================
epoch no : 6, batch no : 79, total loss : 0.28736770153045654,  classifier :0.030204754322767258, mask: 0.14151224493980408 ===================
epoch no : 6, batch no : 80, total loss : 0.3504507541656494,  classifier :0.05546806380152702, mask: 0.13152596354484558 ===================
epoch no : 6, batch no : 81, total loss : 0.2630721926689148,  classifier :0.025402981787919998, mask: 0.10440680384635925 ===================
epoch no : 6, batch no : 82, total loss : 0.2867359220981598,  classifier :0.026737019419670105, mask: 0.12464386969804764 ===================
epoch no : 6, batch no : 83, total loss : 0.2633734345436096,  classifier :0.034933168441057205, mask: 0.09529842436313629 ===================
epoch no : 6, batch no : 84, total loss : 0.35137826204299927,  classifier :0.029269227758049965, mask: 0.09600840508937836 ===================
epoch no : 6, batch no : 85, total loss : 0.308025062084198,  classifier :0.035853736102581024, mask: 0.13062503933906555 ===================
epoch no : 6, batch no : 86, total loss : 0.22839461266994476,  classifier :0.032728567719459534, mask: 0.0933397188782692 ===================
epoch no : 6, batch no : 87, total loss : 0.2990247309207916,  classifier :0.024543369188904762, mask: 0.11865054816007614 ===================
epoch no : 6, batch no : 88, total loss : 0.32716503739356995,  classifier :0.030181292444467545, mask: 0.12381219118833542 ===================
epoch no : 6, batch no : 89, total loss : 0.2624773383140564,  classifier :0.02123572863638401, mask: 0.11895207315683365 ===================
epoch no : 6, batch no : 90, total loss : 0.36728525161743164,  classifier :0.035425737500190735, mask: 0.15302674472332 ===================
epoch no : 6, batch no : 91, total loss : 0.27535077929496765,  classifier :0.032926566898822784, mask: 0.12207670509815216 ===================
epoch no : 6, batch no : 92, total loss : 0.24479995667934418,  classifier :0.03205495700240135, mask: 0.09943731129169464 ===================
epoch no : 6, batch no : 93, total loss : 0.26333895325660706,  classifier :0.025326939299702644, mask: 0.10597427934408188 ===================
epoch no : 6, batch no : 94, total loss : 0.2723991870880127,  classifier :0.030305419117212296, mask: 0.10232511907815933 ===================
epoch no : 6, batch no : 95, total loss : 0.3124372661113739,  classifier :0.028742065653204918, mask: 0.10310277342796326 ===================
epoch no : 6, batch no : 96, total loss : 0.32280269265174866,  classifier :0.03054037131369114, mask: 0.14352299273014069 ===================
epoch no : 6, batch no : 97, total loss : 0.3445102572441101,  classifier :0.02422771416604519, mask: 0.16836118698120117 ===================
epoch no : 6, batch no : 98, total loss : 0.29237696528434753,  classifier :0.02625764161348343, mask: 0.12118376791477203 ===================
epoch no : 6, batch no : 99, total loss : 0.3478279709815979,  classifier :0.029353994876146317, mask: 0.1419685035943985 ===================
epoch no : 6, batch no : 100, total loss : 0.31039807200431824,  classifier :0.039634570479393005, mask: 0.1258288472890854 ===================
epoch no : 6, batch no : 101, total loss : 0.23273935914039612,  classifier :0.04249488189816475, mask: 0.09531428664922714 ===================
epoch no : 6, batch no : 102, total loss : 0.25211575627326965,  classifier :0.028100354596972466, mask: 0.09521502256393433 ===================
epoch no : 6, batch no : 103, total loss : 0.31488943099975586,  classifier :0.03827796131372452, mask: 0.12330304831266403 ===================
epoch no : 6, batch no : 104, total loss : 0.30898481607437134,  classifier :0.04535633698105812, mask: 0.13029831647872925 ===================
epoch no : 6, batch no : 105, total loss : 0.3437805473804474,  classifier :0.03688613325357437, mask: 0.13271446526050568 ===================
epoch no : 6, batch no : 106, total loss : 0.2631891071796417,  classifier :0.03295006603002548, mask: 0.10493656992912292 ===================
epoch no : 6, batch no : 107, total loss : 0.4381284713745117,  classifier :0.048409998416900635, mask: 0.18390510976314545 ===================
epoch no : 6, batch no : 108, total loss : 0.2344309240579605,  classifier :0.036734700202941895, mask: 0.10784758627414703 ===================
epoch no : 6, batch no : 109, total loss : 0.23708049952983856,  classifier :0.026575520634651184, mask: 0.11185909807682037 ===================
epoch no : 6, batch no : 110, total loss : 0.209554523229599,  classifier :0.023054778575897217, mask: 0.09382468461990356 ===================
epoch no : 6, batch no : 111, total loss : 0.2578384280204773,  classifier :0.03783605247735977, mask: 0.08262544870376587 ===================
epoch no : 6, batch no : 112, total loss : 0.3073912262916565,  classifier :0.03164783492684364, mask: 0.10539544373750687 ===================
epoch no : 6, batch no : 113, total loss : 0.28805845975875854,  classifier :0.035670291632413864, mask: 0.12790408730506897 ===================
epoch no : 6, batch no : 114, total loss : 0.2812894880771637,  classifier :0.02659001015126705, mask: 0.1505262404680252 ===================
epoch no : 6, batch no : 115, total loss : 0.24348971247673035,  classifier :0.03376215323805809, mask: 0.09579015523195267 ===================
epoch no : 6, batch no : 116, total loss : 0.3061579763889313,  classifier :0.0401158407330513, mask: 0.11233022063970566 ===================
epoch no : 6, batch no : 117, total loss : 0.2338692545890808,  classifier :0.0326533205807209, mask: 0.09005147963762283 ===================
epoch no : 6, batch no : 118, total loss : 0.2983938753604889,  classifier :0.03959140181541443, mask: 0.12605831027030945 ===================
epoch no : 6, batch no : 119, total loss : 0.2822010815143585,  classifier :0.02876010164618492, mask: 0.12447446584701538 ===================
epoch no : 6, batch no : 120, total loss : 0.3635571599006653,  classifier :0.02260499820113182, mask: 0.1512562483549118 ===================
epoch no : 6, batch no : 121, total loss : 0.4042978882789612,  classifier :0.04354512318968773, mask: 0.12583689391613007 ===================
epoch no : 6, batch no : 122, total loss : 0.35406485199928284,  classifier :0.03753466159105301, mask: 0.11748117208480835 ===================
epoch no : 6, batch no : 123, total loss : 0.3046436607837677,  classifier :0.03170809522271156, mask: 0.1582615226507187 ===================
epoch no : 6, batch no : 124, total loss : 0.21072226762771606,  classifier :0.022130172699689865, mask: 0.09471669793128967 ===================
epoch no : 6, batch no : 125, total loss : 0.4114550054073334,  classifier :0.03624556586146355, mask: 0.17912405729293823 ===================
epoch no : 6, batch no : 126, total loss : 0.3006390333175659,  classifier :0.029768748208880424, mask: 0.125784233212471 ===================
epoch no : 6, batch no : 127, total loss : 0.24816374480724335,  classifier :0.03456344082951546, mask: 0.10934645682573318 ===================
epoch no : 6, batch no : 128, total loss : 0.2691080868244171,  classifier :0.02644982933998108, mask: 0.1350031942129135 ===================
epoch no : 6, batch no : 129, total loss : 0.2694348394870758,  classifier :0.027885332703590393, mask: 0.11360683292150497 ===================
epoch no : 6, batch no : 130, total loss : 0.2665255069732666,  classifier :0.03946968913078308, mask: 0.11355143040418625 ===================
epoch no : 6, batch no : 131, total loss : 0.2077653408050537,  classifier :0.020421741530299187, mask: 0.10082565248012543 ===================
epoch no : 6, batch no : 132, total loss : 0.22720500826835632,  classifier :0.023026127368211746, mask: 0.10047753900289536 ===================
epoch no : 6, batch no : 133, total loss : 0.3198698163032532,  classifier :0.02444269321858883, mask: 0.13168761134147644 ===================
epoch no : 6, batch no : 134, total loss : 0.32828381657600403,  classifier :0.02825615182518959, mask: 0.12756314873695374 ===================
epoch no : 6, batch no : 135, total loss : 0.2793387174606323,  classifier :0.03353440761566162, mask: 0.1307782083749771 ===================
epoch no : 6, batch no : 136, total loss : 0.26745760440826416,  classifier :0.02396259643137455, mask: 0.1350589245557785 ===================
epoch no : 6, batch no : 137, total loss : 0.26431697607040405,  classifier :0.030340395867824554, mask: 0.11163603514432907 ===================
epoch no : 6, batch no : 138, total loss : 0.2115291804075241,  classifier :0.03561471030116081, mask: 0.08985470980405807 ===================
epoch no : 6, batch no : 139, total loss : 0.3485558331012726,  classifier :0.026296216994524002, mask: 0.1311192363500595 ===================
epoch no : 6, batch no : 140, total loss : 0.24095392227172852,  classifier :0.026463281363248825, mask: 0.10423971712589264 ===================
epoch no : 6, batch no : 141, total loss : 0.2676495909690857,  classifier :0.028877072036266327, mask: 0.12318708002567291 ===================
epoch no : 6, batch no : 142, total loss : 0.20647300779819489,  classifier :0.024387845769524574, mask: 0.10450711846351624 ===================
epoch no : 6, batch no : 143, total loss : 0.35621514916419983,  classifier :0.027574509382247925, mask: 0.1460225135087967 ===================
epoch no : 6, batch no : 144, total loss : 0.38763412833213806,  classifier :0.03170830383896828, mask: 0.1563744992017746 ===================
epoch no : 6, batch no : 145, total loss : 0.3710799515247345,  classifier :0.03749943897128105, mask: 0.13380087912082672 ===================
epoch no : 6, batch no : 146, total loss : 0.2689693570137024,  classifier :0.030461857095360756, mask: 0.1058674231171608 ===================
epoch no : 6, batch no : 147, total loss : 0.32042741775512695,  classifier :0.025689758360385895, mask: 0.15287074446678162 ===================
epoch no : 6, batch no : 148, total loss : 0.31617477536201477,  classifier :0.03137575089931488, mask: 0.15567757189273834 ===================
epoch no : 6, batch no : 149, total loss : 0.3939136266708374,  classifier :0.033569417893886566, mask: 0.14538143575191498 ===================
epoch no : 6, batch no : 150, total loss : 0.2638694941997528,  classifier :0.027832703664898872, mask: 0.11220387369394302 ===================
epoch no : 6, batch no : 151, total loss : 0.2994571328163147,  classifier :0.032967403531074524, mask: 0.12843303382396698 ===================
epoch no : 6, batch no : 152, total loss : 0.2995186746120453,  classifier :0.02667180635035038, mask: 0.12377343326807022 ===================
epoch no : 6, batch no : 153, total loss : 0.2964918613433838,  classifier :0.030261777341365814, mask: 0.1452154964208603 ===================
epoch no : 6, batch no : 154, total loss : 0.2945866584777832,  classifier :0.02774222567677498, mask: 0.15693315863609314 ===================
epoch no : 6, batch no : 155, total loss : 0.26866090297698975,  classifier :0.03189510479569435, mask: 0.11161452531814575 ===================
epoch no : 6, batch no : 156, total loss : 0.2764170169830322,  classifier :0.028477229177951813, mask: 0.1179637685418129 ===================
epoch no : 6, batch no : 157, total loss : 0.2321694791316986,  classifier :0.028882412239909172, mask: 0.11558292806148529 ===================
epoch no : 6, batch no : 158, total loss : 0.2618456482887268,  classifier :0.032548293471336365, mask: 0.09534605592489243 ===================
epoch no : 6, batch no : 159, total loss : 0.25720545649528503,  classifier :0.025176342576742172, mask: 0.11265920847654343 ===================
epoch no : 6, batch no : 160, total loss : 0.27924591302871704,  classifier :0.024244533851742744, mask: 0.1202666312456131 ===================
epoch no : 6, batch no : 161, total loss : 0.30726197361946106,  classifier :0.021304184570908546, mask: 0.12226459383964539 ===================
epoch no : 6, batch no : 162, total loss : 0.28608494997024536,  classifier :0.03648688271641731, mask: 0.1247982457280159 ===================
epoch no : 6, batch no : 163, total loss : 0.25221216678619385,  classifier :0.02577739953994751, mask: 0.10331263393163681 ===================
epoch no : 6, batch no : 164, total loss : 0.3614845275878906,  classifier :0.03586167097091675, mask: 0.10541395843029022 ===================
epoch no : 6, batch no : 165, total loss : 0.3356926441192627,  classifier :0.06174873188138008, mask: 0.11735664308071136 ===================
epoch no : 6, batch no : 166, total loss : 0.2313108891248703,  classifier :0.03255206346511841, mask: 0.09156183153390884 ===================
epoch no : 6, batch no : 167, total loss : 0.2531362473964691,  classifier :0.021226098760962486, mask: 0.12830378115177155 ===================
epoch no : 6, batch no : 168, total loss : 0.1778990775346756,  classifier :0.0246542040258646, mask: 0.08255601674318314 ===================
epoch no : 6, batch no : 169, total loss : 0.2687983214855194,  classifier :0.02964511513710022, mask: 0.1116068959236145 ===================
epoch no : 6, batch no : 170, total loss : 0.25327691435813904,  classifier :0.02542451210319996, mask: 0.10613714158535004 ===================
epoch no : 6, batch no : 171, total loss : 0.31325075030326843,  classifier :0.025569666177034378, mask: 0.1625126749277115 ===================
epoch no : 6, batch no : 172, total loss : 0.3495428264141083,  classifier :0.025973381474614143, mask: 0.13173608481884003 ===================
epoch no : 6, batch no : 173, total loss : 0.2864622473716736,  classifier :0.04282095283269882, mask: 0.1363728791475296 ===================
epoch no : 6, batch no : 174, total loss : 0.26368847489356995,  classifier :0.025841161608695984, mask: 0.12400545179843903 ===================
epoch no : 6, batch no : 175, total loss : 0.24362702667713165,  classifier :0.02189958654344082, mask: 0.11929696798324585 ===================
epoch no : 6, batch no : 176, total loss : 0.28994300961494446,  classifier :0.04449847340583801, mask: 0.13004861772060394 ===================
epoch no : 6, batch no : 177, total loss : 0.21461686491966248,  classifier :0.024237491190433502, mask: 0.0940215215086937 ===================
epoch no : 6, batch no : 178, total loss : 0.20215579867362976,  classifier :0.01802755519747734, mask: 0.09994442760944366 ===================
epoch no : 6, batch no : 179, total loss : 0.2788257300853729,  classifier :0.02359914965927601, mask: 0.14889462292194366 ===================
epoch no : 6, batch no : 180, total loss : 0.33889955282211304,  classifier :0.03167954459786415, mask: 0.13386690616607666 ===================
epoch no : 6, batch no : 181, total loss : 0.2343769371509552,  classifier :0.022752409800887108, mask: 0.10039898753166199 ===================
epoch no : 6, batch no : 182, total loss : 0.26738637685775757,  classifier :0.02829357609152794, mask: 0.11838356405496597 ===================
epoch no : 6, batch no : 183, total loss : 0.30828163027763367,  classifier :0.03552502766251564, mask: 0.11757051199674606 ===================
epoch no : 6, batch no : 184, total loss : 0.3272569477558136,  classifier :0.04296816140413284, mask: 0.13930749893188477 ===================
epoch no : 6, batch no : 185, total loss : 0.34878018498420715,  classifier :0.04436307027935982, mask: 0.15662451088428497 ===================
epoch no : 6, batch no : 186, total loss : 0.2133256494998932,  classifier :0.027984237298369408, mask: 0.09773122519254684 ===================
epoch no : 6, batch no : 187, total loss : 0.3149903118610382,  classifier :0.035731539130210876, mask: 0.14765095710754395 ===================
epoch no : 6, batch no : 188, total loss : 0.23768092691898346,  classifier :0.03606628626585007, mask: 0.08718369156122208 ===================
epoch no : 6, batch no : 189, total loss : 0.2576698958873749,  classifier :0.023630641400814056, mask: 0.11277896910905838 ===================
epoch no : 6, batch no : 190, total loss : 0.30024147033691406,  classifier :0.030042601749300957, mask: 0.14426173269748688 ===================
epoch no : 6, batch no : 191, total loss : 0.2981913983821869,  classifier :0.023175083100795746, mask: 0.14659427106380463 ===================
epoch no : 6, batch no : 192, total loss : 0.3289048373699188,  classifier :0.026827586814761162, mask: 0.15908849239349365 ===================
epoch no : 6, batch no : 193, total loss : 0.2640725076198578,  classifier :0.026798656210303307, mask: 0.10725835710763931 ===================
epoch no : 6, batch no : 194, total loss : 0.20049408078193665,  classifier :0.0314454548060894, mask: 0.09601500630378723 ===================
epoch no : 6, batch no : 195, total loss : 0.24317918717861176,  classifier :0.024495966732501984, mask: 0.11192247271537781 ===================
epoch no : 6, batch no : 196, total loss : 0.2963915169239044,  classifier :0.029814478009939194, mask: 0.15263012051582336 ===================
epoch no : 6, batch no : 197, total loss : 0.26781904697418213,  classifier :0.028654461726546288, mask: 0.13409695029258728 ===================
epoch no : 6, batch no : 198, total loss : 0.2810400426387787,  classifier :0.01880532130599022, mask: 0.13738569617271423 ===================
epoch no : 6, batch no : 199, total loss : 0.24363626539707184,  classifier :0.044864896684885025, mask: 0.10224706679582596 ===================
epoch no : 6, batch no : 200, total loss : 0.2549208998680115,  classifier :0.030543122440576553, mask: 0.11664961278438568 ===================
epoch no : 6, batch no : 201, total loss : 0.22586975991725922,  classifier :0.02709379233419895, mask: 0.1071709543466568 ===================
epoch no : 6, batch no : 202, total loss : 0.23808996379375458,  classifier :0.026828810572624207, mask: 0.11174643784761429 ===================
epoch no : 6, batch no : 203, total loss : 0.31610122323036194,  classifier :0.03456525504589081, mask: 0.1465863287448883 ===================
epoch no : 6, batch no : 204, total loss : 0.23214606940746307,  classifier :0.025242719799280167, mask: 0.09996841847896576 ===================
epoch no : 6, batch no : 205, total loss : 0.22180047631263733,  classifier :0.022891156375408173, mask: 0.10997986793518066 ===================
epoch no : 6, batch no : 206, total loss : 0.3197919726371765,  classifier :0.04610953480005264, mask: 0.10918605327606201 ===================
epoch no : 6, batch no : 207, total loss : 0.30193671584129333,  classifier :0.03986367955803871, mask: 0.10928346961736679 ===================
epoch no : 6, batch no : 208, total loss : 0.29706305265426636,  classifier :0.027072284370660782, mask: 0.11456894874572754 ===================
epoch no : 6, batch no : 209, total loss : 0.30505192279815674,  classifier :0.02976278029382229, mask: 0.11852608621120453 ===================
epoch no : 6, batch no : 210, total loss : 0.4133078455924988,  classifier :0.03486299887299538, mask: 0.1763843297958374 ===================
epoch no : 6, batch no : 211, total loss : 0.3167804479598999,  classifier :0.024741733446717262, mask: 0.13656066358089447 ===================
epoch no : 6, batch no : 212, total loss : 0.26707780361175537,  classifier :0.03570757806301117, mask: 0.09885639697313309 ===================
epoch no : 6, batch no : 213, total loss : 0.2875954508781433,  classifier :0.02705257572233677, mask: 0.11111284047365189 ===================
epoch no : 6, batch no : 214, total loss : 0.25079867243766785,  classifier :0.021029477939009666, mask: 0.10694224387407303 ===================
epoch no : 6, batch no : 215, total loss : 0.21179640293121338,  classifier :0.031779270619153976, mask: 0.0916033685207367 ===================
epoch no : 6, batch no : 216, total loss : 0.20098546147346497,  classifier :0.025232432410120964, mask: 0.08269068598747253 ===================
epoch no : 6, batch no : 217, total loss : 0.21514731645584106,  classifier :0.028960028663277626, mask: 0.09226319938898087 ===================
epoch no : 6, batch no : 218, total loss : 0.3467836380004883,  classifier :0.02880597673356533, mask: 0.1603543907403946 ===================
epoch no : 6, batch no : 219, total loss : 0.3302072286605835,  classifier :0.027011629194021225, mask: 0.14275862276554108 ===================
epoch no : 6, batch no : 220, total loss : 0.3578569293022156,  classifier :0.033477310091257095, mask: 0.15836311876773834 ===================
epoch no : 6, batch no : 221, total loss : 0.26921287178993225,  classifier :0.026545532047748566, mask: 0.13623271882534027 ===================
epoch no : 6, batch no : 222, total loss : 0.3113600015640259,  classifier :0.03814470022916794, mask: 0.13285328447818756 ===================
epoch no : 6, batch no : 223, total loss : 0.2316405177116394,  classifier :0.024368975311517715, mask: 0.09716632962226868 ===================
epoch no : 6, batch no : 224, total loss : 0.2159813493490219,  classifier :0.025252925232052803, mask: 0.10204090923070908 ===================
epoch no : 6, batch no : 225, total loss : 0.20515382289886475,  classifier :0.02208704687654972, mask: 0.09991564601659775 ===================
epoch no : 6, batch no : 226, total loss : 0.2493596225976944,  classifier :0.036570996046066284, mask: 0.09489436447620392 ===================
epoch no : 6, batch no : 227, total loss : 0.34078264236450195,  classifier :0.03860915079712868, mask: 0.152798593044281 ===================
epoch no : 6, batch no : 228, total loss : 0.2956784665584564,  classifier :0.029246386140584946, mask: 0.12636761367321014 ===================
epoch no : 6, batch no : 229, total loss : 0.3577675223350525,  classifier :0.04101981222629547, mask: 0.1524079591035843 ===================
epoch no : 6, batch no : 230, total loss : 0.5800580978393555,  classifier :0.03900333493947983, mask: 0.27762171626091003 ===================
epoch no : 6, batch no : 231, total loss : 0.26990965008735657,  classifier :0.03148549795150757, mask: 0.1156153604388237 ===================
epoch no : 6, batch no : 232, total loss : 0.30320727825164795,  classifier :0.044863615185022354, mask: 0.12878498435020447 ===================
epoch no : 6, batch no : 233, total loss : 0.24458856880664825,  classifier :0.026514720171689987, mask: 0.10531251132488251 ===================
epoch no : 6, batch no : 234, total loss : 0.25735709071159363,  classifier :0.02417338266968727, mask: 0.10621573776006699 ===================
epoch no : 6, batch no : 235, total loss : 0.3037058413028717,  classifier :0.03838763386011124, mask: 0.12431129068136215 ===================
epoch no : 6, batch no : 236, total loss : 0.2707822322845459,  classifier :0.0327029787003994, mask: 0.11578353494405746 ===================
epoch no : 6, batch no : 237, total loss : 0.25873634219169617,  classifier :0.02590584196150303, mask: 0.11575768142938614 ===================
epoch no : 6, batch no : 238, total loss : 0.21344129741191864,  classifier :0.021338388323783875, mask: 0.10939580947160721 ===================
epoch no : 6, batch no : 239, total loss : 0.24814090132713318,  classifier :0.02752910554409027, mask: 0.10632863640785217 ===================
epoch no : 6, batch no : 240, total loss : 0.32983633875846863,  classifier :0.031879931688308716, mask: 0.138933464884758 ===================
epoch no : 6, batch no : 241, total loss : 0.24267101287841797,  classifier :0.023533420637249947, mask: 0.12818965315818787 ===================
epoch no : 6, batch no : 242, total loss : 0.2752143144607544,  classifier :0.028852546587586403, mask: 0.11726366728544235 ===================
epoch no : 6, batch no : 243, total loss : 0.2835030257701874,  classifier :0.024561313912272453, mask: 0.1250685453414917 ===================
epoch no : 6, batch no : 244, total loss : 0.25251883268356323,  classifier :0.026385053992271423, mask: 0.1333710104227066 ===================
epoch no : 6, batch no : 245, total loss : 0.3057345151901245,  classifier :0.03168004751205444, mask: 0.1317269206047058 ===================
epoch no : 6, batch no : 246, total loss : 0.21711421012878418,  classifier :0.031153380870819092, mask: 0.0955907478928566 ===================
epoch no : 6, batch no : 247, total loss : 0.30569353699684143,  classifier :0.024777662009000778, mask: 0.14744050800800323 ===================
epoch no : 6, batch no : 248, total loss : 0.329554945230484,  classifier :0.03416438400745392, mask: 0.14694301784038544 ===================
epoch no : 6, batch no : 249, total loss : 0.26520052552223206,  classifier :0.03454253822565079, mask: 0.09432197362184525 ===================
epoch no : 6, batch no : 250, total loss : 0.48335757851600647,  classifier :0.053274430334568024, mask: 0.16718314588069916 ===================
epoch no : 6, batch no : 251, total loss : 0.24418608844280243,  classifier :0.02643461711704731, mask: 0.108042411506176 ===================
epoch no : 6, batch no : 252, total loss : 0.2734169363975525,  classifier :0.03150683268904686, mask: 0.11999381333589554 ===================
epoch no : 6, batch no : 253, total loss : 0.25124043226242065,  classifier :0.0313878133893013, mask: 0.12734189629554749 ===================
epoch no : 6, batch no : 254, total loss : 0.24628032743930817,  classifier :0.035215482115745544, mask: 0.11302643269300461 ===================
epoch no : 6, batch no : 255, total loss : 0.25249379873275757,  classifier :0.026294566690921783, mask: 0.11168627440929413 ===================
epoch no : 6, batch no : 256, total loss : 0.30241844058036804,  classifier :0.044610947370529175, mask: 0.1302855908870697 ===================
epoch no : 6, batch no : 257, total loss : 0.3843686580657959,  classifier :0.033648744225502014, mask: 0.15739315748214722 ===================
epoch no : 6, batch no : 258, total loss : 0.34549573063850403,  classifier :0.031747523695230484, mask: 0.13503189384937286 ===================
epoch no : 6, batch no : 259, total loss : 0.2932284474372864,  classifier :0.02927502617239952, mask: 0.13177554309368134 ===================
epoch no : 6, batch no : 260, total loss : 0.24428915977478027,  classifier :0.02373206987977028, mask: 0.11066854745149612 ===================
epoch no : 6, batch no : 261, total loss : 0.317550390958786,  classifier :0.028714165091514587, mask: 0.14014415442943573 ===================
epoch no : 6, batch no : 262, total loss : 0.27588677406311035,  classifier :0.027807017788290977, mask: 0.10793988406658173 ===================
epoch no : 6, batch no : 263, total loss : 0.2333880066871643,  classifier :0.0240083709359169, mask: 0.12168996781110764 ===================
epoch no : 6, batch no : 264, total loss : 0.29965996742248535,  classifier :0.03194907680153847, mask: 0.1372775137424469 ===================
epoch no : 6, batch no : 265, total loss : 0.3423227071762085,  classifier :0.03170780465006828, mask: 0.14345255494117737 ===================
epoch no : 6, batch no : 266, total loss : 0.223436638712883,  classifier :0.028786741197109222, mask: 0.09103664755821228 ===================
epoch no : 6, batch no : 267, total loss : 0.23486649990081787,  classifier :0.02437800168991089, mask: 0.09697055071592331 ===================
epoch no : 6, batch no : 268, total loss : 0.21060948073863983,  classifier :0.024053581058979034, mask: 0.09873141348361969 ===================
epoch no : 6, batch no : 269, total loss : 0.24688053131103516,  classifier :0.029714837670326233, mask: 0.1034734696149826 ===================
epoch no : 6, batch no : 270, total loss : 0.33644339442253113,  classifier :0.026569770649075508, mask: 0.14316748082637787 ===================
epoch no : 6, batch no : 271, total loss : 0.2889394164085388,  classifier :0.03245804086327553, mask: 0.1296161711215973 ===================
epoch no : 6, batch no : 272, total loss : 0.2508417069911957,  classifier :0.026877833530306816, mask: 0.12607505917549133 ===================
epoch no : 6, batch no : 273, total loss : 0.25158756971359253,  classifier :0.024352481588721275, mask: 0.12336023151874542 ===================
epoch no : 6, batch no : 274, total loss : 0.23409512639045715,  classifier :0.021541893482208252, mask: 0.1152728721499443 ===================
epoch no : 6, batch no : 275, total loss : 0.2679390609264374,  classifier :0.03528905659914017, mask: 0.13421334326267242 ===================
epoch no : 6, batch no : 276, total loss : 0.25547659397125244,  classifier :0.03550739586353302, mask: 0.10688383877277374 ===================
epoch no : 6, batch no : 277, total loss : 0.2025793194770813,  classifier :0.027971873059868813, mask: 0.09686789661645889 ===================
epoch no : 6, batch no : 278, total loss : 0.23354749381542206,  classifier :0.028499368578195572, mask: 0.104693703353405 ===================
epoch no : 6, batch no : 279, total loss : 0.23911435902118683,  classifier :0.023446764796972275, mask: 0.10159559547901154 ===================
epoch no : 6, batch no : 280, total loss : 0.41302040219306946,  classifier :0.04138125479221344, mask: 0.15906250476837158 ===================
epoch no : 6, batch no : 281, total loss : 0.25972262024879456,  classifier :0.028139548376202583, mask: 0.09878712892532349 ===================
epoch no : 6, batch no : 282, total loss : 0.3445425033569336,  classifier :0.053765520453453064, mask: 0.14202181994915009 ===================
epoch no : 6, batch no : 283, total loss : 0.21506991982460022,  classifier :0.018516581505537033, mask: 0.10371772199869156 ===================
epoch no : 6, batch no : 284, total loss : 0.23570731282234192,  classifier :0.027932683005928993, mask: 0.10564594715833664 ===================
epoch no : 6, batch no : 285, total loss : 0.2351388931274414,  classifier :0.026955313980579376, mask: 0.10165061801671982 ===================
epoch no : 6, batch no : 286, total loss : 0.1951325237751007,  classifier :0.02078462764620781, mask: 0.08946745097637177 ===================
epoch no : 6, batch no : 287, total loss : 0.22325599193572998,  classifier :0.018329424783587456, mask: 0.09867335855960846 ===================
epoch no : 6, batch no : 288, total loss : 0.2795310616493225,  classifier :0.025335418060421944, mask: 0.1293724775314331 ===================
epoch no : 6, batch no : 289, total loss : 0.27384451031684875,  classifier :0.02721267193555832, mask: 0.11820460110902786 ===================
epoch no : 6, batch no : 290, total loss : 0.2808297574520111,  classifier :0.03258870169520378, mask: 0.10711740702390671 ===================
epoch no : 6, batch no : 291, total loss : 0.287901371717453,  classifier :0.029852693900465965, mask: 0.09268677234649658 ===================
epoch no : 6, batch no : 292, total loss : 0.2981041371822357,  classifier :0.025145087391138077, mask: 0.10154673457145691 ===================
epoch no : 6, batch no : 293, total loss : 0.21089652180671692,  classifier :0.027662096545100212, mask: 0.08113109320402145 ===================
epoch no : 6, batch no : 294, total loss : 0.32895150780677795,  classifier :0.038030095398426056, mask: 0.1379341036081314 ===================
epoch no : 6, batch no : 295, total loss : 0.2865520715713501,  classifier :0.026948152109980583, mask: 0.11632370203733444 ===================
epoch no : 6, batch no : 296, total loss : 0.2193945199251175,  classifier :0.02096877060830593, mask: 0.09721799194812775 ===================
epoch no : 6, batch no : 297, total loss : 0.27773332595825195,  classifier :0.031578559428453445, mask: 0.11176887899637222 ===================
epoch no : 6, batch no : 298, total loss : 0.28769031167030334,  classifier :0.03139035031199455, mask: 0.11585354804992676 ===================
epoch no : 6, batch no : 299, total loss : 0.3559574484825134,  classifier :0.03905465453863144, mask: 0.1348952054977417 ===================
epoch no : 6, batch no : 300, total loss : 0.27483701705932617,  classifier :0.032195255160331726, mask: 0.11721491068601608 ===================
epoch no : 6, batch no : 301, total loss : 0.2068091630935669,  classifier :0.02395028993487358, mask: 0.09552013128995895 ===================
epoch no : 6, batch no : 302, total loss : 0.24675194919109344,  classifier :0.03701825439929962, mask: 0.09700962901115417 ===================
epoch no : 6, batch no : 303, total loss : 0.349059134721756,  classifier :0.051324523985385895, mask: 0.1188153401017189 ===================
epoch no : 6, batch no : 304, total loss : 0.30611011385917664,  classifier :0.02298310585319996, mask: 0.13173101842403412 ===================
epoch no : 6, batch no : 305, total loss : 0.23410767316818237,  classifier :0.027565546333789825, mask: 0.09975031763315201 ===================
epoch no : 6, batch no : 306, total loss : 0.2447327971458435,  classifier :0.034338321536779404, mask: 0.09641405194997787 ===================
epoch no : 6, batch no : 307, total loss : 0.22401505708694458,  classifier :0.02334996871650219, mask: 0.10026392340660095 ===================
epoch no : 6, batch no : 308, total loss : 0.2949720323085785,  classifier :0.02277746982872486, mask: 0.12779194116592407 ===================
epoch no : 6, batch no : 309, total loss : 0.25392115116119385,  classifier :0.040396708995103836, mask: 0.08633420616388321 ===================
epoch no : 6, batch no : 310, total loss : 0.2809932827949524,  classifier :0.025252755731344223, mask: 0.1017678752541542 ===================
epoch no : 6, batch no : 311, total loss : 0.23292504251003265,  classifier :0.02906440757215023, mask: 0.10047483444213867 ===================
epoch no : 6, batch no : 312, total loss : 0.2687632739543915,  classifier :0.021427804604172707, mask: 0.1307346671819687 ===================
epoch no : 6, batch no : 313, total loss : 0.28856244683265686,  classifier :0.03625086322426796, mask: 0.11656790971755981 ===================
epoch no : 6, batch no : 314, total loss : 0.2752660810947418,  classifier :0.03314344584941864, mask: 0.11294040083885193 ===================
epoch no : 6, batch no : 315, total loss : 0.2194008082151413,  classifier :0.02853618934750557, mask: 0.10726393014192581 ===================
epoch no : 6, batch no : 316, total loss : 0.21447572112083435,  classifier :0.027954701334238052, mask: 0.11348370462656021 ===================
epoch no : 6, batch no : 317, total loss : 0.22263655066490173,  classifier :0.027356363832950592, mask: 0.09341797232627869 ===================
epoch no : 6, batch no : 318, total loss : 0.31803637742996216,  classifier :0.044363733381032944, mask: 0.10992958396673203 ===================
epoch no : 6, batch no : 319, total loss : 0.2893086075782776,  classifier :0.03430847451090813, mask: 0.10792756080627441 ===================
epoch no : 6, batch no : 320, total loss : 0.2357010692358017,  classifier :0.04298314452171326, mask: 0.09069419652223587 ===================
epoch no : 6, batch no : 321, total loss : 0.2799958884716034,  classifier :0.02753349579870701, mask: 0.12059292197227478 ===================
epoch no : 6, batch no : 322, total loss : 0.2970573604106903,  classifier :0.03132033348083496, mask: 0.11029808223247528 ===================
epoch no : 6, batch no : 323, total loss : 0.2943342924118042,  classifier :0.033730462193489075, mask: 0.11381170898675919 ===================
epoch no : 6, batch no : 324, total loss : 0.26696935296058655,  classifier :0.02698795683681965, mask: 0.10226597636938095 ===================
epoch no : 6, batch no : 325, total loss : 0.31509172916412354,  classifier :0.024321386590600014, mask: 0.13127022981643677 ===================
epoch no : 6, batch no : 326, total loss : 0.3478454351425171,  classifier :0.03134564310312271, mask: 0.1657998263835907 ===================
epoch no : 6, batch no : 327, total loss : 0.2631955146789551,  classifier :0.02607680857181549, mask: 0.11804940551519394 ===================
epoch no : 6, batch no : 328, total loss : 0.2656048536300659,  classifier :0.026895148679614067, mask: 0.12725508213043213 ===================
epoch no : 6, batch no : 329, total loss : 0.21786482632160187,  classifier :0.029841862618923187, mask: 0.09113112837076187 ===================
epoch no : 6, batch no : 330, total loss : 0.22301997244358063,  classifier :0.025999203324317932, mask: 0.10615033656358719 ===================
epoch no : 6, batch no : 331, total loss : 0.2671450078487396,  classifier :0.03498001769185066, mask: 0.11171674728393555 ===================
epoch no : 6, batch no : 332, total loss : 0.19489353895187378,  classifier :0.02116374857723713, mask: 0.09138467907905579 ===================
epoch no : 6, batch no : 333, total loss : 0.2401375025510788,  classifier :0.02936534583568573, mask: 0.09075626730918884 ===================
epoch no : 6, batch no : 334, total loss : 0.2601701617240906,  classifier :0.02779224142432213, mask: 0.09388597309589386 ===================
epoch no : 6, batch no : 335, total loss : 0.267606258392334,  classifier :0.025884490460157394, mask: 0.10951337218284607 ===================
epoch no : 6, batch no : 336, total loss : 0.2850275933742523,  classifier :0.0319974310696125, mask: 0.09652367979288101 ===================
epoch no : 6, batch no : 337, total loss : 0.27988797426223755,  classifier :0.020957257598638535, mask: 0.11541076749563217 ===================
epoch no : 6, batch no : 338, total loss : 0.35298341512680054,  classifier :0.031092075631022453, mask: 0.14037834107875824 ===================
epoch no : 6, batch no : 339, total loss : 0.27736830711364746,  classifier :0.02809242531657219, mask: 0.12466016411781311 ===================
epoch no : 6, batch no : 340, total loss : 0.2521370053291321,  classifier :0.022902075201272964, mask: 0.12266363203525543 ===================
epoch no : 6, batch no : 341, total loss : 0.27695947885513306,  classifier :0.025706574320793152, mask: 0.11301887035369873 ===================
epoch no : 6, batch no : 342, total loss : 0.28412461280822754,  classifier :0.03290078416466713, mask: 0.10020970553159714 ===================
epoch no : 6, batch no : 343, total loss : 0.3322966396808624,  classifier :0.04824155941605568, mask: 0.11692789196968079 ===================
epoch no : 6, batch no : 344, total loss : 0.22318147122859955,  classifier :0.03849398344755173, mask: 0.09606125205755234 ===================
epoch no : 6, batch no : 345, total loss : 0.2392347753047943,  classifier :0.028912197798490524, mask: 0.11399141699075699 ===================
epoch no : 6, batch no : 346, total loss : 0.23660552501678467,  classifier :0.021693486720323563, mask: 0.11154131591320038 ===================
epoch no : 6, batch no : 347, total loss : 0.20726297795772552,  classifier :0.024650396779179573, mask: 0.09967754036188126 ===================
epoch no : 6, batch no : 348, total loss : 0.25283753871917725,  classifier :0.03229500725865364, mask: 0.10137896239757538 ===================
epoch no : 6, batch no : 349, total loss : 0.2273612916469574,  classifier :0.024524448439478874, mask: 0.093951016664505 ===================
epoch no : 6, batch no : 350, total loss : 0.2221212238073349,  classifier :0.028616888448596, mask: 0.0886787697672844 ===================
epoch no : 6, batch no : 351, total loss : 0.2127029150724411,  classifier :0.029894279316067696, mask: 0.08742613345384598 ===================
epoch no : 6, batch no : 352, total loss : 0.20216354727745056,  classifier :0.021306680515408516, mask: 0.08607609570026398 ===================
epoch no : 6, batch no : 353, total loss : 0.2054739147424698,  classifier :0.026992948725819588, mask: 0.0826127752661705 ===================
epoch no : 6, batch no : 354, total loss : 0.28823167085647583,  classifier :0.03009435534477234, mask: 0.12123915553092957 ===================
epoch no : 6, batch no : 355, total loss : 0.24091926217079163,  classifier :0.025628529489040375, mask: 0.10691254585981369 ===================
epoch no : 6, batch no : 356, total loss : 0.27676165103912354,  classifier :0.024124689400196075, mask: 0.11090745031833649 ===================
epoch no : 6, batch no : 357, total loss : 0.31373336911201477,  classifier :0.028114816173911095, mask: 0.122263103723526 ===================
epoch no : 6, batch no : 358, total loss : 0.3351840078830719,  classifier :0.033734943717718124, mask: 0.1456005573272705 ===================
epoch no : 6, batch no : 359, total loss : 0.2821645736694336,  classifier :0.03801658749580383, mask: 0.11722764372825623 ===================
epoch no : 6, batch no : 360, total loss : 0.20992311835289001,  classifier :0.021172955632209778, mask: 0.09854903817176819 ===================
epoch no : 6, batch no : 361, total loss : 0.2192814201116562,  classifier :0.024489711970090866, mask: 0.11137040704488754 ===================
epoch no : 6, batch no : 362, total loss : 0.2220194786787033,  classifier :0.020671971142292023, mask: 0.10547424107789993 ===================
epoch no : 6, batch no : 363, total loss : 0.2717980742454529,  classifier :0.02465067245066166, mask: 0.0992732122540474 ===================
epoch no : 6, batch no : 364, total loss : 0.2703224718570709,  classifier :0.030737821012735367, mask: 0.11114097386598587 ===================
epoch no : 6, batch no : 365, total loss : 0.23845836520195007,  classifier :0.020833788439631462, mask: 0.11217387765645981 ===================
epoch no : 6, batch no : 366, total loss : 0.23304980993270874,  classifier :0.03311825171113014, mask: 0.10878393054008484 ===================
epoch no : 6, batch no : 367, total loss : 0.300493061542511,  classifier :0.033974844962358475, mask: 0.14658984541893005 ===================
epoch no : 6, batch no : 368, total loss : 0.34797102212905884,  classifier :0.04102819040417671, mask: 0.14824309945106506 ===================
epoch no : 6, batch no : 369, total loss : 0.27717724442481995,  classifier :0.033645499497652054, mask: 0.10424945503473282 ===================
epoch no : 6, batch no : 370, total loss : 0.3254477381706238,  classifier :0.027223920449614525, mask: 0.11782814562320709 ===================
epoch no : 6, batch no : 371, total loss : 0.3143927752971649,  classifier :0.04048875719308853, mask: 0.10443603247404099 ===================
epoch no : 6, batch no : 372, total loss : 0.286649227142334,  classifier :0.02658449485898018, mask: 0.10181722044944763 ===================
epoch no : 6, batch no : 373, total loss : 0.2932870388031006,  classifier :0.026308545842766762, mask: 0.11905555427074432 ===================
epoch no : 6, batch no : 374, total loss : 0.29859229922294617,  classifier :0.034827131778001785, mask: 0.1458221971988678 ===================
epoch no : 6, batch no : 375, total loss : 0.20835751295089722,  classifier :0.029755383729934692, mask: 0.08730072528123856 ===================
epoch no : 6, batch no : 376, total loss : 0.21221038699150085,  classifier :0.02724548988044262, mask: 0.08605067431926727 ===================
epoch no : 6, batch no : 377, total loss : 0.24013029038906097,  classifier :0.030150560662150383, mask: 0.09712857007980347 ===================
epoch no : 6, batch no : 378, total loss : 0.28136900067329407,  classifier :0.02376614511013031, mask: 0.11926120519638062 ===================
epoch no : 6, batch no : 379, total loss : 0.19638705253601074,  classifier :0.02697303332388401, mask: 0.0825224295258522 ===================
epoch no : 6, batch no : 380, total loss : 0.28134220838546753,  classifier :0.025827961042523384, mask: 0.14989586174488068 ===================
epoch no : 6, batch no : 381, total loss : 0.23943865299224854,  classifier :0.027753015980124474, mask: 0.10012856870889664 ===================
epoch no : 6, batch no : 382, total loss : 0.2639943063259125,  classifier :0.02623175084590912, mask: 0.12974192202091217 ===================
epoch no : 6, batch no : 383, total loss : 0.17945381999015808,  classifier :0.020417794585227966, mask: 0.08433233201503754 ===================
epoch no : 6, batch no : 384, total loss : 0.24614739418029785,  classifier :0.035131897777318954, mask: 0.12589086592197418 ===================
epoch no : 6, batch no : 385, total loss : 0.24932430684566498,  classifier :0.020417513325810432, mask: 0.09249459952116013 ===================
epoch no : 6, batch no : 386, total loss : 0.25965049862861633,  classifier :0.021355140954256058, mask: 0.09318114817142487 ===================
epoch no : 6, batch no : 387, total loss : 0.21345196664333344,  classifier :0.02060738578438759, mask: 0.1001085564494133 ===================
epoch no : 6, batch no : 388, total loss : 0.3068569302558899,  classifier :0.028211480006575584, mask: 0.10625441372394562 ===================
epoch no : 6, batch no : 389, total loss : 0.23236560821533203,  classifier :0.01902650110423565, mask: 0.12075290083885193 ===================
epoch no : 6, batch no : 390, total loss : 0.20762242376804352,  classifier :0.02496403455734253, mask: 0.09329812973737717 ===================
epoch no : 6, batch no : 391, total loss : 0.2399204820394516,  classifier :0.029612382873892784, mask: 0.09483399242162704 ===================
epoch no : 6, batch no : 392, total loss : 0.3476124405860901,  classifier :0.029224500060081482, mask: 0.13763147592544556 ===================
epoch no : 6, batch no : 393, total loss : 0.40474334359169006,  classifier :0.0384332500398159, mask: 0.1505163609981537 ===================
epoch no : 6, batch no : 394, total loss : 0.26136353611946106,  classifier :0.03204925358295441, mask: 0.10032915323972702 ===================
epoch no : 6, batch no : 395, total loss : 0.26027214527130127,  classifier :0.03812701627612114, mask: 0.10525332391262054 ===================
epoch no : 6, batch no : 396, total loss : 0.2221488058567047,  classifier :0.025638818740844727, mask: 0.11200019717216492 ===================
epoch no : 6, batch no : 397, total loss : 0.2702694833278656,  classifier :0.03643283620476723, mask: 0.10000674426555634 ===================
epoch no : 6, batch no : 398, total loss : 0.262777715921402,  classifier :0.028751080855727196, mask: 0.09358489513397217 ===================
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch no : 7, batch no : 0, total loss : 0.24591399729251862,  classifier :0.026198167353868484, mask: 0.09111382067203522 ===================
epoch no : 7, batch no : 1, total loss : 0.28103071451187134,  classifier :0.0240509994328022, mask: 0.11205277591943741 ===================
epoch no : 7, batch no : 2, total loss : 0.20921820402145386,  classifier :0.02392975613474846, mask: 0.09253954887390137 ===================
epoch no : 7, batch no : 3, total loss : 0.308910608291626,  classifier :0.02768215350806713, mask: 0.137663334608078 ===================
epoch no : 7, batch no : 4, total loss : 0.2946106493473053,  classifier :0.032302629202604294, mask: 0.1286272406578064 ===================
epoch no : 7, batch no : 5, total loss : 0.22590430080890656,  classifier :0.02661149576306343, mask: 0.09614972770214081 ===================
epoch no : 7, batch no : 6, total loss : 0.19732323288917542,  classifier :0.02401307411491871, mask: 0.09853480756282806 ===================
epoch no : 7, batch no : 7, total loss : 0.21660281717777252,  classifier :0.022951822727918625, mask: 0.09058389067649841 ===================
epoch no : 7, batch no : 8, total loss : 0.3261418640613556,  classifier :0.026977546513080597, mask: 0.10225845128297806 ===================
epoch no : 7, batch no : 9, total loss : 0.2724607288837433,  classifier :0.030853010714054108, mask: 0.11444612592458725 ===================
epoch no : 7, batch no : 10, total loss : 0.2929304242134094,  classifier :0.04090411216020584, mask: 0.11777681112289429 ===================
epoch no : 7, batch no : 11, total loss : 0.24239861965179443,  classifier :0.01810903660953045, mask: 0.1130368784070015 ===================
epoch no : 7, batch no : 12, total loss : 0.2225579172372818,  classifier :0.024630427360534668, mask: 0.1178935319185257 ===================
epoch no : 7, batch no : 13, total loss : 0.2445463240146637,  classifier :0.033843085169792175, mask: 0.1232791319489479 ===================
epoch no : 7, batch no : 14, total loss : 0.22451233863830566,  classifier :0.028485994786024094, mask: 0.09699618816375732 ===================
epoch no : 7, batch no : 15, total loss : 0.26374247670173645,  classifier :0.0297858864068985, mask: 0.12738826870918274 ===================
epoch no : 7, batch no : 16, total loss : 0.29944875836372375,  classifier :0.02150234393775463, mask: 0.14770475029945374 ===================
epoch no : 7, batch no : 17, total loss : 0.2045641988515854,  classifier :0.034773088991642, mask: 0.10214010626077652 ===================
epoch no : 7, batch no : 18, total loss : 0.24849721789360046,  classifier :0.022180479019880295, mask: 0.09752028435468674 ===================
epoch no : 7, batch no : 19, total loss : 0.35425642132759094,  classifier :0.03087356872856617, mask: 0.18913157284259796 ===================
epoch no : 7, batch no : 20, total loss : 0.2805446684360504,  classifier :0.027435634285211563, mask: 0.1211332157254219 ===================
epoch no : 7, batch no : 21, total loss : 0.20669440925121307,  classifier :0.01965499483048916, mask: 0.10832258313894272 ===================
epoch no : 7, batch no : 22, total loss : 0.19594545662403107,  classifier :0.018580764532089233, mask: 0.09272141009569168 ===================
epoch no : 7, batch no : 23, total loss : 0.2466704249382019,  classifier :0.02922523021697998, mask: 0.0942959114909172 ===================
epoch no : 7, batch no : 24, total loss : 0.2786303758621216,  classifier :0.028547018766403198, mask: 0.11586164683103561 ===================
epoch no : 7, batch no : 25, total loss : 0.19586926698684692,  classifier :0.0251785721629858, mask: 0.08075374364852905 ===================
epoch no : 7, batch no : 26, total loss : 0.2362961322069168,  classifier :0.042094774544239044, mask: 0.10577191412448883 ===================
epoch no : 7, batch no : 27, total loss : 0.2917509078979492,  classifier :0.023618699982762337, mask: 0.16404123604297638 ===================
epoch no : 7, batch no : 28, total loss : 0.30085647106170654,  classifier :0.03428884223103523, mask: 0.1447034478187561 ===================
epoch no : 7, batch no : 29, total loss : 0.27568936347961426,  classifier :0.034678809344768524, mask: 0.11610089242458344 ===================
epoch no : 7, batch no : 30, total loss : 0.21629756689071655,  classifier :0.021603114902973175, mask: 0.08528931438922882 ===================
epoch no : 7, batch no : 31, total loss : 0.21344438195228577,  classifier :0.01885897107422352, mask: 0.0893184021115303 ===================
epoch no : 7, batch no : 32, total loss : 0.3209325969219208,  classifier :0.02259749546647072, mask: 0.18996861577033997 ===================
epoch no : 7, batch no : 33, total loss : 0.2704259157180786,  classifier :0.02462884783744812, mask: 0.11117801070213318 ===================
epoch no : 7, batch no : 34, total loss : 0.22111988067626953,  classifier :0.021854866296052933, mask: 0.09671925008296967 ===================
epoch no : 7, batch no : 35, total loss : 0.2779403328895569,  classifier :0.021557291969656944, mask: 0.13030123710632324 ===================
epoch no : 7, batch no : 36, total loss : 0.2659499943256378,  classifier :0.022882815450429916, mask: 0.12205494940280914 ===================
epoch no : 7, batch no : 37, total loss : 0.24432584643363953,  classifier :0.02505015768110752, mask: 0.13461916148662567 ===================
epoch no : 7, batch no : 38, total loss : 0.20755158364772797,  classifier :0.027118297293782234, mask: 0.09891066700220108 ===================
epoch no : 7, batch no : 39, total loss : 0.2392798811197281,  classifier :0.028682801872491837, mask: 0.10500740259885788 ===================
epoch no : 7, batch no : 40, total loss : 0.24116650223731995,  classifier :0.027701670303940773, mask: 0.08942940086126328 ===================
epoch no : 7, batch no : 41, total loss : 0.26097002625465393,  classifier :0.03220951557159424, mask: 0.10746961086988449 ===================
epoch no : 7, batch no : 42, total loss : 0.21851640939712524,  classifier :0.02239249460399151, mask: 0.10696712881326675 ===================
epoch no : 7, batch no : 43, total loss : 0.23592056334018707,  classifier :0.021820800378918648, mask: 0.11139847338199615 ===================
epoch no : 7, batch no : 44, total loss : 0.3304065763950348,  classifier :0.030067676678299904, mask: 0.14630606770515442 ===================
epoch no : 7, batch no : 45, total loss : 0.24264362454414368,  classifier :0.024399446323513985, mask: 0.10696884244680405 ===================
epoch no : 7, batch no : 46, total loss : 0.2174462229013443,  classifier :0.03352154791355133, mask: 0.10408427566289902 ===================
epoch no : 7, batch no : 47, total loss : 0.20985165238380432,  classifier :0.02292865328490734, mask: 0.1015779972076416 ===================
epoch no : 7, batch no : 48, total loss : 0.23945079743862152,  classifier :0.027018621563911438, mask: 0.09805230051279068 ===================
epoch no : 7, batch no : 49, total loss : 0.22867225110530853,  classifier :0.029136139899492264, mask: 0.09239760041236877 ===================
epoch no : 7, batch no : 50, total loss : 0.3017546236515045,  classifier :0.027231669053435326, mask: 0.11879605054855347 ===================
epoch no : 7, batch no : 51, total loss : 0.2534087300300598,  classifier :0.022503023967146873, mask: 0.11386170983314514 ===================
epoch no : 7, batch no : 52, total loss : 0.2832285761833191,  classifier :0.028537606820464134, mask: 0.10237167030572891 ===================
epoch no : 7, batch no : 53, total loss : 0.27681413292884827,  classifier :0.037156954407691956, mask: 0.10502369701862335 ===================
epoch no : 7, batch no : 54, total loss : 0.28702110052108765,  classifier :0.03062242455780506, mask: 0.10329627245664597 ===================
epoch no : 7, batch no : 55, total loss : 0.34460484981536865,  classifier :0.028434354811906815, mask: 0.1295999139547348 ===================
epoch no : 7, batch no : 56, total loss : 0.3021756112575531,  classifier :0.021545015275478363, mask: 0.1402950882911682 ===================
epoch no : 7, batch no : 57, total loss : 0.3125047981739044,  classifier :0.02460564114153385, mask: 0.1814633160829544 ===================
epoch no : 7, batch no : 58, total loss : 0.35666435956954956,  classifier :0.048838913440704346, mask: 0.13859228789806366 ===================
epoch no : 7, batch no : 59, total loss : 0.2070668339729309,  classifier :0.03323444351553917, mask: 0.0877377837896347 ===================
epoch no : 7, batch no : 60, total loss : 0.22034604847431183,  classifier :0.024710142984986305, mask: 0.09235282242298126 ===================
epoch no : 7, batch no : 61, total loss : 0.23474940657615662,  classifier :0.025666493922472, mask: 0.1207418143749237 ===================
epoch no : 7, batch no : 62, total loss : 0.21579943597316742,  classifier :0.024178074672818184, mask: 0.09325018525123596 ===================
epoch no : 7, batch no : 63, total loss : 0.3162443935871124,  classifier :0.03095269575715065, mask: 0.1478833258152008 ===================
epoch no : 7, batch no : 64, total loss : 0.3680468797683716,  classifier :0.038104426115751266, mask: 0.11983860284090042 ===================
epoch no : 7, batch no : 65, total loss : 0.3510775864124298,  classifier :0.03350687399506569, mask: 0.1416819989681244 ===================
epoch no : 7, batch no : 66, total loss : 0.2047518491744995,  classifier :0.0199588630348444, mask: 0.080352284014225 ===================
epoch no : 7, batch no : 67, total loss : 0.2863885164260864,  classifier :0.03065774030983448, mask: 0.13285711407661438 ===================
epoch no : 7, batch no : 68, total loss : 0.23550565540790558,  classifier :0.033660344779491425, mask: 0.10213645547628403 ===================
epoch no : 7, batch no : 69, total loss : 0.21584415435791016,  classifier :0.02330934815108776, mask: 0.09761486202478409 ===================
epoch no : 7, batch no : 70, total loss : 0.19679464399814606,  classifier :0.02385151945054531, mask: 0.09529569000005722 ===================
epoch no : 7, batch no : 71, total loss : 0.30361005663871765,  classifier :0.022082634270191193, mask: 0.17133192718029022 ===================
epoch no : 7, batch no : 72, total loss : 0.19744804501533508,  classifier :0.021080806851387024, mask: 0.09267808496952057 ===================
epoch no : 7, batch no : 73, total loss : 0.24671106040477753,  classifier :0.01944287121295929, mask: 0.11096833646297455 ===================
epoch no : 7, batch no : 74, total loss : 0.245024174451828,  classifier :0.02510516531765461, mask: 0.09413932263851166 ===================
epoch no : 7, batch no : 75, total loss : 0.24534925818443298,  classifier :0.028162524104118347, mask: 0.10705521702766418 ===================
epoch no : 7, batch no : 76, total loss : 0.2944484353065491,  classifier :0.03196285665035248, mask: 0.12556910514831543 ===================
epoch no : 7, batch no : 77, total loss : 0.29702407121658325,  classifier :0.03257434070110321, mask: 0.1458931863307953 ===================
epoch no : 7, batch no : 78, total loss : 0.2452564835548401,  classifier :0.030437570065259933, mask: 0.09984716773033142 ===================
epoch no : 7, batch no : 79, total loss : 0.2539840638637543,  classifier :0.03361795097589493, mask: 0.10319507867097855 ===================
epoch no : 7, batch no : 80, total loss : 0.23594479262828827,  classifier :0.02483067661523819, mask: 0.11354635655879974 ===================
epoch no : 7, batch no : 81, total loss : 0.28586485981941223,  classifier :0.022668203338980675, mask: 0.14219729602336884 ===================
epoch no : 7, batch no : 82, total loss : 0.2948055565357208,  classifier :0.03503965213894844, mask: 0.11011682450771332 ===================
epoch no : 7, batch no : 83, total loss : 0.2945425808429718,  classifier :0.03193630650639534, mask: 0.10831528156995773 ===================
epoch no : 7, batch no : 84, total loss : 0.3139730393886566,  classifier :0.0404525101184845, mask: 0.1335042268037796 ===================
epoch no : 7, batch no : 85, total loss : 0.21983474493026733,  classifier :0.027118783444166183, mask: 0.09348104149103165 ===================
epoch no : 7, batch no : 86, total loss : 0.237442746758461,  classifier :0.02560286410152912, mask: 0.11184386163949966 ===================
epoch no : 7, batch no : 87, total loss : 0.33430594205856323,  classifier :0.024291682988405228, mask: 0.13579191267490387 ===================
epoch no : 7, batch no : 88, total loss : 0.20688779652118683,  classifier :0.02567809447646141, mask: 0.07198943942785263 ===================
epoch no : 7, batch no : 89, total loss : 0.2832762897014618,  classifier :0.032155755907297134, mask: 0.0878341868519783 ===================
epoch no : 7, batch no : 90, total loss : 0.2216051071882248,  classifier :0.02868218719959259, mask: 0.09511321783065796 ===================
epoch no : 7, batch no : 91, total loss : 0.26187047362327576,  classifier :0.020550990477204323, mask: 0.1064421683549881 ===================
epoch no : 7, batch no : 92, total loss : 0.2098219394683838,  classifier :0.027251847088336945, mask: 0.0884769856929779 ===================
epoch no : 7, batch no : 93, total loss : 0.2332097887992859,  classifier :0.029552090913057327, mask: 0.10081679373979568 ===================
epoch no : 7, batch no : 94, total loss : 0.24588756263256073,  classifier :0.03004707768559456, mask: 0.1061842069029808 ===================
epoch no : 7, batch no : 95, total loss : 0.22879798710346222,  classifier :0.020907608792185783, mask: 0.11296774446964264 ===================
epoch no : 7, batch no : 96, total loss : 0.2836070656776428,  classifier :0.027197903022170067, mask: 0.11645376682281494 ===================
epoch no : 7, batch no : 97, total loss : 0.29930850863456726,  classifier :0.03146502003073692, mask: 0.1396755427122116 ===================
epoch no : 7, batch no : 98, total loss : 0.23434847593307495,  classifier :0.02288863994181156, mask: 0.11768967658281326 ===================
epoch no : 7, batch no : 99, total loss : 0.26176536083221436,  classifier :0.024170396849513054, mask: 0.10062423348426819 ===================
epoch no : 7, batch no : 100, total loss : 0.26862043142318726,  classifier :0.019958678632974625, mask: 0.1268141120672226 ===================
epoch no : 7, batch no : 101, total loss : 0.2459164559841156,  classifier :0.02871311828494072, mask: 0.13144269585609436 ===================
epoch no : 7, batch no : 102, total loss : 0.2655647397041321,  classifier :0.03353821113705635, mask: 0.12032441794872284 ===================
epoch no : 7, batch no : 103, total loss : 0.27521100640296936,  classifier :0.02459833025932312, mask: 0.10615409910678864 ===================
epoch no : 7, batch no : 104, total loss : 0.19067752361297607,  classifier :0.03035696968436241, mask: 0.08211948722600937 ===================
epoch no : 7, batch no : 105, total loss : 0.22484813630580902,  classifier :0.021157993003726006, mask: 0.11396856606006622 ===================
epoch no : 7, batch no : 106, total loss : 0.24568594992160797,  classifier :0.03397032618522644, mask: 0.09571820497512817 ===================
epoch no : 7, batch no : 107, total loss : 0.2595272958278656,  classifier :0.03319447860121727, mask: 0.09661761671304703 ===================
epoch no : 7, batch no : 108, total loss : 0.27578291296958923,  classifier :0.025687335059046745, mask: 0.12519845366477966 ===================
epoch no : 7, batch no : 109, total loss : 0.2756752073764801,  classifier :0.027618518099188805, mask: 0.11599202454090118 ===================
epoch no : 7, batch no : 110, total loss : 0.264421671628952,  classifier :0.024244898930191994, mask: 0.11337486654520035 ===================
epoch no : 7, batch no : 111, total loss : 0.23473569750785828,  classifier :0.022689353674650192, mask: 0.0968492180109024 ===================
epoch no : 7, batch no : 112, total loss : 0.2727339267730713,  classifier :0.029599357396364212, mask: 0.12593664228916168 ===================
epoch no : 7, batch no : 113, total loss : 0.25555089116096497,  classifier :0.03639750927686691, mask: 0.11073610931634903 ===================
epoch no : 7, batch no : 114, total loss : 0.24420912563800812,  classifier :0.029703699052333832, mask: 0.11407124996185303 ===================
epoch no : 7, batch no : 115, total loss : 0.18337686359882355,  classifier :0.02261231653392315, mask: 0.07831215858459473 ===================
epoch no : 7, batch no : 116, total loss : 0.20520494878292084,  classifier :0.03116108663380146, mask: 0.09064410626888275 ===================
epoch no : 7, batch no : 117, total loss : 0.22519630193710327,  classifier :0.02368277683854103, mask: 0.08710940927267075 ===================
epoch no : 7, batch no : 118, total loss : 0.4397008717060089,  classifier :0.05353882163763046, mask: 0.18826253712177277 ===================
epoch no : 7, batch no : 119, total loss : 0.26802554726600647,  classifier :0.023234067484736443, mask: 0.11873055249452591 ===================
epoch no : 7, batch no : 120, total loss : 0.3332839906215668,  classifier :0.027063827961683273, mask: 0.1374569833278656 ===================
epoch no : 7, batch no : 121, total loss : 0.2923596501350403,  classifier :0.021758850663900375, mask: 0.13871218264102936 ===================
epoch no : 7, batch no : 122, total loss : 0.24523630738258362,  classifier :0.027897922322154045, mask: 0.09950174391269684 ===================
epoch no : 7, batch no : 123, total loss : 0.2339245080947876,  classifier :0.021516850218176842, mask: 0.1287318468093872 ===================
epoch no : 7, batch no : 124, total loss : 0.24814552068710327,  classifier :0.03231494501233101, mask: 0.09975317120552063 ===================
epoch no : 7, batch no : 125, total loss : 0.3121834695339203,  classifier :0.03827543929219246, mask: 0.10845818370580673 ===================
epoch no : 7, batch no : 126, total loss : 0.24097004532814026,  classifier :0.034012194722890854, mask: 0.09803395718336105 ===================
epoch no : 7, batch no : 127, total loss : 0.23681047558784485,  classifier :0.026276858523488045, mask: 0.09123688191175461 ===================
epoch no : 7, batch no : 128, total loss : 0.2345946729183197,  classifier :0.018442723900079727, mask: 0.10582028329372406 ===================
epoch no : 7, batch no : 129, total loss : 0.25494644045829773,  classifier :0.03546378016471863, mask: 0.1037779301404953 ===================
epoch no : 7, batch no : 130, total loss : 0.22114808857440948,  classifier :0.021946417167782784, mask: 0.09317723661661148 ===================
epoch no : 7, batch no : 131, total loss : 0.273434579372406,  classifier :0.0234929621219635, mask: 0.13809143006801605 ===================
epoch no : 7, batch no : 132, total loss : 0.23065632581710815,  classifier :0.02434014528989792, mask: 0.10017290711402893 ===================
epoch no : 7, batch no : 133, total loss : 0.26563990116119385,  classifier :0.022411642596125603, mask: 0.10789485275745392 ===================
epoch no : 7, batch no : 134, total loss : 0.2469037026166916,  classifier :0.021388433873653412, mask: 0.10351713746786118 ===================
epoch no : 7, batch no : 135, total loss : 0.22015437483787537,  classifier :0.028271548449993134, mask: 0.10245540738105774 ===================
epoch no : 7, batch no : 136, total loss : 0.2574722170829773,  classifier :0.038111086934804916, mask: 0.11825048178434372 ===================
epoch no : 7, batch no : 137, total loss : 0.3077327609062195,  classifier :0.03300338611006737, mask: 0.12313468754291534 ===================
epoch no : 7, batch no : 138, total loss : 0.2760296165943146,  classifier :0.030736858025193214, mask: 0.11064743995666504 ===================
epoch no : 7, batch no : 139, total loss : 0.31447863578796387,  classifier :0.03453383222222328, mask: 0.11819860339164734 ===================
epoch no : 7, batch no : 140, total loss : 0.28242573142051697,  classifier :0.035880789160728455, mask: 0.14666007459163666 ===================
epoch no : 7, batch no : 141, total loss : 0.2198217660188675,  classifier :0.020160185173153877, mask: 0.09396789222955704 ===================
epoch no : 7, batch no : 142, total loss : 0.21663464605808258,  classifier :0.02512119896709919, mask: 0.09249738603830338 ===================
epoch no : 7, batch no : 143, total loss : 0.2084932178258896,  classifier :0.030581053346395493, mask: 0.08173415809869766 ===================
epoch no : 7, batch no : 144, total loss : 0.20920760929584503,  classifier :0.02003144659101963, mask: 0.09255016595125198 ===================
epoch no : 7, batch no : 145, total loss : 0.3073154091835022,  classifier :0.03371091187000275, mask: 0.10026874393224716 ===================
epoch no : 7, batch no : 146, total loss : 0.2787732779979706,  classifier :0.028645973652601242, mask: 0.12992744147777557 ===================
epoch no : 7, batch no : 147, total loss : 0.19776472449302673,  classifier :0.020840343087911606, mask: 0.08340347558259964 ===================
epoch no : 7, batch no : 148, total loss : 0.2248946726322174,  classifier :0.01938634179532528, mask: 0.11624842882156372 ===================
epoch no : 7, batch no : 149, total loss : 0.28334927558898926,  classifier :0.025298036634922028, mask: 0.15464450418949127 ===================
epoch no : 7, batch no : 150, total loss : 0.27410635352134705,  classifier :0.02896403707563877, mask: 0.110889732837677 ===================
epoch no : 7, batch no : 151, total loss : 0.2476571649312973,  classifier :0.028502678498625755, mask: 0.09104561805725098 ===================
epoch no : 7, batch no : 152, total loss : 0.21762330830097198,  classifier :0.02069462090730667, mask: 0.10878687351942062 ===================
epoch no : 7, batch no : 153, total loss : 0.2852514386177063,  classifier :0.029629182070493698, mask: 0.15861672163009644 ===================
epoch no : 7, batch no : 154, total loss : 0.21994256973266602,  classifier :0.02387651614844799, mask: 0.10928776860237122 ===================
epoch no : 7, batch no : 155, total loss : 0.18387800455093384,  classifier :0.024879662320017815, mask: 0.08510487526655197 ===================
epoch no : 7, batch no : 156, total loss : 0.19730976223945618,  classifier :0.025103574618697166, mask: 0.09481295198202133 ===================
epoch no : 7, batch no : 157, total loss : 0.2624584436416626,  classifier :0.041097767651081085, mask: 0.0978289395570755 ===================
epoch no : 7, batch no : 158, total loss : 0.22099748253822327,  classifier :0.020503604784607887, mask: 0.0904754176735878 ===================
epoch no : 7, batch no : 159, total loss : 0.2517215609550476,  classifier :0.03401260823011398, mask: 0.10175742208957672 ===================
epoch no : 7, batch no : 160, total loss : 0.2777974009513855,  classifier :0.023444566875696182, mask: 0.11332961916923523 ===================
epoch no : 7, batch no : 161, total loss : 0.2390088438987732,  classifier :0.022626258432865143, mask: 0.10685515403747559 ===================
epoch no : 7, batch no : 162, total loss : 0.20721803605556488,  classifier :0.02679583430290222, mask: 0.09029006958007812 ===================
epoch no : 7, batch no : 163, total loss : 0.20892131328582764,  classifier :0.021970191970467567, mask: 0.10425535589456558 ===================
epoch no : 7, batch no : 164, total loss : 0.3021019399166107,  classifier :0.02241058647632599, mask: 0.15635152161121368 ===================
epoch no : 7, batch no : 165, total loss : 0.22813506424427032,  classifier :0.033051248639822006, mask: 0.09124255180358887 ===================
epoch no : 7, batch no : 166, total loss : 0.20972760021686554,  classifier :0.023510441184043884, mask: 0.09596936404705048 ===================
epoch no : 7, batch no : 167, total loss : 0.26081302762031555,  classifier :0.024098670110106468, mask: 0.11804763972759247 ===================
epoch no : 7, batch no : 168, total loss : 0.22581452131271362,  classifier :0.03143078088760376, mask: 0.10788942128419876 ===================
epoch no : 7, batch no : 169, total loss : 0.27774226665496826,  classifier :0.03094577044248581, mask: 0.1293717920780182 ===================
epoch no : 7, batch no : 170, total loss : 0.22835657000541687,  classifier :0.03551550582051277, mask: 0.09151951223611832 ===================
epoch no : 7, batch no : 171, total loss : 0.2671119272708893,  classifier :0.0286877378821373, mask: 0.10317833721637726 ===================
epoch no : 7, batch no : 172, total loss : 0.24059520661830902,  classifier :0.027023013681173325, mask: 0.09776854515075684 ===================
epoch no : 7, batch no : 173, total loss : 0.324701726436615,  classifier :0.0427175909280777, mask: 0.13166847825050354 ===================
epoch no : 7, batch no : 174, total loss : 0.22187119722366333,  classifier :0.023101136088371277, mask: 0.10145148634910583 ===================
epoch no : 7, batch no : 175, total loss : 0.3592992126941681,  classifier :0.06887727975845337, mask: 0.13344447314739227 ===================
epoch no : 7, batch no : 176, total loss : 0.21253235638141632,  classifier :0.025197744369506836, mask: 0.07763241976499557 ===================
epoch no : 7, batch no : 177, total loss : 0.2678908407688141,  classifier :0.029378116130828857, mask: 0.08796616643667221 ===================
epoch no : 7, batch no : 178, total loss : 0.3118009567260742,  classifier :0.029554590582847595, mask: 0.14832530915737152 ===================
epoch no : 7, batch no : 179, total loss : 0.23394666612148285,  classifier :0.028187140822410583, mask: 0.1065170094370842 ===================
epoch no : 7, batch no : 180, total loss : 0.2677379846572876,  classifier :0.027515802532434464, mask: 0.10228676348924637 ===================
epoch no : 7, batch no : 181, total loss : 0.24005021154880524,  classifier :0.022919880226254463, mask: 0.10261011868715286 ===================
epoch no : 7, batch no : 182, total loss : 0.229068323969841,  classifier :0.021938027814030647, mask: 0.1213851198554039 ===================
epoch no : 7, batch no : 183, total loss : 0.205179825425148,  classifier :0.022629451006650925, mask: 0.08409810811281204 ===================
epoch no : 7, batch no : 184, total loss : 0.294278085231781,  classifier :0.025609923526644707, mask: 0.13447678089141846 ===================
epoch no : 7, batch no : 185, total loss : 0.2252124845981598,  classifier :0.02261795476078987, mask: 0.09146839380264282 ===================
epoch no : 7, batch no : 186, total loss : 0.34878280758857727,  classifier :0.02614440768957138, mask: 0.1444229632616043 ===================
epoch no : 7, batch no : 187, total loss : 0.3088173568248749,  classifier :0.03509894385933876, mask: 0.12961402535438538 ===================
epoch no : 7, batch no : 188, total loss : 0.24794627726078033,  classifier :0.03191698342561722, mask: 0.1178809329867363 ===================
epoch no : 7, batch no : 189, total loss : 0.2555515766143799,  classifier :0.03215642273426056, mask: 0.09502776712179184 ===================
epoch no : 7, batch no : 190, total loss : 0.2662777304649353,  classifier :0.026839008554816246, mask: 0.12063255161046982 ===================
epoch no : 7, batch no : 191, total loss : 0.23977969586849213,  classifier :0.018927039578557014, mask: 0.11034541577100754 ===================
epoch no : 7, batch no : 192, total loss : 0.23201337456703186,  classifier :0.02490212768316269, mask: 0.08964281529188156 ===================
epoch no : 7, batch no : 193, total loss : 0.2403986006975174,  classifier :0.022275425493717194, mask: 0.11182790994644165 ===================
epoch no : 7, batch no : 194, total loss : 0.29238876700401306,  classifier :0.038344334810972214, mask: 0.1080155000090599 ===================
epoch no : 7, batch no : 195, total loss : 0.3168661892414093,  classifier :0.03258199989795685, mask: 0.1301557570695877 ===================
epoch no : 7, batch no : 196, total loss : 0.2511277496814728,  classifier :0.03215925395488739, mask: 0.10051145404577255 ===================
epoch no : 7, batch no : 197, total loss : 0.3595658540725708,  classifier :0.051478311419487, mask: 0.14947283267974854 ===================
epoch no : 7, batch no : 198, total loss : 0.3055504560470581,  classifier :0.03616742044687271, mask: 0.11860363185405731 ===================
epoch no : 7, batch no : 199, total loss : 0.2648334205150604,  classifier :0.02257397025823593, mask: 0.11046155542135239 ===================
epoch no : 7, batch no : 200, total loss : 0.28675177693367004,  classifier :0.026247674599289894, mask: 0.12051168829202652 ===================
epoch no : 7, batch no : 201, total loss : 0.24392960965633392,  classifier :0.03835491091012955, mask: 0.08784864097833633 ===================
epoch no : 7, batch no : 202, total loss : 0.24041298031806946,  classifier :0.030982548370957375, mask: 0.11112437397241592 ===================
epoch no : 7, batch no : 203, total loss : 0.2823612689971924,  classifier :0.03622481971979141, mask: 0.1356794685125351 ===================
epoch no : 7, batch no : 204, total loss : 0.20915773510932922,  classifier :0.0265207439661026, mask: 0.09921387583017349 ===================
epoch no : 7, batch no : 205, total loss : 0.22165994346141815,  classifier :0.024914974346756935, mask: 0.09560610353946686 ===================
epoch no : 7, batch no : 206, total loss : 0.31141340732574463,  classifier :0.025105591863393784, mask: 0.1381537914276123 ===================
epoch no : 7, batch no : 207, total loss : 0.2104661762714386,  classifier :0.030840108171105385, mask: 0.09478127956390381 ===================
epoch no : 7, batch no : 208, total loss : 0.30998513102531433,  classifier :0.022089160978794098, mask: 0.14573149383068085 ===================
epoch no : 7, batch no : 209, total loss : 0.2933090925216675,  classifier :0.0243531484156847, mask: 0.13645759224891663 ===================
epoch no : 7, batch no : 210, total loss : 0.2740352153778076,  classifier :0.02269306778907776, mask: 0.1445527970790863 ===================
epoch no : 7, batch no : 211, total loss : 0.28510135412216187,  classifier :0.03136657178401947, mask: 0.15505535900592804 ===================
epoch no : 7, batch no : 212, total loss : 0.27730926871299744,  classifier :0.033980559557676315, mask: 0.12186643481254578 ===================
epoch no : 7, batch no : 213, total loss : 0.24208123981952667,  classifier :0.03133714571595192, mask: 0.10519011318683624 ===================
epoch no : 7, batch no : 214, total loss : 0.21018987894058228,  classifier :0.03762160614132881, mask: 0.09191514551639557 ===================
epoch no : 7, batch no : 215, total loss : 0.21623758971691132,  classifier :0.03206194192171097, mask: 0.10146241635084152 ===================
epoch no : 7, batch no : 216, total loss : 0.19051127135753632,  classifier :0.024604255333542824, mask: 0.08667446672916412 ===================
epoch no : 7, batch no : 217, total loss : 0.23350781202316284,  classifier :0.02351892925798893, mask: 0.10078166425228119 ===================
epoch no : 7, batch no : 218, total loss : 0.23023653030395508,  classifier :0.021739300340414047, mask: 0.09216351807117462 ===================
epoch no : 7, batch no : 219, total loss : 0.26966220140457153,  classifier :0.03309081867337227, mask: 0.126824751496315 ===================
epoch no : 7, batch no : 220, total loss : 0.22642339766025543,  classifier :0.026429645717144012, mask: 0.10051275789737701 ===================
epoch no : 7, batch no : 221, total loss : 0.2572469115257263,  classifier :0.026085009798407555, mask: 0.11921524256467819 ===================
epoch no : 7, batch no : 222, total loss : 0.2404770851135254,  classifier :0.030146121978759766, mask: 0.09444454312324524 ===================
epoch no : 7, batch no : 223, total loss : 0.2928727865219116,  classifier :0.029570966958999634, mask: 0.11153594404459 ===================
epoch no : 7, batch no : 224, total loss : 0.22788603603839874,  classifier :0.02262922003865242, mask: 0.08816182613372803 ===================
epoch no : 7, batch no : 225, total loss : 0.2988814115524292,  classifier :0.03216917812824249, mask: 0.12713097035884857 ===================
epoch no : 7, batch no : 226, total loss : 0.3205552399158478,  classifier :0.02495226450264454, mask: 0.14285090565681458 ===================
epoch no : 7, batch no : 227, total loss : 0.30864349007606506,  classifier :0.02544703520834446, mask: 0.14997164905071259 ===================
epoch no : 7, batch no : 228, total loss : 0.2873659133911133,  classifier :0.033733077347278595, mask: 0.13610012829303741 ===================
epoch no : 7, batch no : 229, total loss : 0.2846220135688782,  classifier :0.023894237354397774, mask: 0.14883100986480713 ===================
epoch no : 7, batch no : 230, total loss : 0.23579859733581543,  classifier :0.01891946978867054, mask: 0.11665824055671692 ===================
epoch no : 7, batch no : 231, total loss : 0.2129151076078415,  classifier :0.019109852612018585, mask: 0.08062179386615753 ===================
epoch no : 7, batch no : 232, total loss : 0.20727278292179108,  classifier :0.02073701284825802, mask: 0.08210378885269165 ===================
epoch no : 7, batch no : 233, total loss : 0.3167688250541687,  classifier :0.022261224687099457, mask: 0.1435871422290802 ===================
epoch no : 7, batch no : 234, total loss : 0.20933617651462555,  classifier :0.025541208684444427, mask: 0.10082165151834488 ===================
epoch no : 7, batch no : 235, total loss : 0.24675436317920685,  classifier :0.025066379457712173, mask: 0.11645665764808655 ===================
epoch no : 7, batch no : 236, total loss : 0.2777678668498993,  classifier :0.02497483231127262, mask: 0.1153484582901001 ===================
epoch no : 7, batch no : 237, total loss : 0.21208994090557098,  classifier :0.01739913411438465, mask: 0.09457334876060486 ===================
epoch no : 7, batch no : 238, total loss : 0.1764073520898819,  classifier :0.01829637587070465, mask: 0.08195596933364868 ===================
epoch no : 7, batch no : 239, total loss : 0.28992804884910583,  classifier :0.029579225927591324, mask: 0.11441826820373535 ===================
epoch no : 7, batch no : 240, total loss : 0.19588637351989746,  classifier :0.024664372205734253, mask: 0.09266382455825806 ===================
epoch no : 7, batch no : 241, total loss : 0.28718239068984985,  classifier :0.031957726925611496, mask: 0.14196176826953888 ===================
epoch no : 7, batch no : 242, total loss : 0.30799388885498047,  classifier :0.021747339516878128, mask: 0.13996438682079315 ===================
epoch no : 7, batch no : 243, total loss : 0.48100200295448303,  classifier :0.04596269130706787, mask: 0.20502424240112305 ===================
epoch no : 7, batch no : 244, total loss : 0.20231062173843384,  classifier :0.02410566434264183, mask: 0.10109911859035492 ===================
epoch no : 7, batch no : 245, total loss : 0.24595241248607635,  classifier :0.027542350813746452, mask: 0.11402930319309235 ===================
epoch no : 7, batch no : 246, total loss : 0.2720109820365906,  classifier :0.03018323890864849, mask: 0.13217668235301971 ===================
epoch no : 7, batch no : 247, total loss : 0.23621821403503418,  classifier :0.020868465304374695, mask: 0.09673451632261276 ===================
epoch no : 7, batch no : 248, total loss : 0.33574891090393066,  classifier :0.041570983827114105, mask: 0.13617642223834991 ===================
epoch no : 7, batch no : 249, total loss : 0.197556272149086,  classifier :0.022288430482149124, mask: 0.10037285834550858 ===================
epoch no : 7, batch no : 250, total loss : 0.2284577488899231,  classifier :0.027963891625404358, mask: 0.10670489072799683 ===================
epoch no : 7, batch no : 251, total loss : 0.26864808797836304,  classifier :0.022418685257434845, mask: 0.11588232964277267 ===================
epoch no : 7, batch no : 252, total loss : 0.24872882664203644,  classifier :0.027469851076602936, mask: 0.10343080759048462 ===================
epoch no : 7, batch no : 253, total loss : 0.2422047257423401,  classifier :0.03536011278629303, mask: 0.09330687671899796 ===================
epoch no : 7, batch no : 254, total loss : 0.267947793006897,  classifier :0.023782653734087944, mask: 0.12708833813667297 ===================
epoch no : 7, batch no : 255, total loss : 0.2484130561351776,  classifier :0.03588641434907913, mask: 0.09403634816408157 ===================
epoch no : 7, batch no : 256, total loss : 0.28502798080444336,  classifier :0.03026413358747959, mask: 0.10404764115810394 ===================
epoch no : 7, batch no : 257, total loss : 0.212867870926857,  classifier :0.029515620321035385, mask: 0.0898992121219635 ===================
epoch no : 7, batch no : 258, total loss : 0.20364302396774292,  classifier :0.018395302817225456, mask: 0.1013324111700058 ===================
epoch no : 7, batch no : 259, total loss : 0.28304269909858704,  classifier :0.03598015382885933, mask: 0.12625712156295776 ===================
epoch no : 7, batch no : 260, total loss : 0.3613576591014862,  classifier :0.020933272317051888, mask: 0.1698571741580963 ===================
epoch no : 7, batch no : 261, total loss : 0.29744091629981995,  classifier :0.022540973499417305, mask: 0.14280807971954346 ===================
epoch no : 7, batch no : 262, total loss : 0.3027087450027466,  classifier :0.033022984862327576, mask: 0.12130001932382584 ===================
epoch no : 7, batch no : 263, total loss : 0.22203968465328217,  classifier :0.02704215981066227, mask: 0.09000961482524872 ===================
epoch no : 7, batch no : 264, total loss : 0.1937170922756195,  classifier :0.021992845460772514, mask: 0.08286622166633606 ===================
epoch no : 7, batch no : 265, total loss : 0.22833651304244995,  classifier :0.020056966692209244, mask: 0.10720780491828918 ===================
epoch no : 7, batch no : 266, total loss : 0.25235122442245483,  classifier :0.026409227401018143, mask: 0.09958766400814056 ===================
epoch no : 7, batch no : 267, total loss : 0.23901104927062988,  classifier :0.033662863075733185, mask: 0.09603581577539444 ===================
epoch no : 7, batch no : 268, total loss : 0.3494024872779846,  classifier :0.038023754954338074, mask: 0.10971999913454056 ===================
epoch no : 7, batch no : 269, total loss : 0.27990782260894775,  classifier :0.02890501171350479, mask: 0.13116930425167084 ===================
epoch no : 7, batch no : 270, total loss : 0.21147596836090088,  classifier :0.02935062348842621, mask: 0.0826454609632492 ===================
epoch no : 7, batch no : 271, total loss : 0.285984069108963,  classifier :0.025096386671066284, mask: 0.12283210456371307 ===================
epoch no : 7, batch no : 272, total loss : 0.25251972675323486,  classifier :0.020170295611023903, mask: 0.10989680886268616 ===================
epoch no : 7, batch no : 273, total loss : 0.36584699153900146,  classifier :0.030614759773015976, mask: 0.1540968418121338 ===================
epoch no : 7, batch no : 274, total loss : 0.2589290142059326,  classifier :0.018182596191763878, mask: 0.12623946368694305 ===================
epoch no : 7, batch no : 275, total loss : 0.30692827701568604,  classifier :0.03243909031152725, mask: 0.14418983459472656 ===================
epoch no : 7, batch no : 276, total loss : 0.2698637545108795,  classifier :0.015749022364616394, mask: 0.12487439811229706 ===================
epoch no : 7, batch no : 277, total loss : 0.2515477240085602,  classifier :0.025320256128907204, mask: 0.1172175481915474 ===================
epoch no : 7, batch no : 278, total loss : 0.24716340005397797,  classifier :0.03073539026081562, mask: 0.10263174772262573 ===================
epoch no : 7, batch no : 279, total loss : 0.2263038158416748,  classifier :0.01928301341831684, mask: 0.11233627796173096 ===================
epoch no : 7, batch no : 280, total loss : 0.40521153807640076,  classifier :0.03138851001858711, mask: 0.17997412383556366 ===================
epoch no : 7, batch no : 281, total loss : 0.36202096939086914,  classifier :0.023567255586385727, mask: 0.18712863326072693 ===================
epoch no : 7, batch no : 282, total loss : 0.2768818736076355,  classifier :0.030204113572835922, mask: 0.11548002809286118 ===================
epoch no : 7, batch no : 283, total loss : 0.3303888738155365,  classifier :0.03385584056377411, mask: 0.12271061539649963 ===================
epoch no : 7, batch no : 284, total loss : 0.4239320456981659,  classifier :0.03184325993061066, mask: 0.15174256265163422 ===================
epoch no : 7, batch no : 285, total loss : 0.2499101758003235,  classifier :0.02722294069826603, mask: 0.10385069251060486 ===================
epoch no : 7, batch no : 286, total loss : 0.20386569201946259,  classifier :0.022289495915174484, mask: 0.08836430311203003 ===================
epoch no : 7, batch no : 287, total loss : 0.24806274473667145,  classifier :0.022296074777841568, mask: 0.11681053787469864 ===================
epoch no : 7, batch no : 288, total loss : 0.2559523582458496,  classifier :0.02037898264825344, mask: 0.11884419620037079 ===================
epoch no : 7, batch no : 289, total loss : 0.3115697503089905,  classifier :0.024305015802383423, mask: 0.15416285395622253 ===================
epoch no : 7, batch no : 290, total loss : 0.27801764011383057,  classifier :0.03007671795785427, mask: 0.12449746578931808 ===================
epoch no : 7, batch no : 291, total loss : 0.3919553756713867,  classifier :0.03652799129486084, mask: 0.15931521356105804 ===================
epoch no : 7, batch no : 292, total loss : 0.24915918707847595,  classifier :0.024965694174170494, mask: 0.11086197942495346 ===================
epoch no : 7, batch no : 293, total loss : 0.2445911169052124,  classifier :0.025123050436377525, mask: 0.10190203785896301 ===================
epoch no : 7, batch no : 294, total loss : 0.19044938683509827,  classifier :0.022478565573692322, mask: 0.0838746652007103 ===================
epoch no : 7, batch no : 295, total loss : 0.28876233100891113,  classifier :0.03261353075504303, mask: 0.13992807269096375 ===================
epoch no : 7, batch no : 296, total loss : 0.21500959992408752,  classifier :0.03316261246800423, mask: 0.11571439355611801 ===================
epoch no : 7, batch no : 297, total loss : 0.18087048828601837,  classifier :0.022854216396808624, mask: 0.07980144768953323 ===================
epoch no : 7, batch no : 298, total loss : 0.22362342476844788,  classifier :0.023683642968535423, mask: 0.10796724259853363 ===================
epoch no : 7, batch no : 299, total loss : 0.2621050179004669,  classifier :0.02869289740920067, mask: 0.13714765012264252 ===================
epoch no : 7, batch no : 300, total loss : 0.19929778575897217,  classifier :0.021532738581299782, mask: 0.09353466331958771 ===================
epoch no : 7, batch no : 301, total loss : 0.24145004153251648,  classifier :0.02133278176188469, mask: 0.11176731437444687 ===================
epoch no : 7, batch no : 302, total loss : 0.28705957531929016,  classifier :0.02238139510154724, mask: 0.11291076242923737 ===================
epoch no : 7, batch no : 303, total loss : 0.22803929448127747,  classifier :0.026002518832683563, mask: 0.08876563608646393 ===================
epoch no : 7, batch no : 304, total loss : 0.27507564425468445,  classifier :0.02754702791571617, mask: 0.12043172866106033 ===================
epoch no : 7, batch no : 305, total loss : 0.23499730229377747,  classifier :0.02532927691936493, mask: 0.08856597542762756 ===================
epoch no : 7, batch no : 306, total loss : 0.2782270908355713,  classifier :0.02617199346423149, mask: 0.11336318403482437 ===================
epoch no : 7, batch no : 307, total loss : 0.2727287709712982,  classifier :0.028373531997203827, mask: 0.12185899913311005 ===================
epoch no : 7, batch no : 308, total loss : 0.35750409960746765,  classifier :0.05122992396354675, mask: 0.12225455045700073 ===================
epoch no : 7, batch no : 309, total loss : 0.24669915437698364,  classifier :0.03410102427005768, mask: 0.0945039689540863 ===================
epoch no : 7, batch no : 310, total loss : 0.23420245945453644,  classifier :0.02348179928958416, mask: 0.09237352013587952 ===================
epoch no : 7, batch no : 311, total loss : 0.26072490215301514,  classifier :0.033027976751327515, mask: 0.1250879168510437 ===================
epoch no : 7, batch no : 312, total loss : 0.21313916146755219,  classifier :0.027045024558901787, mask: 0.10231407731771469 ===================
epoch no : 7, batch no : 313, total loss : 0.2893238067626953,  classifier :0.03609900549054146, mask: 0.13420064747333527 ===================
epoch no : 7, batch no : 314, total loss : 0.2660655379295349,  classifier :0.022737253457307816, mask: 0.10360480844974518 ===================
epoch no : 7, batch no : 315, total loss : 0.28550487756729126,  classifier :0.017795339226722717, mask: 0.1321861445903778 ===================
epoch no : 7, batch no : 316, total loss : 0.3016679883003235,  classifier :0.02908560074865818, mask: 0.13441415131092072 ===================
epoch no : 7, batch no : 317, total loss : 0.2338855266571045,  classifier :0.01877751015126705, mask: 0.11748063564300537 ===================
epoch no : 7, batch no : 318, total loss : 0.2522928714752197,  classifier :0.021331695839762688, mask: 0.12991270422935486 ===================
epoch no : 7, batch no : 319, total loss : 0.2348182499408722,  classifier :0.021936483681201935, mask: 0.11202108860015869 ===================
epoch no : 7, batch no : 320, total loss : 0.25571686029434204,  classifier :0.029142368584871292, mask: 0.1084999218583107 ===================
epoch no : 7, batch no : 321, total loss : 0.26440608501434326,  classifier :0.029408996924757957, mask: 0.11638950556516647 ===================
epoch no : 7, batch no : 322, total loss : 0.29781344532966614,  classifier :0.03397559002041817, mask: 0.11906058341264725 ===================
epoch no : 7, batch no : 323, total loss : 0.2849905490875244,  classifier :0.02384207211434841, mask: 0.11469754576683044 ===================
epoch no : 7, batch no : 324, total loss : 0.21495062112808228,  classifier :0.01831457018852234, mask: 0.08903497457504272 ===================
epoch no : 7, batch no : 325, total loss : 0.2721814513206482,  classifier :0.029939599335193634, mask: 0.128765270113945 ===================
epoch no : 7, batch no : 326, total loss : 0.2611977458000183,  classifier :0.021004751324653625, mask: 0.1363927125930786 ===================
epoch no : 7, batch no : 327, total loss : 0.28940096497535706,  classifier :0.02607329562306404, mask: 0.10738194733858109 ===================
epoch no : 7, batch no : 328, total loss : 0.2368599772453308,  classifier :0.024950284510850906, mask: 0.09354449063539505 ===================
epoch no : 7, batch no : 329, total loss : 0.20448479056358337,  classifier :0.028913289308547974, mask: 0.10039632767438889 ===================
epoch no : 7, batch no : 330, total loss : 0.28760746121406555,  classifier :0.032955072820186615, mask: 0.1172838881611824 ===================
epoch no : 7, batch no : 331, total loss : 0.24414490163326263,  classifier :0.027478458359837532, mask: 0.09516898542642593 ===================
epoch no : 7, batch no : 332, total loss : 0.27846118807792664,  classifier :0.03344307467341423, mask: 0.12308888137340546 ===================
epoch no : 7, batch no : 333, total loss : 0.2054368555545807,  classifier :0.02298576384782791, mask: 0.09279178828001022 ===================
epoch no : 7, batch no : 334, total loss : 0.26545506715774536,  classifier :0.032758451998233795, mask: 0.10764720290899277 ===================
epoch no : 7, batch no : 335, total loss : 0.22658802568912506,  classifier :0.030797768384218216, mask: 0.09545564651489258 ===================
epoch no : 7, batch no : 336, total loss : 0.25929632782936096,  classifier :0.02318592555820942, mask: 0.11454040557146072 ===================
epoch no : 7, batch no : 337, total loss : 0.28505268692970276,  classifier :0.03570245951414108, mask: 0.10772596299648285 ===================
epoch no : 7, batch no : 338, total loss : 0.2667619585990906,  classifier :0.03091391921043396, mask: 0.11067727953195572 ===================
epoch no : 7, batch no : 339, total loss : 0.19349880516529083,  classifier :0.021174419671297073, mask: 0.0939038097858429 ===================
epoch no : 7, batch no : 340, total loss : 0.2555204927921295,  classifier :0.02855084091424942, mask: 0.11597311496734619 ===================
epoch no : 7, batch no : 341, total loss : 0.2997012436389923,  classifier :0.036661576479673386, mask: 0.12300927937030792 ===================
epoch no : 7, batch no : 342, total loss : 0.2678041160106659,  classifier :0.01761840470135212, mask: 0.12463272362947464 ===================
epoch no : 7, batch no : 343, total loss : 0.4232761263847351,  classifier :0.031185487285256386, mask: 0.13954369723796844 ===================
epoch no : 7, batch no : 344, total loss : 0.2685897946357727,  classifier :0.023397108539938927, mask: 0.11125070601701736 ===================
epoch no : 7, batch no : 345, total loss : 0.22228367626667023,  classifier :0.025273723527789116, mask: 0.09322012215852737 ===================
epoch no : 7, batch no : 346, total loss : 0.24289767444133759,  classifier :0.027417849749326706, mask: 0.10587761551141739 ===================
epoch no : 7, batch no : 347, total loss : 0.254183292388916,  classifier :0.028311656787991524, mask: 0.1040748804807663 ===================
epoch no : 7, batch no : 348, total loss : 0.2551365792751312,  classifier :0.025316977873444557, mask: 0.12157516926527023 ===================
epoch no : 7, batch no : 349, total loss : 0.3440473973751068,  classifier :0.02899968810379505, mask: 0.16208787262439728 ===================
epoch no : 7, batch no : 350, total loss : 0.3383536636829376,  classifier :0.032563138753175735, mask: 0.1572955995798111 ===================
epoch no : 7, batch no : 351, total loss : 0.38433295488357544,  classifier :0.0316920280456543, mask: 0.16756395995616913 ===================
epoch no : 7, batch no : 352, total loss : 0.2840803563594818,  classifier :0.024221500381827354, mask: 0.10863479226827621 ===================
epoch no : 7, batch no : 353, total loss : 0.20668454468250275,  classifier :0.022970501333475113, mask: 0.09678958356380463 ===================
epoch no : 7, batch no : 354, total loss : 0.19192412495613098,  classifier :0.024570981040596962, mask: 0.07904709130525589 ===================
epoch no : 7, batch no : 355, total loss : 0.2058960497379303,  classifier :0.023162730038166046, mask: 0.10004081577062607 ===================
epoch no : 7, batch no : 356, total loss : 0.2276209592819214,  classifier :0.021571610122919083, mask: 0.10629284381866455 ===================
epoch no : 7, batch no : 357, total loss : 0.2807925343513489,  classifier :0.02416144125163555, mask: 0.13191545009613037 ===================
epoch no : 7, batch no : 358, total loss : 0.2568538188934326,  classifier :0.021897219121456146, mask: 0.09502612054347992 ===================
epoch no : 7, batch no : 359, total loss : 0.23849166929721832,  classifier :0.025958264246582985, mask: 0.10098914057016373 ===================
epoch no : 7, batch no : 360, total loss : 0.24147789180278778,  classifier :0.039313338696956635, mask: 0.11293084174394608 ===================
epoch no : 7, batch no : 361, total loss : 0.19705666601657867,  classifier :0.022036291658878326, mask: 0.08712588995695114 ===================
epoch no : 7, batch no : 362, total loss : 0.21597327291965485,  classifier :0.020650295540690422, mask: 0.09068217128515244 ===================
epoch no : 7, batch no : 363, total loss : 0.24426230788230896,  classifier :0.029522504657506943, mask: 0.10343410819768906 ===================
epoch no : 7, batch no : 364, total loss : 0.27022239565849304,  classifier :0.027612552046775818, mask: 0.1203269362449646 ===================
epoch no : 7, batch no : 365, total loss : 0.23169714212417603,  classifier :0.022189190611243248, mask: 0.102477066218853 ===================
epoch no : 7, batch no : 366, total loss : 0.2595643699169159,  classifier :0.022020353004336357, mask: 0.11128706485033035 ===================
epoch no : 7, batch no : 367, total loss : 0.32635408639907837,  classifier :0.02907359041273594, mask: 0.12515394389629364 ===================
epoch no : 7, batch no : 368, total loss : 0.257963091135025,  classifier :0.021079516038298607, mask: 0.1214507669210434 ===================
epoch no : 7, batch no : 369, total loss : 0.26828300952911377,  classifier :0.033897221088409424, mask: 0.11228286474943161 ===================
epoch no : 7, batch no : 370, total loss : 0.24079008400440216,  classifier :0.027860810980200768, mask: 0.10060763359069824 ===================
epoch no : 7, batch no : 371, total loss : 0.23620645701885223,  classifier :0.02656473033130169, mask: 0.10461434721946716 ===================
epoch no : 7, batch no : 372, total loss : 0.19978787004947662,  classifier :0.033822450786828995, mask: 0.08265477418899536 ===================
epoch no : 7, batch no : 373, total loss : 0.20134924352169037,  classifier :0.02551644667983055, mask: 0.09109766036272049 ===================
epoch no : 7, batch no : 374, total loss : 0.3573712110519409,  classifier :0.04780300334095955, mask: 0.1382570117712021 ===================
epoch no : 7, batch no : 375, total loss : 0.23080268502235413,  classifier :0.021992888301610947, mask: 0.12475179880857468 ===================
epoch no : 7, batch no : 376, total loss : 0.2590489983558655,  classifier :0.02649097517132759, mask: 0.11680048704147339 ===================
epoch no : 7, batch no : 377, total loss : 0.18440872430801392,  classifier :0.01822515018284321, mask: 0.09835951775312424 ===================
epoch no : 7, batch no : 378, total loss : 0.1997191607952118,  classifier :0.022692780941724777, mask: 0.08113135397434235 ===================
epoch no : 7, batch no : 379, total loss : 0.3768824338912964,  classifier :0.04408867284655571, mask: 0.13726115226745605 ===================
epoch no : 7, batch no : 380, total loss : 0.25433072447776794,  classifier :0.020837310701608658, mask: 0.10367555171251297 ===================
epoch no : 7, batch no : 381, total loss : 0.2455400973558426,  classifier :0.025054926052689552, mask: 0.09393862634897232 ===================
epoch no : 7, batch no : 382, total loss : 0.1969916671514511,  classifier :0.02247677929699421, mask: 0.09532204270362854 ===================
epoch no : 7, batch no : 383, total loss : 0.17057330906391144,  classifier :0.024327056482434273, mask: 0.0829714685678482 ===================
epoch no : 7, batch no : 384, total loss : 0.19471730291843414,  classifier :0.028921490535140038, mask: 0.08650362491607666 ===================
epoch no : 7, batch no : 385, total loss : 0.19554798305034637,  classifier :0.0248428825289011, mask: 0.08117075264453888 ===================
epoch no : 7, batch no : 386, total loss : 0.22630085051059723,  classifier :0.03659662976861, mask: 0.09636008739471436 ===================
epoch no : 7, batch no : 387, total loss : 0.20237131416797638,  classifier :0.024092072620987892, mask: 0.0798904299736023 ===================
epoch no : 7, batch no : 388, total loss : 0.23241257667541504,  classifier :0.023505520075559616, mask: 0.09599597007036209 ===================
epoch no : 7, batch no : 389, total loss : 0.3183092474937439,  classifier :0.028919575735926628, mask: 0.17308710515499115 ===================
epoch no : 7, batch no : 390, total loss : 0.2622016966342926,  classifier :0.027359480038285255, mask: 0.1046917513012886 ===================
epoch no : 7, batch no : 391, total loss : 0.3428618907928467,  classifier :0.0427045039832592, mask: 0.14029455184936523 ===================
epoch no : 7, batch no : 392, total loss : 0.1990901678800583,  classifier :0.026868468150496483, mask: 0.08569405227899551 ===================
epoch no : 7, batch no : 393, total loss : 0.19741728901863098,  classifier :0.019280431792140007, mask: 0.10444572567939758 ===================
epoch no : 7, batch no : 394, total loss : 0.19858163595199585,  classifier :0.02252531610429287, mask: 0.09656593948602676 ===================
epoch no : 7, batch no : 395, total loss : 0.24485133588314056,  classifier :0.03198876604437828, mask: 0.10869832336902618 ===================
epoch no : 7, batch no : 396, total loss : 0.24514225125312805,  classifier :0.021209267899394035, mask: 0.11474846303462982 ===================
epoch no : 7, batch no : 397, total loss : 0.22133709490299225,  classifier :0.02539951168000698, mask: 0.10700942575931549 ===================
epoch no : 7, batch no : 398, total loss : 0.30140942335128784,  classifier :0.023325713351368904, mask: 0.126558318734169 ===================
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch no : 8, batch no : 0, total loss : 0.27340036630630493,  classifier :0.023519687354564667, mask: 0.0954044982790947 ===================
epoch no : 8, batch no : 1, total loss : 0.2907554507255554,  classifier :0.03169750049710274, mask: 0.11344979703426361 ===================
epoch no : 8, batch no : 2, total loss : 0.27007684111595154,  classifier :0.02159327268600464, mask: 0.09706942737102509 ===================
epoch no : 8, batch no : 3, total loss : 0.2009577602148056,  classifier :0.019207194447517395, mask: 0.09374907612800598 ===================
epoch no : 8, batch no : 4, total loss : 0.26515933871269226,  classifier :0.01994909532368183, mask: 0.13207347691059113 ===================
epoch no : 8, batch no : 5, total loss : 0.23673078417778015,  classifier :0.01830565556883812, mask: 0.09331956505775452 ===================
epoch no : 8, batch no : 6, total loss : 0.32873594760894775,  classifier :0.025877302512526512, mask: 0.1320219188928604 ===================
epoch no : 8, batch no : 7, total loss : 0.25453051924705505,  classifier :0.03409726917743683, mask: 0.11448201537132263 ===================
epoch no : 8, batch no : 8, total loss : 0.17400997877120972,  classifier :0.023986876010894775, mask: 0.0914304181933403 ===================
epoch no : 8, batch no : 9, total loss : 0.20443128049373627,  classifier :0.022199133411049843, mask: 0.0912904366850853 ===================
epoch no : 8, batch no : 10, total loss : 0.23024430871009827,  classifier :0.019238213077187538, mask: 0.11256106942892075 ===================
epoch no : 8, batch no : 11, total loss : 0.22630339860916138,  classifier :0.021439004689455032, mask: 0.09871593862771988 ===================
epoch no : 8, batch no : 12, total loss : 0.2071727216243744,  classifier :0.023115288466215134, mask: 0.10098887234926224 ===================
epoch no : 8, batch no : 13, total loss : 0.17372383177280426,  classifier :0.020057763904333115, mask: 0.0803867056965828 ===================
epoch no : 8, batch no : 14, total loss : 0.2556858956813812,  classifier :0.026629935950040817, mask: 0.09764255583286285 ===================
epoch no : 8, batch no : 15, total loss : 0.2129056453704834,  classifier :0.022755302488803864, mask: 0.0946313887834549 ===================
epoch no : 8, batch no : 16, total loss : 0.2751144468784332,  classifier :0.02505601942539215, mask: 0.1173134595155716 ===================
epoch no : 8, batch no : 17, total loss : 0.22219838201999664,  classifier :0.023732032626867294, mask: 0.10467540472745895 ===================
epoch no : 8, batch no : 18, total loss : 0.19041892886161804,  classifier :0.01688506081700325, mask: 0.0946214571595192 ===================
epoch no : 8, batch no : 19, total loss : 0.2441178858280182,  classifier :0.023418257012963295, mask: 0.10907629877328873 ===================
epoch no : 8, batch no : 20, total loss : 0.1670689880847931,  classifier :0.02211037650704384, mask: 0.07565698772668839 ===================
epoch no : 8, batch no : 21, total loss : 0.181422621011734,  classifier :0.024969756603240967, mask: 0.08564069122076035 ===================
epoch no : 8, batch no : 22, total loss : 0.22013795375823975,  classifier :0.02588893659412861, mask: 0.09945563226938248 ===================
epoch no : 8, batch no : 23, total loss : 0.24884697794914246,  classifier :0.02694300003349781, mask: 0.10752449184656143 ===================
epoch no : 8, batch no : 24, total loss : 0.22189956903457642,  classifier :0.017248451709747314, mask: 0.1001756340265274 ===================
epoch no : 8, batch no : 25, total loss : 0.23418617248535156,  classifier :0.019877057522535324, mask: 0.09388796985149384 ===================
epoch no : 8, batch no : 26, total loss : 0.24996541440486908,  classifier :0.024997469037771225, mask: 0.10123596340417862 ===================
epoch no : 8, batch no : 27, total loss : 0.29131415486335754,  classifier :0.02545906789600849, mask: 0.1155153214931488 ===================
epoch no : 8, batch no : 28, total loss : 0.26200148463249207,  classifier :0.02318997122347355, mask: 0.12615688145160675 ===================
epoch no : 8, batch no : 29, total loss : 0.251787006855011,  classifier :0.01886395551264286, mask: 0.1349417269229889 ===================
epoch no : 8, batch no : 30, total loss : 0.2424967885017395,  classifier :0.025699680671095848, mask: 0.0942135602235794 ===================
epoch no : 8, batch no : 31, total loss : 0.27844542264938354,  classifier :0.024674227461218834, mask: 0.12235156446695328 ===================
epoch no : 8, batch no : 32, total loss : 0.2843337655067444,  classifier :0.02645576372742653, mask: 0.12024670839309692 ===================
epoch no : 8, batch no : 33, total loss : 0.24655207991600037,  classifier :0.019450027495622635, mask: 0.11254557222127914 ===================
epoch no : 8, batch no : 34, total loss : 0.21784833073616028,  classifier :0.028047841042280197, mask: 0.09421336650848389 ===================
epoch no : 8, batch no : 35, total loss : 0.22184528410434723,  classifier :0.022044342011213303, mask: 0.10413862764835358 ===================
epoch no : 8, batch no : 36, total loss : 0.16382871568202972,  classifier :0.019855201244354248, mask: 0.07336008548736572 ===================
epoch no : 8, batch no : 37, total loss : 0.27030161023139954,  classifier :0.045073915272951126, mask: 0.11764121055603027 ===================
epoch no : 8, batch no : 38, total loss : 0.2631004750728607,  classifier :0.0309491828083992, mask: 0.11345575749874115 ===================
epoch no : 8, batch no : 39, total loss : 0.3548145294189453,  classifier :0.0425269678235054, mask: 0.15597690641880035 ===================
epoch no : 8, batch no : 40, total loss : 0.21880459785461426,  classifier :0.019979307428002357, mask: 0.09449587017297745 ===================
epoch no : 8, batch no : 41, total loss : 0.2604052722454071,  classifier :0.02238350734114647, mask: 0.09976944327354431 ===================
epoch no : 8, batch no : 42, total loss : 0.22797313332557678,  classifier :0.02426568791270256, mask: 0.09187320619821548 ===================
epoch no : 8, batch no : 43, total loss : 0.23066821694374084,  classifier :0.025645865127444267, mask: 0.10717236995697021 ===================
epoch no : 8, batch no : 44, total loss : 0.2955089211463928,  classifier :0.026492001488804817, mask: 0.11683882772922516 ===================
epoch no : 8, batch no : 45, total loss : 0.3618222773075104,  classifier :0.025960678234696388, mask: 0.12139670550823212 ===================
epoch no : 8, batch no : 46, total loss : 0.2162865698337555,  classifier :0.030202828347682953, mask: 0.10237069427967072 ===================
epoch no : 8, batch no : 47, total loss : 0.20483887195587158,  classifier :0.02683447301387787, mask: 0.10434143990278244 ===================
epoch no : 8, batch no : 48, total loss : 0.23445212841033936,  classifier :0.027971025556325912, mask: 0.11022597551345825 ===================
epoch no : 8, batch no : 49, total loss : 0.22996696829795837,  classifier :0.03262651711702347, mask: 0.10695910453796387 ===================
epoch no : 8, batch no : 50, total loss : 0.22990210354328156,  classifier :0.023972857743501663, mask: 0.1046736016869545 ===================
epoch no : 8, batch no : 51, total loss : 0.22071559727191925,  classifier :0.021842587739229202, mask: 0.09730087220668793 ===================
epoch no : 8, batch no : 52, total loss : 0.3539862334728241,  classifier :0.027297204360365868, mask: 0.18148556351661682 ===================
epoch no : 8, batch no : 53, total loss : 0.22491134703159332,  classifier :0.015460281632840633, mask: 0.11084393411874771 ===================
epoch no : 8, batch no : 54, total loss : 0.2731393873691559,  classifier :0.03869659826159477, mask: 0.1072118878364563 ===================
epoch no : 8, batch no : 55, total loss : 0.2746155261993408,  classifier :0.03320718929171562, mask: 0.12140727788209915 ===================
epoch no : 8, batch no : 56, total loss : 0.2164388746023178,  classifier :0.015262193977832794, mask: 0.10605057328939438 ===================
epoch no : 8, batch no : 57, total loss : 0.25437235832214355,  classifier :0.027334729209542274, mask: 0.12480886280536652 ===================
epoch no : 8, batch no : 58, total loss : 0.19304481148719788,  classifier :0.03061768412590027, mask: 0.08621016889810562 ===================
epoch no : 8, batch no : 59, total loss : 0.21481388807296753,  classifier :0.030263205990195274, mask: 0.08321033418178558 ===================
epoch no : 8, batch no : 60, total loss : 0.3047613501548767,  classifier :0.029813243076205254, mask: 0.11542797088623047 ===================
epoch no : 8, batch no : 61, total loss : 0.2740926444530487,  classifier :0.033051639795303345, mask: 0.11093465983867645 ===================
epoch no : 8, batch no : 62, total loss : 0.2319047898054123,  classifier :0.02664273791015148, mask: 0.08206266164779663 ===================
epoch no : 8, batch no : 63, total loss : 0.29930758476257324,  classifier :0.02861425094306469, mask: 0.12260600179433823 ===================
epoch no : 8, batch no : 64, total loss : 0.2649514377117157,  classifier :0.029116952791810036, mask: 0.11783547699451447 ===================
epoch no : 8, batch no : 65, total loss : 0.19153733551502228,  classifier :0.020755339413881302, mask: 0.09302747994661331 ===================
epoch no : 8, batch no : 66, total loss : 0.22449679672718048,  classifier :0.02603861875832081, mask: 0.08637148141860962 ===================
epoch no : 8, batch no : 67, total loss : 0.21174350380897522,  classifier :0.02360440045595169, mask: 0.079243965446949 ===================
epoch no : 8, batch no : 68, total loss : 0.21022169291973114,  classifier :0.020189808681607246, mask: 0.09918349981307983 ===================
epoch no : 8, batch no : 69, total loss : 0.2028418481349945,  classifier :0.02347838133573532, mask: 0.09989634901285172 ===================
epoch no : 8, batch no : 70, total loss : 0.20092983543872833,  classifier :0.022212810814380646, mask: 0.08708718419075012 ===================
epoch no : 8, batch no : 71, total loss : 0.22816571593284607,  classifier :0.0206147488206625, mask: 0.10086730867624283 ===================
epoch no : 8, batch no : 72, total loss : 0.2060934156179428,  classifier :0.01742102950811386, mask: 0.09249291568994522 ===================
epoch no : 8, batch no : 73, total loss : 0.21250256896018982,  classifier :0.024517759680747986, mask: 0.09220407158136368 ===================
epoch no : 8, batch no : 74, total loss : 0.21754084527492523,  classifier :0.021913766860961914, mask: 0.107329823076725 ===================
epoch no : 8, batch no : 75, total loss : 0.18653519451618195,  classifier :0.027295751497149467, mask: 0.08382592350244522 ===================
epoch no : 8, batch no : 76, total loss : 0.2085975706577301,  classifier :0.020019784569740295, mask: 0.11648205667734146 ===================
epoch no : 8, batch no : 77, total loss : 0.2626010775566101,  classifier :0.02638871781527996, mask: 0.11385718733072281 ===================
epoch no : 8, batch no : 78, total loss : 0.17717376351356506,  classifier :0.02338186837732792, mask: 0.08807805925607681 ===================
epoch no : 8, batch no : 79, total loss : 0.20998229086399078,  classifier :0.016790304332971573, mask: 0.11354763060808182 ===================
epoch no : 8, batch no : 80, total loss : 0.2779398560523987,  classifier :0.05000809207558632, mask: 0.10352272540330887 ===================
epoch no : 8, batch no : 81, total loss : 0.21332082152366638,  classifier :0.024377930909395218, mask: 0.11531560122966766 ===================
epoch no : 8, batch no : 82, total loss : 0.20420746505260468,  classifier :0.02508678287267685, mask: 0.09949851036071777 ===================
epoch no : 8, batch no : 83, total loss : 0.2314140349626541,  classifier :0.03484620898962021, mask: 0.10611825436353683 ===================
epoch no : 8, batch no : 84, total loss : 0.3369627892971039,  classifier :0.03522810339927673, mask: 0.12645986676216125 ===================
epoch no : 8, batch no : 85, total loss : 0.2139211744070053,  classifier :0.020209472626447678, mask: 0.1036563590168953 ===================
epoch no : 8, batch no : 86, total loss : 0.29787713289260864,  classifier :0.04038144648075104, mask: 0.1193951666355133 ===================
epoch no : 8, batch no : 87, total loss : 0.1910003125667572,  classifier :0.021550221368670464, mask: 0.09107499569654465 ===================
epoch no : 8, batch no : 88, total loss : 0.1988084465265274,  classifier :0.025896351784467697, mask: 0.0982108786702156 ===================
epoch no : 8, batch no : 89, total loss : 0.33964869379997253,  classifier :0.027785049751400948, mask: 0.1479617953300476 ===================
epoch no : 8, batch no : 90, total loss : 0.2774573266506195,  classifier :0.0230538509786129, mask: 0.11466486752033234 ===================
epoch no : 8, batch no : 91, total loss : 0.380031555891037,  classifier :0.04637247696518898, mask: 0.1441388875246048 ===================
epoch no : 8, batch no : 92, total loss : 0.21833670139312744,  classifier :0.01589236781001091, mask: 0.1119895651936531 ===================
epoch no : 8, batch no : 93, total loss : 0.24278044700622559,  classifier :0.019803009927272797, mask: 0.09722921252250671 ===================
epoch no : 8, batch no : 94, total loss : 0.29287421703338623,  classifier :0.02632994018495083, mask: 0.11398416012525558 ===================
epoch no : 8, batch no : 95, total loss : 0.2722887098789215,  classifier :0.02008182927966118, mask: 0.10894045978784561 ===================
epoch no : 8, batch no : 96, total loss : 0.28462839126586914,  classifier :0.02649019844830036, mask: 0.12198429554700851 ===================
epoch no : 8, batch no : 97, total loss : 0.24763548374176025,  classifier :0.022946953773498535, mask: 0.13170868158340454 ===================
epoch no : 8, batch no : 98, total loss : 0.19544774293899536,  classifier :0.01830662228167057, mask: 0.09047441929578781 ===================
epoch no : 8, batch no : 99, total loss : 0.2636016607284546,  classifier :0.022373080253601074, mask: 0.10511159151792526 ===================
epoch no : 8, batch no : 100, total loss : 0.26513126492500305,  classifier :0.025228649377822876, mask: 0.10177502781152725 ===================
epoch no : 8, batch no : 101, total loss : 0.1957004815340042,  classifier :0.023069126531481743, mask: 0.09190778434276581 ===================
epoch no : 8, batch no : 102, total loss : 0.20397841930389404,  classifier :0.019667422398924828, mask: 0.09494596719741821 ===================
epoch no : 8, batch no : 103, total loss : 0.21274009346961975,  classifier :0.020534472540020943, mask: 0.09122176468372345 ===================
epoch no : 8, batch no : 104, total loss : 0.35872867703437805,  classifier :0.041976895183324814, mask: 0.12058060616254807 ===================
epoch no : 8, batch no : 105, total loss : 0.38488221168518066,  classifier :0.03912309929728508, mask: 0.1622542440891266 ===================
epoch no : 8, batch no : 106, total loss : 0.2716871201992035,  classifier :0.02075819857418537, mask: 0.11784143000841141 ===================
epoch no : 8, batch no : 107, total loss : 0.30691197514533997,  classifier :0.01683429628610611, mask: 0.10576749593019485 ===================
epoch no : 8, batch no : 108, total loss : 0.2739909887313843,  classifier :0.03242109715938568, mask: 0.11300859600305557 ===================
epoch no : 8, batch no : 109, total loss : 0.2262515127658844,  classifier :0.023787809535861015, mask: 0.09635917097330093 ===================
epoch no : 8, batch no : 110, total loss : 0.20323273539543152,  classifier :0.024118557572364807, mask: 0.0890141949057579 ===================
epoch no : 8, batch no : 111, total loss : 0.25021231174468994,  classifier :0.0247748214751482, mask: 0.11924556642770767 ===================
epoch no : 8, batch no : 112, total loss : 0.22414220869541168,  classifier :0.019417433068156242, mask: 0.09951615333557129 ===================
epoch no : 8, batch no : 113, total loss : 0.2257174551486969,  classifier :0.01700040139257908, mask: 0.09905146062374115 ===================
epoch no : 8, batch no : 114, total loss : 0.21374624967575073,  classifier :0.021603191271424294, mask: 0.1129637062549591 ===================
epoch no : 8, batch no : 115, total loss : 0.24773992598056793,  classifier :0.019786100834608078, mask: 0.10197223722934723 ===================
epoch no : 8, batch no : 116, total loss : 0.2674449384212494,  classifier :0.03231855109333992, mask: 0.1089516282081604 ===================
epoch no : 8, batch no : 117, total loss : 0.2573223412036896,  classifier :0.0305195152759552, mask: 0.11586932837963104 ===================
epoch no : 8, batch no : 118, total loss : 0.22895418107509613,  classifier :0.023206794634461403, mask: 0.10722529888153076 ===================
epoch no : 8, batch no : 119, total loss : 0.24889202415943146,  classifier :0.021660564467310905, mask: 0.12801559269428253 ===================
epoch no : 8, batch no : 120, total loss : 0.207378089427948,  classifier :0.025323376059532166, mask: 0.0939750000834465 ===================
epoch no : 8, batch no : 121, total loss : 0.21482807397842407,  classifier :0.02518954873085022, mask: 0.09171391278505325 ===================
epoch no : 8, batch no : 122, total loss : 0.2830224931240082,  classifier :0.03528553619980812, mask: 0.15301458537578583 ===================
epoch no : 8, batch no : 123, total loss : 0.28758737444877625,  classifier :0.03184543922543526, mask: 0.1377871036529541 ===================
epoch no : 8, batch no : 124, total loss : 0.283089816570282,  classifier :0.029363051056861877, mask: 0.11527471989393234 ===================
epoch no : 8, batch no : 125, total loss : 0.2166324108839035,  classifier :0.017103468999266624, mask: 0.11250438541173935 ===================
epoch no : 8, batch no : 126, total loss : 0.16654299199581146,  classifier :0.01866069622337818, mask: 0.08524815738201141 ===================
epoch no : 8, batch no : 127, total loss : 0.23813718557357788,  classifier :0.01706182211637497, mask: 0.14324496686458588 ===================
epoch no : 8, batch no : 128, total loss : 0.2774224877357483,  classifier :0.035150233656167984, mask: 0.10679389536380768 ===================
epoch no : 8, batch no : 129, total loss : 0.1793247014284134,  classifier :0.02691103145480156, mask: 0.08661460876464844 ===================
epoch no : 8, batch no : 130, total loss : 0.17573074996471405,  classifier :0.017336303368210793, mask: 0.08805697411298752 ===================
epoch no : 8, batch no : 131, total loss : 0.2687651515007019,  classifier :0.023867296054959297, mask: 0.1344100385904312 ===================
epoch no : 8, batch no : 132, total loss : 0.2739117741584778,  classifier :0.019788775593042374, mask: 0.1303960084915161 ===================
epoch no : 8, batch no : 133, total loss : 0.28483885526657104,  classifier :0.025653520599007607, mask: 0.14562487602233887 ===================
epoch no : 8, batch no : 134, total loss : 0.24031569063663483,  classifier :0.032538335770368576, mask: 0.11223730444908142 ===================
epoch no : 8, batch no : 135, total loss : 0.25041458010673523,  classifier :0.021929163485765457, mask: 0.08928070217370987 ===================
epoch no : 8, batch no : 136, total loss : 0.21074020862579346,  classifier :0.019781729206442833, mask: 0.08906400203704834 ===================
epoch no : 8, batch no : 137, total loss : 0.34370386600494385,  classifier :0.030780579894781113, mask: 0.15021178126335144 ===================
epoch no : 8, batch no : 138, total loss : 0.2390318363904953,  classifier :0.020426630973815918, mask: 0.10779954493045807 ===================
epoch no : 8, batch no : 139, total loss : 0.23785381019115448,  classifier :0.025928448885679245, mask: 0.09953807294368744 ===================
epoch no : 8, batch no : 140, total loss : 0.2714499533176422,  classifier :0.018499314785003662, mask: 0.12899908423423767 ===================
epoch no : 8, batch no : 141, total loss : 0.2356431782245636,  classifier :0.024885956197977066, mask: 0.10131844878196716 ===================
epoch no : 8, batch no : 142, total loss : 0.2650025486946106,  classifier :0.035175565630197525, mask: 0.112938292324543 ===================
epoch no : 8, batch no : 143, total loss : 0.27723658084869385,  classifier :0.02093324065208435, mask: 0.13573743402957916 ===================
epoch no : 8, batch no : 144, total loss : 0.2238864302635193,  classifier :0.026705767959356308, mask: 0.11773641407489777 ===================
epoch no : 8, batch no : 145, total loss : 0.24927778542041779,  classifier :0.01876557432115078, mask: 0.1378294676542282 ===================
epoch no : 8, batch no : 146, total loss : 0.2857285141944885,  classifier :0.030226541683077812, mask: 0.1292891502380371 ===================
epoch no : 8, batch no : 147, total loss : 0.22836421430110931,  classifier :0.023530742153525352, mask: 0.10912875086069107 ===================
epoch no : 8, batch no : 148, total loss : 0.20977288484573364,  classifier :0.022457631304860115, mask: 0.09418283402919769 ===================
epoch no : 8, batch no : 149, total loss : 0.21069611608982086,  classifier :0.021003851667046547, mask: 0.11322330683469772 ===================
epoch no : 8, batch no : 150, total loss : 0.20280638337135315,  classifier :0.023306790739297867, mask: 0.09819050133228302 ===================
epoch no : 8, batch no : 151, total loss : 0.28668609261512756,  classifier :0.03614641726016998, mask: 0.12508131563663483 ===================
epoch no : 8, batch no : 152, total loss : 0.19900692999362946,  classifier :0.023550257086753845, mask: 0.09909133613109589 ===================
epoch no : 8, batch no : 153, total loss : 0.2955108880996704,  classifier :0.02377534657716751, mask: 0.11899963021278381 ===================
epoch no : 8, batch no : 154, total loss : 0.25607025623321533,  classifier :0.028180934488773346, mask: 0.11412476003170013 ===================
epoch no : 8, batch no : 155, total loss : 0.23017370700836182,  classifier :0.02087271772325039, mask: 0.11266908049583435 ===================
epoch no : 8, batch no : 156, total loss : 0.21261204779148102,  classifier :0.017770756036043167, mask: 0.11391685158014297 ===================
epoch no : 8, batch no : 157, total loss : 0.3134762644767761,  classifier :0.04285329207777977, mask: 0.13246607780456543 ===================
epoch no : 8, batch no : 158, total loss : 0.2404187023639679,  classifier :0.03187810629606247, mask: 0.1148340180516243 ===================
epoch no : 8, batch no : 159, total loss : 0.2138805091381073,  classifier :0.028136450797319412, mask: 0.08651439100503922 ===================
epoch no : 8, batch no : 160, total loss : 0.26565253734588623,  classifier :0.027777235954999924, mask: 0.10108289122581482 ===================
epoch no : 8, batch no : 161, total loss : 0.20738503336906433,  classifier :0.025066033005714417, mask: 0.0989784374833107 ===================
epoch no : 8, batch no : 162, total loss : 0.20391979813575745,  classifier :0.023056942969560623, mask: 0.09388900548219681 ===================
epoch no : 8, batch no : 163, total loss : 0.25593748688697815,  classifier :0.025354281067848206, mask: 0.12377265095710754 ===================
epoch no : 8, batch no : 164, total loss : 0.2578735649585724,  classifier :0.028438067063689232, mask: 0.10479658097028732 ===================
epoch no : 8, batch no : 165, total loss : 0.19272463023662567,  classifier :0.02447742037475109, mask: 0.07742584496736526 ===================
epoch no : 8, batch no : 166, total loss : 0.2534870505332947,  classifier :0.02821861021220684, mask: 0.11525600403547287 ===================
epoch no : 8, batch no : 167, total loss : 0.28750649094581604,  classifier :0.021913260221481323, mask: 0.14589941501617432 ===================
epoch no : 8, batch no : 168, total loss : 0.20359887182712555,  classifier :0.021398553624749184, mask: 0.10793197900056839 ===================
epoch no : 8, batch no : 169, total loss : 0.19460192322731018,  classifier :0.018195675686001778, mask: 0.10061328113079071 ===================
epoch no : 8, batch no : 170, total loss : 0.17879673838615417,  classifier :0.02055666409432888, mask: 0.09355882555246353 ===================
epoch no : 8, batch no : 171, total loss : 0.24606309831142426,  classifier :0.015146338380873203, mask: 0.11670224368572235 ===================
epoch no : 8, batch no : 172, total loss : 0.2900172770023346,  classifier :0.03296798840165138, mask: 0.09698864817619324 ===================
epoch no : 8, batch no : 173, total loss : 0.2667764127254486,  classifier :0.029999295249581337, mask: 0.09818941354751587 ===================
epoch no : 8, batch no : 174, total loss : 0.2668435275554657,  classifier :0.02815922535955906, mask: 0.13356685638427734 ===================
epoch no : 8, batch no : 175, total loss : 0.2536541521549225,  classifier :0.023883165791630745, mask: 0.12521764636039734 ===================
epoch no : 8, batch no : 176, total loss : 0.2570779025554657,  classifier :0.021041318774223328, mask: 0.11489018052816391 ===================
epoch no : 8, batch no : 177, total loss : 0.24798958003520966,  classifier :0.02321445941925049, mask: 0.13607539236545563 ===================
epoch no : 8, batch no : 178, total loss : 0.2341998666524887,  classifier :0.023015590384602547, mask: 0.10389374196529388 ===================
epoch no : 8, batch no : 179, total loss : 0.2408227175474167,  classifier :0.023973623290657997, mask: 0.09145347028970718 ===================
epoch no : 8, batch no : 180, total loss : 0.2054540514945984,  classifier :0.022303717210888863, mask: 0.11518429219722748 ===================
epoch no : 8, batch no : 181, total loss : 0.23205776512622833,  classifier :0.023599907755851746, mask: 0.10466907173395157 ===================
epoch no : 8, batch no : 182, total loss : 0.19066257774829865,  classifier :0.025451473891735077, mask: 0.09011171758174896 ===================
epoch no : 8, batch no : 183, total loss : 0.2473815232515335,  classifier :0.029589515179395676, mask: 0.10078984498977661 ===================
epoch no : 8, batch no : 184, total loss : 0.20682942867279053,  classifier :0.02845942974090576, mask: 0.09782733768224716 ===================
epoch no : 8, batch no : 185, total loss : 0.1953289955854416,  classifier :0.01912119798362255, mask: 0.08510377258062363 ===================
epoch no : 8, batch no : 186, total loss : 0.23056171834468842,  classifier :0.019876953214406967, mask: 0.11043135076761246 ===================
epoch no : 8, batch no : 187, total loss : 0.2583320736885071,  classifier :0.030035631731152534, mask: 0.11284001171588898 ===================
epoch no : 8, batch no : 188, total loss : 0.24466769397258759,  classifier :0.032283902168273926, mask: 0.10751021653413773 ===================
epoch no : 8, batch no : 189, total loss : 0.24717403948307037,  classifier :0.01877402886748314, mask: 0.13226403295993805 ===================
epoch no : 8, batch no : 190, total loss : 0.27550992369651794,  classifier :0.027607185766100883, mask: 0.12214715778827667 ===================
epoch no : 8, batch no : 191, total loss : 0.236484095454216,  classifier :0.027320001274347305, mask: 0.08386871963739395 ===================
epoch no : 8, batch no : 192, total loss : 0.18534883856773376,  classifier :0.02246830426156521, mask: 0.08323974907398224 ===================
epoch no : 8, batch no : 193, total loss : 0.20104548335075378,  classifier :0.022147750481963158, mask: 0.09602942317724228 ===================
epoch no : 8, batch no : 194, total loss : 0.18615952134132385,  classifier :0.019041497260332108, mask: 0.08569037914276123 ===================
epoch no : 8, batch no : 195, total loss : 0.27729228138923645,  classifier :0.033393699675798416, mask: 0.12292608618736267 ===================
epoch no : 8, batch no : 196, total loss : 0.2487485110759735,  classifier :0.02139737270772457, mask: 0.11986351758241653 ===================
epoch no : 8, batch no : 197, total loss : 0.23136313259601593,  classifier :0.0231197290122509, mask: 0.10641162842512131 ===================
epoch no : 8, batch no : 198, total loss : 0.22404351830482483,  classifier :0.022968783974647522, mask: 0.09313459694385529 ===================
epoch no : 8, batch no : 199, total loss : 0.2038174718618393,  classifier :0.022534064948558807, mask: 0.09225674718618393 ===================
epoch no : 8, batch no : 200, total loss : 0.4113808870315552,  classifier :0.05687471106648445, mask: 0.20166969299316406 ===================
epoch no : 8, batch no : 201, total loss : 0.2174702286720276,  classifier :0.02238353155553341, mask: 0.1041218489408493 ===================
epoch no : 8, batch no : 202, total loss : 0.2455013245344162,  classifier :0.017769474536180496, mask: 0.13058854639530182 ===================
epoch no : 8, batch no : 203, total loss : 0.24267058074474335,  classifier :0.032614316791296005, mask: 0.11188726127147675 ===================
epoch no : 8, batch no : 204, total loss : 0.20126290619373322,  classifier :0.02552732639014721, mask: 0.08685155212879181 ===================
epoch no : 8, batch no : 205, total loss : 0.29753944277763367,  classifier :0.022947315126657486, mask: 0.10300445556640625 ===================
epoch no : 8, batch no : 206, total loss : 0.2730189561843872,  classifier :0.02603733539581299, mask: 0.11132881045341492 ===================
epoch no : 8, batch no : 207, total loss : 0.32534706592559814,  classifier :0.03377103433012962, mask: 0.12354017049074173 ===================
epoch no : 8, batch no : 208, total loss : 0.23106829822063446,  classifier :0.026692332699894905, mask: 0.08240778744220734 ===================
epoch no : 8, batch no : 209, total loss : 0.26996049284935,  classifier :0.025087440386414528, mask: 0.13082726299762726 ===================
epoch no : 8, batch no : 210, total loss : 0.3196536898612976,  classifier :0.051784418523311615, mask: 0.13479933142662048 ===================
epoch no : 8, batch no : 211, total loss : 0.183999165892601,  classifier :0.01823003776371479, mask: 0.07126017659902573 ===================
epoch no : 8, batch no : 212, total loss : 0.24936392903327942,  classifier :0.02185598760843277, mask: 0.1150953620672226 ===================
epoch no : 8, batch no : 213, total loss : 0.22870808839797974,  classifier :0.022268159314990044, mask: 0.09480060636997223 ===================
epoch no : 8, batch no : 214, total loss : 0.2584262490272522,  classifier :0.02801506035029888, mask: 0.10466323047876358 ===================
epoch no : 8, batch no : 215, total loss : 0.185062438249588,  classifier :0.021652277559041977, mask: 0.08161809295415878 ===================
epoch no : 8, batch no : 216, total loss : 0.20449338853359222,  classifier :0.01655002124607563, mask: 0.10720907896757126 ===================
epoch no : 8, batch no : 217, total loss : 0.26657834649086,  classifier :0.018454793840646744, mask: 0.15201039612293243 ===================
epoch no : 8, batch no : 218, total loss : 0.2550075054168701,  classifier :0.02841312438249588, mask: 0.11707916110754013 ===================
epoch no : 8, batch no : 219, total loss : 0.2173406332731247,  classifier :0.03218909725546837, mask: 0.09475378692150116 ===================
epoch no : 8, batch no : 220, total loss : 0.25403594970703125,  classifier :0.020895982161164284, mask: 0.10749225318431854 ===================
epoch no : 8, batch no : 221, total loss : 0.23737916350364685,  classifier :0.02284770831465721, mask: 0.10482211410999298 ===================
epoch no : 8, batch no : 222, total loss : 0.2351589947938919,  classifier :0.0171064343303442, mask: 0.09651827067136765 ===================
epoch no : 8, batch no : 223, total loss : 0.29932987689971924,  classifier :0.028254706412553787, mask: 0.12442260980606079 ===================
epoch no : 8, batch no : 224, total loss : 0.18726953864097595,  classifier :0.026253627613186836, mask: 0.08957556635141373 ===================
epoch no : 8, batch no : 225, total loss : 0.21117371320724487,  classifier :0.02000189945101738, mask: 0.09482178092002869 ===================
epoch no : 8, batch no : 226, total loss : 0.2025962471961975,  classifier :0.02007780782878399, mask: 0.08699185401201248 ===================
epoch no : 8, batch no : 227, total loss : 0.2627990245819092,  classifier :0.02206883206963539, mask: 0.12200917303562164 ===================
epoch no : 8, batch no : 228, total loss : 0.21909473836421967,  classifier :0.021646209061145782, mask: 0.09014921635389328 ===================
epoch no : 8, batch no : 229, total loss : 0.28446847200393677,  classifier :0.031211961060762405, mask: 0.12806658446788788 ===================
epoch no : 8, batch no : 230, total loss : 0.2844974100589752,  classifier :0.025848858058452606, mask: 0.11064192652702332 ===================
epoch no : 8, batch no : 231, total loss : 0.29567790031433105,  classifier :0.02218646928668022, mask: 0.15454114973545074 ===================
epoch no : 8, batch no : 232, total loss : 0.26122933626174927,  classifier :0.022177573293447495, mask: 0.13898177444934845 ===================
epoch no : 8, batch no : 233, total loss : 0.21150656044483185,  classifier :0.018490221351385117, mask: 0.11103202402591705 ===================
epoch no : 8, batch no : 234, total loss : 0.1738179326057434,  classifier :0.01782497763633728, mask: 0.09910603612661362 ===================
epoch no : 8, batch no : 235, total loss : 0.17618124186992645,  classifier :0.02125445380806923, mask: 0.09112147986888885 ===================
epoch no : 8, batch no : 236, total loss : 0.31468620896339417,  classifier :0.04592509567737579, mask: 0.13222528994083405 ===================
epoch no : 8, batch no : 237, total loss : 0.21595171093940735,  classifier :0.024317728355526924, mask: 0.08952485769987106 ===================
epoch no : 8, batch no : 238, total loss : 0.19315418601036072,  classifier :0.01932578533887863, mask: 0.08796009421348572 ===================
epoch no : 8, batch no : 239, total loss : 0.2980327010154724,  classifier :0.036895476281642914, mask: 0.10824453830718994 ===================
epoch no : 8, batch no : 240, total loss : 0.2733025550842285,  classifier :0.032890040427446365, mask: 0.08696196228265762 ===================
epoch no : 8, batch no : 241, total loss : 0.3276473581790924,  classifier :0.04080010950565338, mask: 0.15177206695079803 ===================
epoch no : 8, batch no : 242, total loss : 0.21211211383342743,  classifier :0.029025230556726456, mask: 0.09486939013004303 ===================
epoch no : 8, batch no : 243, total loss : 0.25250351428985596,  classifier :0.024297351017594337, mask: 0.1112900897860527 ===================
epoch no : 8, batch no : 244, total loss : 0.23139475286006927,  classifier :0.02237141691148281, mask: 0.10086570680141449 ===================
epoch no : 8, batch no : 245, total loss : 0.22431699931621552,  classifier :0.018867386505007744, mask: 0.10054084658622742 ===================
epoch no : 8, batch no : 246, total loss : 0.2489316314458847,  classifier :0.02112863026559353, mask: 0.1157061830163002 ===================
epoch no : 8, batch no : 247, total loss : 0.21676966547966003,  classifier :0.018905263394117355, mask: 0.12250114977359772 ===================
epoch no : 8, batch no : 248, total loss : 0.2314104586839676,  classifier :0.025396190583705902, mask: 0.11811728030443192 ===================
epoch no : 8, batch no : 249, total loss : 0.25120845437049866,  classifier :0.03262611851096153, mask: 0.10543284565210342 ===================
epoch no : 8, batch no : 250, total loss : 0.2395695000886917,  classifier :0.023424899205565453, mask: 0.10822535306215286 ===================
epoch no : 8, batch no : 251, total loss : 0.19945137202739716,  classifier :0.027497360482811928, mask: 0.08156663924455643 ===================
epoch no : 8, batch no : 252, total loss : 0.22919881343841553,  classifier :0.029000025242567062, mask: 0.08349571377038956 ===================
epoch no : 8, batch no : 253, total loss : 0.2391699105501175,  classifier :0.030626127496361732, mask: 0.10028856992721558 ===================
epoch no : 8, batch no : 254, total loss : 0.26128554344177246,  classifier :0.02273569442331791, mask: 0.09279057383537292 ===================
epoch no : 8, batch no : 255, total loss : 0.22314119338989258,  classifier :0.02130875363945961, mask: 0.11911630630493164 ===================
epoch no : 8, batch no : 256, total loss : 0.19030438363552094,  classifier :0.018197907134890556, mask: 0.09408972412347794 ===================
epoch no : 8, batch no : 257, total loss : 0.21087530255317688,  classifier :0.02408929355442524, mask: 0.1017775908112526 ===================
epoch no : 8, batch no : 258, total loss : 0.18706464767456055,  classifier :0.02171061560511589, mask: 0.08466335386037827 ===================
epoch no : 8, batch no : 259, total loss : 0.23110347986221313,  classifier :0.02292708493769169, mask: 0.10637882351875305 ===================
epoch no : 8, batch no : 260, total loss : 0.2259124219417572,  classifier :0.028888659551739693, mask: 0.11630557477474213 ===================
epoch no : 8, batch no : 261, total loss : 0.29371973872184753,  classifier :0.02494913712143898, mask: 0.12857191264629364 ===================
epoch no : 8, batch no : 262, total loss : 0.20251333713531494,  classifier :0.023941680788993835, mask: 0.09262190014123917 ===================
epoch no : 8, batch no : 263, total loss : 0.20523084700107574,  classifier :0.022329727187752724, mask: 0.09926824271678925 ===================
epoch no : 8, batch no : 264, total loss : 0.25276151299476624,  classifier :0.021223565563559532, mask: 0.11878971755504608 ===================
epoch no : 8, batch no : 265, total loss : 0.2275223582983017,  classifier :0.022391872480511665, mask: 0.11997930705547333 ===================
epoch no : 8, batch no : 266, total loss : 0.19344614446163177,  classifier :0.020227359607815742, mask: 0.09208983182907104 ===================
epoch no : 8, batch no : 267, total loss : 0.18141531944274902,  classifier :0.021878426894545555, mask: 0.09151029586791992 ===================
epoch no : 8, batch no : 268, total loss : 0.21455323696136475,  classifier :0.028141481801867485, mask: 0.09226926416158676 ===================
epoch no : 8, batch no : 269, total loss : 0.1973889023065567,  classifier :0.019153671339154243, mask: 0.10001665353775024 ===================
epoch no : 8, batch no : 270, total loss : 0.2255764603614807,  classifier :0.023343410342931747, mask: 0.09419605880975723 ===================
epoch no : 8, batch no : 271, total loss : 0.2684763967990875,  classifier :0.03066432848572731, mask: 0.13280579447746277 ===================
epoch no : 8, batch no : 272, total loss : 0.20966020226478577,  classifier :0.022980866953730583, mask: 0.09443726390600204 ===================
epoch no : 8, batch no : 273, total loss : 0.30164530873298645,  classifier :0.030270613729953766, mask: 0.17322877049446106 ===================
epoch no : 8, batch no : 274, total loss : 0.29991957545280457,  classifier :0.021715691313147545, mask: 0.1656905561685562 ===================
epoch no : 8, batch no : 275, total loss : 0.2887970209121704,  classifier :0.025059478357434273, mask: 0.11095915734767914 ===================
epoch no : 8, batch no : 276, total loss : 0.2731953263282776,  classifier :0.025885986164212227, mask: 0.1493993103504181 ===================
epoch no : 8, batch no : 277, total loss : 0.19771067798137665,  classifier :0.024314654991030693, mask: 0.08774963021278381 ===================
epoch no : 8, batch no : 278, total loss : 0.3013874888420105,  classifier :0.020556487143039703, mask: 0.14657029509544373 ===================
epoch no : 8, batch no : 279, total loss : 0.25644928216934204,  classifier :0.020608818158507347, mask: 0.10351648181676865 ===================
epoch no : 8, batch no : 280, total loss : 0.17455081641674042,  classifier :0.019796222448349, mask: 0.09179028868675232 ===================
epoch no : 8, batch no : 281, total loss : 0.1822902411222458,  classifier :0.022062867879867554, mask: 0.07893875241279602 ===================
epoch no : 8, batch no : 282, total loss : 0.19497081637382507,  classifier :0.029153477400541306, mask: 0.08605960011482239 ===================
epoch no : 8, batch no : 283, total loss : 0.25007864832878113,  classifier :0.020650535821914673, mask: 0.10143856704235077 ===================
epoch no : 8, batch no : 284, total loss : 0.30344587564468384,  classifier :0.035564351826906204, mask: 0.135425865650177 ===================
epoch no : 8, batch no : 285, total loss : 0.23191824555397034,  classifier :0.02267482317984104, mask: 0.11500048637390137 ===================
epoch no : 8, batch no : 286, total loss : 0.17821122705936432,  classifier :0.022636136040091515, mask: 0.08241402357816696 ===================
epoch no : 8, batch no : 287, total loss : 0.25280675292015076,  classifier :0.023717300966382027, mask: 0.10800813883543015 ===================
epoch no : 8, batch no : 288, total loss : 0.28310561180114746,  classifier :0.03165373578667641, mask: 0.11560776084661484 ===================
epoch no : 8, batch no : 289, total loss : 0.24328841269016266,  classifier :0.022717595100402832, mask: 0.12331172823905945 ===================
epoch no : 8, batch no : 290, total loss : 0.3092748522758484,  classifier :0.030938321724534035, mask: 0.12927700579166412 ===================
epoch no : 8, batch no : 291, total loss : 0.210449680685997,  classifier :0.021655654534697533, mask: 0.0932793915271759 ===================
epoch no : 8, batch no : 292, total loss : 0.2093735635280609,  classifier :0.01817815564572811, mask: 0.08280409872531891 ===================
epoch no : 8, batch no : 293, total loss : 0.23406492173671722,  classifier :0.019531946629285812, mask: 0.11107435822486877 ===================
epoch no : 8, batch no : 294, total loss : 0.24201729893684387,  classifier :0.02051560766994953, mask: 0.1264631450176239 ===================
epoch no : 8, batch no : 295, total loss : 0.1988348364830017,  classifier :0.01489193830639124, mask: 0.09292753040790558 ===================
epoch no : 8, batch no : 296, total loss : 0.2285027801990509,  classifier :0.022374629974365234, mask: 0.09697031229734421 ===================
epoch no : 8, batch no : 297, total loss : 0.24394266307353973,  classifier :0.019914593547582626, mask: 0.11202973127365112 ===================
epoch no : 8, batch no : 298, total loss : 0.32929298281669617,  classifier :0.022440621629357338, mask: 0.13521751761436462 ===================
epoch no : 8, batch no : 299, total loss : 0.28336018323898315,  classifier :0.026151295751333237, mask: 0.11468131840229034 ===================
epoch no : 8, batch no : 300, total loss : 0.24653837084770203,  classifier :0.02009926363825798, mask: 0.10545500367879868 ===================
epoch no : 8, batch no : 301, total loss : 0.22324904799461365,  classifier :0.026165727525949478, mask: 0.09094440191984177 ===================
epoch no : 8, batch no : 302, total loss : 0.26802998781204224,  classifier :0.03651737421751022, mask: 0.10520892590284348 ===================
epoch no : 8, batch no : 303, total loss : 0.2451733946800232,  classifier :0.02962087094783783, mask: 0.10615416616201401 ===================
epoch no : 8, batch no : 304, total loss : 0.18204142153263092,  classifier :0.021353330463171005, mask: 0.08118029683828354 ===================
epoch no : 8, batch no : 305, total loss : 0.25291404128074646,  classifier :0.02725851535797119, mask: 0.09460310637950897 ===================
epoch no : 8, batch no : 306, total loss : 0.29745128750801086,  classifier :0.021237315610051155, mask: 0.0950564593076706 ===================
epoch no : 8, batch no : 307, total loss : 0.26919516921043396,  classifier :0.022984230890870094, mask: 0.10988321155309677 ===================
epoch no : 8, batch no : 308, total loss : 0.23754499852657318,  classifier :0.02597547508776188, mask: 0.11115849763154984 ===================
epoch no : 8, batch no : 309, total loss : 0.22861799597740173,  classifier :0.020983759313821793, mask: 0.09633053094148636 ===================
epoch no : 8, batch no : 310, total loss : 0.20913328230381012,  classifier :0.025987006723880768, mask: 0.10903245955705643 ===================
epoch no : 8, batch no : 311, total loss : 0.17848306894302368,  classifier :0.021675419062376022, mask: 0.09080304205417633 ===================
epoch no : 8, batch no : 312, total loss : 0.22262462973594666,  classifier :0.018794890493154526, mask: 0.0991264060139656 ===================
epoch no : 8, batch no : 313, total loss : 0.27676284313201904,  classifier :0.026779696345329285, mask: 0.12425560504198074 ===================
epoch no : 8, batch no : 314, total loss : 0.21473811566829681,  classifier :0.019452063366770744, mask: 0.1035311222076416 ===================
epoch no : 8, batch no : 315, total loss : 0.21608316898345947,  classifier :0.02604939229786396, mask: 0.096292644739151 ===================
epoch no : 8, batch no : 316, total loss : 0.2309340387582779,  classifier :0.03565461188554764, mask: 0.09444478899240494 ===================
epoch no : 8, batch no : 317, total loss : 0.2901014983654022,  classifier :0.020706456154584885, mask: 0.13678164780139923 ===================
epoch no : 8, batch no : 318, total loss : 0.22484123706817627,  classifier :0.028161335736513138, mask: 0.08656936883926392 ===================
epoch no : 8, batch no : 319, total loss : 0.18840479850769043,  classifier :0.017995258793234825, mask: 0.08784304559230804 ===================
epoch no : 8, batch no : 320, total loss : 0.2502326965332031,  classifier :0.017762426286935806, mask: 0.10845375806093216 ===================
epoch no : 8, batch no : 321, total loss : 0.2855546474456787,  classifier :0.03410059213638306, mask: 0.11009333282709122 ===================
epoch no : 8, batch no : 322, total loss : 0.3061892092227936,  classifier :0.03367774561047554, mask: 0.1162656918168068 ===================
epoch no : 8, batch no : 323, total loss : 0.2835410237312317,  classifier :0.023372024297714233, mask: 0.1294180005788803 ===================
epoch no : 8, batch no : 324, total loss : 0.22789901494979858,  classifier :0.034009553492069244, mask: 0.09713881462812424 ===================
epoch no : 8, batch no : 325, total loss : 0.25531113147735596,  classifier :0.02250518649816513, mask: 0.09513401240110397 ===================
epoch no : 8, batch no : 326, total loss : 0.31348174810409546,  classifier :0.03143448755145073, mask: 0.14906874299049377 ===================
epoch no : 8, batch no : 327, total loss : 0.2318813055753708,  classifier :0.01907920278608799, mask: 0.11596786230802536 ===================
epoch no : 8, batch no : 328, total loss : 0.23078453540802002,  classifier :0.025958692654967308, mask: 0.09956135600805283 ===================
epoch no : 8, batch no : 329, total loss : 0.22797273099422455,  classifier :0.024476224556565285, mask: 0.09919163584709167 ===================
epoch no : 8, batch no : 330, total loss : 0.2971161901950836,  classifier :0.03821585699915886, mask: 0.1230735033750534 ===================
epoch no : 8, batch no : 331, total loss : 0.24067716300487518,  classifier :0.025761080905795097, mask: 0.09586741775274277 ===================
epoch no : 8, batch no : 332, total loss : 0.3153820335865021,  classifier :0.029750386252999306, mask: 0.13490518927574158 ===================
epoch no : 8, batch no : 333, total loss : 0.30683818459510803,  classifier :0.05359753593802452, mask: 0.111650750041008 ===================
epoch no : 8, batch no : 334, total loss : 0.18580594658851624,  classifier :0.02077329158782959, mask: 0.08926622569561005 ===================
epoch no : 8, batch no : 335, total loss : 0.4055449366569519,  classifier :0.0505850650370121, mask: 0.18414877355098724 ===================
epoch no : 8, batch no : 336, total loss : 0.2753457725048065,  classifier :0.025899814441800117, mask: 0.1285996288061142 ===================
epoch no : 8, batch no : 337, total loss : 0.25057923793792725,  classifier :0.01870054192841053, mask: 0.1036883145570755 ===================
epoch no : 8, batch no : 338, total loss : 0.3317483961582184,  classifier :0.031181275844573975, mask: 0.13253837823867798 ===================
epoch no : 8, batch no : 339, total loss : 0.20162181556224823,  classifier :0.02513596974313259, mask: 0.10029835999011993 ===================
epoch no : 8, batch no : 340, total loss : 0.19580066204071045,  classifier :0.023074505850672722, mask: 0.07597887516021729 ===================
epoch no : 8, batch no : 341, total loss : 0.21710936725139618,  classifier :0.027189981192350388, mask: 0.09220191836357117 ===================
epoch no : 8, batch no : 342, total loss : 0.2592012286186218,  classifier :0.026078088209033012, mask: 0.11269207298755646 ===================
epoch no : 8, batch no : 343, total loss : 0.22450757026672363,  classifier :0.023513980209827423, mask: 0.10086575150489807 ===================
epoch no : 8, batch no : 344, total loss : 0.25447744131088257,  classifier :0.0261400043964386, mask: 0.10337810218334198 ===================
epoch no : 8, batch no : 345, total loss : 0.29388171434402466,  classifier :0.027098525315523148, mask: 0.12768423557281494 ===================
epoch no : 8, batch no : 346, total loss : 0.2630334794521332,  classifier :0.02771659754216671, mask: 0.09021133184432983 ===================
epoch no : 8, batch no : 347, total loss : 0.2393997460603714,  classifier :0.034565214067697525, mask: 0.09257674962282181 ===================
epoch no : 8, batch no : 348, total loss : 0.24812529981136322,  classifier :0.02137639932334423, mask: 0.10550904273986816 ===================
epoch no : 8, batch no : 349, total loss : 0.24133823812007904,  classifier :0.022662905976176262, mask: 0.10513828694820404 ===================
epoch no : 8, batch no : 350, total loss : 0.18295931816101074,  classifier :0.019823119044303894, mask: 0.08691511303186417 ===================
epoch no : 8, batch no : 351, total loss : 0.21352437138557434,  classifier :0.020335379987955093, mask: 0.10799238085746765 ===================
epoch no : 8, batch no : 352, total loss : 0.21514920890331268,  classifier :0.015421739779412746, mask: 0.10991430282592773 ===================
epoch no : 8, batch no : 353, total loss : 0.21634116768836975,  classifier :0.023989979177713394, mask: 0.08487292379140854 ===================
epoch no : 8, batch no : 354, total loss : 0.19687452912330627,  classifier :0.017240239307284355, mask: 0.10785911232233047 ===================
epoch no : 8, batch no : 355, total loss : 0.25720903277397156,  classifier :0.026278436183929443, mask: 0.11161082237958908 ===================
epoch no : 8, batch no : 356, total loss : 0.3128892779350281,  classifier :0.026136841624975204, mask: 0.11400379985570908 ===================
epoch no : 8, batch no : 357, total loss : 0.2737331986427307,  classifier :0.030632926151156425, mask: 0.10590632259845734 ===================
epoch no : 8, batch no : 358, total loss : 0.3006340563297272,  classifier :0.02125992625951767, mask: 0.13437481224536896 ===================
epoch no : 8, batch no : 359, total loss : 0.2982989549636841,  classifier :0.025474997237324715, mask: 0.12691761553287506 ===================
epoch no : 8, batch no : 360, total loss : 0.2396712750196457,  classifier :0.026019684970378876, mask: 0.09424861520528793 ===================
epoch no : 8, batch no : 361, total loss : 0.21790504455566406,  classifier :0.024481939151883125, mask: 0.11070991307497025 ===================
epoch no : 8, batch no : 362, total loss : 0.1655382513999939,  classifier :0.02057904750108719, mask: 0.07426150888204575 ===================
epoch no : 8, batch no : 363, total loss : 0.1891406923532486,  classifier :0.02132500521838665, mask: 0.08639126271009445 ===================
epoch no : 8, batch no : 364, total loss : 0.16788345575332642,  classifier :0.017494775354862213, mask: 0.08453165739774704 ===================
epoch no : 8, batch no : 365, total loss : 0.20472943782806396,  classifier :0.023447776213288307, mask: 0.09192594140768051 ===================
epoch no : 8, batch no : 366, total loss : 0.22040778398513794,  classifier :0.02311175875365734, mask: 0.10448209196329117 ===================
epoch no : 8, batch no : 367, total loss : 0.20603269338607788,  classifier :0.019431009888648987, mask: 0.08914848417043686 ===================
epoch no : 8, batch no : 368, total loss : 0.21905292570590973,  classifier :0.019042784348130226, mask: 0.07678184658288956 ===================
epoch no : 8, batch no : 369, total loss : 0.26428931951522827,  classifier :0.01704644039273262, mask: 0.09024767577648163 ===================
epoch no : 8, batch no : 370, total loss : 0.21651510894298553,  classifier :0.024354303255677223, mask: 0.09387966245412827 ===================
epoch no : 8, batch no : 371, total loss : 0.18276241421699524,  classifier :0.025144580751657486, mask: 0.07345101237297058 ===================
epoch no : 8, batch no : 372, total loss : 0.2469392567873001,  classifier :0.023450275883078575, mask: 0.10844484716653824 ===================
epoch no : 8, batch no : 373, total loss : 0.20677794516086578,  classifier :0.02672494202852249, mask: 0.09272052347660065 ===================
epoch no : 8, batch no : 374, total loss : 0.17605364322662354,  classifier :0.018892332911491394, mask: 0.07639089226722717 ===================
epoch no : 8, batch no : 375, total loss : 0.29782262444496155,  classifier :0.038999080657958984, mask: 0.1266569197177887 ===================
epoch no : 8, batch no : 376, total loss : 0.223743736743927,  classifier :0.01746869832277298, mask: 0.11762657761573792 ===================
epoch no : 8, batch no : 377, total loss : 0.2066182792186737,  classifier :0.02326897531747818, mask: 0.09628649055957794 ===================
epoch no : 8, batch no : 378, total loss : 0.20289376378059387,  classifier :0.02186466194689274, mask: 0.09470750391483307 ===================
epoch no : 8, batch no : 379, total loss : 0.2028849571943283,  classifier :0.02105151116847992, mask: 0.10135539621114731 ===================
epoch no : 8, batch no : 380, total loss : 0.24487043917179108,  classifier :0.028588751330971718, mask: 0.10503470152616501 ===================
epoch no : 8, batch no : 381, total loss : 0.251592755317688,  classifier :0.02364267408847809, mask: 0.10636864602565765 ===================
epoch no : 8, batch no : 382, total loss : 0.17584319412708282,  classifier :0.02146601490676403, mask: 0.07441912591457367 ===================
epoch no : 8, batch no : 383, total loss : 0.22525162994861603,  classifier :0.020108340308070183, mask: 0.1063198670744896 ===================
epoch no : 8, batch no : 384, total loss : 0.21747054159641266,  classifier :0.02767372690141201, mask: 0.08822304755449295 ===================
epoch no : 8, batch no : 385, total loss : 0.21832461655139923,  classifier :0.02172660455107689, mask: 0.08878405392169952 ===================
epoch no : 8, batch no : 386, total loss : 0.2634117007255554,  classifier :0.02628152258694172, mask: 0.10743595659732819 ===================
epoch no : 8, batch no : 387, total loss : 0.2642078101634979,  classifier :0.026954157277941704, mask: 0.13653108477592468 ===================
epoch no : 8, batch no : 388, total loss : 0.3220541477203369,  classifier :0.03673316538333893, mask: 0.1445762813091278 ===================
epoch no : 8, batch no : 389, total loss : 0.17094284296035767,  classifier :0.02248293347656727, mask: 0.08757980912923813 ===================
epoch no : 8, batch no : 390, total loss : 0.2099529355764389,  classifier :0.02418307214975357, mask: 0.0986548438668251 ===================
epoch no : 8, batch no : 391, total loss : 0.19097661972045898,  classifier :0.020012540742754936, mask: 0.08359932899475098 ===================
epoch no : 8, batch no : 392, total loss : 0.26942986249923706,  classifier :0.02029661275446415, mask: 0.11317457258701324 ===================
epoch no : 8, batch no : 393, total loss : 0.19034922122955322,  classifier :0.026443861424922943, mask: 0.08014190942049026 ===================
epoch no : 8, batch no : 394, total loss : 0.2627490758895874,  classifier :0.03004656359553337, mask: 0.12049932032823563 ===================
epoch no : 8, batch no : 395, total loss : 0.22378358244895935,  classifier :0.020531516522169113, mask: 0.10253510624170303 ===================
epoch no : 8, batch no : 396, total loss : 0.2291015088558197,  classifier :0.026660911738872528, mask: 0.0895562395453453 ===================
epoch no : 8, batch no : 397, total loss : 0.25101280212402344,  classifier :0.021292218938469887, mask: 0.110467329621315 ===================
epoch no : 8, batch no : 398, total loss : 0.2027895152568817,  classifier :0.030116567388176918, mask: 0.09648337215185165 ===================
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch no : 9, batch no : 0, total loss : 0.2093065232038498,  classifier :0.017071684822440147, mask: 0.08302396535873413 ===================
epoch no : 9, batch no : 1, total loss : 0.21097944676876068,  classifier :0.027510851621627808, mask: 0.09108012169599533 ===================
epoch no : 9, batch no : 2, total loss : 0.21886391937732697,  classifier :0.0228651762008667, mask: 0.09452604502439499 ===================
epoch no : 9, batch no : 3, total loss : 0.24887965619564056,  classifier :0.01833586022257805, mask: 0.1228904128074646 ===================
epoch no : 9, batch no : 4, total loss : 0.1966252326965332,  classifier :0.021414440125226974, mask: 0.09909681230783463 ===================
epoch no : 9, batch no : 5, total loss : 0.24057525396347046,  classifier :0.02509254217147827, mask: 0.1003284677863121 ===================
epoch no : 9, batch no : 6, total loss : 0.28421837091445923,  classifier :0.022929605096578598, mask: 0.11095309257507324 ===================
epoch no : 9, batch no : 7, total loss : 0.28714171051979065,  classifier :0.023273218423128128, mask: 0.12456276267766953 ===================
epoch no : 9, batch no : 8, total loss : 0.23964272439479828,  classifier :0.017952298745512962, mask: 0.10281461477279663 ===================
epoch no : 9, batch no : 9, total loss : 0.3038718104362488,  classifier :0.02989535592496395, mask: 0.11841589957475662 ===================
epoch no : 9, batch no : 10, total loss : 0.18800419569015503,  classifier :0.01976415514945984, mask: 0.08824232965707779 ===================
epoch no : 9, batch no : 11, total loss : 0.17035292088985443,  classifier :0.020276475697755814, mask: 0.0792175829410553 ===================
epoch no : 9, batch no : 12, total loss : 0.21631281077861786,  classifier :0.018699539825320244, mask: 0.09069247543811798 ===================
epoch no : 9, batch no : 13, total loss : 0.18746747076511383,  classifier :0.01952660083770752, mask: 0.08806223422288895 ===================
epoch no : 9, batch no : 14, total loss : 0.21026912331581116,  classifier :0.029887687414884567, mask: 0.09167112410068512 ===================
epoch no : 9, batch no : 15, total loss : 0.18732382357120514,  classifier :0.019633878022432327, mask: 0.08936574310064316 ===================
epoch no : 9, batch no : 16, total loss : 0.21018867194652557,  classifier :0.015938114374876022, mask: 0.09489242732524872 ===================
epoch no : 9, batch no : 17, total loss : 0.3597176969051361,  classifier :0.04275022819638252, mask: 0.1257980912923813 ===================
epoch no : 9, batch no : 18, total loss : 0.2930268943309784,  classifier :0.022414783015847206, mask: 0.11848991364240646 ===================
epoch no : 9, batch no : 19, total loss : 0.2437305897474289,  classifier :0.01787162758409977, mask: 0.1158330887556076 ===================
epoch no : 9, batch no : 20, total loss : 0.3042006194591522,  classifier :0.03172879293560982, mask: 0.12423650920391083 ===================
epoch no : 9, batch no : 21, total loss : 0.30540773272514343,  classifier :0.024764906615018845, mask: 0.118520088493824 ===================
epoch no : 9, batch no : 22, total loss : 0.2803701162338257,  classifier :0.024603763595223427, mask: 0.11658163368701935 ===================
epoch no : 9, batch no : 23, total loss : 0.21560883522033691,  classifier :0.021325761452317238, mask: 0.10201118886470795 ===================
epoch no : 9, batch no : 24, total loss : 0.20857392251491547,  classifier :0.02084842137992382, mask: 0.10350330173969269 ===================
epoch no : 9, batch no : 25, total loss : 0.17670081555843353,  classifier :0.017982829362154007, mask: 0.07728748023509979 ===================
epoch no : 9, batch no : 26, total loss : 0.29599878191947937,  classifier :0.026710357517004013, mask: 0.11413480341434479 ===================
epoch no : 9, batch no : 27, total loss : 0.20680595934391022,  classifier :0.01717899926006794, mask: 0.08968982100486755 ===================
epoch no : 9, batch no : 28, total loss : 0.2806655168533325,  classifier :0.029000964015722275, mask: 0.13390091061592102 ===================
epoch no : 9, batch no : 29, total loss : 0.19443395733833313,  classifier :0.021764488890767097, mask: 0.09426391124725342 ===================
epoch no : 9, batch no : 30, total loss : 0.21932381391525269,  classifier :0.02850514091551304, mask: 0.09628856182098389 ===================
epoch no : 9, batch no : 31, total loss : 0.19335578382015228,  classifier :0.023046327754855156, mask: 0.08900829404592514 ===================
epoch no : 9, batch no : 32, total loss : 0.21500274538993835,  classifier :0.027345752343535423, mask: 0.10016249865293503 ===================
epoch no : 9, batch no : 33, total loss : 0.256919264793396,  classifier :0.029104355722665787, mask: 0.10391431301832199 ===================
epoch no : 9, batch no : 34, total loss : 0.1580355316400528,  classifier :0.019896242767572403, mask: 0.0761442556977272 ===================
epoch no : 9, batch no : 35, total loss : 0.21227365732192993,  classifier :0.025711925700306892, mask: 0.09948544204235077 ===================
epoch no : 9, batch no : 36, total loss : 0.21192172169685364,  classifier :0.019814522936940193, mask: 0.10910145193338394 ===================
epoch no : 9, batch no : 37, total loss : 0.24534045159816742,  classifier :0.033602047711610794, mask: 0.11282066255807877 ===================
epoch no : 9, batch no : 38, total loss : 0.2234349399805069,  classifier :0.023756135255098343, mask: 0.107399120926857 ===================
epoch no : 9, batch no : 39, total loss : 0.20611733198165894,  classifier :0.020164787769317627, mask: 0.11805756390094757 ===================
epoch no : 9, batch no : 40, total loss : 0.21977530419826508,  classifier :0.028126874938607216, mask: 0.11519540846347809 ===================
epoch no : 9, batch no : 41, total loss : 0.3101199269294739,  classifier :0.04190519079566002, mask: 0.14433546364307404 ===================
epoch no : 9, batch no : 42, total loss : 0.1845501810312271,  classifier :0.026194605976343155, mask: 0.08402860164642334 ===================
epoch no : 9, batch no : 43, total loss : 0.25492578744888306,  classifier :0.02084975689649582, mask: 0.14711424708366394 ===================
epoch no : 9, batch no : 44, total loss : 0.235979825258255,  classifier :0.020653657615184784, mask: 0.09882929921150208 ===================
epoch no : 9, batch no : 45, total loss : 0.22853770852088928,  classifier :0.017478300258517265, mask: 0.12527532875537872 ===================
epoch no : 9, batch no : 46, total loss : 0.2764851748943329,  classifier :0.02317127026617527, mask: 0.15361851453781128 ===================
epoch no : 9, batch no : 47, total loss : 0.22446005046367645,  classifier :0.021695366129279137, mask: 0.10753824561834335 ===================
epoch no : 9, batch no : 48, total loss : 0.22467616200447083,  classifier :0.024714825674891472, mask: 0.0885772779583931 ===================
epoch no : 9, batch no : 49, total loss : 0.25686025619506836,  classifier :0.019309163093566895, mask: 0.08703771233558655 ===================
epoch no : 9, batch no : 50, total loss : 0.221802219748497,  classifier :0.03081163763999939, mask: 0.10494527220726013 ===================
epoch no : 9, batch no : 51, total loss : 0.3028729259967804,  classifier :0.03591505065560341, mask: 0.14207518100738525 ===================
epoch no : 9, batch no : 52, total loss : 0.22326311469078064,  classifier :0.01986910216510296, mask: 0.10760682821273804 ===================
epoch no : 9, batch no : 53, total loss : 0.2564202547073364,  classifier :0.03168824687600136, mask: 0.1122194454073906 ===================
epoch no : 9, batch no : 54, total loss : 0.21230266988277435,  classifier :0.023826895281672478, mask: 0.0994429662823677 ===================
epoch no : 9, batch no : 55, total loss : 0.25327587127685547,  classifier :0.035220060497522354, mask: 0.10733933746814728 ===================
epoch no : 9, batch no : 56, total loss : 0.27214524149894714,  classifier :0.022606482729315758, mask: 0.1407039314508438 ===================
epoch no : 9, batch no : 57, total loss : 0.20119693875312805,  classifier :0.023901207372546196, mask: 0.08228373527526855 ===================
epoch no : 9, batch no : 58, total loss : 0.24156954884529114,  classifier :0.018387842923402786, mask: 0.1269359290599823 ===================
epoch no : 9, batch no : 59, total loss : 0.250881552696228,  classifier :0.01860894076526165, mask: 0.11328389495611191 ===================
epoch no : 9, batch no : 60, total loss : 0.21737170219421387,  classifier :0.025827020406723022, mask: 0.09839149564504623 ===================
epoch no : 9, batch no : 61, total loss : 0.23945946991443634,  classifier :0.025745440274477005, mask: 0.09796566516160965 ===================
epoch no : 9, batch no : 62, total loss : 0.2116633653640747,  classifier :0.0212290920317173, mask: 0.09724035114049911 ===================
epoch no : 9, batch no : 63, total loss : 0.24691316485404968,  classifier :0.02378734201192856, mask: 0.12352815270423889 ===================
epoch no : 9, batch no : 64, total loss : 0.373069167137146,  classifier :0.020941998809576035, mask: 0.1630401611328125 ===================
epoch no : 9, batch no : 65, total loss : 0.39151445031166077,  classifier :0.03439297899603844, mask: 0.19453324377536774 ===================
epoch no : 9, batch no : 66, total loss : 0.2314019352197647,  classifier :0.021110642701387405, mask: 0.11444858461618423 ===================
epoch no : 9, batch no : 67, total loss : 0.27635306119918823,  classifier :0.03182012587785721, mask: 0.11916191130876541 ===================
epoch no : 9, batch no : 68, total loss : 0.20801734924316406,  classifier :0.03141272813081741, mask: 0.09691165387630463 ===================
epoch no : 9, batch no : 69, total loss : 0.19407391548156738,  classifier :0.016736451536417007, mask: 0.09030705690383911 ===================
epoch no : 9, batch no : 70, total loss : 0.21838617324829102,  classifier :0.02152646705508232, mask: 0.10565359890460968 ===================
epoch no : 9, batch no : 71, total loss : 0.26151975989341736,  classifier :0.01648382656276226, mask: 0.12523308396339417 ===================
epoch no : 9, batch no : 72, total loss : 0.2326395958662033,  classifier :0.021867617964744568, mask: 0.09365438669919968 ===================
epoch no : 9, batch no : 73, total loss : 0.25601816177368164,  classifier :0.02940390259027481, mask: 0.10488757491111755 ===================
epoch no : 9, batch no : 74, total loss : 0.18324224650859833,  classifier :0.02235984243452549, mask: 0.08360043913125992 ===================
epoch no : 9, batch no : 75, total loss : 0.22314414381980896,  classifier :0.019278818741440773, mask: 0.08748838305473328 ===================
epoch no : 9, batch no : 76, total loss : 0.21629276871681213,  classifier :0.018070371821522713, mask: 0.10318278521299362 ===================
epoch no : 9, batch no : 77, total loss : 0.23180778324604034,  classifier :0.028691058978438377, mask: 0.13326896727085114 ===================
epoch no : 9, batch no : 78, total loss : 0.26870793104171753,  classifier :0.023746324703097343, mask: 0.11579376459121704 ===================
epoch no : 9, batch no : 79, total loss : 0.21863575279712677,  classifier :0.02269137278199196, mask: 0.11710572987794876 ===================
epoch no : 9, batch no : 80, total loss : 0.24398604035377502,  classifier :0.019801564514636993, mask: 0.12653686106204987 ===================
epoch no : 9, batch no : 81, total loss : 0.20573900640010834,  classifier :0.019398337230086327, mask: 0.07672788202762604 ===================
epoch no : 9, batch no : 82, total loss : 0.28698936104774475,  classifier :0.019324513152241707, mask: 0.13255086541175842 ===================
epoch no : 9, batch no : 83, total loss : 0.2676880955696106,  classifier :0.015572124160826206, mask: 0.108888179063797 ===================
epoch no : 9, batch no : 84, total loss : 0.23925288021564484,  classifier :0.025596551597118378, mask: 0.10030556470155716 ===================
epoch no : 9, batch no : 85, total loss : 0.2217143177986145,  classifier :0.02271760068833828, mask: 0.1025930792093277 ===================
epoch no : 9, batch no : 86, total loss : 0.19818058609962463,  classifier :0.020859280601143837, mask: 0.08432377874851227 ===================
epoch no : 9, batch no : 87, total loss : 0.24091018736362457,  classifier :0.026987140998244286, mask: 0.10203034430742264 ===================
epoch no : 9, batch no : 88, total loss : 0.2678670883178711,  classifier :0.02102356217801571, mask: 0.12179088592529297 ===================
epoch no : 9, batch no : 89, total loss : 0.2549416422843933,  classifier :0.017535677179694176, mask: 0.13877703249454498 ===================
epoch no : 9, batch no : 90, total loss : 0.23451411724090576,  classifier :0.022800974547863007, mask: 0.10397566109895706 ===================
epoch no : 9, batch no : 91, total loss : 0.18846672773361206,  classifier :0.019119013100862503, mask: 0.10191463679075241 ===================
epoch no : 9, batch no : 92, total loss : 0.27869442105293274,  classifier :0.031229980289936066, mask: 0.1344422549009323 ===================
epoch no : 9, batch no : 93, total loss : 0.24036230146884918,  classifier :0.02071586437523365, mask: 0.10782615095376968 ===================
epoch no : 9, batch no : 94, total loss : 0.24270756542682648,  classifier :0.0236744936555624, mask: 0.10693318396806717 ===================
epoch no : 9, batch no : 95, total loss : 0.19679324328899384,  classifier :0.02518394961953163, mask: 0.09837055206298828 ===================
epoch no : 9, batch no : 96, total loss : 0.23892417550086975,  classifier :0.016969656571745872, mask: 0.11582031846046448 ===================
epoch no : 9, batch no : 97, total loss : 0.28045427799224854,  classifier :0.04073234647512436, mask: 0.11139027029275894 ===================
epoch no : 9, batch no : 98, total loss : 0.2159288227558136,  classifier :0.025637531653046608, mask: 0.09062612801790237 ===================
epoch no : 9, batch no : 99, total loss : 0.24144065380096436,  classifier :0.012546545825898647, mask: 0.11635559052228928 ===================
epoch no : 9, batch no : 100, total loss : 0.26505762338638306,  classifier :0.02939356304705143, mask: 0.12116296589374542 ===================
epoch no : 9, batch no : 101, total loss : 0.21086148917675018,  classifier :0.022511081770062447, mask: 0.09671738743782043 ===================
epoch no : 9, batch no : 102, total loss : 0.20583264529705048,  classifier :0.02048588916659355, mask: 0.08618340641260147 ===================
epoch no : 9, batch no : 103, total loss : 0.20522569119930267,  classifier :0.018940752372145653, mask: 0.09008766710758209 ===================
epoch no : 9, batch no : 104, total loss : 0.3039056360721588,  classifier :0.02528580091893673, mask: 0.14712123572826385 ===================
epoch no : 9, batch no : 105, total loss : 0.21552442014217377,  classifier :0.02245134301483631, mask: 0.08714038133621216 ===================
epoch no : 9, batch no : 106, total loss : 0.22438549995422363,  classifier :0.01827904023230076, mask: 0.11294256150722504 ===================
epoch no : 9, batch no : 107, total loss : 0.1922481507062912,  classifier :0.02158241905272007, mask: 0.08700717985630035 ===================
epoch no : 9, batch no : 108, total loss : 0.2741369307041168,  classifier :0.021007021889090538, mask: 0.13044440746307373 ===================
epoch no : 9, batch no : 109, total loss : 0.2508811056613922,  classifier :0.027444742619991302, mask: 0.11363496631383896 ===================
epoch no : 9, batch no : 110, total loss : 0.2376660406589508,  classifier :0.021302860230207443, mask: 0.08701619505882263 ===================
epoch no : 9, batch no : 111, total loss : 0.2629343867301941,  classifier :0.018289364874362946, mask: 0.10147387534379959 ===================
epoch no : 9, batch no : 112, total loss : 0.25348395109176636,  classifier :0.025230828672647476, mask: 0.10993846505880356 ===================
epoch no : 9, batch no : 113, total loss : 0.19609159231185913,  classifier :0.02463165856897831, mask: 0.09327369183301926 ===================
epoch no : 9, batch no : 114, total loss : 0.2034795731306076,  classifier :0.018430102616548538, mask: 0.1046382486820221 ===================
epoch no : 9, batch no : 115, total loss : 0.21464920043945312,  classifier :0.02270740084350109, mask: 0.09584290534257889 ===================
epoch no : 9, batch no : 116, total loss : 0.23013971745967865,  classifier :0.021304387599229813, mask: 0.10583214461803436 ===================
epoch no : 9, batch no : 117, total loss : 0.26663169264793396,  classifier :0.02131263166666031, mask: 0.11375391483306885 ===================
epoch no : 9, batch no : 118, total loss : 0.217708557844162,  classifier :0.031804632395505905, mask: 0.09685823321342468 ===================
epoch no : 9, batch no : 119, total loss : 0.2829056978225708,  classifier :0.0423043891787529, mask: 0.12526318430900574 ===================
epoch no : 9, batch no : 120, total loss : 0.35766300559043884,  classifier :0.042254168540239334, mask: 0.15370270609855652 ===================
epoch no : 9, batch no : 121, total loss : 0.2618677318096161,  classifier :0.032135166227817535, mask: 0.10896114259958267 ===================
epoch no : 9, batch no : 122, total loss : 0.16361308097839355,  classifier :0.019916553050279617, mask: 0.07951819896697998 ===================
epoch no : 9, batch no : 123, total loss : 0.22730794548988342,  classifier :0.026860598474740982, mask: 0.10292400419712067 ===================
epoch no : 9, batch no : 124, total loss : 0.29427218437194824,  classifier :0.036972712725400925, mask: 0.1281326413154602 ===================
epoch no : 9, batch no : 125, total loss : 0.23496174812316895,  classifier :0.025141561403870583, mask: 0.11031028628349304 ===================
epoch no : 9, batch no : 126, total loss : 0.20868931710720062,  classifier :0.02041403017938137, mask: 0.11046937853097916 ===================
epoch no : 9, batch no : 127, total loss : 0.2016141414642334,  classifier :0.01971501111984253, mask: 0.08755474537611008 ===================
epoch no : 9, batch no : 128, total loss : 0.2892327904701233,  classifier :0.028970349580049515, mask: 0.11422719061374664 ===================
epoch no : 9, batch no : 129, total loss : 0.26448461413383484,  classifier :0.026424475014209747, mask: 0.1061301976442337 ===================
epoch no : 9, batch no : 130, total loss : 0.23518793284893036,  classifier :0.021264847368001938, mask: 0.08832181990146637 ===================
epoch no : 9, batch no : 131, total loss : 0.28774386644363403,  classifier :0.026812337338924408, mask: 0.11312442272901535 ===================
epoch no : 9, batch no : 132, total loss : 0.17653080821037292,  classifier :0.02613072283565998, mask: 0.08956002444028854 ===================
epoch no : 9, batch no : 133, total loss : 0.1713387817144394,  classifier :0.021201100200414658, mask: 0.09006334096193314 ===================
epoch no : 9, batch no : 134, total loss : 0.24807621538639069,  classifier :0.025991305708885193, mask: 0.10967359691858292 ===================
epoch no : 9, batch no : 135, total loss : 0.19239269196987152,  classifier :0.021421030163764954, mask: 0.08488288521766663 ===================
epoch no : 9, batch no : 136, total loss : 0.17988376319408417,  classifier :0.01938275620341301, mask: 0.09164362400770187 ===================
epoch no : 9, batch no : 137, total loss : 0.18505731225013733,  classifier :0.021295830607414246, mask: 0.08779983967542648 ===================
epoch no : 9, batch no : 138, total loss : 0.16182872653007507,  classifier :0.020854772999882698, mask: 0.08476623147726059 ===================
epoch no : 9, batch no : 139, total loss : 0.19539083540439606,  classifier :0.021631546318531036, mask: 0.09856665879487991 ===================
epoch no : 9, batch no : 140, total loss : 0.20434170961380005,  classifier :0.020480090752243996, mask: 0.09777694195508957 ===================
epoch no : 9, batch no : 141, total loss : 0.17986935377120972,  classifier :0.018115755170583725, mask: 0.07124091684818268 ===================
epoch no : 9, batch no : 142, total loss : 0.22222964465618134,  classifier :0.021627778187394142, mask: 0.08735743910074234 ===================
epoch no : 9, batch no : 143, total loss : 0.23942743241786957,  classifier :0.019775915890932083, mask: 0.11736944317817688 ===================
epoch no : 9, batch no : 144, total loss : 0.22964753210544586,  classifier :0.021763676777482033, mask: 0.10871367156505585 ===================
epoch no : 9, batch no : 145, total loss : 0.279526948928833,  classifier :0.01993754878640175, mask: 0.1434844583272934 ===================
epoch no : 9, batch no : 146, total loss : 0.2260279655456543,  classifier :0.025250736624002457, mask: 0.12801888585090637 ===================
epoch no : 9, batch no : 147, total loss : 0.2386680394411087,  classifier :0.016043469309806824, mask: 0.10261335968971252 ===================
epoch no : 9, batch no : 148, total loss : 0.20512540638446808,  classifier :0.021829761564731598, mask: 0.10645987093448639 ===================
epoch no : 9, batch no : 149, total loss : 0.2461344301700592,  classifier :0.024996353313326836, mask: 0.10796372592449188 ===================
epoch no : 9, batch no : 150, total loss : 0.23462681472301483,  classifier :0.02218785136938095, mask: 0.09506722539663315 ===================
epoch no : 9, batch no : 151, total loss : 0.27509137988090515,  classifier :0.036209553480148315, mask: 0.1399860978126526 ===================
epoch no : 9, batch no : 152, total loss : 0.26326876878738403,  classifier :0.016254588961601257, mask: 0.12159644812345505 ===================
epoch no : 9, batch no : 153, total loss : 0.21958434581756592,  classifier :0.023077061399817467, mask: 0.09811089932918549 ===================
epoch no : 9, batch no : 154, total loss : 0.21300792694091797,  classifier :0.016108784824609756, mask: 0.10100197792053223 ===================
epoch no : 9, batch no : 155, total loss : 0.18074195086956024,  classifier :0.01761731319129467, mask: 0.0959826111793518 ===================
epoch no : 9, batch no : 156, total loss : 0.22506779432296753,  classifier :0.024500947445631027, mask: 0.093733049929142 ===================
epoch no : 9, batch no : 157, total loss : 0.1912769079208374,  classifier :0.020419225096702576, mask: 0.09322196245193481 ===================
epoch no : 9, batch no : 158, total loss : 0.22287678718566895,  classifier :0.022360743954777718, mask: 0.1217159628868103 ===================
epoch no : 9, batch no : 159, total loss : 0.19531448185443878,  classifier :0.03092343918979168, mask: 0.08940701186656952 ===================
epoch no : 9, batch no : 160, total loss : 0.2390185296535492,  classifier :0.02149653434753418, mask: 0.11963589489459991 ===================
epoch no : 9, batch no : 161, total loss : 0.23162630200386047,  classifier :0.017002610489726067, mask: 0.11925806105136871 ===================
epoch no : 9, batch no : 162, total loss : 0.3363055884838104,  classifier :0.04391482472419739, mask: 0.13797694444656372 ===================
epoch no : 9, batch no : 163, total loss : 0.19069945812225342,  classifier :0.02138354256749153, mask: 0.08696355670690536 ===================
epoch no : 9, batch no : 164, total loss : 0.16775988042354584,  classifier :0.020661402493715286, mask: 0.08308060467243195 ===================
epoch no : 9, batch no : 165, total loss : 0.17190733551979065,  classifier :0.018357975408434868, mask: 0.08712421357631683 ===================
epoch no : 9, batch no : 166, total loss : 0.3570774793624878,  classifier :0.05260930210351944, mask: 0.1664734184741974 ===================
epoch no : 9, batch no : 167, total loss : 0.16725023090839386,  classifier :0.026813646778464317, mask: 0.07364659756422043 ===================
epoch no : 9, batch no : 168, total loss : 0.22920988500118256,  classifier :0.016895873472094536, mask: 0.12976735830307007 ===================
epoch no : 9, batch no : 169, total loss : 0.16905313730239868,  classifier :0.01533388439565897, mask: 0.0904441699385643 ===================
epoch no : 9, batch no : 170, total loss : 0.2564451992511749,  classifier :0.021441631019115448, mask: 0.12371702492237091 ===================
epoch no : 9, batch no : 171, total loss : 0.16562797129154205,  classifier :0.01997416652739048, mask: 0.07555924355983734 ===================
epoch no : 9, batch no : 172, total loss : 0.23148861527442932,  classifier :0.01831812970340252, mask: 0.13377484679222107 ===================
epoch no : 9, batch no : 173, total loss : 0.2169477790594101,  classifier :0.02621140144765377, mask: 0.09078624844551086 ===================
epoch no : 9, batch no : 174, total loss : 0.18488045036792755,  classifier :0.019441062584519386, mask: 0.08615141361951828 ===================
epoch no : 9, batch no : 175, total loss : 0.24327470362186432,  classifier :0.01987791620194912, mask: 0.10464178025722504 ===================
epoch no : 9, batch no : 176, total loss : 0.19208641350269318,  classifier :0.0241542961448431, mask: 0.08114850521087646 ===================
epoch no : 9, batch no : 177, total loss : 0.18875013291835785,  classifier :0.017622003331780434, mask: 0.09709664434194565 ===================
epoch no : 9, batch no : 178, total loss : 0.16372445225715637,  classifier :0.019254345446825027, mask: 0.07916729897260666 ===================
epoch no : 9, batch no : 179, total loss : 0.16217102110385895,  classifier :0.031291741877794266, mask: 0.07662083208560944 ===================
epoch no : 9, batch no : 180, total loss : 0.21521316468715668,  classifier :0.02292516827583313, mask: 0.11146669834852219 ===================
epoch no : 9, batch no : 181, total loss : 0.18885350227355957,  classifier :0.020318109542131424, mask: 0.08386009186506271 ===================
epoch no : 9, batch no : 182, total loss : 0.19395053386688232,  classifier :0.01918802410364151, mask: 0.08931055665016174 ===================
epoch no : 9, batch no : 183, total loss : 0.17657119035720825,  classifier :0.013241607695817947, mask: 0.10406623780727386 ===================
epoch no : 9, batch no : 184, total loss : 0.21960650384426117,  classifier :0.020987745374441147, mask: 0.11134101450443268 ===================
epoch no : 9, batch no : 185, total loss : 0.22082938253879547,  classifier :0.0274856798350811, mask: 0.09655612707138062 ===================
epoch no : 9, batch no : 186, total loss : 0.20896251499652863,  classifier :0.022028034552931786, mask: 0.08178344368934631 ===================
epoch no : 9, batch no : 187, total loss : 0.25109267234802246,  classifier :0.023286886513233185, mask: 0.09502936154603958 ===================
epoch no : 9, batch no : 188, total loss : 0.2822631895542145,  classifier :0.01804417371749878, mask: 0.13108175992965698 ===================
epoch no : 9, batch no : 189, total loss : 0.2745363712310791,  classifier :0.022705016657710075, mask: 0.11697659641504288 ===================
epoch no : 9, batch no : 190, total loss : 0.21560817956924438,  classifier :0.02030908316373825, mask: 0.10266343504190445 ===================
epoch no : 9, batch no : 191, total loss : 0.1981694996356964,  classifier :0.02813473716378212, mask: 0.09232675284147263 ===================
epoch no : 9, batch no : 192, total loss : 0.18758165836334229,  classifier :0.019116442650556564, mask: 0.1053222194314003 ===================
epoch no : 9, batch no : 193, total loss : 0.17894360423088074,  classifier :0.020520003512501717, mask: 0.08852004259824753 ===================
epoch no : 9, batch no : 194, total loss : 0.2088852971792221,  classifier :0.026936225593090057, mask: 0.07814877480268478 ===================
epoch no : 9, batch no : 195, total loss : 0.25150758028030396,  classifier :0.024622399359941483, mask: 0.10923244804143906 ===================
epoch no : 9, batch no : 196, total loss : 0.26003479957580566,  classifier :0.023164307698607445, mask: 0.0904373824596405 ===================
epoch no : 9, batch no : 197, total loss : 0.20413319766521454,  classifier :0.019769569858908653, mask: 0.09195602685213089 ===================
epoch no : 9, batch no : 198, total loss : 0.2077733874320984,  classifier :0.022084124386310577, mask: 0.09519889950752258 ===================
epoch no : 9, batch no : 199, total loss : 0.2290215790271759,  classifier :0.026455562561750412, mask: 0.11344125121831894 ===================
epoch no : 9, batch no : 200, total loss : 0.2029646635055542,  classifier :0.021589670330286026, mask: 0.09241151064634323 ===================
epoch no : 9, batch no : 201, total loss : 0.18409575521945953,  classifier :0.018101776018738747, mask: 0.08371920883655548 ===================
epoch no : 9, batch no : 202, total loss : 0.20941179990768433,  classifier :0.016059650108218193, mask: 0.10987929999828339 ===================
epoch no : 9, batch no : 203, total loss : 0.2681344151496887,  classifier :0.026203393936157227, mask: 0.13160830736160278 ===================
epoch no : 9, batch no : 204, total loss : 0.258286714553833,  classifier :0.030332470312714577, mask: 0.11988842487335205 ===================
epoch no : 9, batch no : 205, total loss : 0.2344929426908493,  classifier :0.03334326297044754, mask: 0.1118808165192604 ===================
epoch no : 9, batch no : 206, total loss : 0.22805562615394592,  classifier :0.025491882115602493, mask: 0.09862446784973145 ===================
epoch no : 9, batch no : 207, total loss : 0.2098819613456726,  classifier :0.02113095484673977, mask: 0.10168866813182831 ===================
epoch no : 9, batch no : 208, total loss : 0.26634103059768677,  classifier :0.023627620190382004, mask: 0.10651098191738129 ===================
epoch no : 9, batch no : 209, total loss : 0.2453605979681015,  classifier :0.023272916674613953, mask: 0.12019027769565582 ===================
epoch no : 9, batch no : 210, total loss : 0.25974828004837036,  classifier :0.03297198563814163, mask: 0.09247040003538132 ===================
epoch no : 9, batch no : 211, total loss : 0.20683375000953674,  classifier :0.020345913246273994, mask: 0.08601057529449463 ===================
epoch no : 9, batch no : 212, total loss : 0.21189647912979126,  classifier :0.02336767129600048, mask: 0.08073127269744873 ===================
epoch no : 9, batch no : 213, total loss : 0.26251569390296936,  classifier :0.035815950483083725, mask: 0.11969929933547974 ===================
epoch no : 9, batch no : 214, total loss : 0.1807519793510437,  classifier :0.01573938876390457, mask: 0.0984712615609169 ===================
epoch no : 9, batch no : 215, total loss : 0.1994120180606842,  classifier :0.022910872474312782, mask: 0.08435957133769989 ===================
epoch no : 9, batch no : 216, total loss : 0.18586011230945587,  classifier :0.016044974327087402, mask: 0.09523124992847443 ===================
epoch no : 9, batch no : 217, total loss : 0.18989035487174988,  classifier :0.020629700273275375, mask: 0.09929157048463821 ===================
epoch no : 9, batch no : 218, total loss : 0.19256997108459473,  classifier :0.02283257432281971, mask: 0.09885904937982559 ===================
epoch no : 9, batch no : 219, total loss : 0.29659005999565125,  classifier :0.029628124088048935, mask: 0.14629855751991272 ===================
epoch no : 9, batch no : 220, total loss : 0.19692139327526093,  classifier :0.014205757528543472, mask: 0.08512403815984726 ===================
epoch no : 9, batch no : 221, total loss : 0.26081645488739014,  classifier :0.026560097932815552, mask: 0.09909863770008087 ===================
epoch no : 9, batch no : 222, total loss : 0.2195570468902588,  classifier :0.02096370793879032, mask: 0.11676976829767227 ===================
epoch no : 9, batch no : 223, total loss : 0.25447505712509155,  classifier :0.021007174625992775, mask: 0.09533758461475372 ===================
epoch no : 9, batch no : 224, total loss : 0.26491233706474304,  classifier :0.035840678960084915, mask: 0.10517525672912598 ===================
epoch no : 9, batch no : 225, total loss : 0.21648725867271423,  classifier :0.017972493544220924, mask: 0.1047021895647049 ===================
epoch no : 9, batch no : 226, total loss : 0.19961658120155334,  classifier :0.020221060141921043, mask: 0.09725198149681091 ===================
epoch no : 9, batch no : 227, total loss : 0.22396518290042877,  classifier :0.016775289550423622, mask: 0.10879073292016983 ===================
epoch no : 9, batch no : 228, total loss : 0.2330312877893448,  classifier :0.018277598544955254, mask: 0.12001367658376694 ===================
epoch no : 9, batch no : 229, total loss : 0.26219499111175537,  classifier :0.025632629171013832, mask: 0.10010715574026108 ===================
epoch no : 9, batch no : 230, total loss : 0.2818422317504883,  classifier :0.028597425669431686, mask: 0.12912604212760925 ===================
epoch no : 9, batch no : 231, total loss : 0.38509222865104675,  classifier :0.04496241733431816, mask: 0.16409486532211304 ===================
epoch no : 9, batch no : 232, total loss : 0.24580615758895874,  classifier :0.020783543586730957, mask: 0.12249475717544556 ===================
epoch no : 9, batch no : 233, total loss : 0.21769706904888153,  classifier :0.021800385788083076, mask: 0.0935869961977005 ===================
epoch no : 9, batch no : 234, total loss : 0.23086267709732056,  classifier :0.017982495948672295, mask: 0.09959188103675842 ===================
epoch no : 9, batch no : 235, total loss : 0.19368772208690643,  classifier :0.022674567997455597, mask: 0.08776989579200745 ===================
epoch no : 9, batch no : 236, total loss : 0.19564375281333923,  classifier :0.021103551611304283, mask: 0.09408055990934372 ===================
epoch no : 9, batch no : 237, total loss : 0.2176057994365692,  classifier :0.018626628443598747, mask: 0.10303127765655518 ===================
epoch no : 9, batch no : 238, total loss : 0.2621642053127289,  classifier :0.01936531439423561, mask: 0.12757423520088196 ===================
epoch no : 9, batch no : 239, total loss : 0.18860676884651184,  classifier :0.017622001469135284, mask: 0.09397564828395844 ===================
epoch no : 9, batch no : 240, total loss : 0.2358894646167755,  classifier :0.025890542194247246, mask: 0.12760451436042786 ===================
epoch no : 9, batch no : 241, total loss : 0.21672970056533813,  classifier :0.02194729447364807, mask: 0.12123963236808777 ===================
epoch no : 9, batch no : 242, total loss : 0.19716514647006989,  classifier :0.021149983629584312, mask: 0.08490268141031265 ===================
epoch no : 9, batch no : 243, total loss : 0.24110746383666992,  classifier :0.02101057954132557, mask: 0.10844838619232178 ===================
epoch no : 9, batch no : 244, total loss : 0.21265049278736115,  classifier :0.022106941789388657, mask: 0.094970703125 ===================
epoch no : 9, batch no : 245, total loss : 0.19644777476787567,  classifier :0.015638628974556923, mask: 0.08102437853813171 ===================
epoch no : 9, batch no : 246, total loss : 0.22526592016220093,  classifier :0.033565159887075424, mask: 0.10927796363830566 ===================
epoch no : 9, batch no : 247, total loss : 0.20957565307617188,  classifier :0.014752005226910114, mask: 0.09168979525566101 ===================
epoch no : 9, batch no : 248, total loss : 0.23700717091560364,  classifier :0.02287333831191063, mask: 0.10616655647754669 ===================
epoch no : 9, batch no : 249, total loss : 0.19592861831188202,  classifier :0.020780393853783607, mask: 0.0997815951704979 ===================
epoch no : 9, batch no : 250, total loss : 0.18408748507499695,  classifier :0.02360977977514267, mask: 0.08468291908502579 ===================
epoch no : 9, batch no : 251, total loss : 0.2572581470012665,  classifier :0.023733412846922874, mask: 0.10326965898275375 ===================
epoch no : 9, batch no : 252, total loss : 0.29061126708984375,  classifier :0.023384420201182365, mask: 0.14935940504074097 ===================
epoch no : 9, batch no : 253, total loss : 0.26315033435821533,  classifier :0.026696544140577316, mask: 0.12080586701631546 ===================
epoch no : 9, batch no : 254, total loss : 0.20578695833683014,  classifier :0.02220272272825241, mask: 0.09619468450546265 ===================
epoch no : 9, batch no : 255, total loss : 0.17064644396305084,  classifier :0.020367184653878212, mask: 0.07963060587644577 ===================
epoch no : 9, batch no : 256, total loss : 0.1811763048171997,  classifier :0.023253843188285828, mask: 0.08627437800168991 ===================
epoch no : 9, batch no : 257, total loss : 0.1695326417684555,  classifier :0.021150369197130203, mask: 0.0900539681315422 ===================
epoch no : 9, batch no : 258, total loss : 0.22830365598201752,  classifier :0.02019159309566021, mask: 0.10316475480794907 ===================
epoch no : 9, batch no : 259, total loss : 0.24762952327728271,  classifier :0.026772277429699898, mask: 0.10417047142982483 ===================
epoch no : 9, batch no : 260, total loss : 0.20663143694400787,  classifier :0.019635863602161407, mask: 0.10082890093326569 ===================
epoch no : 9, batch no : 261, total loss : 0.25186434388160706,  classifier :0.019556434825062752, mask: 0.1117057129740715 ===================
epoch no : 9, batch no : 262, total loss : 0.18792012333869934,  classifier :0.014894235879182816, mask: 0.08820762485265732 ===================
epoch no : 9, batch no : 263, total loss : 0.32085320353507996,  classifier :0.04433654621243477, mask: 0.13407309353351593 ===================
epoch no : 9, batch no : 264, total loss : 0.26386603713035583,  classifier :0.018101686611771584, mask: 0.10871589183807373 ===================
epoch no : 9, batch no : 265, total loss : 0.268312931060791,  classifier :0.028059393167495728, mask: 0.11800791323184967 ===================
epoch no : 9, batch no : 266, total loss : 0.19094693660736084,  classifier :0.02144906297326088, mask: 0.08559586107730865 ===================
epoch no : 9, batch no : 267, total loss : 0.23827317357063293,  classifier :0.016064712777733803, mask: 0.12496759742498398 ===================
epoch no : 9, batch no : 268, total loss : 0.3252542316913605,  classifier :0.03370315581560135, mask: 0.14932963252067566 ===================
epoch no : 9, batch no : 269, total loss : 0.17000357806682587,  classifier :0.016823356971144676, mask: 0.0893765315413475 ===================
epoch no : 9, batch no : 270, total loss : 0.17412550747394562,  classifier :0.018835600465536118, mask: 0.0803358405828476 ===================
epoch no : 9, batch no : 271, total loss : 0.22295385599136353,  classifier :0.02353432960808277, mask: 0.10837803781032562 ===================
epoch no : 9, batch no : 272, total loss : 0.18427056074142456,  classifier :0.018484557047486305, mask: 0.10217640548944473 ===================
epoch no : 9, batch no : 273, total loss : 0.17803479731082916,  classifier :0.023501791059970856, mask: 0.08537773787975311 ===================
epoch no : 9, batch no : 274, total loss : 0.24804754555225372,  classifier :0.01666305400431156, mask: 0.12265767902135849 ===================
epoch no : 9, batch no : 275, total loss : 0.1784176081418991,  classifier :0.014045984484255314, mask: 0.09384354203939438 ===================
epoch no : 9, batch no : 276, total loss : 0.21077385544776917,  classifier :0.028679464012384415, mask: 0.08928294479846954 ===================
epoch no : 9, batch no : 277, total loss : 0.1676771491765976,  classifier :0.024892518296837807, mask: 0.07185839116573334 ===================
epoch no : 9, batch no : 278, total loss : 0.21357740461826324,  classifier :0.020916584879159927, mask: 0.09569884091615677 ===================
epoch no : 9, batch no : 279, total loss : 0.2144654542207718,  classifier :0.01488625817000866, mask: 0.11768544465303421 ===================
epoch no : 9, batch no : 280, total loss : 0.2355862706899643,  classifier :0.023794837296009064, mask: 0.09804616123437881 ===================
epoch no : 9, batch no : 281, total loss : 0.20273420214653015,  classifier :0.01717599853873253, mask: 0.09112613648176193 ===================
epoch no : 9, batch no : 282, total loss : 0.23713630437850952,  classifier :0.022388245910406113, mask: 0.10244261473417282 ===================
epoch no : 9, batch no : 283, total loss : 0.23890471458435059,  classifier :0.025453820824623108, mask: 0.09771659225225449 ===================
epoch no : 9, batch no : 284, total loss : 0.18821966648101807,  classifier :0.02654886059463024, mask: 0.08437692373991013 ===================
epoch no : 9, batch no : 285, total loss : 0.19539088010787964,  classifier :0.018313150852918625, mask: 0.08993832021951675 ===================
epoch no : 9, batch no : 286, total loss : 0.16556121408939362,  classifier :0.01917463168501854, mask: 0.08161820471286774 ===================
epoch no : 9, batch no : 287, total loss : 0.20236358046531677,  classifier :0.024923942983150482, mask: 0.09253207594156265 ===================
epoch no : 9, batch no : 288, total loss : 0.282794326543808,  classifier :0.03532351553440094, mask: 0.13025666773319244 ===================
epoch no : 9, batch no : 289, total loss : 0.1859894096851349,  classifier :0.01800985261797905, mask: 0.1009371429681778 ===================
epoch no : 9, batch no : 290, total loss : 0.22375331819057465,  classifier :0.023390693590044975, mask: 0.09805870056152344 ===================
epoch no : 9, batch no : 291, total loss : 0.21383173763751984,  classifier :0.0159576665610075, mask: 0.1026163324713707 ===================
epoch no : 9, batch no : 292, total loss : 0.22574275732040405,  classifier :0.018612192943692207, mask: 0.09831035882234573 ===================
epoch no : 9, batch no : 293, total loss : 0.2005614936351776,  classifier :0.016602735966444016, mask: 0.09861177951097488 ===================
epoch no : 9, batch no : 294, total loss : 0.27014827728271484,  classifier :0.03637119382619858, mask: 0.10186028480529785 ===================
epoch no : 9, batch no : 295, total loss : 0.1990867704153061,  classifier :0.022600088268518448, mask: 0.09259799867868423 ===================
epoch no : 9, batch no : 296, total loss : 0.2008546143770218,  classifier :0.018977446481585503, mask: 0.09138047695159912 ===================
epoch no : 9, batch no : 297, total loss : 0.343828946352005,  classifier :0.02644210122525692, mask: 0.11985142529010773 ===================
epoch no : 9, batch no : 298, total loss : 0.2854137718677521,  classifier :0.020907266065478325, mask: 0.1382521390914917 ===================
epoch no : 9, batch no : 299, total loss : 0.20708847045898438,  classifier :0.018456043675541878, mask: 0.09958948940038681 ===================
epoch no : 9, batch no : 300, total loss : 0.1818159520626068,  classifier :0.020059052854776382, mask: 0.0968317836523056 ===================
epoch no : 9, batch no : 301, total loss : 0.2120574712753296,  classifier :0.020695971325039864, mask: 0.09475492686033249 ===================
epoch no : 9, batch no : 302, total loss : 0.28074178099632263,  classifier :0.020571015775203705, mask: 0.1405525803565979 ===================
epoch no : 9, batch no : 303, total loss : 0.2661265432834625,  classifier :0.028423290699720383, mask: 0.1104506179690361 ===================
epoch no : 9, batch no : 304, total loss : 0.233589306473732,  classifier :0.023124415427446365, mask: 0.07999923080205917 ===================
epoch no : 9, batch no : 305, total loss : 0.2173016369342804,  classifier :0.0193452350795269, mask: 0.08931881189346313 ===================
epoch no : 9, batch no : 306, total loss : 0.20037469267845154,  classifier :0.027148161083459854, mask: 0.07759666442871094 ===================
epoch no : 9, batch no : 307, total loss : 0.21676969528198242,  classifier :0.02140326425433159, mask: 0.10503550618886948 ===================
epoch no : 9, batch no : 308, total loss : 0.22650916874408722,  classifier :0.020157193765044212, mask: 0.10621009021997452 ===================
epoch no : 9, batch no : 309, total loss : 0.19884753227233887,  classifier :0.018981223925948143, mask: 0.10074029117822647 ===================
epoch no : 9, batch no : 310, total loss : 0.1999695748090744,  classifier :0.018376655876636505, mask: 0.10350795835256577 ===================
epoch no : 9, batch no : 311, total loss : 0.17041318118572235,  classifier :0.020060736685991287, mask: 0.07407017052173615 ===================
epoch no : 9, batch no : 312, total loss : 0.22276508808135986,  classifier :0.028402287513017654, mask: 0.10246641933917999 ===================
epoch no : 9, batch no : 313, total loss : 0.2223866730928421,  classifier :0.024147696793079376, mask: 0.08766939491033554 ===================
epoch no : 9, batch no : 314, total loss : 0.2249080240726471,  classifier :0.019192304462194443, mask: 0.09278325736522675 ===================
epoch no : 9, batch no : 315, total loss : 0.16133823990821838,  classifier :0.022694405168294907, mask: 0.07779409736394882 ===================
epoch no : 9, batch no : 316, total loss : 0.1832306683063507,  classifier :0.01786624826490879, mask: 0.08209650218486786 ===================
epoch no : 9, batch no : 317, total loss : 0.2018318772315979,  classifier :0.01807754673063755, mask: 0.09623388200998306 ===================
epoch no : 9, batch no : 318, total loss : 0.19365866482257843,  classifier :0.02135082334280014, mask: 0.09463357925415039 ===================
epoch no : 9, batch no : 319, total loss : 0.189632385969162,  classifier :0.022867543622851372, mask: 0.09635018557310104 ===================
epoch no : 9, batch no : 320, total loss : 0.20012319087982178,  classifier :0.024990906938910484, mask: 0.10062059015035629 ===================
epoch no : 9, batch no : 321, total loss : 0.27481335401535034,  classifier :0.0392996110022068, mask: 0.11112711578607559 ===================
epoch no : 9, batch no : 322, total loss : 0.17719273269176483,  classifier :0.014980139210820198, mask: 0.100112684071064 ===================
epoch no : 9, batch no : 323, total loss : 0.17529557645320892,  classifier :0.018684206530451775, mask: 0.08378546684980392 ===================
epoch no : 9, batch no : 324, total loss : 0.15349674224853516,  classifier :0.02168397232890129, mask: 0.08310458064079285 ===================
epoch no : 9, batch no : 325, total loss : 0.1665392965078354,  classifier :0.025686975568532944, mask: 0.07409656792879105 ===================
epoch no : 9, batch no : 326, total loss : 0.19479338824748993,  classifier :0.027402833104133606, mask: 0.08853109180927277 ===================
epoch no : 9, batch no : 327, total loss : 0.17254750430583954,  classifier :0.019236886873841286, mask: 0.08069581538438797 ===================
epoch no : 9, batch no : 328, total loss : 0.2234763503074646,  classifier :0.01736699417233467, mask: 0.11096394062042236 ===================
epoch no : 9, batch no : 329, total loss : 0.15870562195777893,  classifier :0.03035215474665165, mask: 0.0696401447057724 ===================
epoch no : 9, batch no : 330, total loss : 0.19269520044326782,  classifier :0.016273735091090202, mask: 0.09251667559146881 ===================
epoch no : 9, batch no : 331, total loss : 0.18197967112064362,  classifier :0.027546465396881104, mask: 0.08926524966955185 ===================
epoch no : 9, batch no : 332, total loss : 0.19358643889427185,  classifier :0.022099921479821205, mask: 0.09430673718452454 ===================
epoch no : 9, batch no : 333, total loss : 0.19458739459514618,  classifier :0.018366243690252304, mask: 0.0928979367017746 ===================
epoch no : 9, batch no : 334, total loss : 0.21611696481704712,  classifier :0.019989682361483574, mask: 0.10476621985435486 ===================
epoch no : 9, batch no : 335, total loss : 0.21798694133758545,  classifier :0.026340162381529808, mask: 0.10357797890901566 ===================
epoch no : 9, batch no : 336, total loss : 0.22118626534938812,  classifier :0.026582928374409676, mask: 0.10222092270851135 ===================
epoch no : 9, batch no : 337, total loss : 0.22112515568733215,  classifier :0.021641544997692108, mask: 0.1045476496219635 ===================
epoch no : 9, batch no : 338, total loss : 0.23643773794174194,  classifier :0.022489264607429504, mask: 0.13756603002548218 ===================
epoch no : 9, batch no : 339, total loss : 0.16992159187793732,  classifier :0.01753893867135048, mask: 0.07049039006233215 ===================
epoch no : 9, batch no : 340, total loss : 0.2336018830537796,  classifier :0.019442500546574593, mask: 0.1112581267952919 ===================
epoch no : 9, batch no : 341, total loss : 0.3280695974826813,  classifier :0.03342587873339653, mask: 0.1337321698665619 ===================
epoch no : 9, batch no : 342, total loss : 0.24671237170696259,  classifier :0.027223778888583183, mask: 0.10228835791349411 ===================
epoch no : 9, batch no : 343, total loss : 0.19009187817573547,  classifier :0.015490367077291012, mask: 0.09464211016893387 ===================
epoch no : 9, batch no : 344, total loss : 0.1384967416524887,  classifier :0.016024621203541756, mask: 0.06908838450908661 ===================
epoch no : 9, batch no : 345, total loss : 0.2199094593524933,  classifier :0.020927291363477707, mask: 0.08968161791563034 ===================
epoch no : 9, batch no : 346, total loss : 0.1798284351825714,  classifier :0.02164805307984352, mask: 0.08756061643362045 ===================
epoch no : 9, batch no : 347, total loss : 0.1985168308019638,  classifier :0.0176814217120409, mask: 0.09315857291221619 ===================
epoch no : 9, batch no : 348, total loss : 0.20384900271892548,  classifier :0.020986558869481087, mask: 0.09009183198213577 ===================
epoch no : 9, batch no : 349, total loss : 0.22100993990898132,  classifier :0.017102405428886414, mask: 0.09556121379137039 ===================
epoch no : 9, batch no : 350, total loss : 0.27917420864105225,  classifier :0.03514455631375313, mask: 0.13647489249706268 ===================
epoch no : 9, batch no : 351, total loss : 0.36929184198379517,  classifier :0.039682768285274506, mask: 0.15061718225479126 ===================
epoch no : 9, batch no : 352, total loss : 0.18215776979923248,  classifier :0.01889716275036335, mask: 0.09040621668100357 ===================
epoch no : 9, batch no : 353, total loss : 0.21422378718852997,  classifier :0.01827601157128811, mask: 0.10158541798591614 ===================
epoch no : 9, batch no : 354, total loss : 0.24538666009902954,  classifier :0.020458947867155075, mask: 0.11790597438812256 ===================
epoch no : 9, batch no : 355, total loss : 0.2106667309999466,  classifier :0.025189818814396858, mask: 0.08954465389251709 ===================
epoch no : 9, batch no : 356, total loss : 0.24777697026729584,  classifier :0.025871099904179573, mask: 0.10058920085430145 ===================
epoch no : 9, batch no : 357, total loss : 0.25934675335884094,  classifier :0.02123115584254265, mask: 0.12579254806041718 ===================
epoch no : 9, batch no : 358, total loss : 0.19071130454540253,  classifier :0.02143022231757641, mask: 0.0888834223151207 ===================
epoch no : 9, batch no : 359, total loss : 0.24998925626277924,  classifier :0.02599993348121643, mask: 0.10231280326843262 ===================
epoch no : 9, batch no : 360, total loss : 0.21913154423236847,  classifier :0.019436730071902275, mask: 0.09901047497987747 ===================
epoch no : 9, batch no : 361, total loss : 0.30759984254837036,  classifier :0.024867402389645576, mask: 0.13371066749095917 ===================
epoch no : 9, batch no : 362, total loss : 0.22281546890735626,  classifier :0.024407614022493362, mask: 0.08881033957004547 ===================
epoch no : 9, batch no : 363, total loss : 0.2043907195329666,  classifier :0.014442874118685722, mask: 0.10444965213537216 ===================
epoch no : 9, batch no : 364, total loss : 0.26909905672073364,  classifier :0.023281442001461983, mask: 0.1333218514919281 ===================
epoch no : 9, batch no : 365, total loss : 0.23769161105155945,  classifier :0.01936260610818863, mask: 0.10092250257730484 ===================
epoch no : 9, batch no : 366, total loss : 0.22964143753051758,  classifier :0.029049333184957504, mask: 0.09824541956186295 ===================
epoch no : 9, batch no : 367, total loss : 0.23149384558200836,  classifier :0.025445735082030296, mask: 0.11101191490888596 ===================
epoch no : 9, batch no : 368, total loss : 0.2325466424226761,  classifier :0.025841210037469864, mask: 0.09314363449811935 ===================
epoch no : 9, batch no : 369, total loss : 0.2579978108406067,  classifier :0.02566305361688137, mask: 0.11834859848022461 ===================
epoch no : 9, batch no : 370, total loss : 0.23622821271419525,  classifier :0.023069322109222412, mask: 0.08552892506122589 ===================
epoch no : 9, batch no : 371, total loss : 0.32982635498046875,  classifier :0.03546855226159096, mask: 0.12739019095897675 ===================
epoch no : 9, batch no : 372, total loss : 0.2429438829421997,  classifier :0.018859975039958954, mask: 0.12736958265304565 ===================
epoch no : 9, batch no : 373, total loss : 0.17864954471588135,  classifier :0.023220382630825043, mask: 0.07948865741491318 ===================
epoch no : 9, batch no : 374, total loss : 0.17999224364757538,  classifier :0.02040093205869198, mask: 0.07981188595294952 ===================
epoch no : 9, batch no : 375, total loss : 0.19980579614639282,  classifier :0.023629145696759224, mask: 0.08943170309066772 ===================
epoch no : 9, batch no : 376, total loss : 0.24992094933986664,  classifier :0.02143019251525402, mask: 0.11807543784379959 ===================
epoch no : 9, batch no : 377, total loss : 0.19605931639671326,  classifier :0.017856214195489883, mask: 0.09905189275741577 ===================
epoch no : 9, batch no : 378, total loss : 0.18977795541286469,  classifier :0.01868031919002533, mask: 0.0850430428981781 ===================
epoch no : 9, batch no : 379, total loss : 0.1817963719367981,  classifier :0.03146781027317047, mask: 0.0904146358370781 ===================
epoch no : 9, batch no : 380, total loss : 0.18384705483913422,  classifier :0.018442707136273384, mask: 0.09773072600364685 ===================
epoch no : 9, batch no : 381, total loss : 0.21201448142528534,  classifier :0.016653593629598618, mask: 0.1120719462633133 ===================
epoch no : 9, batch no : 382, total loss : 0.18846458196640015,  classifier :0.01486847922205925, mask: 0.0996081605553627 ===================
epoch no : 9, batch no : 383, total loss : 0.2063470184803009,  classifier :0.022084470838308334, mask: 0.09736692905426025 ===================
epoch no : 9, batch no : 384, total loss : 0.26283326745033264,  classifier :0.03861420974135399, mask: 0.09591444581747055 ===================
epoch no : 9, batch no : 385, total loss : 0.21489682793617249,  classifier :0.024725571274757385, mask: 0.10709256678819656 ===================
epoch no : 9, batch no : 386, total loss : 0.33551767468452454,  classifier :0.034572988748550415, mask: 0.13210368156433105 ===================
epoch no : 9, batch no : 387, total loss : 0.1644296646118164,  classifier :0.01891716569662094, mask: 0.07239878922700882 ===================
epoch no : 9, batch no : 388, total loss : 0.19316966831684113,  classifier :0.02285163663327694, mask: 0.09169739484786987 ===================
epoch no : 9, batch no : 389, total loss : 0.17727771401405334,  classifier :0.021567871794104576, mask: 0.09269929677248001 ===================
epoch no : 9, batch no : 390, total loss : 0.17473916709423065,  classifier :0.015839384868741035, mask: 0.10153080523014069 ===================
epoch no : 9, batch no : 391, total loss : 0.21036610007286072,  classifier :0.02208472043275833, mask: 0.11913684755563736 ===================
epoch no : 9, batch no : 392, total loss : 0.203097864985466,  classifier :0.018450362607836723, mask: 0.11050626635551453 ===================
epoch no : 9, batch no : 393, total loss : 0.2685745656490326,  classifier :0.03218059614300728, mask: 0.12495186179876328 ===================
epoch no : 9, batch no : 394, total loss : 0.21106532216072083,  classifier :0.019965285435318947, mask: 0.1029130071401596 ===================
epoch no : 9, batch no : 395, total loss : 0.18547207117080688,  classifier :0.021374106407165527, mask: 0.08445274084806442 ===================
epoch no : 9, batch no : 396, total loss : 0.1921558529138565,  classifier :0.019510358572006226, mask: 0.08883582800626755 ===================
epoch no : 9, batch no : 397, total loss : 0.22557973861694336,  classifier :0.021366655826568604, mask: 0.09544181823730469 ===================
epoch no : 9, batch no : 398, total loss : 0.22332896292209625,  classifier :0.021952016279101372, mask: 0.08453519642353058 ===================

 =================The Model is Trained!====================
-----------------Visualizing Model predictions----------------
  0%|          | 0/2 [00:00<?, ?it/s]
 /gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/test-patients/images

0it [00:00, ?it/s][A0it [00:00, ?it/s]
100%|██████████| 2/2 [00:00<00:00, 27.82it/s]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: epoch ▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇████
wandb:  loss █▄▄▅▃▂▂▃▃▂▄▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▁▁▂▂▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb: epoch 9
wandb:  loss 0.22333
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /wynton/home/finkbeiner/vgramas/Projects/amyb-plaque-detection/src/models/wandb/offline-run-20230329_143424-2xxv044q
wandb: Find logs at: ./wandb/offline-run-20230329_143424-2xxv044q/logs

 /gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/test-patients/labels
The model is running on node qb3-idgpu10
Successfully stopped recording stats for 2283466.
Successfully retrieved statistics for job: 2283466. 
+------------------------------------------------------------------------------+
| GPU ID: 3                                                                    |
+====================================+=========================================+
|-----  Execution Stats  ------------+-----------------------------------------|
| Start Time                         | Wed Mar 29 14:33:16 2023                |
| End Time                           | Wed Mar 29 16:33:39 2023                |
| Total Execution Time (sec)         | 7222.44                                 |
| No. of Processes                   | 0                                       |
+-----  Performance Stats  ----------+-----------------------------------------+
| Energy Consumed (Joules)           | 24346                                   |
| Power Usage (Watts)                | Avg: 7.13443, Max: 8.282, Min: 6.011    |
| Max GPU Memory Used (bytes)        | 0                                       |
| SM Clock (MHz)                     | Avg: 300, Max: 300, Min: 300            |
| Memory Clock (MHz)                 | Avg: 405, Max: 405, Min: 405            |
| SM Utilization (%)                 | Avg: 0, Max: 0, Min: 0                  |
| Memory Utilization (%)             | Avg: 0, Max: 0, Min: 0                  |
| PCIe Rx Bandwidth (megabytes)      | Avg: N/A, Max: N/A, Min: N/A            |
| PCIe Tx Bandwidth (megabytes)      | Avg: N/A, Max: N/A, Min: N/A            |
+-----  Event Stats  ----------------+-----------------------------------------+
| Single Bit ECC Errors              | 0                                       |
| Double Bit ECC Errors              | 0                                       |
| PCIe Replay Warnings               | 0                                       |
| Critical XID Errors                | 0                                       |
+-----  Slowdown Stats  -------------+-----------------------------------------+
| Due to - Power (%)                 | 0                                       |
|        - Thermal (%)               | 0                                       |
|        - Reliability (%)           | Not Supported                           |
|        - Board Limit (%)           | Not Supported                           |
|        - Low Utilization (%)       | Not Supported                           |
|        - Sync Boost (%)            | 0                                       |
+-----  Overall Health  -------------+-----------------------------------------+
| Overall Health                     | Healthy                                 |
+------------------------------------+-----------------------------------------+

Successfully removed group 68
