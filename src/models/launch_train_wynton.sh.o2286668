Successfully started process watches.
Successfully started recording stats for 2286668.
W&B offline. Running your script from this directory will only write metadata locally. Use wandb disabled to completely turn off W&B.
wandb: Tracking run with wandb version 0.13.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
/wynton/home/finkbeiner/vgramas/.conda/envs/amyb/lib/python3.9/site-packages/torchvision/transforms/functional.py:165: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  img = torch.as_tensor(np.asarray(pic))
/wynton/home/finkbeiner/vgramas/.conda/envs/amyb/lib/python3.9/site-packages/torchvision/transforms/functional.py:165: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  img = torch.as_tensor(np.asarray(pic))
/wynton/home/finkbeiner/vgramas/.conda/envs/amyb/lib/python3.9/site-packages/torchvision/transforms/functional.py:165: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  img = torch.as_tensor(np.asarray(pic))
/wynton/home/finkbeiner/vgramas/.conda/envs/amyb/lib/python3.9/site-packages/torchvision/transforms/functional.py:165: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  img = torch.as_tensor(np.asarray(pic))
/wynton/home/finkbeiner/vgramas/.conda/envs/amyb/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/wynton/home/finkbeiner/vgramas/.conda/envs/amyb/lib/python3.9/site-packages/torchvision/transforms/functional.py:165: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  img = torch.as_tensor(np.asarray(pic))
epoch no : 0, batch no : 0, total loss : 3.7469892501831055,  classifier :1.6271982192993164, mask: 1.3815194368362427 ===================
epoch no : 0, batch no : 1, total loss : 2.7576119899749756,  classifier :1.3657846450805664, mask: 0.6604986190795898 ===================
epoch no : 0, batch no : 2, total loss : 2.4285671710968018,  classifier :0.984935462474823, mask: 0.7067245244979858 ===================
epoch no : 0, batch no : 3, total loss : 1.8009597063064575,  classifier :0.31464511156082153, mask: 0.7408044338226318 ===================
epoch no : 0, batch no : 4, total loss : 1.8862757682800293,  classifier :0.3573538661003113, mask: 0.7417387366294861 ===================
epoch no : 0, batch no : 5, total loss : 2.0372226238250732,  classifier :0.4174755811691284, mask: 0.8536837100982666 ===================
epoch no : 0, batch no : 6, total loss : 2.103181838989258,  classifier :0.36610668897628784, mask: 0.8286553025245667 ===================
epoch no : 0, batch no : 7, total loss : 2.0349032878875732,  classifier :0.25223544239997864, mask: 0.9862150549888611 ===================
epoch no : 0, batch no : 8, total loss : 2.2335586547851562,  classifier :0.13636569678783417, mask: 1.2649625539779663 ===================
epoch no : 0, batch no : 9, total loss : 2.0001354217529297,  classifier :0.40331143140792847, mask: 0.7547727823257446 ===================
epoch no : 0, batch no : 10, total loss : 1.9315922260284424,  classifier :0.13282828032970428, mask: 1.1022553443908691 ===================
epoch no : 0, batch no : 11, total loss : 1.930743932723999,  classifier :0.33528080582618713, mask: 0.7144631147384644 ===================
epoch no : 0, batch no : 12, total loss : 1.6377737522125244,  classifier :0.157462015748024, mask: 0.7909038066864014 ===================
epoch no : 0, batch no : 13, total loss : 1.524130940437317,  classifier :0.1341654360294342, mask: 0.6833200454711914 ===================
epoch no : 0, batch no : 14, total loss : 1.3704208135604858,  classifier :0.11679810285568237, mask: 0.6330234408378601 ===================
epoch no : 0, batch no : 15, total loss : 1.2472776174545288,  classifier :0.11866330355405807, mask: 0.6175509095191956 ===================
epoch no : 0, batch no : 16, total loss : 1.3023607730865479,  classifier :0.1177246943116188, mask: 0.6484854221343994 ===================
epoch no : 0, batch no : 17, total loss : 1.0984165668487549,  classifier :0.09530707448720932, mask: 0.4981246292591095 ===================
epoch no : 0, batch no : 18, total loss : 1.5200268030166626,  classifier :0.15372394025325775, mask: 0.848420262336731 ===================
epoch no : 0, batch no : 19, total loss : 1.5044559240341187,  classifier :0.33372482657432556, mask: 0.6764155626296997 ===================
epoch no : 0, batch no : 20, total loss : 1.3906729221343994,  classifier :0.15105165541172028, mask: 0.5835856199264526 ===================
epoch no : 0, batch no : 21, total loss : 1.2344701290130615,  classifier :0.13228406012058258, mask: 0.5239508748054504 ===================
epoch no : 0, batch no : 22, total loss : 1.1774154901504517,  classifier :0.12288276851177216, mask: 0.5371490716934204 ===================
epoch no : 0, batch no : 23, total loss : 1.229727864265442,  classifier :0.1370665580034256, mask: 0.5263465046882629 ===================
epoch no : 0, batch no : 24, total loss : 1.143702745437622,  classifier :0.12420833110809326, mask: 0.48849770426750183 ===================
epoch no : 0, batch no : 25, total loss : 1.0736472606658936,  classifier :0.09598000347614288, mask: 0.5253283381462097 ===================
epoch no : 0, batch no : 26, total loss : 1.4952746629714966,  classifier :0.14320696890354156, mask: 0.8024243712425232 ===================
epoch no : 0, batch no : 27, total loss : 1.5889607667922974,  classifier :0.3590167164802551, mask: 0.691639244556427 ===================
epoch no : 0, batch no : 28, total loss : 1.33744215965271,  classifier :0.12203102558851242, mask: 0.7623578310012817 ===================
epoch no : 0, batch no : 29, total loss : 1.207209825515747,  classifier :0.1309134066104889, mask: 0.6127259731292725 ===================
epoch no : 0, batch no : 30, total loss : 1.1267203092575073,  classifier :0.1161053329706192, mask: 0.599607527256012 ===================
epoch no : 0, batch no : 31, total loss : 1.2775706052780151,  classifier :0.12005095183849335, mask: 0.6360986828804016 ===================
epoch no : 0, batch no : 32, total loss : 1.145237922668457,  classifier :0.1392585039138794, mask: 0.4857932925224304 ===================
epoch no : 0, batch no : 33, total loss : 1.068413257598877,  classifier :0.10773108899593353, mask: 0.4644760489463806 ===================
epoch no : 0, batch no : 34, total loss : 1.0801866054534912,  classifier :0.12559852004051208, mask: 0.4827307462692261 ===================
epoch no : 0, batch no : 35, total loss : 1.0330827236175537,  classifier :0.11216195672750473, mask: 0.44008737802505493 ===================
epoch no : 0, batch no : 36, total loss : 0.9594050049781799,  classifier :0.11905961483716965, mask: 0.4063871204853058 ===================
epoch no : 0, batch no : 37, total loss : 0.9466516971588135,  classifier :0.12815231084823608, mask: 0.3562355637550354 ===================
epoch no : 0, batch no : 38, total loss : 1.0237114429473877,  classifier :0.11471407115459442, mask: 0.4101375341415405 ===================
epoch no : 0, batch no : 39, total loss : 1.1380788087844849,  classifier :0.13122202455997467, mask: 0.5156873464584351 ===================
epoch no : 0, batch no : 40, total loss : 1.132972002029419,  classifier :0.11968539655208588, mask: 0.5389094352722168 ===================
epoch no : 0, batch no : 41, total loss : 0.9715248942375183,  classifier :0.1113903820514679, mask: 0.40916067361831665 ===================
epoch no : 0, batch no : 42, total loss : 0.8792546987533569,  classifier :0.11271384358406067, mask: 0.3603261411190033 ===================
epoch no : 0, batch no : 43, total loss : 0.9992233514785767,  classifier :0.12442336231470108, mask: 0.37622615694999695 ===================
epoch no : 0, batch no : 44, total loss : 1.0197588205337524,  classifier :0.11504412442445755, mask: 0.44908443093299866 ===================
epoch no : 0, batch no : 45, total loss : 1.048180103302002,  classifier :0.1175423413515091, mask: 0.4419980049133301 ===================
epoch no : 0, batch no : 46, total loss : 0.8868308663368225,  classifier :0.09031708538532257, mask: 0.3655811548233032 ===================
epoch no : 0, batch no : 47, total loss : 0.9449182152748108,  classifier :0.11929535865783691, mask: 0.374090313911438 ===================
epoch no : 0, batch no : 48, total loss : 1.0608692169189453,  classifier :0.11394025385379791, mask: 0.3836771845817566 ===================
epoch no : 0, batch no : 49, total loss : 0.8288788795471191,  classifier :0.11185585707426071, mask: 0.28553229570388794 ===================
epoch no : 0, batch no : 50, total loss : 0.8827406167984009,  classifier :0.1105508953332901, mask: 0.33614906668663025 ===================
epoch no : 0, batch no : 51, total loss : 0.9774603247642517,  classifier :0.11640272289514542, mask: 0.3383798897266388 ===================
epoch no : 0, batch no : 52, total loss : 1.3014212846755981,  classifier :0.11121899634599686, mask: 0.7958929538726807 ===================
epoch no : 0, batch no : 53, total loss : 0.997188150882721,  classifier :0.11194438487291336, mask: 0.4071855843067169 ===================
epoch no : 0, batch no : 54, total loss : 1.020588994026184,  classifier :0.12411487847566605, mask: 0.363517701625824 ===================
epoch no : 0, batch no : 55, total loss : 0.9773159623146057,  classifier :0.12065645307302475, mask: 0.38450056314468384 ===================
epoch no : 0, batch no : 56, total loss : 0.8134728670120239,  classifier :0.09917744249105453, mask: 0.28074488043785095 ===================
epoch no : 0, batch no : 57, total loss : 0.9118934273719788,  classifier :0.1297639012336731, mask: 0.3172606825828552 ===================
epoch no : 0, batch no : 58, total loss : 0.9150334000587463,  classifier :0.12200064957141876, mask: 0.32284945249557495 ===================
epoch no : 0, batch no : 59, total loss : 1.018489122390747,  classifier :0.11889296025037766, mask: 0.4768942892551422 ===================
epoch no : 0, batch no : 60, total loss : 1.3713167905807495,  classifier :0.1141965463757515, mask: 0.8311545252799988 ===================
epoch no : 0, batch no : 61, total loss : 1.6133365631103516,  classifier :0.3753582239151001, mask: 0.7860280871391296 ===================
epoch no : 0, batch no : 62, total loss : 1.0237637758255005,  classifier :0.0981127917766571, mask: 0.4951634705066681 ===================
epoch no : 0, batch no : 63, total loss : 1.0853055715560913,  classifier :0.13215921819210052, mask: 0.47496888041496277 ===================
epoch no : 0, batch no : 64, total loss : 1.0323482751846313,  classifier :0.12412922084331512, mask: 0.39989984035491943 ===================
epoch no : 0, batch no : 65, total loss : 0.8989060521125793,  classifier :0.10240399837493896, mask: 0.35888877511024475 ===================
epoch no : 0, batch no : 66, total loss : 0.9561914801597595,  classifier :0.10973279923200607, mask: 0.37773630023002625 ===================
epoch no : 0, batch no : 67, total loss : 0.994117796421051,  classifier :0.1363365203142166, mask: 0.3333684206008911 ===================
epoch no : 0, batch no : 68, total loss : 0.8303612470626831,  classifier :0.09127764403820038, mask: 0.28367340564727783 ===================
epoch no : 0, batch no : 69, total loss : 0.7508970499038696,  classifier :0.10681835561990738, mask: 0.2850550413131714 ===================
epoch no : 0, batch no : 70, total loss : 0.8598746657371521,  classifier :0.12385541945695877, mask: 0.2813775837421417 ===================
epoch no : 0, batch no : 71, total loss : 0.8144920468330383,  classifier :0.09653585404157639, mask: 0.3061676025390625 ===================
epoch no : 0, batch no : 72, total loss : 0.8363413214683533,  classifier :0.09574269503355026, mask: 0.2915744185447693 ===================
epoch no : 0, batch no : 73, total loss : 0.8089309930801392,  classifier :0.11889979243278503, mask: 0.26672789454460144 ===================
epoch no : 0, batch no : 74, total loss : 0.7615514993667603,  classifier :0.09698658436536789, mask: 0.24211038649082184 ===================
epoch no : 0, batch no : 75, total loss : 0.7848608493804932,  classifier :0.11816052347421646, mask: 0.27899107336997986 ===================
epoch no : 0, batch no : 76, total loss : 0.8216953277587891,  classifier :0.09794875979423523, mask: 0.29570135474205017 ===================
epoch no : 0, batch no : 77, total loss : 0.9073498249053955,  classifier :0.10659949481487274, mask: 0.3687662184238434 ===================
epoch no : 0, batch no : 78, total loss : 1.104658603668213,  classifier :0.11178229004144669, mask: 0.5335160493850708 ===================
epoch no : 0, batch no : 79, total loss : 0.8236314654350281,  classifier :0.09062321484088898, mask: 0.32567423582077026 ===================
epoch no : 0, batch no : 80, total loss : 0.8208520412445068,  classifier :0.11308107525110245, mask: 0.2687511742115021 ===================
epoch no : 0, batch no : 81, total loss : 0.7673322558403015,  classifier :0.09684644639492035, mask: 0.31593120098114014 ===================
epoch no : 0, batch no : 82, total loss : 0.8850176930427551,  classifier :0.0957799106836319, mask: 0.4144405424594879 ===================
epoch no : 0, batch no : 83, total loss : 0.8345785140991211,  classifier :0.10891786217689514, mask: 0.2840961813926697 ===================
epoch no : 0, batch no : 84, total loss : 0.8841676115989685,  classifier :0.13233159482479095, mask: 0.3044915199279785 ===================
epoch no : 0, batch no : 85, total loss : 0.7869206070899963,  classifier :0.10387152433395386, mask: 0.21805013716220856 ===================
epoch no : 0, batch no : 86, total loss : 0.8848419785499573,  classifier :0.12132774293422699, mask: 0.320675253868103 ===================
epoch no : 0, batch no : 87, total loss : 0.8786036968231201,  classifier :0.10180724412202835, mask: 0.3961111605167389 ===================
epoch no : 0, batch no : 88, total loss : 0.915649950504303,  classifier :0.12024975568056107, mask: 0.3803815543651581 ===================
epoch no : 0, batch no : 89, total loss : 0.8498627543449402,  classifier :0.13348683714866638, mask: 0.26133841276168823 ===================
epoch no : 0, batch no : 90, total loss : 0.7649254202842712,  classifier :0.09296876937150955, mask: 0.28742682933807373 ===================
epoch no : 0, batch no : 91, total loss : 0.7440493106842041,  classifier :0.10858976095914841, mask: 0.23346899449825287 ===================
epoch no : 0, batch no : 92, total loss : 0.7200098037719727,  classifier :0.10063499957323074, mask: 0.292318195104599 ===================
epoch no : 0, batch no : 93, total loss : 0.7658659815788269,  classifier :0.103843554854393, mask: 0.2829289734363556 ===================
epoch no : 0, batch no : 94, total loss : 0.8767908215522766,  classifier :0.11239968985319138, mask: 0.38072216510772705 ===================
epoch no : 0, batch no : 95, total loss : 0.770952045917511,  classifier :0.11913102120161057, mask: 0.22863338887691498 ===================
epoch no : 0, batch no : 96, total loss : 0.8273689150810242,  classifier :0.11964099109172821, mask: 0.30192896723747253 ===================
epoch no : 0, batch no : 97, total loss : 0.9425261616706848,  classifier :0.09811308979988098, mask: 0.46294400095939636 ===================
epoch no : 0, batch no : 98, total loss : 0.7367671728134155,  classifier :0.09736137092113495, mask: 0.27521491050720215 ===================
epoch no : 0, batch no : 99, total loss : 0.7690024971961975,  classifier :0.08738403767347336, mask: 0.3056381046772003 ===================
epoch no : 0, batch no : 100, total loss : 0.658015787601471,  classifier :0.08403106778860092, mask: 0.24177446961402893 ===================
epoch no : 0, batch no : 101, total loss : 0.6734886169433594,  classifier :0.08845694363117218, mask: 0.24777454137802124 ===================
epoch no : 0, batch no : 102, total loss : 0.6789992451667786,  classifier :0.0950784906744957, mask: 0.2025684416294098 ===================
epoch no : 0, batch no : 103, total loss : 0.6213873624801636,  classifier :0.08104436099529266, mask: 0.24021437764167786 ===================
epoch no : 0, batch no : 104, total loss : 0.6508195996284485,  classifier :0.09489516913890839, mask: 0.2043049931526184 ===================
epoch no : 0, batch no : 105, total loss : 0.6267766356468201,  classifier :0.09224219620227814, mask: 0.19606263935565948 ===================
epoch no : 0, batch no : 106, total loss : 0.6854525804519653,  classifier :0.09832774847745895, mask: 0.2129649668931961 ===================
epoch no : 0, batch no : 107, total loss : 0.6914734244346619,  classifier :0.0863473191857338, mask: 0.29648247361183167 ===================
epoch no : 0, batch no : 108, total loss : 0.7305185198783875,  classifier :0.09152447432279587, mask: 0.26550525426864624 ===================
epoch no : 0, batch no : 109, total loss : 0.6207174062728882,  classifier :0.08201166242361069, mask: 0.2267216593027115 ===================
epoch no : 0, batch no : 110, total loss : 1.2315692901611328,  classifier :0.11585864424705505, mask: 0.7608587145805359 ===================
epoch no : 0, batch no : 111, total loss : 1.393416404724121,  classifier :0.325156033039093, mask: 0.6418575048446655 ===================
epoch no : 0, batch no : 112, total loss : 1.0709375143051147,  classifier :0.126492440700531, mask: 0.4855048656463623 ===================
epoch no : 0, batch no : 113, total loss : 1.0393811464309692,  classifier :0.13260334730148315, mask: 0.3491990864276886 ===================
epoch no : 0, batch no : 114, total loss : 0.9590654969215393,  classifier :0.11353527009487152, mask: 0.34465816617012024 ===================
epoch no : 0, batch no : 115, total loss : 0.7528247833251953,  classifier :0.09013310819864273, mask: 0.3378123939037323 ===================
epoch no : 0, batch no : 116, total loss : 0.7500900626182556,  classifier :0.09832864999771118, mask: 0.26723533868789673 ===================
epoch no : 0, batch no : 117, total loss : 0.8794901371002197,  classifier :0.11986794322729111, mask: 0.3812365233898163 ===================
epoch no : 0, batch no : 118, total loss : 0.7086203098297119,  classifier :0.11147301644086838, mask: 0.257007896900177 ===================
epoch no : 0, batch no : 119, total loss : 0.7571963667869568,  classifier :0.1186206266283989, mask: 0.26615065336227417 ===================
epoch no : 0, batch no : 120, total loss : 0.7929955124855042,  classifier :0.10705452412366867, mask: 0.31170326471328735 ===================
epoch no : 0, batch no : 121, total loss : 0.7253400087356567,  classifier :0.09908949583768845, mask: 0.2764425277709961 ===================
epoch no : 0, batch no : 122, total loss : 0.6347296237945557,  classifier :0.10188402235507965, mask: 0.20301957428455353 ===================
epoch no : 0, batch no : 123, total loss : 0.6984008550643921,  classifier :0.09993075579404831, mask: 0.284262478351593 ===================
epoch no : 0, batch no : 124, total loss : 0.8241000771522522,  classifier :0.10005483031272888, mask: 0.2946203052997589 ===================
epoch no : 0, batch no : 125, total loss : 0.789109468460083,  classifier :0.08874626457691193, mask: 0.3520841896533966 ===================
epoch no : 0, batch no : 126, total loss : 0.9904900193214417,  classifier :0.11846120655536652, mask: 0.47589510679244995 ===================
epoch no : 0, batch no : 127, total loss : 1.0003607273101807,  classifier :0.1416090875864029, mask: 0.46069207787513733 ===================
epoch no : 0, batch no : 128, total loss : 0.7189754843711853,  classifier :0.09610756486654282, mask: 0.29239988327026367 ===================
epoch no : 0, batch no : 129, total loss : 0.7082319855690002,  classifier :0.08900923281908035, mask: 0.2930361330509186 ===================
epoch no : 0, batch no : 130, total loss : 0.6778439879417419,  classifier :0.10850070416927338, mask: 0.2368766963481903 ===================
epoch no : 0, batch no : 131, total loss : 0.866759717464447,  classifier :0.10124657303094864, mask: 0.3382605314254761 ===================
epoch no : 0, batch no : 132, total loss : 0.6228955388069153,  classifier :0.08337591588497162, mask: 0.19904100894927979 ===================
epoch no : 0, batch no : 133, total loss : 0.7066882252693176,  classifier :0.09958219528198242, mask: 0.2378777116537094 ===================
epoch no : 0, batch no : 134, total loss : 0.6002914905548096,  classifier :0.09500500559806824, mask: 0.19771355390548706 ===================
epoch no : 0, batch no : 135, total loss : 0.533296525478363,  classifier :0.08049283921718597, mask: 0.1933944821357727 ===================
epoch no : 0, batch no : 136, total loss : 0.5950537323951721,  classifier :0.09061677753925323, mask: 0.20295201241970062 ===================
epoch no : 0, batch no : 137, total loss : 0.6547157764434814,  classifier :0.08892916887998581, mask: 0.24228964745998383 ===================
epoch no : 0, batch no : 138, total loss : 0.5745392441749573,  classifier :0.08094028383493423, mask: 0.19258607923984528 ===================
epoch no : 0, batch no : 139, total loss : 0.6360917091369629,  classifier :0.10034175217151642, mask: 0.21579360961914062 ===================
epoch no : 0, batch no : 140, total loss : 0.6625953316688538,  classifier :0.0883929505944252, mask: 0.267126202583313 ===================
epoch no : 0, batch no : 141, total loss : 0.5339890122413635,  classifier :0.086369089782238, mask: 0.15073232352733612 ===================
epoch no : 0, batch no : 142, total loss : 0.5744414329528809,  classifier :0.08263234049081802, mask: 0.22395756840705872 ===================
epoch no : 0, batch no : 143, total loss : 0.6401342153549194,  classifier :0.08533085137605667, mask: 0.29866454005241394 ===================
epoch no : 0, batch no : 144, total loss : 0.6192950010299683,  classifier :0.09079739451408386, mask: 0.2121068388223648 ===================
epoch no : 0, batch no : 145, total loss : 0.7114210724830627,  classifier :0.09411167353391647, mask: 0.3263154625892639 ===================
epoch no : 0, batch no : 146, total loss : 0.687275767326355,  classifier :0.08815880864858627, mask: 0.2713528573513031 ===================
epoch no : 0, batch no : 147, total loss : 0.6986241936683655,  classifier :0.09664006531238556, mask: 0.25389254093170166 ===================
epoch no : 0, batch no : 148, total loss : 0.5978211760520935,  classifier :0.0927969217300415, mask: 0.2216663956642151 ===================
epoch no : 0, batch no : 149, total loss : 0.7070253491401672,  classifier :0.10346725583076477, mask: 0.19050167500972748 ===================
epoch no : 0, batch no : 150, total loss : 0.5973546504974365,  classifier :0.09833324700593948, mask: 0.1910671889781952 ===================
epoch no : 0, batch no : 151, total loss : 0.6965145468711853,  classifier :0.10573497414588928, mask: 0.23852163553237915 ===================
epoch no : 0, batch no : 152, total loss : 0.6617981791496277,  classifier :0.08556223660707474, mask: 0.25821375846862793 ===================
epoch no : 0, batch no : 153, total loss : 0.5646006464958191,  classifier :0.08582773059606552, mask: 0.18577097356319427 ===================
epoch no : 0, batch no : 154, total loss : 0.7475412487983704,  classifier :0.08275911211967468, mask: 0.29093292355537415 ===================
epoch no : 0, batch no : 155, total loss : 0.6696041822433472,  classifier :0.09149385988712311, mask: 0.27344492077827454 ===================
epoch no : 0, batch no : 156, total loss : 0.5864558815956116,  classifier :0.08522269129753113, mask: 0.19736255705356598 ===================
epoch no : 0, batch no : 157, total loss : 0.7374562621116638,  classifier :0.08782890439033508, mask: 0.3763883411884308 ===================
epoch no : 0, batch no : 158, total loss : 0.5526678562164307,  classifier :0.08697222173213959, mask: 0.20113657414913177 ===================
epoch no : 0, batch no : 159, total loss : 0.5870703458786011,  classifier :0.07341007143259048, mask: 0.21796296536922455 ===================
epoch no : 0, batch no : 160, total loss : 0.6158319711685181,  classifier :0.08208616077899933, mask: 0.23683889210224152 ===================
epoch no : 0, batch no : 161, total loss : 0.682873547077179,  classifier :0.11903911083936691, mask: 0.24364516139030457 ===================
epoch no : 0, batch no : 162, total loss : 0.7220039367675781,  classifier :0.10425622761249542, mask: 0.26666495203971863 ===================
epoch no : 0, batch no : 163, total loss : 0.5989819169044495,  classifier :0.08404523879289627, mask: 0.22667177021503448 ===================
epoch no : 0, batch no : 164, total loss : 0.6266754269599915,  classifier :0.07831713557243347, mask: 0.2271818071603775 ===================
epoch no : 0, batch no : 165, total loss : 0.8366672396659851,  classifier :0.08893351256847382, mask: 0.2905791699886322 ===================
epoch no : 0, batch no : 166, total loss : 0.7493893504142761,  classifier :0.0939541906118393, mask: 0.31105509400367737 ===================
epoch no : 0, batch no : 167, total loss : 0.6608864068984985,  classifier :0.10646062344312668, mask: 0.2014342099428177 ===================
epoch no : 0, batch no : 168, total loss : 0.6161884665489197,  classifier :0.0953713059425354, mask: 0.20910091698169708 ===================
epoch no : 0, batch no : 169, total loss : 0.5513635873794556,  classifier :0.09139297157526016, mask: 0.2035815268754959 ===================
epoch no : 0, batch no : 170, total loss : 0.5560935139656067,  classifier :0.08126678317785263, mask: 0.20200976729393005 ===================
epoch no : 0, batch no : 171, total loss : 0.5473024845123291,  classifier :0.09409823268651962, mask: 0.19959096610546112 ===================
epoch no : 0, batch no : 172, total loss : 0.5765923261642456,  classifier :0.10107086598873138, mask: 0.16471347212791443 ===================
epoch no : 0, batch no : 173, total loss : 0.6161558032035828,  classifier :0.09699138253927231, mask: 0.19470606744289398 ===================
epoch no : 0, batch no : 174, total loss : 0.6708207726478577,  classifier :0.08473806828260422, mask: 0.29263266921043396 ===================
epoch no : 0, batch no : 175, total loss : 0.618598997592926,  classifier :0.09497281163930893, mask: 0.24873247742652893 ===================
epoch no : 0, batch no : 176, total loss : 0.6014145612716675,  classifier :0.09929604083299637, mask: 0.23115351796150208 ===================
epoch no : 0, batch no : 177, total loss : 0.5505847930908203,  classifier :0.08715324103832245, mask: 0.21558691561222076 ===================
epoch no : 0, batch no : 178, total loss : 0.5752516984939575,  classifier :0.09899953007698059, mask: 0.2009335309267044 ===================
epoch no : 0, batch no : 179, total loss : 0.5274052619934082,  classifier :0.08865945786237717, mask: 0.1821804940700531 ===================
epoch no : 0, batch no : 180, total loss : 0.5645358562469482,  classifier :0.07051320374011993, mask: 0.20401540398597717 ===================
epoch no : 0, batch no : 181, total loss : 0.5314927697181702,  classifier :0.07719963788986206, mask: 0.19797803461551666 ===================
epoch no : 0, batch no : 182, total loss : 0.7591668367385864,  classifier :0.10718681663274765, mask: 0.28491562604904175 ===================
epoch no : 0, batch no : 183, total loss : 0.7569941878318787,  classifier :0.08693002909421921, mask: 0.394023597240448 ===================
epoch no : 0, batch no : 184, total loss : 0.7898092269897461,  classifier :0.0872735008597374, mask: 0.39641955494880676 ===================
epoch no : 0, batch no : 185, total loss : 0.664058268070221,  classifier :0.09426862001419067, mask: 0.2538067400455475 ===================
epoch no : 0, batch no : 186, total loss : 0.5361910462379456,  classifier :0.07959412783384323, mask: 0.1907936930656433 ===================
epoch no : 0, batch no : 187, total loss : 0.7389789819717407,  classifier :0.08911334723234177, mask: 0.3187098205089569 ===================
epoch no : 0, batch no : 188, total loss : 0.6420251131057739,  classifier :0.09333857148885727, mask: 0.28648871183395386 ===================
epoch no : 0, batch no : 189, total loss : 0.5754839777946472,  classifier :0.08967199921607971, mask: 0.22554421424865723 ===================
epoch no : 0, batch no : 190, total loss : 0.5878989696502686,  classifier :0.07722581177949905, mask: 0.21199828386306763 ===================
epoch no : 0, batch no : 191, total loss : 0.7473815679550171,  classifier :0.1148320883512497, mask: 0.28204867243766785 ===================
epoch no : 0, batch no : 192, total loss : 0.5612245798110962,  classifier :0.07823607325553894, mask: 0.20467297732830048 ===================
epoch no : 0, batch no : 193, total loss : 0.645896315574646,  classifier :0.09063161909580231, mask: 0.2653939425945282 ===================
epoch no : 0, batch no : 194, total loss : 0.5866923928260803,  classifier :0.09320223331451416, mask: 0.206091970205307 ===================
epoch no : 0, batch no : 195, total loss : 0.5375120043754578,  classifier :0.0846363976597786, mask: 0.19764237105846405 ===================
epoch no : 0, batch no : 196, total loss : 0.5574445724487305,  classifier :0.09018157422542572, mask: 0.21344007551670074 ===================
epoch no : 0, batch no : 197, total loss : 0.5360862612724304,  classifier :0.06464250385761261, mask: 0.1873192936182022 ===================
epoch no : 0, batch no : 198, total loss : 0.5178883075714111,  classifier :0.07745024561882019, mask: 0.2036444991827011 ===================
epoch no : 0, batch no : 199, total loss : 0.6111516356468201,  classifier :0.09675655514001846, mask: 0.21556034684181213 ===================
epoch no : 0, batch no : 200, total loss : 0.8217322826385498,  classifier :0.09992944449186325, mask: 0.29517459869384766 ===================
epoch no : 0, batch no : 201, total loss : 0.5217347145080566,  classifier :0.0673171654343605, mask: 0.2070777714252472 ===================
epoch no : 0, batch no : 202, total loss : 0.5649433135986328,  classifier :0.07624475657939911, mask: 0.2518237233161926 ===================
epoch no : 0, batch no : 203, total loss : 0.5519835948944092,  classifier :0.07332074642181396, mask: 0.19769826531410217 ===================
epoch no : 0, batch no : 204, total loss : 0.4924694001674652,  classifier :0.06998522579669952, mask: 0.17751120030879974 ===================
epoch no : 0, batch no : 205, total loss : 0.5041440725326538,  classifier :0.0825263261795044, mask: 0.17040474712848663 ===================
epoch no : 0, batch no : 206, total loss : 0.5318403840065002,  classifier :0.0759190246462822, mask: 0.18987391889095306 ===================
epoch no : 0, batch no : 207, total loss : 0.5113457441329956,  classifier :0.0840064212679863, mask: 0.1583794504404068 ===================
epoch no : 0, batch no : 208, total loss : 0.5330986380577087,  classifier :0.08930297195911407, mask: 0.20385833084583282 ===================
epoch no : 0, batch no : 209, total loss : 0.5370868444442749,  classifier :0.09181786328554153, mask: 0.15748436748981476 ===================
epoch no : 0, batch no : 210, total loss : 0.5436208844184875,  classifier :0.08815872669219971, mask: 0.19681338965892792 ===================
epoch no : 0, batch no : 211, total loss : 0.5930682420730591,  classifier :0.09219605475664139, mask: 0.20951426029205322 ===================
epoch no : 0, batch no : 212, total loss : 0.6193731427192688,  classifier :0.0922442376613617, mask: 0.19405920803546906 ===================
epoch no : 0, batch no : 213, total loss : 0.5603897571563721,  classifier :0.08885318040847778, mask: 0.20873618125915527 ===================
epoch no : 0, batch no : 214, total loss : 0.5241293907165527,  classifier :0.07811646908521652, mask: 0.19032974541187286 ===================
epoch no : 0, batch no : 215, total loss : 0.5767307281494141,  classifier :0.07383490353822708, mask: 0.20424725115299225 ===================
epoch no : 0, batch no : 216, total loss : 0.8165171146392822,  classifier :0.08466985821723938, mask: 0.3297348916530609 ===================
epoch no : 0, batch no : 217, total loss : 0.5743376612663269,  classifier :0.09097731113433838, mask: 0.22549477219581604 ===================
epoch no : 0, batch no : 218, total loss : 0.4852108061313629,  classifier :0.07082998752593994, mask: 0.14952053129673004 ===================
epoch no : 0, batch no : 219, total loss : 0.6875088214874268,  classifier :0.08346132934093475, mask: 0.2806922197341919 ===================
epoch no : 0, batch no : 220, total loss : 0.5355010628700256,  classifier :0.08607886731624603, mask: 0.1960921585559845 ===================
epoch no : 0, batch no : 221, total loss : 0.40522441267967224,  classifier :0.07595087587833405, mask: 0.13177266716957092 ===================
epoch no : 0, batch no : 222, total loss : 0.4952213168144226,  classifier :0.07883866876363754, mask: 0.1801646649837494 ===================
epoch no : 0, batch no : 223, total loss : 0.5514487624168396,  classifier :0.07275351136922836, mask: 0.22460278868675232 ===================
epoch no : 0, batch no : 224, total loss : 0.5377048850059509,  classifier :0.08141794055700302, mask: 0.18285731971263885 ===================
epoch no : 0, batch no : 225, total loss : 0.4735267758369446,  classifier :0.06712641566991806, mask: 0.19106322526931763 ===================
epoch no : 0, batch no : 226, total loss : 0.5076062083244324,  classifier :0.07621285319328308, mask: 0.1904839426279068 ===================
epoch no : 0, batch no : 227, total loss : 0.4713609218597412,  classifier :0.08656022697687149, mask: 0.14875423908233643 ===================
epoch no : 0, batch no : 228, total loss : 0.6472387313842773,  classifier :0.07324745506048203, mask: 0.2581975758075714 ===================
epoch no : 0, batch no : 229, total loss : 0.622983992099762,  classifier :0.0868101567029953, mask: 0.20403899252414703 ===================
epoch no : 0, batch no : 230, total loss : 0.515684962272644,  classifier :0.07989615201950073, mask: 0.1894676834344864 ===================
epoch no : 0, batch no : 231, total loss : 0.5435129404067993,  classifier :0.0765521302819252, mask: 0.18381857872009277 ===================
epoch no : 0, batch no : 232, total loss : 0.5287477374076843,  classifier :0.07042406499385834, mask: 0.2314072847366333 ===================
epoch no : 0, batch no : 233, total loss : 0.5677350163459778,  classifier :0.08270286023616791, mask: 0.19632825255393982 ===================
epoch no : 0, batch no : 234, total loss : 0.5774410963058472,  classifier :0.07931756228208542, mask: 0.23555076122283936 ===================
epoch no : 0, batch no : 235, total loss : 0.5857635140419006,  classifier :0.07497725635766983, mask: 0.19041118025779724 ===================
epoch no : 0, batch no : 236, total loss : 0.5287203788757324,  classifier :0.0639190524816513, mask: 0.19345630705356598 ===================
epoch no : 0, batch no : 237, total loss : 0.64687180519104,  classifier :0.08227226138114929, mask: 0.2327621877193451 ===================
epoch no : 0, batch no : 238, total loss : 0.5106257796287537,  classifier :0.08005348592996597, mask: 0.19075806438922882 ===================
epoch no : 0, batch no : 239, total loss : 0.498007208108902,  classifier :0.07706502079963684, mask: 0.2157265692949295 ===================
epoch no : 0, batch no : 240, total loss : 0.6276925206184387,  classifier :0.07979550212621689, mask: 0.22559452056884766 ===================
epoch no : 0, batch no : 241, total loss : 0.6144469380378723,  classifier :0.07976306229829788, mask: 0.2194683849811554 ===================
epoch no : 0, batch no : 242, total loss : 0.6003596186637878,  classifier :0.07747463881969452, mask: 0.21731476485729218 ===================
epoch no : 0, batch no : 243, total loss : 0.5082846879959106,  classifier :0.08698207885026932, mask: 0.14855080842971802 ===================
epoch no : 0, batch no : 244, total loss : 0.5057197213172913,  classifier :0.07417591661214828, mask: 0.20501381158828735 ===================
epoch no : 0, batch no : 245, total loss : 0.5597481727600098,  classifier :0.08212857693433762, mask: 0.1784556359052658 ===================
epoch no : 0, batch no : 246, total loss : 0.46080124378204346,  classifier :0.07003892213106155, mask: 0.17117425799369812 ===================
epoch no : 0, batch no : 247, total loss : 0.4364110827445984,  classifier :0.08933687210083008, mask: 0.15537479519844055 ===================
epoch no : 0, batch no : 248, total loss : 0.5767769813537598,  classifier :0.0879177376627922, mask: 0.1568017303943634 ===================
epoch no : 0, batch no : 249, total loss : 0.4851094186306,  classifier :0.07320471853017807, mask: 0.18291634321212769 ===================
epoch no : 0, batch no : 250, total loss : 0.5500776767730713,  classifier :0.07219599932432175, mask: 0.21653467416763306 ===================
epoch no : 0, batch no : 251, total loss : 0.5923581123352051,  classifier :0.07597527652978897, mask: 0.24058552086353302 ===================
epoch no : 0, batch no : 252, total loss : 0.5752673149108887,  classifier :0.08445598185062408, mask: 0.1957545429468155 ===================
epoch no : 0, batch no : 253, total loss : 0.57235187292099,  classifier :0.07409502565860748, mask: 0.21018844842910767 ===================
epoch no : 0, batch no : 254, total loss : 0.6763957738876343,  classifier :0.08852636814117432, mask: 0.25506553053855896 ===================
epoch no : 0, batch no : 255, total loss : 0.5446430444717407,  classifier :0.08590570837259293, mask: 0.18619076907634735 ===================
epoch no : 0, batch no : 256, total loss : 0.4607977867126465,  classifier :0.06931417435407639, mask: 0.16340048611164093 ===================
epoch no : 0, batch no : 257, total loss : 0.4784115254878998,  classifier :0.08967555314302444, mask: 0.16179077327251434 ===================
epoch no : 0, batch no : 258, total loss : 0.4863664507865906,  classifier :0.07827260345220566, mask: 0.19762025773525238 ===================
epoch no : 0, batch no : 259, total loss : 0.44637802243232727,  classifier :0.08042695373296738, mask: 0.1898183673620224 ===================
epoch no : 0, batch no : 260, total loss : 0.5373186469078064,  classifier :0.086276575922966, mask: 0.19170764088630676 ===================
epoch no : 0, batch no : 261, total loss : 0.4879675805568695,  classifier :0.06534452736377716, mask: 0.21183015406131744 ===================
epoch no : 0, batch no : 262, total loss : 0.5351574420928955,  classifier :0.09778085350990295, mask: 0.18417687714099884 ===================
epoch no : 0, batch no : 263, total loss : 0.49857017397880554,  classifier :0.07807959616184235, mask: 0.18001745641231537 ===================
epoch no : 0, batch no : 264, total loss : 0.569100022315979,  classifier :0.0834333598613739, mask: 0.23559816181659698 ===================
epoch no : 0, batch no : 265, total loss : 0.5702300071716309,  classifier :0.07952085137367249, mask: 0.2042575627565384 ===================
epoch no : 0, batch no : 266, total loss : 0.5713038444519043,  classifier :0.0798611044883728, mask: 0.1962774693965912 ===================
epoch no : 0, batch no : 267, total loss : 0.6336567997932434,  classifier :0.08809857070446014, mask: 0.24241428077220917 ===================
epoch no : 0, batch no : 268, total loss : 0.5179265737533569,  classifier :0.08553549647331238, mask: 0.20425501465797424 ===================
epoch no : 0, batch no : 269, total loss : 0.5219764709472656,  classifier :0.07796196639537811, mask: 0.19248482584953308 ===================
epoch no : 0, batch no : 270, total loss : 0.48098504543304443,  classifier :0.06919757276773453, mask: 0.20406568050384521 ===================
epoch no : 0, batch no : 271, total loss : 0.527234673500061,  classifier :0.08235355466604233, mask: 0.18278713524341583 ===================
epoch no : 0, batch no : 272, total loss : 0.49015378952026367,  classifier :0.06974998861551285, mask: 0.15917591750621796 ===================
epoch no : 0, batch no : 273, total loss : 0.5797807574272156,  classifier :0.08689150959253311, mask: 0.21712014079093933 ===================
epoch no : 0, batch no : 274, total loss : 0.4719424247741699,  classifier :0.0804559662938118, mask: 0.17616738379001617 ===================
epoch no : 0, batch no : 275, total loss : 0.5125571489334106,  classifier :0.062429964542388916, mask: 0.2032027393579483 ===================
epoch no : 0, batch no : 276, total loss : 0.49662721157073975,  classifier :0.0730174332857132, mask: 0.16800552606582642 ===================
epoch no : 0, batch no : 277, total loss : 0.521126925945282,  classifier :0.09315533190965652, mask: 0.16534024477005005 ===================
epoch no : 0, batch no : 278, total loss : 0.5102267861366272,  classifier :0.08492819219827652, mask: 0.16785460710525513 ===================
epoch no : 0, batch no : 279, total loss : 0.6085071563720703,  classifier :0.07305233925580978, mask: 0.22086402773857117 ===================
epoch no : 0, batch no : 280, total loss : 0.5239853262901306,  classifier :0.06767831742763519, mask: 0.19370901584625244 ===================
epoch no : 0, batch no : 281, total loss : 0.6366734504699707,  classifier :0.09701012820005417, mask: 0.26341912150382996 ===================
epoch no : 0, batch no : 282, total loss : 0.6020041108131409,  classifier :0.08765152096748352, mask: 0.25676390528678894 ===================
epoch no : 0, batch no : 283, total loss : 0.5215514898300171,  classifier :0.08255387842655182, mask: 0.18108992278575897 ===================
epoch no : 0, batch no : 284, total loss : 0.5436108112335205,  classifier :0.09593607485294342, mask: 0.19126512110233307 ===================
epoch no : 0, batch no : 285, total loss : 0.4809310734272003,  classifier :0.07178474217653275, mask: 0.19289951026439667 ===================
epoch no : 0, batch no : 286, total loss : 0.5502902269363403,  classifier :0.06432508677244186, mask: 0.2433110475540161 ===================
epoch no : 0, batch no : 287, total loss : 0.5379999279975891,  classifier :0.07206220179796219, mask: 0.19817568361759186 ===================
epoch no : 0, batch no : 288, total loss : 0.45559579133987427,  classifier :0.07132795453071594, mask: 0.1637439876794815 ===================
epoch no : 0, batch no : 289, total loss : 0.4849914312362671,  classifier :0.06762024015188217, mask: 0.1896716058254242 ===================
epoch no : 0, batch no : 290, total loss : 0.4960096478462219,  classifier :0.07714021950960159, mask: 0.1648569107055664 ===================
epoch no : 0, batch no : 291, total loss : 0.4476364254951477,  classifier :0.0671418234705925, mask: 0.14435642957687378 ===================
epoch no : 0, batch no : 292, total loss : 0.4337027668952942,  classifier :0.06620912253856659, mask: 0.1924605667591095 ===================
epoch no : 0, batch no : 293, total loss : 0.43726682662963867,  classifier :0.08170080929994583, mask: 0.1446281224489212 ===================
epoch no : 0, batch no : 294, total loss : 0.4838206171989441,  classifier :0.07969557493925095, mask: 0.16988158226013184 ===================
epoch no : 0, batch no : 295, total loss : 0.5618492960929871,  classifier :0.08264854550361633, mask: 0.1895296722650528 ===================
epoch no : 0, batch no : 296, total loss : 0.5901355743408203,  classifier :0.09028299152851105, mask: 0.23921123147010803 ===================
epoch no : 0, batch no : 297, total loss : 0.46354836225509644,  classifier :0.09004220366477966, mask: 0.16872748732566833 ===================
epoch no : 0, batch no : 298, total loss : 0.5217958688735962,  classifier :0.08210143446922302, mask: 0.16992338001728058 ===================
epoch no : 0, batch no : 299, total loss : 0.5223122835159302,  classifier :0.08888933807611465, mask: 0.15493342280387878 ===================
epoch no : 0, batch no : 300, total loss : 0.5116003751754761,  classifier :0.06627097725868225, mask: 0.18197815120220184 ===================
epoch no : 0, batch no : 301, total loss : 0.5308625102043152,  classifier :0.07599092274904251, mask: 0.21630404889583588 ===================
epoch no : 0, batch no : 302, total loss : 0.5078206062316895,  classifier :0.08413615822792053, mask: 0.16632448136806488 ===================
epoch no : 0, batch no : 303, total loss : 0.5040125846862793,  classifier :0.0775207132101059, mask: 0.15425032377243042 ===================
epoch no : 0, batch no : 304, total loss : 0.5056133270263672,  classifier :0.07392971217632294, mask: 0.1712825894355774 ===================
epoch no : 0, batch no : 305, total loss : 0.49642637372016907,  classifier :0.07518527656793594, mask: 0.19543024897575378 ===================
epoch no : 0, batch no : 306, total loss : 0.619725227355957,  classifier :0.07539917528629303, mask: 0.2521040141582489 ===================
epoch no : 0, batch no : 307, total loss : 0.6027979850769043,  classifier :0.07832437753677368, mask: 0.26312941312789917 ===================
epoch no : 0, batch no : 308, total loss : 0.6536303758621216,  classifier :0.0785774514079094, mask: 0.28430962562561035 ===================
epoch no : 0, batch no : 309, total loss : 0.5918585658073425,  classifier :0.08947278559207916, mask: 0.21419107913970947 ===================
epoch no : 0, batch no : 310, total loss : 0.48548227548599243,  classifier :0.06770973652601242, mask: 0.17451713979244232 ===================
epoch no : 0, batch no : 311, total loss : 0.5893391370773315,  classifier :0.07865044474601746, mask: 0.21307244896888733 ===================
epoch no : 0, batch no : 312, total loss : 0.5096455812454224,  classifier :0.07733675092458725, mask: 0.1768360286951065 ===================
epoch no : 0, batch no : 313, total loss : 0.4773752689361572,  classifier :0.07925581932067871, mask: 0.165370374917984 ===================
epoch no : 0, batch no : 314, total loss : 0.4002617597579956,  classifier :0.06048324704170227, mask: 0.1451016366481781 ===================
epoch no : 0, batch no : 315, total loss : 0.5634276866912842,  classifier :0.07146228849887848, mask: 0.21851496398448944 ===================
epoch no : 0, batch no : 316, total loss : 0.5072377324104309,  classifier :0.07703585177659988, mask: 0.192954421043396 ===================
epoch no : 0, batch no : 317, total loss : 0.5738921165466309,  classifier :0.07554615288972855, mask: 0.23794446885585785 ===================
epoch no : 0, batch no : 318, total loss : 0.5358603596687317,  classifier :0.08913245052099228, mask: 0.1763264536857605 ===================
epoch no : 0, batch no : 319, total loss : 0.5141327977180481,  classifier :0.07677149772644043, mask: 0.22024935483932495 ===================
epoch no : 0, batch no : 320, total loss : 0.5192041397094727,  classifier :0.07018020749092102, mask: 0.19894254207611084 ===================
epoch no : 0, batch no : 321, total loss : 0.5060597658157349,  classifier :0.07426943629980087, mask: 0.17980216443538666 ===================
epoch no : 0, batch no : 322, total loss : 0.4697097837924957,  classifier :0.07766740769147873, mask: 0.15839648246765137 ===================
epoch no : 0, batch no : 323, total loss : 0.6919857859611511,  classifier :0.10063215345144272, mask: 0.3570336401462555 ===================
epoch no : 0, batch no : 324, total loss : 0.575395941734314,  classifier :0.07415381819009781, mask: 0.25670501589775085 ===================
epoch no : 0, batch no : 325, total loss : 0.4991113841533661,  classifier :0.06758882105350494, mask: 0.18379196524620056 ===================
epoch no : 0, batch no : 326, total loss : 0.5738144516944885,  classifier :0.07816538959741592, mask: 0.20876595377922058 ===================
epoch no : 0, batch no : 327, total loss : 0.6948398947715759,  classifier :0.10362508147954941, mask: 0.246928408741951 ===================
epoch no : 0, batch no : 328, total loss : 0.4494306147098541,  classifier :0.06411915272474289, mask: 0.20620042085647583 ===================
epoch no : 0, batch no : 329, total loss : 0.5551474094390869,  classifier :0.08111337572336197, mask: 0.2077694982290268 ===================
epoch no : 0, batch no : 330, total loss : 0.5761581659317017,  classifier :0.07180352509021759, mask: 0.21464581787586212 ===================
epoch no : 0, batch no : 331, total loss : 0.4371565580368042,  classifier :0.07870542258024216, mask: 0.15517450869083405 ===================
epoch no : 0, batch no : 332, total loss : 0.5425116419792175,  classifier :0.07295697182416916, mask: 0.19379831850528717 ===================
epoch no : 0, batch no : 333, total loss : 0.4803535044193268,  classifier :0.07600926607847214, mask: 0.16397923231124878 ===================
epoch no : 0, batch no : 334, total loss : 0.4510049521923065,  classifier :0.06876356899738312, mask: 0.1864824891090393 ===================
epoch no : 0, batch no : 335, total loss : 0.4592796266078949,  classifier :0.07126487046480179, mask: 0.17713665962219238 ===================
epoch no : 0, batch no : 336, total loss : 0.4170612096786499,  classifier :0.05577043816447258, mask: 0.14571568369865417 ===================
epoch no : 0, batch no : 337, total loss : 0.5188810229301453,  classifier :0.07392500340938568, mask: 0.1982952356338501 ===================
epoch no : 0, batch no : 338, total loss : 0.5571272373199463,  classifier :0.06913784146308899, mask: 0.23055633902549744 ===================
epoch no : 0, batch no : 339, total loss : 0.46289554238319397,  classifier :0.06980805844068527, mask: 0.17506085336208344 ===================
epoch no : 0, batch no : 340, total loss : 0.4788418114185333,  classifier :0.06611346453428268, mask: 0.18015502393245697 ===================
epoch no : 0, batch no : 341, total loss : 0.561577320098877,  classifier :0.08024388551712036, mask: 0.22043541073799133 ===================
epoch no : 0, batch no : 342, total loss : 0.5454995036125183,  classifier :0.08008516579866409, mask: 0.17745471000671387 ===================
epoch no : 0, batch no : 343, total loss : 0.44329503178596497,  classifier :0.0753265842795372, mask: 0.15724223852157593 ===================
epoch no : 0, batch no : 344, total loss : 0.6362760663032532,  classifier :0.07849787920713425, mask: 0.25720760226249695 ===================
epoch no : 0, batch no : 345, total loss : 0.5846666693687439,  classifier :0.09531695395708084, mask: 0.2157185971736908 ===================
epoch no : 0, batch no : 346, total loss : 0.4368544816970825,  classifier :0.0719812735915184, mask: 0.1602623015642166 ===================
epoch no : 0, batch no : 347, total loss : 0.4741913378238678,  classifier :0.06554487347602844, mask: 0.19972540438175201 ===================
epoch no : 0, batch no : 348, total loss : 0.5509997010231018,  classifier :0.09215531498193741, mask: 0.22571499645709991 ===================
epoch no : 0, batch no : 349, total loss : 0.5327253937721252,  classifier :0.09872700273990631, mask: 0.19599904119968414 ===================
epoch no : 0, batch no : 350, total loss : 0.5880473256111145,  classifier :0.08428747951984406, mask: 0.1868971884250641 ===================
epoch no : 0, batch no : 351, total loss : 0.49711406230926514,  classifier :0.08626146614551544, mask: 0.16900669038295746 ===================
epoch no : 0, batch no : 352, total loss : 0.6545901894569397,  classifier :0.10131627321243286, mask: 0.2393037974834442 ===================
epoch no : 0, batch no : 353, total loss : 0.5774218440055847,  classifier :0.08298981189727783, mask: 0.24855855107307434 ===================
epoch no : 0, batch no : 354, total loss : 0.4113633334636688,  classifier :0.06524107605218887, mask: 0.16181635856628418 ===================
epoch no : 0, batch no : 355, total loss : 0.41347986459732056,  classifier :0.08160243183374405, mask: 0.15819813311100006 ===================
epoch no : 0, batch no : 356, total loss : 0.4657495319843292,  classifier :0.08410146832466125, mask: 0.16854509711265564 ===================
epoch no : 0, batch no : 357, total loss : 0.6168370842933655,  classifier :0.07960477471351624, mask: 0.23197199404239655 ===================
epoch no : 0, batch no : 358, total loss : 0.5127476453781128,  classifier :0.07390817999839783, mask: 0.19578470289707184 ===================
epoch no : 0, batch no : 359, total loss : 0.48558059334754944,  classifier :0.06929325312376022, mask: 0.16920378804206848 ===================
epoch no : 0, batch no : 360, total loss : 0.4217580556869507,  classifier :0.06562510877847672, mask: 0.16822440922260284 ===================
epoch no : 0, batch no : 361, total loss : 0.6633613109588623,  classifier :0.07658044248819351, mask: 0.2774844765663147 ===================
epoch no : 0, batch no : 362, total loss : 0.6436281204223633,  classifier :0.07826024293899536, mask: 0.27918389439582825 ===================
epoch no : 0, batch no : 363, total loss : 0.5968266725540161,  classifier :0.08022440969944, mask: 0.22072917222976685 ===================
epoch no : 0, batch no : 364, total loss : 0.48099854588508606,  classifier :0.07237166911363602, mask: 0.20748336613178253 ===================
epoch no : 0, batch no : 365, total loss : 0.4535865783691406,  classifier :0.08343982696533203, mask: 0.16288956999778748 ===================
epoch no : 0, batch no : 366, total loss : 0.5108159184455872,  classifier :0.07165325433015823, mask: 0.1785338670015335 ===================
epoch no : 0, batch no : 367, total loss : 0.478518009185791,  classifier :0.07566392421722412, mask: 0.16710159182548523 ===================
epoch no : 0, batch no : 368, total loss : 0.5341598391532898,  classifier :0.08367426693439484, mask: 0.18290174007415771 ===================
epoch no : 0, batch no : 369, total loss : 0.5342795848846436,  classifier :0.08749058097600937, mask: 0.16334033012390137 ===================
epoch no : 0, batch no : 370, total loss : 0.4116717576980591,  classifier :0.07484579086303711, mask: 0.14455725252628326 ===================
epoch no : 0, batch no : 371, total loss : 0.6548082232475281,  classifier :0.08462092280387878, mask: 0.27886855602264404 ===================
epoch no : 0, batch no : 372, total loss : 0.6459138989448547,  classifier :0.06947728246450424, mask: 0.26079416275024414 ===================
epoch no : 0, batch no : 373, total loss : 0.7390608191490173,  classifier :0.10631488263607025, mask: 0.28325945138931274 ===================
epoch no : 0, batch no : 374, total loss : 0.5048132538795471,  classifier :0.08863434195518494, mask: 0.18904517590999603 ===================
epoch no : 0, batch no : 375, total loss : 0.4219326674938202,  classifier :0.07887160778045654, mask: 0.16712121665477753 ===================
epoch no : 0, batch no : 376, total loss : 0.6671777963638306,  classifier :0.10009240359067917, mask: 0.23513300716876984 ===================
epoch no : 0, batch no : 377, total loss : 0.46175417304039,  classifier :0.06268538534641266, mask: 0.18172293901443481 ===================
epoch no : 0, batch no : 378, total loss : 0.5637044906616211,  classifier :0.08697690069675446, mask: 0.22091606259346008 ===================
epoch no : 0, batch no : 379, total loss : 0.575441300868988,  classifier :0.09069167822599411, mask: 0.2189350426197052 ===================
epoch no : 0, batch no : 380, total loss : 0.5098391771316528,  classifier :0.07371942698955536, mask: 0.1895553320646286 ===================
epoch no : 0, batch no : 381, total loss : 0.6783714890480042,  classifier :0.09976835548877716, mask: 0.2385273426771164 ===================
epoch no : 0, batch no : 382, total loss : 0.5119915008544922,  classifier :0.07898947596549988, mask: 0.16529816389083862 ===================
epoch no : 0, batch no : 383, total loss : 0.4524909257888794,  classifier :0.07575878500938416, mask: 0.1572088599205017 ===================
epoch no : 0, batch no : 384, total loss : 0.6435067653656006,  classifier :0.08293954282999039, mask: 0.2366379052400589 ===================
epoch no : 0, batch no : 385, total loss : 0.48635491728782654,  classifier :0.07247713953256607, mask: 0.22829554975032806 ===================
epoch no : 0, batch no : 386, total loss : 0.5344522595405579,  classifier :0.09203583747148514, mask: 0.16790777444839478 ===================
epoch no : 0, batch no : 387, total loss : 0.4862116575241089,  classifier :0.07720046490430832, mask: 0.16617032885551453 ===================
epoch no : 0, batch no : 388, total loss : 0.5541896820068359,  classifier :0.07149781286716461, mask: 0.1933611035346985 ===================
epoch no : 0, batch no : 389, total loss : 0.5503153204917908,  classifier :0.07198470830917358, mask: 0.19027553498744965 ===================
epoch no : 0, batch no : 390, total loss : 0.5204146504402161,  classifier :0.07214022427797318, mask: 0.1709941029548645 ===================
epoch no : 0, batch no : 391, total loss : 0.5627612471580505,  classifier :0.06660669296979904, mask: 0.24535112082958221 ===================
epoch no : 0, batch no : 392, total loss : 0.6093727946281433,  classifier :0.07384985685348511, mask: 0.2655889391899109 ===================
epoch no : 0, batch no : 393, total loss : 0.41212671995162964,  classifier :0.06593272089958191, mask: 0.1652076542377472 ===================
epoch no : 0, batch no : 394, total loss : 0.5231366157531738,  classifier :0.09068265557289124, mask: 0.1737312376499176 ===================
epoch no : 0, batch no : 395, total loss : 0.43052712082862854,  classifier :0.08085846155881882, mask: 0.1608450710773468 ===================
epoch no : 0, batch no : 396, total loss : 0.42924803495407104,  classifier :0.07055465131998062, mask: 0.14658860862255096 ===================
epoch no : 0, batch no : 397, total loss : 0.44244542717933655,  classifier :0.07208472490310669, mask: 0.1346842348575592 ===================
epoch no : 0, batch no : 398, total loss : 0.4879383444786072,  classifier :0.0684046670794487, mask: 0.1604047417640686 ===================
creating index...
index created!
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
Test:  [   0/3188]  eta: 0:40:05  model_time: 0.2207 (0.2207)  evaluator_time: 0.0995 (0.0995)  time: 0.7545  data: 0.2619  max mem: 9500
Test:  [ 100/3188]  eta: 0:14:03  model_time: 0.1182 (0.1189)  evaluator_time: 0.0264 (0.0288)  time: 0.2693  data: 0.0046  max mem: 9500
Test:  [ 200/3188]  eta: 0:13:37  model_time: 0.1202 (0.1195)  evaluator_time: 0.0312 (0.0295)  time: 0.2778  data: 0.0049  max mem: 9500
Test:  [ 300/3188]  eta: 0:13:01  model_time: 0.1191 (0.1179)  evaluator_time: 0.0302 (0.0289)  time: 0.2743  data: 0.0043  max mem: 9500
Test:  [ 400/3188]  eta: 0:12:31  model_time: 0.1161 (0.1172)  evaluator_time: 0.0278 (0.0294)  time: 0.2607  data: 0.0046  max mem: 9500
Test:  [ 500/3188]  eta: 0:12:02  model_time: 0.1156 (0.1171)  evaluator_time: 0.0272 (0.0292)  time: 0.2711  data: 0.0046  max mem: 9500
Test:  [ 600/3188]  eta: 0:11:36  model_time: 0.1117 (0.1171)  evaluator_time: 0.0244 (0.0296)  time: 0.2577  data: 0.0042  max mem: 9500
Test:  [ 700/3188]  eta: 0:11:04  model_time: 0.1105 (0.1165)  evaluator_time: 0.0192 (0.0289)  time: 0.2529  data: 0.0045  max mem: 9500
Test:  [ 800/3188]  eta: 0:10:34  model_time: 0.1116 (0.1161)  evaluator_time: 0.0197 (0.0282)  time: 0.2510  data: 0.0047  max mem: 9500
Test:  [ 900/3188]  eta: 0:10:07  model_time: 0.1126 (0.1159)  evaluator_time: 0.0224 (0.0282)  time: 0.2765  data: 0.0045  max mem: 9500
Test:  [1000/3188]  eta: 0:09:41  model_time: 0.1150 (0.1161)  evaluator_time: 0.0231 (0.0283)  time: 0.2625  data: 0.0046  max mem: 9500
Test:  [1100/3188]  eta: 0:09:19  model_time: 0.1223 (0.1171)  evaluator_time: 0.0293 (0.0287)  time: 0.2807  data: 0.0048  max mem: 9500
Test:  [1200/3188]  eta: 0:08:53  model_time: 0.1103 (0.1172)  evaluator_time: 0.0231 (0.0288)  time: 0.2695  data: 0.0048  max mem: 9500
Test:  [1300/3188]  eta: 0:08:25  model_time: 0.1132 (0.1171)  evaluator_time: 0.0210 (0.0286)  time: 0.2555  data: 0.0046  max mem: 9500
Test:  [1400/3188]  eta: 0:07:58  model_time: 0.1204 (0.1173)  evaluator_time: 0.0228 (0.0287)  time: 0.2576  data: 0.0045  max mem: 9500
Test:  [1500/3188]  eta: 0:07:31  model_time: 0.1129 (0.1171)  evaluator_time: 0.0200 (0.0284)  time: 0.2593  data: 0.0044  max mem: 9500
Test:  [1600/3188]  eta: 0:07:03  model_time: 0.1085 (0.1170)  evaluator_time: 0.0184 (0.0281)  time: 0.2543  data: 0.0045  max mem: 9500
Test:  [1700/3188]  eta: 0:06:35  model_time: 0.1063 (0.1167)  evaluator_time: 0.0159 (0.0278)  time: 0.2381  data: 0.0045  max mem: 9500
Test:  [1800/3188]  eta: 0:06:09  model_time: 0.1156 (0.1168)  evaluator_time: 0.0220 (0.0277)  time: 0.2574  data: 0.0046  max mem: 9500
Test:  [1900/3188]  eta: 0:05:42  model_time: 0.1075 (0.1168)  evaluator_time: 0.0197 (0.0277)  time: 0.2550  data: 0.0046  max mem: 9500
Test:  [2000/3188]  eta: 0:05:16  model_time: 0.1214 (0.1169)  evaluator_time: 0.0283 (0.0276)  time: 0.2794  data: 0.0045  max mem: 9500
Test:  [2100/3188]  eta: 0:04:49  model_time: 0.1160 (0.1171)  evaluator_time: 0.0192 (0.0275)  time: 0.2607  data: 0.0045  max mem: 9500
Test:  [2200/3188]  eta: 0:04:22  model_time: 0.1224 (0.1171)  evaluator_time: 0.0246 (0.0273)  time: 0.2729  data: 0.0043  max mem: 9500
Test:  [2300/3188]  eta: 0:03:54  model_time: 0.0602 (0.1160)  evaluator_time: 0.0192 (0.0271)  time: 0.1766  data: 0.0045  max mem: 9500
Test:  [2400/3188]  eta: 0:03:24  model_time: 0.0692 (0.1141)  evaluator_time: 0.0197 (0.0269)  time: 0.1601  data: 0.0043  max mem: 9500
Test:  [2500/3188]  eta: 0:02:58  model_time: 0.1114 (0.1139)  evaluator_time: 0.0209 (0.0267)  time: 0.2667  data: 0.0046  max mem: 9500
Test:  [2600/3188]  eta: 0:02:31  model_time: 0.0606 (0.1135)  evaluator_time: 0.0154 (0.0265)  time: 0.1496  data: 0.0045  max mem: 9500
Test:  [2700/3188]  eta: 0:02:04  model_time: 0.0754 (0.1120)  evaluator_time: 0.0263 (0.0264)  time: 0.1840  data: 0.0046  max mem: 9500
Test:  [2800/3188]  eta: 0:01:38  model_time: 0.1143 (0.1116)  evaluator_time: 0.0236 (0.0264)  time: 0.2820  data: 0.0047  max mem: 9500
Test:  [2900/3188]  eta: 0:01:13  model_time: 0.1152 (0.1118)  evaluator_time: 0.0189 (0.0263)  time: 0.2591  data: 0.0049  max mem: 9500
Test:  [3000/3188]  eta: 0:00:47  model_time: 0.1195 (0.1121)  evaluator_time: 0.0231 (0.0263)  time: 0.2662  data: 0.0049  max mem: 9500
Test:  [3100/3188]  eta: 0:00:22  model_time: 0.1204 (0.1122)  evaluator_time: 0.0254 (0.0262)  time: 0.2779  data: 0.0046  max mem: 9500
Test:  [3187/3188]  eta: 0:00:00  model_time: 0.1154 (0.1123)  evaluator_time: 0.0227 (0.0262)  time: 0.2603  data: 0.0045  max mem: 9500
Test: Total time: 0:13:34 (0.2555 s / it)
Averaged stats: model_time: 0.1154 (0.1123)  evaluator_time: 0.0227 (0.0262)
Accumulating evaluation results...
DONE-test (t=2.33s).
Accumulating evaluation results...
DONE-test (t=2.05s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.421
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.703
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.491
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.421
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.660
IoU metric: segm
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.512
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.707
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.602
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.512
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.736
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.764
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.764
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch no : 1, batch no : 0, total loss : 0.4385554790496826,  classifier :0.07333412021398544, mask: 0.1653352826833725 ===================
epoch no : 1, batch no : 1, total loss : 0.5293945670127869,  classifier :0.07143000513315201, mask: 0.19409982860088348 ===================
epoch no : 1, batch no : 2, total loss : 0.5632384419441223,  classifier :0.06410955637693405, mask: 0.23699502646923065 ===================
epoch no : 1, batch no : 3, total loss : 0.49488282203674316,  classifier :0.07545026391744614, mask: 0.19386765360832214 ===================
epoch no : 1, batch no : 4, total loss : 0.4432741403579712,  classifier :0.06910134106874466, mask: 0.16072481870651245 ===================
epoch no : 1, batch no : 5, total loss : 0.46264955401420593,  classifier :0.06678838282823563, mask: 0.1832009106874466 ===================
epoch no : 1, batch no : 6, total loss : 0.4723670482635498,  classifier :0.06818385422229767, mask: 0.17335069179534912 ===================
epoch no : 1, batch no : 7, total loss : 0.4968934655189514,  classifier :0.07305857539176941, mask: 0.1674262434244156 ===================
epoch no : 1, batch no : 8, total loss : 0.5699583292007446,  classifier :0.0708656832575798, mask: 0.21647365391254425 ===================
epoch no : 1, batch no : 9, total loss : 0.5479714274406433,  classifier :0.09227678924798965, mask: 0.1467672884464264 ===================
epoch no : 1, batch no : 10, total loss : 0.5286117792129517,  classifier :0.06339714676141739, mask: 0.20237694680690765 ===================
epoch no : 1, batch no : 11, total loss : 0.48316532373428345,  classifier :0.07690384984016418, mask: 0.1648307889699936 ===================
epoch no : 1, batch no : 12, total loss : 0.5489597916603088,  classifier :0.06955450773239136, mask: 0.2235453873872757 ===================
epoch no : 1, batch no : 13, total loss : 0.3886486291885376,  classifier :0.07178552448749542, mask: 0.13369768857955933 ===================
epoch no : 1, batch no : 14, total loss : 0.4921753406524658,  classifier :0.08675455302000046, mask: 0.17091494798660278 ===================
epoch no : 1, batch no : 15, total loss : 0.4141468405723572,  classifier :0.06821604818105698, mask: 0.1461840122938156 ===================
epoch no : 1, batch no : 16, total loss : 0.4297935962677002,  classifier :0.07896417379379272, mask: 0.1412401795387268 ===================
epoch no : 1, batch no : 17, total loss : 0.48272398114204407,  classifier :0.08362540602684021, mask: 0.18684537708759308 ===================
epoch no : 1, batch no : 18, total loss : 0.4196605384349823,  classifier :0.07564287632703781, mask: 0.14024579524993896 ===================
epoch no : 1, batch no : 19, total loss : 0.4709746241569519,  classifier :0.06880468875169754, mask: 0.17202039062976837 ===================
epoch no : 1, batch no : 20, total loss : 0.44423776865005493,  classifier :0.06682330369949341, mask: 0.17924553155899048 ===================
epoch no : 1, batch no : 21, total loss : 0.3620675802230835,  classifier :0.06991111487150192, mask: 0.13088764250278473 ===================
epoch no : 1, batch no : 22, total loss : 0.534619152545929,  classifier :0.07830987125635147, mask: 0.20721742510795593 ===================
epoch no : 1, batch no : 23, total loss : 0.556410014629364,  classifier :0.08084626495838165, mask: 0.19921132922172546 ===================
epoch no : 1, batch no : 24, total loss : 0.39546459913253784,  classifier :0.05661192163825035, mask: 0.17205959558486938 ===================
epoch no : 1, batch no : 25, total loss : 0.4097568392753601,  classifier :0.06231216341257095, mask: 0.15477733314037323 ===================
epoch no : 1, batch no : 26, total loss : 0.6231542229652405,  classifier :0.08181589841842651, mask: 0.2164274901151657 ===================
epoch no : 1, batch no : 27, total loss : 0.4756365418434143,  classifier :0.07006671279668808, mask: 0.1833452433347702 ===================
epoch no : 1, batch no : 28, total loss : 0.4646804630756378,  classifier :0.06105848401784897, mask: 0.1786850541830063 ===================
epoch no : 1, batch no : 29, total loss : 0.4088156819343567,  classifier :0.06824760138988495, mask: 0.13758952915668488 ===================
epoch no : 1, batch no : 30, total loss : 0.46118098497390747,  classifier :0.07593292742967606, mask: 0.15641549229621887 ===================
epoch no : 1, batch no : 31, total loss : 0.36017096042633057,  classifier :0.06458553671836853, mask: 0.12331647425889969 ===================
epoch no : 1, batch no : 32, total loss : 0.5270131230354309,  classifier :0.08695755898952484, mask: 0.2141144722700119 ===================
epoch no : 1, batch no : 33, total loss : 0.41075900197029114,  classifier :0.07325137406587601, mask: 0.14371831715106964 ===================
epoch no : 1, batch no : 34, total loss : 0.4776059687137604,  classifier :0.08692415058612823, mask: 0.157806396484375 ===================
epoch no : 1, batch no : 35, total loss : 0.5762109756469727,  classifier :0.07694226503372192, mask: 0.21287493407726288 ===================
epoch no : 1, batch no : 36, total loss : 0.47306448221206665,  classifier :0.07311539351940155, mask: 0.16089583933353424 ===================
epoch no : 1, batch no : 37, total loss : 0.47356364130973816,  classifier :0.05714484304189682, mask: 0.2006244659423828 ===================
epoch no : 1, batch no : 38, total loss : 0.5579726696014404,  classifier :0.08957885205745697, mask: 0.17280206084251404 ===================
epoch no : 1, batch no : 39, total loss : 0.5315385460853577,  classifier :0.0739155262708664, mask: 0.1767064332962036 ===================
epoch no : 1, batch no : 40, total loss : 0.43633583188056946,  classifier :0.06316760182380676, mask: 0.15902432799339294 ===================
epoch no : 1, batch no : 41, total loss : 0.5625607371330261,  classifier :0.07382036745548248, mask: 0.22494247555732727 ===================
epoch no : 1, batch no : 42, total loss : 0.468332976102829,  classifier :0.06692351400852203, mask: 0.1669432520866394 ===================
epoch no : 1, batch no : 43, total loss : 0.5227285623550415,  classifier :0.06623483449220657, mask: 0.2236945480108261 ===================
epoch no : 1, batch no : 44, total loss : 0.5453440546989441,  classifier :0.0781068354845047, mask: 0.22380897402763367 ===================
epoch no : 1, batch no : 45, total loss : 0.5850600004196167,  classifier :0.0833326205611229, mask: 0.20044328272342682 ===================
epoch no : 1, batch no : 46, total loss : 0.5057766437530518,  classifier :0.07079558819532394, mask: 0.19298218190670013 ===================
epoch no : 1, batch no : 47, total loss : 0.47596436738967896,  classifier :0.0869390219449997, mask: 0.1574414223432541 ===================
epoch no : 1, batch no : 48, total loss : 0.4464872479438782,  classifier :0.059277161955833435, mask: 0.1724524348974228 ===================
epoch no : 1, batch no : 49, total loss : 0.60748690366745,  classifier :0.08155279606580734, mask: 0.2066965103149414 ===================
epoch no : 1, batch no : 50, total loss : 0.45555996894836426,  classifier :0.07857447862625122, mask: 0.16115649044513702 ===================
epoch no : 1, batch no : 51, total loss : 0.4406450092792511,  classifier :0.07060661166906357, mask: 0.14145198464393616 ===================
epoch no : 1, batch no : 52, total loss : 0.4427676796913147,  classifier :0.08276066184043884, mask: 0.14134715497493744 ===================
epoch no : 1, batch no : 53, total loss : 0.44039422273635864,  classifier :0.08466149866580963, mask: 0.16741077601909637 ===================
epoch no : 1, batch no : 54, total loss : 0.42792606353759766,  classifier :0.06510809063911438, mask: 0.17023557424545288 ===================
epoch no : 1, batch no : 55, total loss : 0.4460194706916809,  classifier :0.0635339543223381, mask: 0.17473042011260986 ===================
epoch no : 1, batch no : 56, total loss : 0.5948973894119263,  classifier :0.08644615113735199, mask: 0.19660449028015137 ===================
epoch no : 1, batch no : 57, total loss : 0.5520199537277222,  classifier :0.0755545049905777, mask: 0.19241471588611603 ===================
epoch no : 1, batch no : 58, total loss : 0.44694018363952637,  classifier :0.06404412537813187, mask: 0.15035127103328705 ===================
epoch no : 1, batch no : 59, total loss : 0.5123328566551208,  classifier :0.08128247410058975, mask: 0.196746364235878 ===================
epoch no : 1, batch no : 60, total loss : 0.4318409264087677,  classifier :0.059111203998327255, mask: 0.144708514213562 ===================
epoch no : 1, batch no : 61, total loss : 0.3925900459289551,  classifier :0.07214780151844025, mask: 0.12748776376247406 ===================
epoch no : 1, batch no : 62, total loss : 0.4828047454357147,  classifier :0.07651035487651825, mask: 0.1504071056842804 ===================
epoch no : 1, batch no : 63, total loss : 0.481117844581604,  classifier :0.06959886848926544, mask: 0.18244366347789764 ===================
epoch no : 1, batch no : 64, total loss : 0.5179853439331055,  classifier :0.06932301074266434, mask: 0.1950874775648117 ===================
epoch no : 1, batch no : 65, total loss : 0.5853736996650696,  classifier :0.07878527790307999, mask: 0.21508565545082092 ===================
epoch no : 1, batch no : 66, total loss : 0.44720879197120667,  classifier :0.07265851646661758, mask: 0.14387382566928864 ===================
epoch no : 1, batch no : 67, total loss : 0.4858188331127167,  classifier :0.07250471413135529, mask: 0.1805463284254074 ===================
epoch no : 1, batch no : 68, total loss : 0.49567118287086487,  classifier :0.05845368281006813, mask: 0.21032799780368805 ===================
epoch no : 1, batch no : 69, total loss : 0.5091890096664429,  classifier :0.08431525528430939, mask: 0.20443594455718994 ===================
epoch no : 1, batch no : 70, total loss : 0.4091610014438629,  classifier :0.05737108737230301, mask: 0.14616483449935913 ===================
epoch no : 1, batch no : 71, total loss : 0.4529223144054413,  classifier :0.0719514787197113, mask: 0.1658543348312378 ===================
epoch no : 1, batch no : 72, total loss : 0.41779762506484985,  classifier :0.06175045669078827, mask: 0.13583797216415405 ===================
epoch no : 1, batch no : 73, total loss : 0.47735321521759033,  classifier :0.06431383639574051, mask: 0.1955970674753189 ===================
epoch no : 1, batch no : 74, total loss : 0.523735523223877,  classifier :0.07944177091121674, mask: 0.1887032687664032 ===================
epoch no : 1, batch no : 75, total loss : 0.4076622724533081,  classifier :0.06241112947463989, mask: 0.13848954439163208 ===================
epoch no : 1, batch no : 76, total loss : 0.3944888710975647,  classifier :0.07405929267406464, mask: 0.12409717589616776 ===================
epoch no : 1, batch no : 77, total loss : 0.5046035051345825,  classifier :0.0755830779671669, mask: 0.1962253451347351 ===================
epoch no : 1, batch no : 78, total loss : 0.549220085144043,  classifier :0.07260724902153015, mask: 0.2517327070236206 ===================
epoch no : 1, batch no : 79, total loss : 0.4849202334880829,  classifier :0.07600417733192444, mask: 0.17234766483306885 ===================
epoch no : 1, batch no : 80, total loss : 0.483901709318161,  classifier :0.0697634294629097, mask: 0.16104067862033844 ===================
epoch no : 1, batch no : 81, total loss : 0.3826913833618164,  classifier :0.06380534172058105, mask: 0.12778228521347046 ===================
epoch no : 1, batch no : 82, total loss : 0.5165075063705444,  classifier :0.07298517227172852, mask: 0.17579010128974915 ===================
epoch no : 1, batch no : 83, total loss : 0.6694011092185974,  classifier :0.08577673882246017, mask: 0.2415241152048111 ===================
epoch no : 1, batch no : 84, total loss : 0.47264745831489563,  classifier :0.06334640085697174, mask: 0.18591909110546112 ===================
epoch no : 1, batch no : 85, total loss : 0.4765244722366333,  classifier :0.08433022350072861, mask: 0.18960069119930267 ===================
epoch no : 1, batch no : 86, total loss : 0.4606708288192749,  classifier :0.07315364480018616, mask: 0.16716593503952026 ===================
epoch no : 1, batch no : 87, total loss : 0.40776973962783813,  classifier :0.057611092925071716, mask: 0.15468306839466095 ===================
epoch no : 1, batch no : 88, total loss : 0.42317432165145874,  classifier :0.07621036469936371, mask: 0.1401047557592392 ===================
epoch no : 1, batch no : 89, total loss : 0.5591180920600891,  classifier :0.07860350608825684, mask: 0.19950342178344727 ===================
epoch no : 1, batch no : 90, total loss : 0.49826857447624207,  classifier :0.06666931509971619, mask: 0.22736501693725586 ===================
epoch no : 1, batch no : 91, total loss : 0.5481383204460144,  classifier :0.06690587848424911, mask: 0.18993189930915833 ===================
epoch no : 1, batch no : 92, total loss : 0.4857873022556305,  classifier :0.06526792794466019, mask: 0.20351137220859528 ===================
epoch no : 1, batch no : 93, total loss : 0.4695788621902466,  classifier :0.06352968513965607, mask: 0.1947205513715744 ===================
epoch no : 1, batch no : 94, total loss : 0.4121118485927582,  classifier :0.05968977138400078, mask: 0.1516369730234146 ===================
epoch no : 1, batch no : 95, total loss : 0.41783031821250916,  classifier :0.06552820652723312, mask: 0.1665959358215332 ===================
epoch no : 1, batch no : 96, total loss : 0.3634302616119385,  classifier :0.06217580661177635, mask: 0.13060078024864197 ===================
epoch no : 1, batch no : 97, total loss : 0.48756271600723267,  classifier :0.06994646787643433, mask: 0.1975308060646057 ===================
epoch no : 1, batch no : 98, total loss : 0.4961925745010376,  classifier :0.06738145649433136, mask: 0.1781192272901535 ===================
epoch no : 1, batch no : 99, total loss : 0.48268193006515503,  classifier :0.06892126798629761, mask: 0.16353337466716766 ===================
epoch no : 1, batch no : 100, total loss : 0.4753226041793823,  classifier :0.07078942656517029, mask: 0.16618236899375916 ===================
epoch no : 1, batch no : 101, total loss : 0.4712454080581665,  classifier :0.07095163315534592, mask: 0.16791817545890808 ===================
epoch no : 1, batch no : 102, total loss : 0.5026403665542603,  classifier :0.07491310685873032, mask: 0.1994026154279709 ===================
epoch no : 1, batch no : 103, total loss : 0.38704970479011536,  classifier :0.06822434812784195, mask: 0.13627192378044128 ===================
epoch no : 1, batch no : 104, total loss : 0.452193945646286,  classifier :0.06377318501472473, mask: 0.16994841396808624 ===================
epoch no : 1, batch no : 105, total loss : 0.382693886756897,  classifier :0.060624826699495316, mask: 0.145828515291214 ===================
epoch no : 1, batch no : 106, total loss : 0.4844793975353241,  classifier :0.06382521241903305, mask: 0.17907123267650604 ===================
epoch no : 1, batch no : 107, total loss : 0.5102250576019287,  classifier :0.0779133141040802, mask: 0.18063925206661224 ===================
epoch no : 1, batch no : 108, total loss : 0.40029215812683105,  classifier :0.06365571171045303, mask: 0.19294552505016327 ===================
epoch no : 1, batch no : 109, total loss : 0.4042832851409912,  classifier :0.05249771103262901, mask: 0.15051162242889404 ===================
epoch no : 1, batch no : 110, total loss : 0.5591320395469666,  classifier :0.08372024446725845, mask: 0.18291014432907104 ===================
epoch no : 1, batch no : 111, total loss : 0.43792760372161865,  classifier :0.06009702757000923, mask: 0.17403234541416168 ===================
epoch no : 1, batch no : 112, total loss : 0.36285775899887085,  classifier :0.06583277881145477, mask: 0.12972049415111542 ===================
epoch no : 1, batch no : 113, total loss : 0.4971822202205658,  classifier :0.06084362044930458, mask: 0.19799062609672546 ===================
epoch no : 1, batch no : 114, total loss : 0.4293394386768341,  classifier :0.06102924793958664, mask: 0.14527933299541473 ===================
epoch no : 1, batch no : 115, total loss : 0.48250827193260193,  classifier :0.06822016835212708, mask: 0.15877094864845276 ===================
epoch no : 1, batch no : 116, total loss : 0.5201788544654846,  classifier :0.06845469027757645, mask: 0.16136719286441803 ===================
epoch no : 1, batch no : 117, total loss : 0.42982733249664307,  classifier :0.08673515915870667, mask: 0.1371477246284485 ===================
epoch no : 1, batch no : 118, total loss : 0.38915300369262695,  classifier :0.07354691624641418, mask: 0.12420348078012466 ===================
epoch no : 1, batch no : 119, total loss : 0.4611620604991913,  classifier :0.07383176684379578, mask: 0.17109693586826324 ===================
epoch no : 1, batch no : 120, total loss : 0.3630963861942291,  classifier :0.0688960924744606, mask: 0.12014350295066833 ===================
epoch no : 1, batch no : 121, total loss : 0.4497385621070862,  classifier :0.062391247600317, mask: 0.14123016595840454 ===================
epoch no : 1, batch no : 122, total loss : 0.46914535760879517,  classifier :0.05732280761003494, mask: 0.1754249483346939 ===================
epoch no : 1, batch no : 123, total loss : 0.3819589614868164,  classifier :0.05592074245214462, mask: 0.15543733537197113 ===================
epoch no : 1, batch no : 124, total loss : 0.5015414953231812,  classifier :0.06489432603120804, mask: 0.2076474130153656 ===================
epoch no : 1, batch no : 125, total loss : 0.7274365425109863,  classifier :0.09588934481143951, mask: 0.27300968766212463 ===================
epoch no : 1, batch no : 126, total loss : 0.5878799557685852,  classifier :0.06802251189947128, mask: 0.2537211775779724 ===================
epoch no : 1, batch no : 127, total loss : 0.4668687582015991,  classifier :0.06437816470861435, mask: 0.19121655821800232 ===================
epoch no : 1, batch no : 128, total loss : 0.3635058104991913,  classifier :0.05807850882411003, mask: 0.1486126184463501 ===================
epoch no : 1, batch no : 129, total loss : 0.45132124423980713,  classifier :0.07665344327688217, mask: 0.18289533257484436 ===================
epoch no : 1, batch no : 130, total loss : 0.3279883861541748,  classifier :0.051299236714839935, mask: 0.1272827386856079 ===================
epoch no : 1, batch no : 131, total loss : 0.41727492213249207,  classifier :0.06793837994337082, mask: 0.13495974242687225 ===================
epoch no : 1, batch no : 132, total loss : 0.3879762589931488,  classifier :0.06522978097200394, mask: 0.1344267576932907 ===================
epoch no : 1, batch no : 133, total loss : 0.49892938137054443,  classifier :0.07081352174282074, mask: 0.17765814065933228 ===================
epoch no : 1, batch no : 134, total loss : 0.45957496762275696,  classifier :0.06711822003126144, mask: 0.16795101761817932 ===================
epoch no : 1, batch no : 135, total loss : 0.44325652718544006,  classifier :0.08060989528894424, mask: 0.165674090385437 ===================
epoch no : 1, batch no : 136, total loss : 0.47597548365592957,  classifier :0.0705561563372612, mask: 0.1556616574525833 ===================
epoch no : 1, batch no : 137, total loss : 0.41045284271240234,  classifier :0.048622772097587585, mask: 0.1305055022239685 ===================
epoch no : 1, batch no : 138, total loss : 0.4496607482433319,  classifier :0.07411885261535645, mask: 0.1610938012599945 ===================
epoch no : 1, batch no : 139, total loss : 0.42808541655540466,  classifier :0.07458638399839401, mask: 0.1424783319234848 ===================
epoch no : 1, batch no : 140, total loss : 0.5073904395103455,  classifier :0.07533403486013412, mask: 0.22256088256835938 ===================
epoch no : 1, batch no : 141, total loss : 0.43096959590911865,  classifier :0.0637083351612091, mask: 0.1497035026550293 ===================
epoch no : 1, batch no : 142, total loss : 0.5535855293273926,  classifier :0.08480095118284225, mask: 0.19012142717838287 ===================
epoch no : 1, batch no : 143, total loss : 0.6377832889556885,  classifier :0.07727177441120148, mask: 0.27301594614982605 ===================
epoch no : 1, batch no : 144, total loss : 0.5001218914985657,  classifier :0.08058234304189682, mask: 0.15944716334342957 ===================
epoch no : 1, batch no : 145, total loss : 0.5061259269714355,  classifier :0.09698259085416794, mask: 0.17516329884529114 ===================
epoch no : 1, batch no : 146, total loss : 0.3541662096977234,  classifier :0.052078213542699814, mask: 0.14401143789291382 ===================
epoch no : 1, batch no : 147, total loss : 0.4540817141532898,  classifier :0.06247914955019951, mask: 0.17196951806545258 ===================
epoch no : 1, batch no : 148, total loss : 0.6017109155654907,  classifier :0.07890097051858902, mask: 0.23260681331157684 ===================
epoch no : 1, batch no : 149, total loss : 0.49214649200439453,  classifier :0.09169850498437881, mask: 0.15557926893234253 ===================
epoch no : 1, batch no : 150, total loss : 0.5125994086265564,  classifier :0.0653386116027832, mask: 0.22066551446914673 ===================
epoch no : 1, batch no : 151, total loss : 0.44669046998023987,  classifier :0.07351002097129822, mask: 0.1676424890756607 ===================
epoch no : 1, batch no : 152, total loss : 0.4097157418727875,  classifier :0.061009541153907776, mask: 0.15665031969547272 ===================
epoch no : 1, batch no : 153, total loss : 0.49390077590942383,  classifier :0.06930909305810928, mask: 0.20179367065429688 ===================
epoch no : 1, batch no : 154, total loss : 0.5028788447380066,  classifier :0.063262440264225, mask: 0.1762004792690277 ===================
epoch no : 1, batch no : 155, total loss : 0.372241735458374,  classifier :0.0675266683101654, mask: 0.1511768102645874 ===================
epoch no : 1, batch no : 156, total loss : 0.42097046971321106,  classifier :0.07531596720218658, mask: 0.14143621921539307 ===================
epoch no : 1, batch no : 157, total loss : 0.4370003640651703,  classifier :0.05833825469017029, mask: 0.1646927446126938 ===================
epoch no : 1, batch no : 158, total loss : 0.33736059069633484,  classifier :0.06791803240776062, mask: 0.12025672197341919 ===================
epoch no : 1, batch no : 159, total loss : 0.391446053981781,  classifier :0.05611423775553703, mask: 0.139741450548172 ===================
epoch no : 1, batch no : 160, total loss : 0.38477885723114014,  classifier :0.07183685153722763, mask: 0.13843302428722382 ===================
epoch no : 1, batch no : 161, total loss : 0.41573378443717957,  classifier :0.07099217921495438, mask: 0.14081187546253204 ===================
epoch no : 1, batch no : 162, total loss : 0.42878201603889465,  classifier :0.07006769627332687, mask: 0.15610702335834503 ===================
epoch no : 1, batch no : 163, total loss : 0.3877607583999634,  classifier :0.051737554371356964, mask: 0.13926905393600464 ===================
epoch no : 1, batch no : 164, total loss : 0.6697360277175903,  classifier :0.08142934739589691, mask: 0.280948281288147 ===================
epoch no : 1, batch no : 165, total loss : 0.7231396436691284,  classifier :0.08297993987798691, mask: 0.30162739753723145 ===================
epoch no : 1, batch no : 166, total loss : 0.6059268712997437,  classifier :0.0810963436961174, mask: 0.20499005913734436 ===================
epoch no : 1, batch no : 167, total loss : 0.5319944620132446,  classifier :0.08490368723869324, mask: 0.20476515591144562 ===================
epoch no : 1, batch no : 168, total loss : 0.4902472496032715,  classifier :0.07256350666284561, mask: 0.18694284558296204 ===================
epoch no : 1, batch no : 169, total loss : 0.5249221324920654,  classifier :0.07603035122156143, mask: 0.20478545129299164 ===================
epoch no : 1, batch no : 170, total loss : 0.4624580442905426,  classifier :0.06547459214925766, mask: 0.16977909207344055 ===================
epoch no : 1, batch no : 171, total loss : 0.364935040473938,  classifier :0.05610857903957367, mask: 0.1373966485261917 ===================
epoch no : 1, batch no : 172, total loss : 0.48142993450164795,  classifier :0.0661890059709549, mask: 0.19100125133991241 ===================
epoch no : 1, batch no : 173, total loss : 0.5269008874893188,  classifier :0.08579343557357788, mask: 0.1733650416135788 ===================
epoch no : 1, batch no : 174, total loss : 0.4785137474536896,  classifier :0.06329497694969177, mask: 0.17796549201011658 ===================
epoch no : 1, batch no : 175, total loss : 0.4088243544101715,  classifier :0.0702504888176918, mask: 0.1539500206708908 ===================
epoch no : 1, batch no : 176, total loss : 0.45578479766845703,  classifier :0.06044420599937439, mask: 0.1639648675918579 ===================
epoch no : 1, batch no : 177, total loss : 0.3501037061214447,  classifier :0.054589636623859406, mask: 0.12499355524778366 ===================
epoch no : 1, batch no : 178, total loss : 0.41768673062324524,  classifier :0.05790035426616669, mask: 0.14177177846431732 ===================
epoch no : 1, batch no : 179, total loss : 0.5021377205848694,  classifier :0.06686052680015564, mask: 0.16119298338890076 ===================
epoch no : 1, batch no : 180, total loss : 0.34743693470954895,  classifier :0.04446420446038246, mask: 0.12510617077350616 ===================
epoch no : 1, batch no : 181, total loss : 0.4490645229816437,  classifier :0.08156606554985046, mask: 0.17089687287807465 ===================
epoch no : 1, batch no : 182, total loss : 0.5297260284423828,  classifier :0.08279915153980255, mask: 0.16997560858726501 ===================
epoch no : 1, batch no : 183, total loss : 0.4264353811740875,  classifier :0.07262851297855377, mask: 0.1438772827386856 ===================
epoch no : 1, batch no : 184, total loss : 0.5968686938285828,  classifier :0.08719009160995483, mask: 0.2244531214237213 ===================
epoch no : 1, batch no : 185, total loss : 0.46877411007881165,  classifier :0.07110419124364853, mask: 0.1577240377664566 ===================
epoch no : 1, batch no : 186, total loss : 0.39944136142730713,  classifier :0.06520948559045792, mask: 0.13653139770030975 ===================
epoch no : 1, batch no : 187, total loss : 0.4122469127178192,  classifier :0.06894408166408539, mask: 0.16022564470767975 ===================
epoch no : 1, batch no : 188, total loss : 0.41860002279281616,  classifier :0.07517839968204498, mask: 0.13479357957839966 ===================
epoch no : 1, batch no : 189, total loss : 0.4634699523448944,  classifier :0.08677682280540466, mask: 0.14381533861160278 ===================
epoch no : 1, batch no : 190, total loss : 0.5168242454528809,  classifier :0.07260916382074356, mask: 0.19502906501293182 ===================
epoch no : 1, batch no : 191, total loss : 0.49254658818244934,  classifier :0.055490847676992416, mask: 0.19106143712997437 ===================
epoch no : 1, batch no : 192, total loss : 0.39371806383132935,  classifier :0.06902292370796204, mask: 0.13494984805583954 ===================
epoch no : 1, batch no : 193, total loss : 0.43936774134635925,  classifier :0.059583645313978195, mask: 0.1511492282152176 ===================
epoch no : 1, batch no : 194, total loss : 0.5124602913856506,  classifier :0.06872493028640747, mask: 0.16185882687568665 ===================
epoch no : 1, batch no : 195, total loss : 0.39004021883010864,  classifier :0.06344355642795563, mask: 0.1406266838312149 ===================
epoch no : 1, batch no : 196, total loss : 0.4757293462753296,  classifier :0.08104681968688965, mask: 0.1501842737197876 ===================
epoch no : 1, batch no : 197, total loss : 0.552760124206543,  classifier :0.07830403000116348, mask: 0.2202194482088089 ===================
epoch no : 1, batch no : 198, total loss : 0.48387205600738525,  classifier :0.06932011991739273, mask: 0.19721221923828125 ===================
epoch no : 1, batch no : 199, total loss : 0.5269762277603149,  classifier :0.06301695108413696, mask: 0.18929879367351532 ===================
epoch no : 1, batch no : 200, total loss : 0.6525086760520935,  classifier :0.07364892214536667, mask: 0.2145472764968872 ===================
epoch no : 1, batch no : 201, total loss : 0.49488726258277893,  classifier :0.0665067806839943, mask: 0.15057261288166046 ===================
epoch no : 1, batch no : 202, total loss : 0.5387734770774841,  classifier :0.07451759278774261, mask: 0.1679580956697464 ===================
epoch no : 1, batch no : 203, total loss : 0.48173433542251587,  classifier :0.060582347214221954, mask: 0.16375921666622162 ===================
epoch no : 1, batch no : 204, total loss : 0.47754213213920593,  classifier :0.06716805696487427, mask: 0.1559339016675949 ===================
epoch no : 1, batch no : 205, total loss : 0.419672429561615,  classifier :0.08432463556528091, mask: 0.14916381239891052 ===================
epoch no : 1, batch no : 206, total loss : 0.36362922191619873,  classifier :0.0593336783349514, mask: 0.13744193315505981 ===================
epoch no : 1, batch no : 207, total loss : 0.4235401451587677,  classifier :0.06989612430334091, mask: 0.16369350254535675 ===================
epoch no : 1, batch no : 208, total loss : 0.44958749413490295,  classifier :0.0756809189915657, mask: 0.1555042266845703 ===================
epoch no : 1, batch no : 209, total loss : 0.495177298784256,  classifier :0.07171902805566788, mask: 0.1921032816171646 ===================
epoch no : 1, batch no : 210, total loss : 0.5969245433807373,  classifier :0.09313688427209854, mask: 0.24079786241054535 ===================
epoch no : 1, batch no : 211, total loss : 0.44307994842529297,  classifier :0.06442616134881973, mask: 0.15792550146579742 ===================
epoch no : 1, batch no : 212, total loss : 0.40133070945739746,  classifier :0.06604214012622833, mask: 0.1392570436000824 ===================
epoch no : 1, batch no : 213, total loss : 0.4977082312107086,  classifier :0.08904922008514404, mask: 0.18303288519382477 ===================
epoch no : 1, batch no : 214, total loss : 0.5317373871803284,  classifier :0.06586911529302597, mask: 0.2288820445537567 ===================
epoch no : 1, batch no : 215, total loss : 0.4441610276699066,  classifier :0.06573864072561264, mask: 0.14941151440143585 ===================
epoch no : 1, batch no : 216, total loss : 0.4064067602157593,  classifier :0.07126495987176895, mask: 0.13211335241794586 ===================
epoch no : 1, batch no : 217, total loss : 0.43808621168136597,  classifier :0.07450105249881744, mask: 0.16526629030704498 ===================
epoch no : 1, batch no : 218, total loss : 0.5274478793144226,  classifier :0.0639868974685669, mask: 0.22075717151165009 ===================
epoch no : 1, batch no : 219, total loss : 0.5436141490936279,  classifier :0.08453993499279022, mask: 0.19725382328033447 ===================
epoch no : 1, batch no : 220, total loss : 0.4173985421657562,  classifier :0.074236661195755, mask: 0.15110504627227783 ===================
epoch no : 1, batch no : 221, total loss : 0.47703710198402405,  classifier :0.07371357828378677, mask: 0.15255330502986908 ===================
epoch no : 1, batch no : 222, total loss : 0.4933697283267975,  classifier :0.0789058580994606, mask: 0.16885925829410553 ===================
epoch no : 1, batch no : 223, total loss : 0.6129748225212097,  classifier :0.12471628934144974, mask: 0.22209703922271729 ===================
epoch no : 1, batch no : 224, total loss : 0.48372647166252136,  classifier :0.057900868356227875, mask: 0.14906750619411469 ===================
epoch no : 1, batch no : 225, total loss : 0.5346978902816772,  classifier :0.06684872508049011, mask: 0.19659478962421417 ===================
epoch no : 1, batch no : 226, total loss : 0.4424104690551758,  classifier :0.06430036574602127, mask: 0.14087453484535217 ===================
epoch no : 1, batch no : 227, total loss : 0.4279222786426544,  classifier :0.0726214051246643, mask: 0.15391452610492706 ===================
epoch no : 1, batch no : 228, total loss : 0.4144897758960724,  classifier :0.07021330296993256, mask: 0.13670480251312256 ===================
epoch no : 1, batch no : 229, total loss : 0.4770384132862091,  classifier :0.07004496455192566, mask: 0.15416909754276276 ===================
epoch no : 1, batch no : 230, total loss : 0.5403875112533569,  classifier :0.07411500066518784, mask: 0.20140162110328674 ===================
epoch no : 1, batch no : 231, total loss : 0.4440971910953522,  classifier :0.06960508972406387, mask: 0.15382137894630432 ===================
epoch no : 1, batch no : 232, total loss : 0.4966736137866974,  classifier :0.07053981721401215, mask: 0.21012215316295624 ===================
epoch no : 1, batch no : 233, total loss : 0.5913206338882446,  classifier :0.05732283741235733, mask: 0.24444566667079926 ===================
epoch no : 1, batch no : 234, total loss : 0.46565622091293335,  classifier :0.07761184871196747, mask: 0.14976897835731506 ===================
epoch no : 1, batch no : 235, total loss : 0.3991166651248932,  classifier :0.06951297074556351, mask: 0.14975158870220184 ===================
epoch no : 1, batch no : 236, total loss : 0.366474449634552,  classifier :0.0654848963022232, mask: 0.13384972512722015 ===================
epoch no : 1, batch no : 237, total loss : 0.49498113989830017,  classifier :0.060363296419382095, mask: 0.15547537803649902 ===================
epoch no : 1, batch no : 238, total loss : 0.47927215695381165,  classifier :0.07130549103021622, mask: 0.1625491827726364 ===================
epoch no : 1, batch no : 239, total loss : 0.4033619165420532,  classifier :0.06425198912620544, mask: 0.13673089444637299 ===================
epoch no : 1, batch no : 240, total loss : 0.45293718576431274,  classifier :0.059511762112379074, mask: 0.131918802857399 ===================
epoch no : 1, batch no : 241, total loss : 0.44768890738487244,  classifier :0.06476299464702606, mask: 0.18401135504245758 ===================
epoch no : 1, batch no : 242, total loss : 0.4210917055606842,  classifier :0.06735935807228088, mask: 0.14726580679416656 ===================
epoch no : 1, batch no : 243, total loss : 0.4349089562892914,  classifier :0.06915967166423798, mask: 0.17560268938541412 ===================
epoch no : 1, batch no : 244, total loss : 0.5573427081108093,  classifier :0.05914347246289253, mask: 0.19228646159172058 ===================
epoch no : 1, batch no : 245, total loss : 0.5189063549041748,  classifier :0.07740918546915054, mask: 0.13961173593997955 ===================
epoch no : 1, batch no : 246, total loss : 0.45654353499412537,  classifier :0.06504203379154205, mask: 0.15771932899951935 ===================
epoch no : 1, batch no : 247, total loss : 0.4021446704864502,  classifier :0.07674490660429001, mask: 0.16482658684253693 ===================
epoch no : 1, batch no : 248, total loss : 0.5015164613723755,  classifier :0.0636259987950325, mask: 0.19138796627521515 ===================
epoch no : 1, batch no : 249, total loss : 0.4631020724773407,  classifier :0.07695465534925461, mask: 0.18318158388137817 ===================
epoch no : 1, batch no : 250, total loss : 0.4811287224292755,  classifier :0.07229910790920258, mask: 0.16887763142585754 ===================
epoch no : 1, batch no : 251, total loss : 0.36812278628349304,  classifier :0.06002040579915047, mask: 0.11823497712612152 ===================
epoch no : 1, batch no : 252, total loss : 0.5178419947624207,  classifier :0.07523588836193085, mask: 0.22167165577411652 ===================
epoch no : 1, batch no : 253, total loss : 0.49225085973739624,  classifier :0.06782127916812897, mask: 0.14823077619075775 ===================
epoch no : 1, batch no : 254, total loss : 0.39034318923950195,  classifier :0.05922984704375267, mask: 0.1538342386484146 ===================
epoch no : 1, batch no : 255, total loss : 0.5244286060333252,  classifier :0.06352301687002182, mask: 0.22579018771648407 ===================
epoch no : 1, batch no : 256, total loss : 0.5611642003059387,  classifier :0.06589063256978989, mask: 0.23324164748191833 ===================
epoch no : 1, batch no : 257, total loss : 0.47761663794517517,  classifier :0.07106383889913559, mask: 0.17937231063842773 ===================
epoch no : 1, batch no : 258, total loss : 0.3989046812057495,  classifier :0.06011592596769333, mask: 0.12231582403182983 ===================
epoch no : 1, batch no : 259, total loss : 0.3999980390071869,  classifier :0.06129107624292374, mask: 0.14421898126602173 ===================
epoch no : 1, batch no : 260, total loss : 0.46192583441734314,  classifier :0.07001388818025589, mask: 0.15145660936832428 ===================
epoch no : 1, batch no : 261, total loss : 0.5384914875030518,  classifier :0.07018368691205978, mask: 0.20371054112911224 ===================
epoch no : 1, batch no : 262, total loss : 0.6176836490631104,  classifier :0.08462695777416229, mask: 0.2619422972202301 ===================
epoch no : 1, batch no : 263, total loss : 0.533816397190094,  classifier :0.07242393493652344, mask: 0.18503516912460327 ===================
epoch no : 1, batch no : 264, total loss : 0.507541835308075,  classifier :0.07411264628171921, mask: 0.18892668187618256 ===================
epoch no : 1, batch no : 265, total loss : 0.4327200949192047,  classifier :0.0749850943684578, mask: 0.12486623227596283 ===================
epoch no : 1, batch no : 266, total loss : 0.47947490215301514,  classifier :0.06726709008216858, mask: 0.15251897275447845 ===================
epoch no : 1, batch no : 267, total loss : 0.4839850068092346,  classifier :0.06314699351787567, mask: 0.1711021065711975 ===================
epoch no : 1, batch no : 268, total loss : 0.45946061611175537,  classifier :0.06327946484088898, mask: 0.14163555204868317 ===================
epoch no : 1, batch no : 269, total loss : 0.4736661911010742,  classifier :0.06509105861186981, mask: 0.18484468758106232 ===================
epoch no : 1, batch no : 270, total loss : 0.4291386008262634,  classifier :0.05938953161239624, mask: 0.1612914353609085 ===================
epoch no : 1, batch no : 271, total loss : 0.5339347124099731,  classifier :0.05191801115870476, mask: 0.21192851662635803 ===================
epoch no : 1, batch no : 272, total loss : 0.5132880806922913,  classifier :0.07683475315570831, mask: 0.18479812145233154 ===================
epoch no : 1, batch no : 273, total loss : 0.41787996888160706,  classifier :0.0556931346654892, mask: 0.16125817596912384 ===================
epoch no : 1, batch no : 274, total loss : 0.45186761021614075,  classifier :0.07069049775600433, mask: 0.18410097062587738 ===================
epoch no : 1, batch no : 275, total loss : 0.5163886547088623,  classifier :0.07861059904098511, mask: 0.1636679768562317 ===================
epoch no : 1, batch no : 276, total loss : 0.4247119426727295,  classifier :0.058518487960100174, mask: 0.16334186494350433 ===================
epoch no : 1, batch no : 277, total loss : 0.5031665563583374,  classifier :0.08907715976238251, mask: 0.16647274792194366 ===================
epoch no : 1, batch no : 278, total loss : 0.42835426330566406,  classifier :0.06317823380231857, mask: 0.12751489877700806 ===================
epoch no : 1, batch no : 279, total loss : 0.5320665240287781,  classifier :0.0720648318529129, mask: 0.1719478815793991 ===================
epoch no : 1, batch no : 280, total loss : 0.5514304041862488,  classifier :0.06770642846822739, mask: 0.182708740234375 ===================
epoch no : 1, batch no : 281, total loss : 0.4539072811603546,  classifier :0.07472260296344757, mask: 0.1835535168647766 ===================
epoch no : 1, batch no : 282, total loss : 0.4195144772529602,  classifier :0.06591011583805084, mask: 0.15005342662334442 ===================
epoch no : 1, batch no : 283, total loss : 0.4874725043773651,  classifier :0.06875423341989517, mask: 0.16446539759635925 ===================
epoch no : 1, batch no : 284, total loss : 0.3982785642147064,  classifier :0.07203927636146545, mask: 0.14212799072265625 ===================
epoch no : 1, batch no : 285, total loss : 0.44835832715034485,  classifier :0.07812508940696716, mask: 0.16042496263980865 ===================
epoch no : 1, batch no : 286, total loss : 0.33658623695373535,  classifier :0.07132451236248016, mask: 0.12082409858703613 ===================
epoch no : 1, batch no : 287, total loss : 0.41136154532432556,  classifier :0.05882442370057106, mask: 0.13525903224945068 ===================
epoch no : 1, batch no : 288, total loss : 0.5619180202484131,  classifier :0.0586484856903553, mask: 0.19716574251651764 ===================
epoch no : 1, batch no : 289, total loss : 0.42781636118888855,  classifier :0.06677824258804321, mask: 0.16772140562534332 ===================
epoch no : 1, batch no : 290, total loss : 0.35532689094543457,  classifier :0.06400669366121292, mask: 0.153860941529274 ===================
epoch no : 1, batch no : 291, total loss : 0.3553902208805084,  classifier :0.05423273146152496, mask: 0.13226386904716492 ===================
epoch no : 1, batch no : 292, total loss : 0.3648281395435333,  classifier :0.08227872103452682, mask: 0.14047837257385254 ===================
epoch no : 1, batch no : 293, total loss : 0.32220709323883057,  classifier :0.04998181760311127, mask: 0.14936085045337677 ===================
epoch no : 1, batch no : 294, total loss : 0.6232366561889648,  classifier :0.10318984091281891, mask: 0.2471335232257843 ===================
epoch no : 1, batch no : 295, total loss : 0.43965646624565125,  classifier :0.06078127771615982, mask: 0.16272228956222534 ===================
epoch no : 1, batch no : 296, total loss : 0.36339646577835083,  classifier :0.06464257091283798, mask: 0.13389019668102264 ===================
epoch no : 1, batch no : 297, total loss : 0.4387645721435547,  classifier :0.07703467458486557, mask: 0.15683700144290924 ===================
epoch no : 1, batch no : 298, total loss : 0.49625739455223083,  classifier :0.06389249116182327, mask: 0.2122696340084076 ===================
epoch no : 1, batch no : 299, total loss : 0.5011913776397705,  classifier :0.06185518205165863, mask: 0.17162823677062988 ===================
epoch no : 1, batch no : 300, total loss : 0.3711167871952057,  classifier :0.06176649406552315, mask: 0.12928320467472076 ===================
epoch no : 1, batch no : 301, total loss : 0.4353591501712799,  classifier :0.06247590109705925, mask: 0.15332941710948944 ===================
epoch no : 1, batch no : 302, total loss : 0.48802313208580017,  classifier :0.061029594391584396, mask: 0.23892179131507874 ===================
epoch no : 1, batch no : 303, total loss : 0.48115476965904236,  classifier :0.06910254061222076, mask: 0.1860731840133667 ===================
epoch no : 1, batch no : 304, total loss : 0.4959809184074402,  classifier :0.08152026683092117, mask: 0.2281462699174881 ===================
epoch no : 1, batch no : 305, total loss : 0.3896486461162567,  classifier :0.07090979069471359, mask: 0.1499762088060379 ===================
epoch no : 1, batch no : 306, total loss : 0.4068480432033539,  classifier :0.06067401543259621, mask: 0.14789800345897675 ===================
epoch no : 1, batch no : 307, total loss : 0.49819815158843994,  classifier :0.06519350409507751, mask: 0.18342237174510956 ===================
epoch no : 1, batch no : 308, total loss : 0.51752769947052,  classifier :0.0775679424405098, mask: 0.17347441613674164 ===================
epoch no : 1, batch no : 309, total loss : 0.4516563415527344,  classifier :0.05210354924201965, mask: 0.14938169717788696 ===================
epoch no : 1, batch no : 310, total loss : 0.4138297438621521,  classifier :0.06372340768575668, mask: 0.17381994426250458 ===================
epoch no : 1, batch no : 311, total loss : 0.5502333045005798,  classifier :0.07084859907627106, mask: 0.19714781641960144 ===================
epoch no : 1, batch no : 312, total loss : 0.4059695601463318,  classifier :0.056580785661935806, mask: 0.15169265866279602 ===================
epoch no : 1, batch no : 313, total loss : 0.47998514771461487,  classifier :0.0659753605723381, mask: 0.1721414029598236 ===================
epoch no : 1, batch no : 314, total loss : 0.44720059633255005,  classifier :0.06723570823669434, mask: 0.18634285032749176 ===================
epoch no : 1, batch no : 315, total loss : 0.4443318545818329,  classifier :0.06950125098228455, mask: 0.1547476053237915 ===================
epoch no : 1, batch no : 316, total loss : 0.5246538519859314,  classifier :0.06274398416280746, mask: 0.19766303896903992 ===================
epoch no : 1, batch no : 317, total loss : 0.39753687381744385,  classifier :0.04631144925951958, mask: 0.12899050116539001 ===================
epoch no : 1, batch no : 318, total loss : 0.42228013277053833,  classifier :0.044444311410188675, mask: 0.17419001460075378 ===================
epoch no : 1, batch no : 319, total loss : 0.4023415744304657,  classifier :0.0658363476395607, mask: 0.13022327423095703 ===================
epoch no : 1, batch no : 320, total loss : 0.4557553231716156,  classifier :0.06759803742170334, mask: 0.13247253000736237 ===================
epoch no : 1, batch no : 321, total loss : 0.43772879242897034,  classifier :0.06608723104000092, mask: 0.15005943179130554 ===================
epoch no : 1, batch no : 322, total loss : 0.42214739322662354,  classifier :0.05499119311571121, mask: 0.18256916105747223 ===================
epoch no : 1, batch no : 323, total loss : 0.46829190850257874,  classifier :0.057950932532548904, mask: 0.18252146244049072 ===================
epoch no : 1, batch no : 324, total loss : 0.5051653385162354,  classifier :0.06184922158718109, mask: 0.17317132651805878 ===================
epoch no : 1, batch no : 325, total loss : 0.3785105347633362,  classifier :0.06254840642213821, mask: 0.12371496856212616 ===================
epoch no : 1, batch no : 326, total loss : 0.45019492506980896,  classifier :0.059678636491298676, mask: 0.18000024557113647 ===================
epoch no : 1, batch no : 327, total loss : 0.39437779784202576,  classifier :0.06288179010152817, mask: 0.1420513391494751 ===================
epoch no : 1, batch no : 328, total loss : 0.4550672173500061,  classifier :0.07194316387176514, mask: 0.16126306354999542 ===================
epoch no : 1, batch no : 329, total loss : 0.44457030296325684,  classifier :0.06472854316234589, mask: 0.15118786692619324 ===================
epoch no : 1, batch no : 330, total loss : 0.4379456341266632,  classifier :0.06141006946563721, mask: 0.14643494784832 ===================
epoch no : 1, batch no : 331, total loss : 0.4268909990787506,  classifier :0.06591066718101501, mask: 0.15036281943321228 ===================
epoch no : 1, batch no : 332, total loss : 0.49018925428390503,  classifier :0.0595768541097641, mask: 0.2336447536945343 ===================
epoch no : 1, batch no : 333, total loss : 0.38130930066108704,  classifier :0.06186243146657944, mask: 0.13600002229213715 ===================
epoch no : 1, batch no : 334, total loss : 0.4543158710002899,  classifier :0.07093104720115662, mask: 0.18750934302806854 ===================
epoch no : 1, batch no : 335, total loss : 0.3767881393432617,  classifier :0.06494709849357605, mask: 0.12807345390319824 ===================
epoch no : 1, batch no : 336, total loss : 0.34236061573028564,  classifier :0.061547525227069855, mask: 0.11803322285413742 ===================
epoch no : 1, batch no : 337, total loss : 0.36787882447242737,  classifier :0.05731486529111862, mask: 0.12897257506847382 ===================
epoch no : 1, batch no : 338, total loss : 0.5105680227279663,  classifier :0.07716510444879532, mask: 0.19297495484352112 ===================
epoch no : 1, batch no : 339, total loss : 0.4353659152984619,  classifier :0.06160612776875496, mask: 0.1412908285856247 ===================
epoch no : 1, batch no : 340, total loss : 0.552839994430542,  classifier :0.06183057650923729, mask: 0.1951349526643753 ===================
epoch no : 1, batch no : 341, total loss : 0.398336797952652,  classifier :0.05994950979948044, mask: 0.16157247126102448 ===================
epoch no : 1, batch no : 342, total loss : 0.42860791087150574,  classifier :0.05536181852221489, mask: 0.17980363965034485 ===================
epoch no : 1, batch no : 343, total loss : 0.4699501693248749,  classifier :0.0693628191947937, mask: 0.17211082577705383 ===================
epoch no : 1, batch no : 344, total loss : 0.38734546303749084,  classifier :0.056557003408670425, mask: 0.14818087220191956 ===================
epoch no : 1, batch no : 345, total loss : 0.39284250140190125,  classifier :0.07026553899049759, mask: 0.1321985423564911 ===================
epoch no : 1, batch no : 346, total loss : 0.3965534269809723,  classifier :0.06414403021335602, mask: 0.1447308212518692 ===================
epoch no : 1, batch no : 347, total loss : 0.5348449349403381,  classifier :0.059289462864398956, mask: 0.20469880104064941 ===================
epoch no : 1, batch no : 348, total loss : 0.39952534437179565,  classifier :0.05222054198384285, mask: 0.1440402865409851 ===================
epoch no : 1, batch no : 349, total loss : 0.4199100434780121,  classifier :0.057642899453639984, mask: 0.15583451092243195 ===================
epoch no : 1, batch no : 350, total loss : 0.43677207827568054,  classifier :0.06874893605709076, mask: 0.15891548991203308 ===================
epoch no : 1, batch no : 351, total loss : 0.43083488941192627,  classifier :0.0641128346323967, mask: 0.15342625975608826 ===================
epoch no : 1, batch no : 352, total loss : 0.39962852001190186,  classifier :0.0639612078666687, mask: 0.1524844765663147 ===================
epoch no : 1, batch no : 353, total loss : 0.44187062978744507,  classifier :0.06532293558120728, mask: 0.1522766649723053 ===================
epoch no : 1, batch no : 354, total loss : 0.48796987533569336,  classifier :0.05263400077819824, mask: 0.1849573254585266 ===================
epoch no : 1, batch no : 355, total loss : 0.5686650276184082,  classifier :0.08271452784538269, mask: 0.22637352347373962 ===================
epoch no : 1, batch no : 356, total loss : 0.4157034456729889,  classifier :0.06931351125240326, mask: 0.1589447259902954 ===================
epoch no : 1, batch no : 357, total loss : 0.4557270109653473,  classifier :0.05779459699988365, mask: 0.21404744684696198 ===================
epoch no : 1, batch no : 358, total loss : 0.6228427886962891,  classifier :0.07554252445697784, mask: 0.22802852094173431 ===================
epoch no : 1, batch no : 359, total loss : 0.4009423553943634,  classifier :0.058404840528964996, mask: 0.13714711368083954 ===================
epoch no : 1, batch no : 360, total loss : 0.3773556053638458,  classifier :0.051110412925481796, mask: 0.1488407701253891 ===================
epoch no : 1, batch no : 361, total loss : 0.4044615626335144,  classifier :0.05893766134977341, mask: 0.1384010910987854 ===================
epoch no : 1, batch no : 362, total loss : 0.4865936040878296,  classifier :0.07320419698953629, mask: 0.17523962259292603 ===================
epoch no : 1, batch no : 363, total loss : 0.4302678108215332,  classifier :0.061037931591272354, mask: 0.15192459523677826 ===================
epoch no : 1, batch no : 364, total loss : 0.38443395495414734,  classifier :0.05620691925287247, mask: 0.13573123514652252 ===================
epoch no : 1, batch no : 365, total loss : 0.5392595529556274,  classifier :0.06237777695059776, mask: 0.17447566986083984 ===================
epoch no : 1, batch no : 366, total loss : 0.46299636363983154,  classifier :0.07905855029821396, mask: 0.17151518166065216 ===================
epoch no : 1, batch no : 367, total loss : 0.3782074451446533,  classifier :0.061935823410749435, mask: 0.13915640115737915 ===================
epoch no : 1, batch no : 368, total loss : 0.44560933113098145,  classifier :0.06329307705163956, mask: 0.15150879323482513 ===================
epoch no : 1, batch no : 369, total loss : 0.5060412883758545,  classifier :0.07115881890058517, mask: 0.1971529722213745 ===================
epoch no : 1, batch no : 370, total loss : 0.37906020879745483,  classifier :0.039885953068733215, mask: 0.14114853739738464 ===================
epoch no : 1, batch no : 371, total loss : 0.40611013770103455,  classifier :0.07986492663621902, mask: 0.11633682250976562 ===================
epoch no : 1, batch no : 372, total loss : 0.4102441072463989,  classifier :0.06482404470443726, mask: 0.13718242943286896 ===================
epoch no : 1, batch no : 373, total loss : 0.5258188247680664,  classifier :0.0638783723115921, mask: 0.16485707461833954 ===================
epoch no : 1, batch no : 374, total loss : 0.40051767230033875,  classifier :0.046592287719249725, mask: 0.15027135610580444 ===================
epoch no : 1, batch no : 375, total loss : 0.3850822448730469,  classifier :0.060142774134874344, mask: 0.13547585904598236 ===================
epoch no : 1, batch no : 376, total loss : 0.39004039764404297,  classifier :0.06658363342285156, mask: 0.13351404666900635 ===================
epoch no : 1, batch no : 377, total loss : 0.36968135833740234,  classifier :0.05194593966007233, mask: 0.12144926190376282 ===================
epoch no : 1, batch no : 378, total loss : 0.5333393812179565,  classifier :0.06492051482200623, mask: 0.17139466106891632 ===================
epoch no : 1, batch no : 379, total loss : 0.5198907852172852,  classifier :0.06437352299690247, mask: 0.2059326171875 ===================
epoch no : 1, batch no : 380, total loss : 0.5316370129585266,  classifier :0.07945750653743744, mask: 0.2114078849554062 ===================
epoch no : 1, batch no : 381, total loss : 0.47319045662879944,  classifier :0.081454336643219, mask: 0.17431719601154327 ===================
epoch no : 1, batch no : 382, total loss : 0.3940623700618744,  classifier :0.05200457572937012, mask: 0.15047280490398407 ===================
epoch no : 1, batch no : 383, total loss : 0.39206454157829285,  classifier :0.062251314520835876, mask: 0.15253347158432007 ===================
epoch no : 1, batch no : 384, total loss : 0.3922278583049774,  classifier :0.05821170285344124, mask: 0.15530644357204437 ===================
epoch no : 1, batch no : 385, total loss : 0.5651724338531494,  classifier :0.05363309755921364, mask: 0.18186210095882416 ===================
epoch no : 1, batch no : 386, total loss : 0.49933353066444397,  classifier :0.0932798683643341, mask: 0.19161787629127502 ===================
epoch no : 1, batch no : 387, total loss : 0.44847050309181213,  classifier :0.05990448221564293, mask: 0.15371358394622803 ===================
epoch no : 1, batch no : 388, total loss : 0.6124929189682007,  classifier :0.07702702283859253, mask: 0.26262781023979187 ===================
epoch no : 1, batch no : 389, total loss : 0.49419891834259033,  classifier :0.05232394114136696, mask: 0.19932766258716583 ===================
epoch no : 1, batch no : 390, total loss : 0.4392927289009094,  classifier :0.06345269083976746, mask: 0.1695699244737625 ===================
epoch no : 1, batch no : 391, total loss : 0.45682159066200256,  classifier :0.06805519014596939, mask: 0.13840565085411072 ===================
epoch no : 1, batch no : 392, total loss : 0.45400843024253845,  classifier :0.052438877522945404, mask: 0.14851802587509155 ===================
epoch no : 1, batch no : 393, total loss : 0.3820522725582123,  classifier :0.05961260199546814, mask: 0.13085642457008362 ===================
epoch no : 1, batch no : 394, total loss : 0.409067839384079,  classifier :0.05728393793106079, mask: 0.14573535323143005 ===================
epoch no : 1, batch no : 395, total loss : 0.40489456057548523,  classifier :0.07775033265352249, mask: 0.13799676299095154 ===================
epoch no : 1, batch no : 396, total loss : 0.42237308621406555,  classifier :0.06340198963880539, mask: 0.17850075662136078 ===================
epoch no : 1, batch no : 397, total loss : 0.5352659821510315,  classifier :0.07193415611982346, mask: 0.20238184928894043 ===================
epoch no : 1, batch no : 398, total loss : 0.42730265855789185,  classifier :0.05635921657085419, mask: 0.1280137449502945 ===================
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch no : 2, batch no : 0, total loss : 0.45055538415908813,  classifier :0.05983439460396767, mask: 0.1554848849773407 ===================
epoch no : 2, batch no : 1, total loss : 0.46100088953971863,  classifier :0.08862283825874329, mask: 0.15842902660369873 ===================
epoch no : 2, batch no : 2, total loss : 0.4976881742477417,  classifier :0.08168591558933258, mask: 0.16734832525253296 ===================
epoch no : 2, batch no : 3, total loss : 0.4032166004180908,  classifier :0.05374213308095932, mask: 0.1345372498035431 ===================
epoch no : 2, batch no : 4, total loss : 0.49245619773864746,  classifier :0.062330350279808044, mask: 0.17202867567539215 ===================
epoch no : 2, batch no : 5, total loss : 0.4199749827384949,  classifier :0.050746552646160126, mask: 0.14864623546600342 ===================
epoch no : 2, batch no : 6, total loss : 0.5195325613021851,  classifier :0.07634706050157547, mask: 0.18043872714042664 ===================
epoch no : 2, batch no : 7, total loss : 0.44617095589637756,  classifier :0.062120985239744186, mask: 0.1604457050561905 ===================
epoch no : 2, batch no : 8, total loss : 0.3331315219402313,  classifier :0.05234260857105255, mask: 0.11408010870218277 ===================
epoch no : 2, batch no : 9, total loss : 0.4191862940788269,  classifier :0.06198236718773842, mask: 0.1271926909685135 ===================
epoch no : 2, batch no : 10, total loss : 0.44526490569114685,  classifier :0.05009967461228371, mask: 0.15545813739299774 ===================
epoch no : 2, batch no : 11, total loss : 0.49292075634002686,  classifier :0.0681333988904953, mask: 0.1967514306306839 ===================
epoch no : 2, batch no : 12, total loss : 0.4486023485660553,  classifier :0.05245117470622063, mask: 0.16272945702075958 ===================
epoch no : 2, batch no : 13, total loss : 0.48826077580451965,  classifier :0.05757925659418106, mask: 0.1883370280265808 ===================
epoch no : 2, batch no : 14, total loss : 0.46633264422416687,  classifier :0.05960269644856453, mask: 0.1665397584438324 ===================
epoch no : 2, batch no : 15, total loss : 0.42810818552970886,  classifier :0.05807094648480415, mask: 0.15189069509506226 ===================
epoch no : 2, batch no : 16, total loss : 0.4009087383747101,  classifier :0.04934168606996536, mask: 0.14057797193527222 ===================
epoch no : 2, batch no : 17, total loss : 0.4979323148727417,  classifier :0.06352950632572174, mask: 0.22437827289104462 ===================
epoch no : 2, batch no : 18, total loss : 0.4402560889720917,  classifier :0.06342918425798416, mask: 0.19004054367542267 ===================
epoch no : 2, batch no : 19, total loss : 0.3767228424549103,  classifier :0.049493320286273956, mask: 0.15251196920871735 ===================
epoch no : 2, batch no : 20, total loss : 0.34207671880722046,  classifier :0.045543693006038666, mask: 0.14078392088413239 ===================
epoch no : 2, batch no : 21, total loss : 0.39519184827804565,  classifier :0.05917934700846672, mask: 0.12946365773677826 ===================
epoch no : 2, batch no : 22, total loss : 0.4597090780735016,  classifier :0.06086219474673271, mask: 0.16418680548667908 ===================
epoch no : 2, batch no : 23, total loss : 0.3690853714942932,  classifier :0.06583753228187561, mask: 0.13467471301555634 ===================
epoch no : 2, batch no : 24, total loss : 0.31880688667297363,  classifier :0.0420907624065876, mask: 0.13522861897945404 ===================
epoch no : 2, batch no : 25, total loss : 0.7213731408119202,  classifier :0.1082843467593193, mask: 0.2774268686771393 ===================
epoch no : 2, batch no : 26, total loss : 0.3639332354068756,  classifier :0.04944976419210434, mask: 0.15318313241004944 ===================
epoch no : 2, batch no : 27, total loss : 0.3484205901622772,  classifier :0.06109548360109329, mask: 0.10956171900033951 ===================
epoch no : 2, batch no : 28, total loss : 0.4811697006225586,  classifier :0.05327063426375389, mask: 0.18477384746074677 ===================
epoch no : 2, batch no : 29, total loss : 0.4565161466598511,  classifier :0.05525534600019455, mask: 0.1554804891347885 ===================
epoch no : 2, batch no : 30, total loss : 0.39118263125419617,  classifier :0.06552647799253464, mask: 0.15733040869235992 ===================
epoch no : 2, batch no : 31, total loss : 0.41698458790779114,  classifier :0.05695318430662155, mask: 0.16735246777534485 ===================
epoch no : 2, batch no : 32, total loss : 0.3019370138645172,  classifier :0.05179399996995926, mask: 0.11522868275642395 ===================
epoch no : 2, batch no : 33, total loss : 0.33092182874679565,  classifier :0.05330633744597435, mask: 0.12574456632137299 ===================
epoch no : 2, batch no : 34, total loss : 0.3868860900402069,  classifier :0.056863635778427124, mask: 0.15326914191246033 ===================
epoch no : 2, batch no : 35, total loss : 0.38330358266830444,  classifier :0.05271577090024948, mask: 0.1264994889497757 ===================
epoch no : 2, batch no : 36, total loss : 0.38454297184944153,  classifier :0.04630061984062195, mask: 0.1280016452074051 ===================
epoch no : 2, batch no : 37, total loss : 0.4143214225769043,  classifier :0.048324622213840485, mask: 0.13346236944198608 ===================
epoch no : 2, batch no : 38, total loss : 0.42570242285728455,  classifier :0.05409965291619301, mask: 0.15505746006965637 ===================
epoch no : 2, batch no : 39, total loss : 0.3561832308769226,  classifier :0.05951414629817009, mask: 0.13380219042301178 ===================
epoch no : 2, batch no : 40, total loss : 0.3286723494529724,  classifier :0.04694290831685066, mask: 0.14153218269348145 ===================
epoch no : 2, batch no : 41, total loss : 0.5191984176635742,  classifier :0.0639328733086586, mask: 0.20849677920341492 ===================
epoch no : 2, batch no : 42, total loss : 0.37182286381721497,  classifier :0.06423559784889221, mask: 0.1339150369167328 ===================
epoch no : 2, batch no : 43, total loss : 0.3479250967502594,  classifier :0.045708782970905304, mask: 0.1359320729970932 ===================
epoch no : 2, batch no : 44, total loss : 0.30632907152175903,  classifier :0.047769296914339066, mask: 0.10521133244037628 ===================
epoch no : 2, batch no : 45, total loss : 0.3942605257034302,  classifier :0.059171270579099655, mask: 0.1303650587797165 ===================
epoch no : 2, batch no : 46, total loss : 0.34525030851364136,  classifier :0.043696075677871704, mask: 0.11467316001653671 ===================
epoch no : 2, batch no : 47, total loss : 0.43992355465888977,  classifier :0.05527186021208763, mask: 0.15365085005760193 ===================
epoch no : 2, batch no : 48, total loss : 0.509335994720459,  classifier :0.05750251188874245, mask: 0.2036849856376648 ===================
epoch no : 2, batch no : 49, total loss : 0.451415091753006,  classifier :0.045775994658470154, mask: 0.1667553186416626 ===================
epoch no : 2, batch no : 50, total loss : 0.4198126792907715,  classifier :0.05476725473999977, mask: 0.13546408712863922 ===================
epoch no : 2, batch no : 51, total loss : 0.41761690378189087,  classifier :0.07753545045852661, mask: 0.14079570770263672 ===================
epoch no : 2, batch no : 52, total loss : 0.3356213867664337,  classifier :0.0567132942378521, mask: 0.11447527259588242 ===================
epoch no : 2, batch no : 53, total loss : 0.4498050808906555,  classifier :0.07059729099273682, mask: 0.1369859129190445 ===================
epoch no : 2, batch no : 54, total loss : 0.47656428813934326,  classifier :0.06284560263156891, mask: 0.16716456413269043 ===================
epoch no : 2, batch no : 55, total loss : 0.4344331920146942,  classifier :0.06692858785390854, mask: 0.1405462771654129 ===================
epoch no : 2, batch no : 56, total loss : 0.3537222146987915,  classifier :0.05711240693926811, mask: 0.10705795884132385 ===================
epoch no : 2, batch no : 57, total loss : 0.43032610416412354,  classifier :0.06313350051641464, mask: 0.15122677385807037 ===================
epoch no : 2, batch no : 58, total loss : 0.33245208859443665,  classifier :0.06156199425458908, mask: 0.12778399884700775 ===================
epoch no : 2, batch no : 59, total loss : 0.33906325697898865,  classifier :0.05626355856657028, mask: 0.13517162203788757 ===================
epoch no : 2, batch no : 60, total loss : 0.36945876479148865,  classifier :0.052419938147068024, mask: 0.13510581851005554 ===================
epoch no : 2, batch no : 61, total loss : 0.36188510060310364,  classifier :0.048777997493743896, mask: 0.13004368543624878 ===================
epoch no : 2, batch no : 62, total loss : 0.334225594997406,  classifier :0.058551203459501266, mask: 0.127280592918396 ===================
epoch no : 2, batch no : 63, total loss : 0.45493316650390625,  classifier :0.07947777956724167, mask: 0.15818436443805695 ===================
epoch no : 2, batch no : 64, total loss : 0.3711468577384949,  classifier :0.04906301200389862, mask: 0.13698655366897583 ===================
epoch no : 2, batch no : 65, total loss : 0.4815574884414673,  classifier :0.057929765433073044, mask: 0.1898164302110672 ===================
epoch no : 2, batch no : 66, total loss : 0.3497026860713959,  classifier :0.059693992137908936, mask: 0.1245243027806282 ===================
epoch no : 2, batch no : 67, total loss : 0.32628464698791504,  classifier :0.04930813983082771, mask: 0.12020574510097504 ===================
epoch no : 2, batch no : 68, total loss : 0.4085884690284729,  classifier :0.0606689527630806, mask: 0.1544177234172821 ===================
epoch no : 2, batch no : 69, total loss : 0.3655673861503601,  classifier :0.05395419895648956, mask: 0.1362753063440323 ===================
epoch no : 2, batch no : 70, total loss : 0.37173688411712646,  classifier :0.052093084901571274, mask: 0.15397138893604279 ===================
epoch no : 2, batch no : 71, total loss : 0.3502355217933655,  classifier :0.0585147999227047, mask: 0.12965303659439087 ===================
epoch no : 2, batch no : 72, total loss : 0.41879960894584656,  classifier :0.05783165991306305, mask: 0.1655556857585907 ===================
epoch no : 2, batch no : 73, total loss : 0.4102703630924225,  classifier :0.06193900480866432, mask: 0.14865249395370483 ===================
epoch no : 2, batch no : 74, total loss : 0.5050926208496094,  classifier :0.054622046649456024, mask: 0.17610108852386475 ===================
epoch no : 2, batch no : 75, total loss : 0.3979799449443817,  classifier :0.06055377423763275, mask: 0.14652377367019653 ===================
epoch no : 2, batch no : 76, total loss : 0.29212260246276855,  classifier :0.05238970369100571, mask: 0.11364255845546722 ===================
epoch no : 2, batch no : 77, total loss : 0.3684988021850586,  classifier :0.05561559647321701, mask: 0.13388791680335999 ===================
epoch no : 2, batch no : 78, total loss : 0.4755113124847412,  classifier :0.05451499670743942, mask: 0.16299059987068176 ===================
epoch no : 2, batch no : 79, total loss : 0.2917686998844147,  classifier :0.059312183409929276, mask: 0.11391783505678177 ===================
epoch no : 2, batch no : 80, total loss : 0.41062623262405396,  classifier :0.06651486456394196, mask: 0.19465439021587372 ===================
epoch no : 2, batch no : 81, total loss : 0.3536706864833832,  classifier :0.05081448331475258, mask: 0.13294513523578644 ===================
epoch no : 2, batch no : 82, total loss : 0.3777749538421631,  classifier :0.05751000717282295, mask: 0.13634595274925232 ===================
epoch no : 2, batch no : 83, total loss : 0.40378135442733765,  classifier :0.05398336425423622, mask: 0.151792973279953 ===================
epoch no : 2, batch no : 84, total loss : 0.4142746925354004,  classifier :0.0585809126496315, mask: 0.15289993584156036 ===================
epoch no : 2, batch no : 85, total loss : 0.3610527217388153,  classifier :0.051740918308496475, mask: 0.1441664844751358 ===================
epoch no : 2, batch no : 86, total loss : 0.5124409198760986,  classifier :0.07539231330156326, mask: 0.16791294515132904 ===================
epoch no : 2, batch no : 87, total loss : 0.40758800506591797,  classifier :0.05469240993261337, mask: 0.16873221099376678 ===================
epoch no : 2, batch no : 88, total loss : 0.30267223715782166,  classifier :0.0512155182659626, mask: 0.11931305378675461 ===================
epoch no : 2, batch no : 89, total loss : 0.316984623670578,  classifier :0.05455336719751358, mask: 0.12743771076202393 ===================
epoch no : 2, batch no : 90, total loss : 0.28369611501693726,  classifier :0.04616127908229828, mask: 0.10900221019983292 ===================
epoch no : 2, batch no : 91, total loss : 0.4647565484046936,  classifier :0.04904278367757797, mask: 0.19965922832489014 ===================
epoch no : 2, batch no : 92, total loss : 0.4973890781402588,  classifier :0.05613575503230095, mask: 0.16753873229026794 ===================
epoch no : 2, batch no : 93, total loss : 0.5832704305648804,  classifier :0.0686783716082573, mask: 0.27659872174263 ===================
epoch no : 2, batch no : 94, total loss : 0.5235106945037842,  classifier :0.06614884734153748, mask: 0.2418312430381775 ===================
epoch no : 2, batch no : 95, total loss : 0.4350231885910034,  classifier :0.06375090777873993, mask: 0.1836206018924713 ===================
epoch no : 2, batch no : 96, total loss : 0.3929533064365387,  classifier :0.04800423979759216, mask: 0.15625545382499695 ===================
epoch no : 2, batch no : 97, total loss : 0.4072794020175934,  classifier :0.045756783336400986, mask: 0.15857160091400146 ===================
epoch no : 2, batch no : 98, total loss : 0.4688650667667389,  classifier :0.0631786361336708, mask: 0.18524324893951416 ===================
epoch no : 2, batch no : 99, total loss : 0.4304368197917938,  classifier :0.05397346243262291, mask: 0.15029479563236237 ===================
epoch no : 2, batch no : 100, total loss : 0.4875883460044861,  classifier :0.07058759778738022, mask: 0.1723124384880066 ===================
epoch no : 2, batch no : 101, total loss : 0.39922022819519043,  classifier :0.06187976151704788, mask: 0.14875821769237518 ===================
epoch no : 2, batch no : 102, total loss : 0.27772995829582214,  classifier :0.04312700033187866, mask: 0.10040000081062317 ===================
epoch no : 2, batch no : 103, total loss : 0.42830631136894226,  classifier :0.06674769520759583, mask: 0.1582137495279312 ===================
epoch no : 2, batch no : 104, total loss : 0.5236627459526062,  classifier :0.06317470222711563, mask: 0.20718364417552948 ===================
epoch no : 2, batch no : 105, total loss : 0.45543116331100464,  classifier :0.06778240948915482, mask: 0.13933242857456207 ===================
epoch no : 2, batch no : 106, total loss : 0.4329771399497986,  classifier :0.06842710822820663, mask: 0.15830837190151215 ===================
epoch no : 2, batch no : 107, total loss : 0.33974403142929077,  classifier :0.05594737082719803, mask: 0.11382117122411728 ===================
epoch no : 2, batch no : 108, total loss : 0.4176974892616272,  classifier :0.05552540719509125, mask: 0.193688303232193 ===================
epoch no : 2, batch no : 109, total loss : 0.45133116841316223,  classifier :0.05295708775520325, mask: 0.16678546369075775 ===================
epoch no : 2, batch no : 110, total loss : 0.3548928201198578,  classifier :0.04700938239693642, mask: 0.13956443965435028 ===================
epoch no : 2, batch no : 111, total loss : 0.3801701068878174,  classifier :0.04778124392032623, mask: 0.14597457647323608 ===================
epoch no : 2, batch no : 112, total loss : 0.32125866413116455,  classifier :0.04828128218650818, mask: 0.1256873905658722 ===================
epoch no : 2, batch no : 113, total loss : 0.5220783948898315,  classifier :0.056539177894592285, mask: 0.20335587859153748 ===================
epoch no : 2, batch no : 114, total loss : 0.41146308183670044,  classifier :0.05987367406487465, mask: 0.14729076623916626 ===================
epoch no : 2, batch no : 115, total loss : 0.35270631313323975,  classifier :0.06115023046731949, mask: 0.10082142055034637 ===================
epoch no : 2, batch no : 116, total loss : 0.4672606289386749,  classifier :0.05326726660132408, mask: 0.20587043464183807 ===================
epoch no : 2, batch no : 117, total loss : 0.4293603003025055,  classifier :0.058961912989616394, mask: 0.1803368777036667 ===================
epoch no : 2, batch no : 118, total loss : 0.4123517870903015,  classifier :0.04679996892809868, mask: 0.1792430579662323 ===================
epoch no : 2, batch no : 119, total loss : 0.4159142076969147,  classifier :0.05846257135272026, mask: 0.17341606318950653 ===================
epoch no : 2, batch no : 120, total loss : 0.40168508887290955,  classifier :0.0503409206867218, mask: 0.1746382713317871 ===================
epoch no : 2, batch no : 121, total loss : 0.35131365060806274,  classifier :0.04936373978853226, mask: 0.11988861113786697 ===================
epoch no : 2, batch no : 122, total loss : 0.3538467288017273,  classifier :0.0508112870156765, mask: 0.15007926523685455 ===================
epoch no : 2, batch no : 123, total loss : 0.4190646708011627,  classifier :0.045833658427000046, mask: 0.16138434410095215 ===================
epoch no : 2, batch no : 124, total loss : 0.5246541500091553,  classifier :0.06296341866254807, mask: 0.1969158798456192 ===================
epoch no : 2, batch no : 125, total loss : 0.3816302418708801,  classifier :0.05481812730431557, mask: 0.14553168416023254 ===================
epoch no : 2, batch no : 126, total loss : 0.4133886396884918,  classifier :0.049205731600522995, mask: 0.1931200474500656 ===================
epoch no : 2, batch no : 127, total loss : 0.5380411148071289,  classifier :0.061644699424505234, mask: 0.22063715755939484 ===================
epoch no : 2, batch no : 128, total loss : 0.6343865990638733,  classifier :0.06005704402923584, mask: 0.22740082442760468 ===================
epoch no : 2, batch no : 129, total loss : 0.41580674052238464,  classifier :0.048446595668792725, mask: 0.14649976789951324 ===================
epoch no : 2, batch no : 130, total loss : 0.3728516697883606,  classifier :0.06414555013179779, mask: 0.1415158063173294 ===================
epoch no : 2, batch no : 131, total loss : 0.31540077924728394,  classifier :0.045369360595941544, mask: 0.12260258942842484 ===================
epoch no : 2, batch no : 132, total loss : 0.4691182076931,  classifier :0.07566192001104355, mask: 0.18458783626556396 ===================
epoch no : 2, batch no : 133, total loss : 0.3684132695198059,  classifier :0.06369093805551529, mask: 0.13499173521995544 ===================
epoch no : 2, batch no : 134, total loss : 0.4830988943576813,  classifier :0.07199513912200928, mask: 0.20609590411186218 ===================
epoch no : 2, batch no : 135, total loss : 0.4869878590106964,  classifier :0.07734891027212143, mask: 0.1854032576084137 ===================
epoch no : 2, batch no : 136, total loss : 0.388070672750473,  classifier :0.05977288633584976, mask: 0.14680227637290955 ===================
epoch no : 2, batch no : 137, total loss : 0.42176443338394165,  classifier :0.057858798652887344, mask: 0.16417351365089417 ===================
epoch no : 2, batch no : 138, total loss : 0.3752976655960083,  classifier :0.07629644870758057, mask: 0.1499997228384018 ===================
epoch no : 2, batch no : 139, total loss : 0.4451947808265686,  classifier :0.06654281169176102, mask: 0.17247073352336884 ===================
epoch no : 2, batch no : 140, total loss : 0.505446195602417,  classifier :0.06590976566076279, mask: 0.16007038950920105 ===================
epoch no : 2, batch no : 141, total loss : 0.4526439905166626,  classifier :0.06646568328142166, mask: 0.17599813640117645 ===================
epoch no : 2, batch no : 142, total loss : 0.41325655579566956,  classifier :0.06780107319355011, mask: 0.135935440659523 ===================
epoch no : 2, batch no : 143, total loss : 0.32664042711257935,  classifier :0.0488881878554821, mask: 0.1349051296710968 ===================
epoch no : 2, batch no : 144, total loss : 0.3960653841495514,  classifier :0.07159410417079926, mask: 0.1429114192724228 ===================
epoch no : 2, batch no : 145, total loss : 0.4661030173301697,  classifier :0.06691603362560272, mask: 0.1483861654996872 ===================
epoch no : 2, batch no : 146, total loss : 0.34438052773475647,  classifier :0.04901949688792229, mask: 0.14685054123401642 ===================
epoch no : 2, batch no : 147, total loss : 0.3571385145187378,  classifier :0.04837850108742714, mask: 0.1410125494003296 ===================
epoch no : 2, batch no : 148, total loss : 0.3405643403530121,  classifier :0.05582452192902565, mask: 0.12058571726083755 ===================
epoch no : 2, batch no : 149, total loss : 0.49910470843315125,  classifier :0.05624636262655258, mask: 0.1852462738752365 ===================
epoch no : 2, batch no : 150, total loss : 0.416606605052948,  classifier :0.049942634999752045, mask: 0.1407434344291687 ===================
epoch no : 2, batch no : 151, total loss : 0.4152475595474243,  classifier :0.051238734275102615, mask: 0.13248714804649353 ===================
epoch no : 2, batch no : 152, total loss : 0.34472328424453735,  classifier :0.057821307331323624, mask: 0.1304049789905548 ===================
epoch no : 2, batch no : 153, total loss : 0.4934159219264984,  classifier :0.05224916711449623, mask: 0.22795575857162476 ===================
epoch no : 2, batch no : 154, total loss : 0.3383713662624359,  classifier :0.04910795018076897, mask: 0.1266370266675949 ===================
epoch no : 2, batch no : 155, total loss : 0.38374099135398865,  classifier :0.054854683578014374, mask: 0.15348942577838898 ===================
epoch no : 2, batch no : 156, total loss : 0.48180440068244934,  classifier :0.05208510905504227, mask: 0.22037401795387268 ===================
epoch no : 2, batch no : 157, total loss : 0.41543832421302795,  classifier :0.04710986837744713, mask: 0.14265015721321106 ===================
epoch no : 2, batch no : 158, total loss : 0.3616098463535309,  classifier :0.06767027825117111, mask: 0.1391497105360031 ===================
epoch no : 2, batch no : 159, total loss : 0.40029942989349365,  classifier :0.0442570336163044, mask: 0.16080312430858612 ===================
epoch no : 2, batch no : 160, total loss : 0.47372210025787354,  classifier :0.05737485736608505, mask: 0.18538175523281097 ===================
epoch no : 2, batch no : 161, total loss : 0.5001376271247864,  classifier :0.0703125149011612, mask: 0.2208576649427414 ===================
epoch no : 2, batch no : 162, total loss : 0.4138652980327606,  classifier :0.05330576002597809, mask: 0.16590577363967896 ===================
epoch no : 2, batch no : 163, total loss : 0.47144192457199097,  classifier :0.04399453103542328, mask: 0.17685678601264954 ===================
epoch no : 2, batch no : 164, total loss : 0.41875746846199036,  classifier :0.04642540216445923, mask: 0.16465650498867035 ===================
epoch no : 2, batch no : 165, total loss : 0.3706408739089966,  classifier :0.05551016703248024, mask: 0.14895887672901154 ===================
epoch no : 2, batch no : 166, total loss : 0.4241100549697876,  classifier :0.06057601794600487, mask: 0.1558099389076233 ===================
epoch no : 2, batch no : 167, total loss : 0.44133269786834717,  classifier :0.07315658032894135, mask: 0.17563867568969727 ===================
epoch no : 2, batch no : 168, total loss : 0.4041231870651245,  classifier :0.04976226016879082, mask: 0.14280077815055847 ===================
epoch no : 2, batch no : 169, total loss : 0.4559367001056671,  classifier :0.058959055691957474, mask: 0.145218625664711 ===================
epoch no : 2, batch no : 170, total loss : 0.35488221049308777,  classifier :0.06010141968727112, mask: 0.13923993706703186 ===================
epoch no : 2, batch no : 171, total loss : 0.38464128971099854,  classifier :0.05114366486668587, mask: 0.1375107765197754 ===================
epoch no : 2, batch no : 172, total loss : 0.43677425384521484,  classifier :0.05311531573534012, mask: 0.18699981272220612 ===================
epoch no : 2, batch no : 173, total loss : 0.45071524381637573,  classifier :0.044935308396816254, mask: 0.16645896434783936 ===================
epoch no : 2, batch no : 174, total loss : 0.3673448860645294,  classifier :0.054518796503543854, mask: 0.14641696214675903 ===================
epoch no : 2, batch no : 175, total loss : 0.5446578860282898,  classifier :0.049849119037389755, mask: 0.23972058296203613 ===================
epoch no : 2, batch no : 176, total loss : 0.3752089738845825,  classifier :0.051085300743579865, mask: 0.13992884755134583 ===================
epoch no : 2, batch no : 177, total loss : 0.44671353697776794,  classifier :0.04916222766041756, mask: 0.17418643832206726 ===================
epoch no : 2, batch no : 178, total loss : 0.40115535259246826,  classifier :0.051154974848032, mask: 0.1493031233549118 ===================
epoch no : 2, batch no : 179, total loss : 0.40462589263916016,  classifier :0.05643273890018463, mask: 0.18349812924861908 ===================
epoch no : 2, batch no : 180, total loss : 0.442219078540802,  classifier :0.04105906933546066, mask: 0.18649935722351074 ===================
epoch no : 2, batch no : 181, total loss : 0.3553823232650757,  classifier :0.04582881182432175, mask: 0.1394064724445343 ===================
epoch no : 2, batch no : 182, total loss : 0.36869168281555176,  classifier :0.0527619943022728, mask: 0.12792815268039703 ===================
epoch no : 2, batch no : 183, total loss : 0.4110060930252075,  classifier :0.07699987292289734, mask: 0.13467466831207275 ===================
epoch no : 2, batch no : 184, total loss : 0.425614595413208,  classifier :0.07247608155012131, mask: 0.1591443568468094 ===================
epoch no : 2, batch no : 185, total loss : 0.39085838198661804,  classifier :0.039657533168792725, mask: 0.15328513085842133 ===================
epoch no : 2, batch no : 186, total loss : 0.46470749378204346,  classifier :0.05521779507398605, mask: 0.17940440773963928 ===================
epoch no : 2, batch no : 187, total loss : 0.463864803314209,  classifier :0.06686069071292877, mask: 0.15346524119377136 ===================
epoch no : 2, batch no : 188, total loss : 0.3476428985595703,  classifier :0.03548671677708626, mask: 0.16464868187904358 ===================
epoch no : 2, batch no : 189, total loss : 0.3330633342266083,  classifier :0.04702557250857353, mask: 0.11948521435260773 ===================
epoch no : 2, batch no : 190, total loss : 0.346125066280365,  classifier :0.040493857115507126, mask: 0.12272165715694427 ===================
epoch no : 2, batch no : 191, total loss : 0.39174753427505493,  classifier :0.058635592460632324, mask: 0.1371140331029892 ===================
epoch no : 2, batch no : 192, total loss : 0.43814659118652344,  classifier :0.045323584228754044, mask: 0.17671960592269897 ===================
epoch no : 2, batch no : 193, total loss : 0.3678504228591919,  classifier :0.060659002512693405, mask: 0.17035767436027527 ===================
epoch no : 2, batch no : 194, total loss : 0.3368043005466461,  classifier :0.052765052765607834, mask: 0.13481354713439941 ===================
epoch no : 2, batch no : 195, total loss : 0.31234148144721985,  classifier :0.04930024966597557, mask: 0.11935985833406448 ===================
epoch no : 2, batch no : 196, total loss : 0.40856078267097473,  classifier :0.05363395810127258, mask: 0.13748183846473694 ===================
epoch no : 2, batch no : 197, total loss : 0.3309754431247711,  classifier :0.045191820710897446, mask: 0.12285327911376953 ===================
epoch no : 2, batch no : 198, total loss : 0.5338237285614014,  classifier :0.0663122907280922, mask: 0.21056760847568512 ===================
epoch no : 2, batch no : 199, total loss : 0.5830748677253723,  classifier :0.07412020862102509, mask: 0.19188806414604187 ===================
epoch no : 2, batch no : 200, total loss : 0.5155523419380188,  classifier :0.07069266587495804, mask: 0.2324451506137848 ===================
epoch no : 2, batch no : 201, total loss : 0.42550772428512573,  classifier :0.06756312400102615, mask: 0.16386210918426514 ===================
epoch no : 2, batch no : 202, total loss : 0.46737128496170044,  classifier :0.05277260020375252, mask: 0.2134973704814911 ===================
epoch no : 2, batch no : 203, total loss : 0.35601747035980225,  classifier :0.054934464395046234, mask: 0.1190788596868515 ===================
epoch no : 2, batch no : 204, total loss : 0.33644652366638184,  classifier :0.0475260354578495, mask: 0.12857002019882202 ===================
epoch no : 2, batch no : 205, total loss : 0.329792857170105,  classifier :0.053501714020967484, mask: 0.11902657896280289 ===================
epoch no : 2, batch no : 206, total loss : 0.36236706376075745,  classifier :0.0589781329035759, mask: 0.12626264989376068 ===================
epoch no : 2, batch no : 207, total loss : 0.35747602581977844,  classifier :0.05023326724767685, mask: 0.1366545557975769 ===================
epoch no : 2, batch no : 208, total loss : 0.41689351201057434,  classifier :0.08200670778751373, mask: 0.15148918330669403 ===================
epoch no : 2, batch no : 209, total loss : 0.5060451030731201,  classifier :0.067927785217762, mask: 0.18171945214271545 ===================
epoch no : 2, batch no : 210, total loss : 0.4486015737056732,  classifier :0.059164222329854965, mask: 0.18230733275413513 ===================
epoch no : 2, batch no : 211, total loss : 0.3889247179031372,  classifier :0.048364780843257904, mask: 0.15879829227924347 ===================
epoch no : 2, batch no : 212, total loss : 0.3741055428981781,  classifier :0.03628670424222946, mask: 0.133392333984375 ===================
epoch no : 2, batch no : 213, total loss : 0.3966939449310303,  classifier :0.055821504443883896, mask: 0.15297871828079224 ===================
epoch no : 2, batch no : 214, total loss : 0.3302725553512573,  classifier :0.05002843216061592, mask: 0.143337219953537 ===================
epoch no : 2, batch no : 215, total loss : 0.4475288987159729,  classifier :0.050118304789066315, mask: 0.18059170246124268 ===================
epoch no : 2, batch no : 216, total loss : 0.33838823437690735,  classifier :0.05270790681242943, mask: 0.11222351342439651 ===================
epoch no : 2, batch no : 217, total loss : 0.43884509801864624,  classifier :0.061584193259477615, mask: 0.1541256457567215 ===================
epoch no : 2, batch no : 218, total loss : 0.3079138994216919,  classifier :0.04988321661949158, mask: 0.10806000977754593 ===================
epoch no : 2, batch no : 219, total loss : 0.35045626759529114,  classifier :0.04205452650785446, mask: 0.10914362967014313 ===================
epoch no : 2, batch no : 220, total loss : 0.39851707220077515,  classifier :0.06353893876075745, mask: 0.14639374613761902 ===================
epoch no : 2, batch no : 221, total loss : 0.3062146306037903,  classifier :0.04831032082438469, mask: 0.12808866798877716 ===================
epoch no : 2, batch no : 222, total loss : 0.3200705349445343,  classifier :0.052925772964954376, mask: 0.13256974518299103 ===================
epoch no : 2, batch no : 223, total loss : 0.32445913553237915,  classifier :0.04099537059664726, mask: 0.1181897446513176 ===================
epoch no : 2, batch no : 224, total loss : 0.44831573963165283,  classifier :0.05834231898188591, mask: 0.1600089818239212 ===================
epoch no : 2, batch no : 225, total loss : 0.4295061230659485,  classifier :0.06604044139385223, mask: 0.15935252606868744 ===================
epoch no : 2, batch no : 226, total loss : 0.38133254647254944,  classifier :0.0428028330206871, mask: 0.16163793206214905 ===================
epoch no : 2, batch no : 227, total loss : 0.3504139482975006,  classifier :0.042798224836587906, mask: 0.13839878141880035 ===================
epoch no : 2, batch no : 228, total loss : 0.5038958787918091,  classifier :0.06535430252552032, mask: 0.1607392430305481 ===================
epoch no : 2, batch no : 229, total loss : 0.4280744791030884,  classifier :0.06281635165214539, mask: 0.13921460509300232 ===================
epoch no : 2, batch no : 230, total loss : 0.3219655454158783,  classifier :0.06019219383597374, mask: 0.11166321486234665 ===================
epoch no : 2, batch no : 231, total loss : 0.42880979180336,  classifier :0.0501052662730217, mask: 0.14077691733837128 ===================
epoch no : 2, batch no : 232, total loss : 0.40241068601608276,  classifier :0.04989389330148697, mask: 0.13849174976348877 ===================
epoch no : 2, batch no : 233, total loss : 0.3893733322620392,  classifier :0.057590048760175705, mask: 0.1327625811100006 ===================
epoch no : 2, batch no : 234, total loss : 0.40527084469795227,  classifier :0.05974460020661354, mask: 0.16006997227668762 ===================
epoch no : 2, batch no : 235, total loss : 0.4475700855255127,  classifier :0.043931759893894196, mask: 0.17950224876403809 ===================
epoch no : 2, batch no : 236, total loss : 0.3816073536872864,  classifier :0.057590190321207047, mask: 0.1513105034828186 ===================
epoch no : 2, batch no : 237, total loss : 0.3446158468723297,  classifier :0.04935138672590256, mask: 0.14047342538833618 ===================
epoch no : 2, batch no : 238, total loss : 0.44545426964759827,  classifier :0.04984262213110924, mask: 0.16493698954582214 ===================
epoch no : 2, batch no : 239, total loss : 0.4509275555610657,  classifier :0.07082316279411316, mask: 0.17018775641918182 ===================
epoch no : 2, batch no : 240, total loss : 0.4936169385910034,  classifier :0.05170327425003052, mask: 0.19849872589111328 ===================
epoch no : 2, batch no : 241, total loss : 0.3565785586833954,  classifier :0.04728091508150101, mask: 0.13693207502365112 ===================
epoch no : 2, batch no : 242, total loss : 0.36015585064888,  classifier :0.06655728816986084, mask: 0.1264873892068863 ===================
epoch no : 2, batch no : 243, total loss : 0.37300756573677063,  classifier :0.042710740119218826, mask: 0.1530475616455078 ===================
epoch no : 2, batch no : 244, total loss : 0.41083675622940063,  classifier :0.044695764780044556, mask: 0.171090766787529 ===================
epoch no : 2, batch no : 245, total loss : 0.4498786926269531,  classifier :0.04892348870635033, mask: 0.13895146548748016 ===================
epoch no : 2, batch no : 246, total loss : 0.4031296372413635,  classifier :0.05040270835161209, mask: 0.1478709578514099 ===================
epoch no : 2, batch no : 247, total loss : 0.50731360912323,  classifier :0.07394751161336899, mask: 0.15673859417438507 ===================
epoch no : 2, batch no : 248, total loss : 0.4837738573551178,  classifier :0.0689569041132927, mask: 0.1581968367099762 ===================
epoch no : 2, batch no : 249, total loss : 0.40050092339515686,  classifier :0.046816494315862656, mask: 0.16552449762821198 ===================
epoch no : 2, batch no : 250, total loss : 0.39286619424819946,  classifier :0.057539548724889755, mask: 0.1585191935300827 ===================
epoch no : 2, batch no : 251, total loss : 0.37772512435913086,  classifier :0.04404427483677864, mask: 0.18884336948394775 ===================
epoch no : 2, batch no : 252, total loss : 0.37228015065193176,  classifier :0.061644524335861206, mask: 0.14651891589164734 ===================
epoch no : 2, batch no : 253, total loss : 0.35922771692276,  classifier :0.04705388844013214, mask: 0.12642481923103333 ===================
epoch no : 2, batch no : 254, total loss : 0.3829526901245117,  classifier :0.04297156631946564, mask: 0.1947304606437683 ===================
epoch no : 2, batch no : 255, total loss : 0.4877561628818512,  classifier :0.05496755614876747, mask: 0.19188429415225983 ===================
epoch no : 2, batch no : 256, total loss : 0.4162392318248749,  classifier :0.04610155150294304, mask: 0.1470148116350174 ===================
epoch no : 2, batch no : 257, total loss : 0.3539510667324066,  classifier :0.05204049125313759, mask: 0.11795571446418762 ===================
epoch no : 2, batch no : 258, total loss : 0.37013915181159973,  classifier :0.046744588762521744, mask: 0.1685197651386261 ===================
epoch no : 2, batch no : 259, total loss : 0.4661986827850342,  classifier :0.0701361894607544, mask: 0.1419372409582138 ===================
epoch no : 2, batch no : 260, total loss : 0.5018071532249451,  classifier :0.05165112391114235, mask: 0.16701889038085938 ===================
epoch no : 2, batch no : 261, total loss : 0.3891672194004059,  classifier :0.0625934824347496, mask: 0.13743403553962708 ===================
epoch no : 2, batch no : 262, total loss : 0.40923774242401123,  classifier :0.0528290793299675, mask: 0.14680995047092438 ===================
epoch no : 2, batch no : 263, total loss : 0.3067111074924469,  classifier :0.04363282024860382, mask: 0.1113729253411293 ===================
epoch no : 2, batch no : 264, total loss : 0.31470465660095215,  classifier :0.05417827144265175, mask: 0.10023842751979828 ===================
epoch no : 2, batch no : 265, total loss : 0.3411500155925751,  classifier :0.04489852488040924, mask: 0.11879224330186844 ===================
epoch no : 2, batch no : 266, total loss : 0.3876054883003235,  classifier :0.05870587006211281, mask: 0.16120970249176025 ===================
epoch no : 2, batch no : 267, total loss : 0.3345237970352173,  classifier :0.06382805854082108, mask: 0.12193457037210464 ===================
epoch no : 2, batch no : 268, total loss : 0.4043166935443878,  classifier :0.05852290242910385, mask: 0.17813284695148468 ===================
epoch no : 2, batch no : 269, total loss : 0.4751339256763458,  classifier :0.06176447123289108, mask: 0.1753499060869217 ===================
epoch no : 2, batch no : 270, total loss : 0.3765948712825775,  classifier :0.056714706122875214, mask: 0.13078558444976807 ===================
epoch no : 2, batch no : 271, total loss : 0.3585773706436157,  classifier :0.04519934952259064, mask: 0.14839543402194977 ===================
epoch no : 2, batch no : 272, total loss : 0.5253790020942688,  classifier :0.07023540884256363, mask: 0.22095850110054016 ===================
epoch no : 2, batch no : 273, total loss : 0.38757777214050293,  classifier :0.048806481063365936, mask: 0.1712445616722107 ===================
epoch no : 2, batch no : 274, total loss : 0.378736674785614,  classifier :0.05596546083688736, mask: 0.1518578976392746 ===================
epoch no : 2, batch no : 275, total loss : 0.3725743889808655,  classifier :0.04407735913991928, mask: 0.13002775609493256 ===================
epoch no : 2, batch no : 276, total loss : 0.33635401725769043,  classifier :0.04299372807145119, mask: 0.14075326919555664 ===================
epoch no : 2, batch no : 277, total loss : 0.35578060150146484,  classifier :0.06212428957223892, mask: 0.13649746775627136 ===================
epoch no : 2, batch no : 278, total loss : 0.3727284073829651,  classifier :0.05755962058901787, mask: 0.15072035789489746 ===================
epoch no : 2, batch no : 279, total loss : 0.4268183708190918,  classifier :0.06187343969941139, mask: 0.17476412653923035 ===================
epoch no : 2, batch no : 280, total loss : 0.3306838572025299,  classifier :0.0591278001666069, mask: 0.11787329614162445 ===================
epoch no : 2, batch no : 281, total loss : 0.4348284900188446,  classifier :0.049719564616680145, mask: 0.17109346389770508 ===================
epoch no : 2, batch no : 282, total loss : 0.35555657744407654,  classifier :0.06017838418483734, mask: 0.12086229026317596 ===================
epoch no : 2, batch no : 283, total loss : 0.35438647866249084,  classifier :0.04880068823695183, mask: 0.13389942049980164 ===================
epoch no : 2, batch no : 284, total loss : 0.37692394852638245,  classifier :0.04750276729464531, mask: 0.13724975287914276 ===================
epoch no : 2, batch no : 285, total loss : 0.5589373111724854,  classifier :0.06356116384267807, mask: 0.21613699197769165 ===================
epoch no : 2, batch no : 286, total loss : 0.3775058388710022,  classifier :0.04921344667673111, mask: 0.16752977669239044 ===================
epoch no : 2, batch no : 287, total loss : 0.4040978252887726,  classifier :0.04519900679588318, mask: 0.15686608850955963 ===================
epoch no : 2, batch no : 288, total loss : 0.4501608908176422,  classifier :0.07278784364461899, mask: 0.16452659666538239 ===================
epoch no : 2, batch no : 289, total loss : 0.5348930358886719,  classifier :0.06903635710477829, mask: 0.17977705597877502 ===================
epoch no : 2, batch no : 290, total loss : 0.47770166397094727,  classifier :0.06524036079645157, mask: 0.15368080139160156 ===================
epoch no : 2, batch no : 291, total loss : 0.4400266408920288,  classifier :0.059454455971717834, mask: 0.14906397461891174 ===================
epoch no : 2, batch no : 292, total loss : 0.3930273652076721,  classifier :0.0633942261338234, mask: 0.16119030117988586 ===================
epoch no : 2, batch no : 293, total loss : 0.4384337365627289,  classifier :0.05153053626418114, mask: 0.1923423707485199 ===================
epoch no : 2, batch no : 294, total loss : 0.3396971821784973,  classifier :0.045747313648462296, mask: 0.1369975060224533 ===================
epoch no : 2, batch no : 295, total loss : 0.3785497844219208,  classifier :0.04134809225797653, mask: 0.1391703486442566 ===================
epoch no : 2, batch no : 296, total loss : 0.5222280025482178,  classifier :0.06707024574279785, mask: 0.19560471177101135 ===================
epoch no : 2, batch no : 297, total loss : 0.40711483359336853,  classifier :0.06118683144450188, mask: 0.13221271336078644 ===================
epoch no : 2, batch no : 298, total loss : 0.45754995942115784,  classifier :0.052229657769203186, mask: 0.16614089906215668 ===================
epoch no : 2, batch no : 299, total loss : 0.36427396535873413,  classifier :0.06074957549571991, mask: 0.1321239322423935 ===================
epoch no : 2, batch no : 300, total loss : 0.4616524279117584,  classifier :0.05412781611084938, mask: 0.12824279069900513 ===================
epoch no : 2, batch no : 301, total loss : 0.30548015236854553,  classifier :0.05422334000468254, mask: 0.10500280559062958 ===================
epoch no : 2, batch no : 302, total loss : 0.552413821220398,  classifier :0.05764095112681389, mask: 0.199754536151886 ===================
epoch no : 2, batch no : 303, total loss : 0.42424193024635315,  classifier :0.05013609305024147, mask: 0.1496400535106659 ===================
epoch no : 2, batch no : 304, total loss : 0.3832872211933136,  classifier :0.05751287192106247, mask: 0.13032479584217072 ===================
epoch no : 2, batch no : 305, total loss : 0.41033634543418884,  classifier :0.048371512442827225, mask: 0.15012642741203308 ===================
epoch no : 2, batch no : 306, total loss : 0.41759738326072693,  classifier :0.04155222326517105, mask: 0.16836172342300415 ===================
epoch no : 2, batch no : 307, total loss : 0.3759276866912842,  classifier :0.05535336956381798, mask: 0.14034390449523926 ===================
epoch no : 2, batch no : 308, total loss : 0.4016081392765045,  classifier :0.0571143701672554, mask: 0.1375143975019455 ===================
epoch no : 2, batch no : 309, total loss : 0.40079793334007263,  classifier :0.05425749719142914, mask: 0.1410207748413086 ===================
epoch no : 2, batch no : 310, total loss : 0.36378398537635803,  classifier :0.04541414976119995, mask: 0.15080326795578003 ===================
epoch no : 2, batch no : 311, total loss : 0.3495500683784485,  classifier :0.052322130650281906, mask: 0.12123271822929382 ===================
epoch no : 2, batch no : 312, total loss : 0.440321147441864,  classifier :0.059747885912656784, mask: 0.14952045679092407 ===================
epoch no : 2, batch no : 313, total loss : 0.5359734892845154,  classifier :0.0890461653470993, mask: 0.19753238558769226 ===================
epoch no : 2, batch no : 314, total loss : 0.38092413544654846,  classifier :0.057338666170835495, mask: 0.1268255114555359 ===================
epoch no : 2, batch no : 315, total loss : 0.3680339455604553,  classifier :0.06439840793609619, mask: 0.14400987327098846 ===================
epoch no : 2, batch no : 316, total loss : 0.40733852982521057,  classifier :0.06116286292672157, mask: 0.13432574272155762 ===================
epoch no : 2, batch no : 317, total loss : 0.5075463056564331,  classifier :0.07086974382400513, mask: 0.18707652390003204 ===================
epoch no : 2, batch no : 318, total loss : 0.3736809492111206,  classifier :0.0487191304564476, mask: 0.14952895045280457 ===================
epoch no : 2, batch no : 319, total loss : 0.45782923698425293,  classifier :0.04927842319011688, mask: 0.1535247266292572 ===================
epoch no : 2, batch no : 320, total loss : 0.30664893984794617,  classifier :0.056550413370132446, mask: 0.13031987845897675 ===================
epoch no : 2, batch no : 321, total loss : 0.41692131757736206,  classifier :0.07343447953462601, mask: 0.15900802612304688 ===================
epoch no : 2, batch no : 322, total loss : 0.3727664649486542,  classifier :0.05000247806310654, mask: 0.12876752018928528 ===================
epoch no : 2, batch no : 323, total loss : 0.3962462544441223,  classifier :0.05672568827867508, mask: 0.14573992788791656 ===================
epoch no : 2, batch no : 324, total loss : 0.36734649538993835,  classifier :0.04293311759829521, mask: 0.14454254508018494 ===================
epoch no : 2, batch no : 325, total loss : 0.36377227306365967,  classifier :0.04782767966389656, mask: 0.12173967063426971 ===================
epoch no : 2, batch no : 326, total loss : 0.34072020649909973,  classifier :0.06339910626411438, mask: 0.12480659782886505 ===================
epoch no : 2, batch no : 327, total loss : 0.39729952812194824,  classifier :0.044918857514858246, mask: 0.15471996366977692 ===================
epoch no : 2, batch no : 328, total loss : 0.3780880570411682,  classifier :0.04645616188645363, mask: 0.12509959936141968 ===================
epoch no : 2, batch no : 329, total loss : 0.3377251625061035,  classifier :0.04982417821884155, mask: 0.11253837496042252 ===================
epoch no : 2, batch no : 330, total loss : 0.4272235929965973,  classifier :0.054853130131959915, mask: 0.14829769730567932 ===================
epoch no : 2, batch no : 331, total loss : 0.4138032793998718,  classifier :0.06878753751516342, mask: 0.125387042760849 ===================
epoch no : 2, batch no : 332, total loss : 0.5161494016647339,  classifier :0.046923261135816574, mask: 0.19727987051010132 ===================
epoch no : 2, batch no : 333, total loss : 0.35049593448638916,  classifier :0.05224165320396423, mask: 0.12489042431116104 ===================
epoch no : 2, batch no : 334, total loss : 0.39449194073677063,  classifier :0.05291583389043808, mask: 0.13660143315792084 ===================
epoch no : 2, batch no : 335, total loss : 0.43279340863227844,  classifier :0.059965647757053375, mask: 0.15989887714385986 ===================
epoch no : 2, batch no : 336, total loss : 0.37422841787338257,  classifier :0.0649525448679924, mask: 0.11078470945358276 ===================
epoch no : 2, batch no : 337, total loss : 0.3382115662097931,  classifier :0.05005116015672684, mask: 0.12762238085269928 ===================
epoch no : 2, batch no : 338, total loss : 0.4536752700805664,  classifier :0.07725077122449875, mask: 0.17331355810165405 ===================
epoch no : 2, batch no : 339, total loss : 0.43172040581703186,  classifier :0.048343561589717865, mask: 0.17427870631217957 ===================
epoch no : 2, batch no : 340, total loss : 0.3384875953197479,  classifier :0.04372062534093857, mask: 0.15111739933490753 ===================
epoch no : 2, batch no : 341, total loss : 0.3514159321784973,  classifier :0.03736007958650589, mask: 0.14129549264907837 ===================
epoch no : 2, batch no : 342, total loss : 0.41268640756607056,  classifier :0.06484996527433395, mask: 0.1450692117214203 ===================
epoch no : 2, batch no : 343, total loss : 0.3941236734390259,  classifier :0.06015003100037575, mask: 0.15401236712932587 ===================
epoch no : 2, batch no : 344, total loss : 0.3606792390346527,  classifier :0.05440960451960564, mask: 0.14452216029167175 ===================
epoch no : 2, batch no : 345, total loss : 0.3405054807662964,  classifier :0.051512859761714935, mask: 0.12453582882881165 ===================
epoch no : 2, batch no : 346, total loss : 0.4200076162815094,  classifier :0.05813571810722351, mask: 0.15656529366970062 ===================
epoch no : 2, batch no : 347, total loss : 0.37274783849716187,  classifier :0.06028827652335167, mask: 0.12843503057956696 ===================
epoch no : 2, batch no : 348, total loss : 0.35519471764564514,  classifier :0.03823059797286987, mask: 0.13673335313796997 ===================
epoch no : 2, batch no : 349, total loss : 0.4003799557685852,  classifier :0.054242804646492004, mask: 0.14816692471504211 ===================
epoch no : 2, batch no : 350, total loss : 0.37472790479660034,  classifier :0.05227714776992798, mask: 0.13573206961154938 ===================
epoch no : 2, batch no : 351, total loss : 0.45055657625198364,  classifier :0.054149556905031204, mask: 0.14145386219024658 ===================
epoch no : 2, batch no : 352, total loss : 0.3582834303379059,  classifier :0.0501440092921257, mask: 0.13844434916973114 ===================
epoch no : 2, batch no : 353, total loss : 0.35244348645210266,  classifier :0.049436021596193314, mask: 0.1280767321586609 ===================
epoch no : 2, batch no : 354, total loss : 0.6343355774879456,  classifier :0.05628659203648567, mask: 0.2723388671875 ===================
epoch no : 2, batch no : 355, total loss : 0.8019115924835205,  classifier :0.07007328420877457, mask: 0.4381340444087982 ===================
epoch no : 2, batch no : 356, total loss : 0.583202064037323,  classifier :0.06785794347524643, mask: 0.2709901034832001 ===================
epoch no : 2, batch no : 357, total loss : 0.3513031005859375,  classifier :0.05303437262773514, mask: 0.15571698546409607 ===================
epoch no : 2, batch no : 358, total loss : 0.3769720196723938,  classifier :0.04978115111589432, mask: 0.1204313188791275 ===================
epoch no : 2, batch no : 359, total loss : 0.36694595217704773,  classifier :0.052765216678380966, mask: 0.1459760069847107 ===================
epoch no : 2, batch no : 360, total loss : 0.3379027843475342,  classifier :0.04168379306793213, mask: 0.12529198825359344 ===================
epoch no : 2, batch no : 361, total loss : 0.3652622699737549,  classifier :0.058083079755306244, mask: 0.1490328311920166 ===================
epoch no : 2, batch no : 362, total loss : 0.4046228229999542,  classifier :0.051246561110019684, mask: 0.15431854128837585 ===================
epoch no : 2, batch no : 363, total loss : 0.390747994184494,  classifier :0.0642855316400528, mask: 0.1513199657201767 ===================
epoch no : 2, batch no : 364, total loss : 0.5487485527992249,  classifier :0.06429008394479752, mask: 0.24703286588191986 ===================
epoch no : 2, batch no : 365, total loss : 0.37087443470954895,  classifier :0.05718378350138664, mask: 0.13546514511108398 ===================
epoch no : 2, batch no : 366, total loss : 0.32853633165359497,  classifier :0.03785543143749237, mask: 0.14317573606967926 ===================
epoch no : 2, batch no : 367, total loss : 0.351452112197876,  classifier :0.04192392900586128, mask: 0.1364169865846634 ===================
epoch no : 2, batch no : 368, total loss : 0.32370802760124207,  classifier :0.05571838468313217, mask: 0.10509487241506577 ===================
epoch no : 2, batch no : 369, total loss : 0.34837400913238525,  classifier :0.04179065302014351, mask: 0.1264263391494751 ===================
epoch no : 2, batch no : 370, total loss : 0.492911696434021,  classifier :0.08449957519769669, mask: 0.18394587934017181 ===================
epoch no : 2, batch no : 371, total loss : 0.36721450090408325,  classifier :0.046889349818229675, mask: 0.1291102021932602 ===================
epoch no : 2, batch no : 372, total loss : 0.3909723162651062,  classifier :0.04716150462627411, mask: 0.15185414254665375 ===================
epoch no : 2, batch no : 373, total loss : 0.374590665102005,  classifier :0.052147284150123596, mask: 0.1649811565876007 ===================
epoch no : 2, batch no : 374, total loss : 0.40305960178375244,  classifier :0.04894687980413437, mask: 0.1467771977186203 ===================
epoch no : 2, batch no : 375, total loss : 0.3936169445514679,  classifier :0.053654130548238754, mask: 0.13948218524456024 ===================
epoch no : 2, batch no : 376, total loss : 0.3260228931903839,  classifier :0.056920990347862244, mask: 0.13581761717796326 ===================
epoch no : 2, batch no : 377, total loss : 0.3154827356338501,  classifier :0.047964442521333694, mask: 0.12900522351264954 ===================
epoch no : 2, batch no : 378, total loss : 0.34290075302124023,  classifier :0.05317189544439316, mask: 0.1334562450647354 ===================
epoch no : 2, batch no : 379, total loss : 0.3040986657142639,  classifier :0.04788912087678909, mask: 0.11628708243370056 ===================
epoch no : 2, batch no : 380, total loss : 0.32513242959976196,  classifier :0.052974190562963486, mask: 0.11250726878643036 ===================
epoch no : 2, batch no : 381, total loss : 0.3157152831554413,  classifier :0.03802529349923134, mask: 0.11829731613397598 ===================
epoch no : 2, batch no : 382, total loss : 0.4212939441204071,  classifier :0.03691994771361351, mask: 0.22341465950012207 ===================
epoch no : 2, batch no : 383, total loss : 0.358604371547699,  classifier :0.044067785143852234, mask: 0.1326940804719925 ===================
epoch no : 2, batch no : 384, total loss : 0.38026806712150574,  classifier :0.055657241493463516, mask: 0.14148105680942535 ===================
epoch no : 2, batch no : 385, total loss : 0.396562397480011,  classifier :0.04662155732512474, mask: 0.16991476714611053 ===================
epoch no : 2, batch no : 386, total loss : 0.38030654191970825,  classifier :0.057617247104644775, mask: 0.1397065818309784 ===================
epoch no : 2, batch no : 387, total loss : 0.33669450879096985,  classifier :0.038946229964494705, mask: 0.14301981031894684 ===================
epoch no : 2, batch no : 388, total loss : 0.3201608657836914,  classifier :0.048187799751758575, mask: 0.11974254250526428 ===================
epoch no : 2, batch no : 389, total loss : 0.34782981872558594,  classifier :0.05484801158308983, mask: 0.1352849304676056 ===================
epoch no : 2, batch no : 390, total loss : 0.30913078784942627,  classifier :0.05105749890208244, mask: 0.11676032096147537 ===================
epoch no : 2, batch no : 391, total loss : 0.4150996506214142,  classifier :0.06887485086917877, mask: 0.14876551926136017 ===================
epoch no : 2, batch no : 392, total loss : 0.3323286771774292,  classifier :0.04503665119409561, mask: 0.13586021959781647 ===================
epoch no : 2, batch no : 393, total loss : 0.36457839608192444,  classifier :0.05472550541162491, mask: 0.15033957362174988 ===================
epoch no : 2, batch no : 394, total loss : 0.3296692967414856,  classifier :0.05247883126139641, mask: 0.1081659346818924 ===================
epoch no : 2, batch no : 395, total loss : 0.33868658542633057,  classifier :0.03636498376727104, mask: 0.14577758312225342 ===================
epoch no : 2, batch no : 396, total loss : 0.3405047655105591,  classifier :0.04956301301717758, mask: 0.1379656046628952 ===================
epoch no : 2, batch no : 397, total loss : 0.4460183382034302,  classifier :0.05355360358953476, mask: 0.17620977759361267 ===================
epoch no : 2, batch no : 398, total loss : 0.4702754616737366,  classifier :0.06513451784849167, mask: 0.1961933970451355 ===================
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch no : 3, batch no : 0, total loss : 0.39824581146240234,  classifier :0.050747573375701904, mask: 0.144637793302536 ===================
epoch no : 3, batch no : 1, total loss : 0.2673918604850769,  classifier :0.04201037064194679, mask: 0.10345285385847092 ===================
epoch no : 3, batch no : 2, total loss : 0.36626115441322327,  classifier :0.037227947264909744, mask: 0.14439673721790314 ===================
epoch no : 3, batch no : 3, total loss : 0.4241894483566284,  classifier :0.04291899502277374, mask: 0.16512364149093628 ===================
epoch no : 3, batch no : 4, total loss : 0.4749342203140259,  classifier :0.048469144850969315, mask: 0.1856701821088791 ===================
epoch no : 3, batch no : 5, total loss : 0.402496874332428,  classifier :0.04414833337068558, mask: 0.16015948355197906 ===================
epoch no : 3, batch no : 6, total loss : 0.3191508650779724,  classifier :0.05891004577279091, mask: 0.12526574730873108 ===================
epoch no : 3, batch no : 7, total loss : 0.3606492578983307,  classifier :0.04661804437637329, mask: 0.1315891444683075 ===================
epoch no : 3, batch no : 8, total loss : 0.28912460803985596,  classifier :0.05088027939200401, mask: 0.10843164473772049 ===================
epoch no : 3, batch no : 9, total loss : 0.36449095606803894,  classifier :0.07284128665924072, mask: 0.12412510067224503 ===================
epoch no : 3, batch no : 10, total loss : 0.4353014826774597,  classifier :0.06350047141313553, mask: 0.14350713789463043 ===================
epoch no : 3, batch no : 11, total loss : 0.37534409761428833,  classifier :0.04133593663573265, mask: 0.16126517951488495 ===================
epoch no : 3, batch no : 12, total loss : 0.32188835740089417,  classifier :0.04785938933491707, mask: 0.10067068785429001 ===================
epoch no : 3, batch no : 13, total loss : 0.40048444271087646,  classifier :0.05770029500126839, mask: 0.15429918467998505 ===================
epoch no : 3, batch no : 14, total loss : 0.3488599359989166,  classifier :0.04505214840173721, mask: 0.14714674651622772 ===================
epoch no : 3, batch no : 15, total loss : 0.28078901767730713,  classifier :0.03555319830775261, mask: 0.11689066886901855 ===================
epoch no : 3, batch no : 16, total loss : 0.34545743465423584,  classifier :0.04579818993806839, mask: 0.15215465426445007 ===================
epoch no : 3, batch no : 17, total loss : 0.4509446918964386,  classifier :0.050896018743515015, mask: 0.18188399076461792 ===================
epoch no : 3, batch no : 18, total loss : 0.4140532314777374,  classifier :0.04429185390472412, mask: 0.14124706387519836 ===================
epoch no : 3, batch no : 19, total loss : 0.4052415192127228,  classifier :0.04680758714675903, mask: 0.16198013722896576 ===================
epoch no : 3, batch no : 20, total loss : 0.30399447679519653,  classifier :0.046771466732025146, mask: 0.11204446107149124 ===================
epoch no : 3, batch no : 21, total loss : 0.44039246439933777,  classifier :0.07371246814727783, mask: 0.15375329554080963 ===================
epoch no : 3, batch no : 22, total loss : 0.3581041991710663,  classifier :0.0405467227101326, mask: 0.14431141316890717 ===================
epoch no : 3, batch no : 23, total loss : 0.33028966188430786,  classifier :0.05936504527926445, mask: 0.10535633563995361 ===================
epoch no : 3, batch no : 24, total loss : 0.3644043207168579,  classifier :0.05166491121053696, mask: 0.12596914172172546 ===================
epoch no : 3, batch no : 25, total loss : 0.4454604983329773,  classifier :0.061143435537815094, mask: 0.1394108533859253 ===================
epoch no : 3, batch no : 26, total loss : 0.3567914068698883,  classifier :0.03869280591607094, mask: 0.13789182901382446 ===================
epoch no : 3, batch no : 27, total loss : 0.37049466371536255,  classifier :0.04713863134384155, mask: 0.1465379297733307 ===================
epoch no : 3, batch no : 28, total loss : 0.38826239109039307,  classifier :0.0396856851875782, mask: 0.154488667845726 ===================
epoch no : 3, batch no : 29, total loss : 0.46851757168769836,  classifier :0.06006716191768646, mask: 0.16971354186534882 ===================
epoch no : 3, batch no : 30, total loss : 0.4197268784046173,  classifier :0.06108161807060242, mask: 0.1526615172624588 ===================
epoch no : 3, batch no : 31, total loss : 0.3579612374305725,  classifier :0.05234218388795853, mask: 0.14008447527885437 ===================
epoch no : 3, batch no : 32, total loss : 0.38243964314460754,  classifier :0.07764734327793121, mask: 0.10877630114555359 ===================
epoch no : 3, batch no : 33, total loss : 0.46589532494544983,  classifier :0.059402987360954285, mask: 0.20961198210716248 ===================
epoch no : 3, batch no : 34, total loss : 0.32453998923301697,  classifier :0.04495333135128021, mask: 0.12487972527742386 ===================
epoch no : 3, batch no : 35, total loss : 0.3947478234767914,  classifier :0.043209634721279144, mask: 0.1581725925207138 ===================
epoch no : 3, batch no : 36, total loss : 0.40267157554626465,  classifier :0.04816610738635063, mask: 0.16288341581821442 ===================
epoch no : 3, batch no : 37, total loss : 0.31148722767829895,  classifier :0.04336439445614815, mask: 0.11982344090938568 ===================
epoch no : 3, batch no : 38, total loss : 0.29825276136398315,  classifier :0.04545653238892555, mask: 0.11842717975378036 ===================
epoch no : 3, batch no : 39, total loss : 0.3396693468093872,  classifier :0.04011864215135574, mask: 0.131417378783226 ===================
epoch no : 3, batch no : 40, total loss : 0.3678933084011078,  classifier :0.04772396758198738, mask: 0.13664031028747559 ===================
epoch no : 3, batch no : 41, total loss : 0.38853925466537476,  classifier :0.044539473950862885, mask: 0.15189996361732483 ===================
epoch no : 3, batch no : 42, total loss : 0.31872156262397766,  classifier :0.048704273998737335, mask: 0.13114619255065918 ===================
epoch no : 3, batch no : 43, total loss : 0.35771963000297546,  classifier :0.044405095279216766, mask: 0.1372382640838623 ===================
epoch no : 3, batch no : 44, total loss : 0.30071091651916504,  classifier :0.034322161227464676, mask: 0.12078361958265305 ===================
epoch no : 3, batch no : 45, total loss : 0.36024680733680725,  classifier :0.05088789388537407, mask: 0.12832549214363098 ===================
epoch no : 3, batch no : 46, total loss : 0.37401583790779114,  classifier :0.051032911986112595, mask: 0.14954838156700134 ===================
epoch no : 3, batch no : 47, total loss : 0.3632134795188904,  classifier :0.07671260833740234, mask: 0.11600016802549362 ===================
epoch no : 3, batch no : 48, total loss : 0.43431249260902405,  classifier :0.06663242727518082, mask: 0.1554582267999649 ===================
epoch no : 3, batch no : 49, total loss : 0.5150072574615479,  classifier :0.04548225179314613, mask: 0.22328303754329681 ===================
epoch no : 3, batch no : 50, total loss : 0.43516474962234497,  classifier :0.056372061371803284, mask: 0.19331753253936768 ===================
epoch no : 3, batch no : 51, total loss : 0.3240300416946411,  classifier :0.040624551475048065, mask: 0.131570965051651 ===================
epoch no : 3, batch no : 52, total loss : 0.3634614944458008,  classifier :0.06505069136619568, mask: 0.13273312151432037 ===================
epoch no : 3, batch no : 53, total loss : 0.39330488443374634,  classifier :0.05120079591870308, mask: 0.15234477818012238 ===================
epoch no : 3, batch no : 54, total loss : 0.37378063797950745,  classifier :0.05503783002495766, mask: 0.13709190487861633 ===================
epoch no : 3, batch no : 55, total loss : 0.4190428555011749,  classifier :0.05958908051252365, mask: 0.17677776515483856 ===================
epoch no : 3, batch no : 56, total loss : 0.3823694884777069,  classifier :0.05959540605545044, mask: 0.1369774341583252 ===================
epoch no : 3, batch no : 57, total loss : 0.39885616302490234,  classifier :0.0365711972117424, mask: 0.16106918454170227 ===================
epoch no : 3, batch no : 58, total loss : 0.3573839068412781,  classifier :0.03623823821544647, mask: 0.16677597165107727 ===================
epoch no : 3, batch no : 59, total loss : 0.3759934902191162,  classifier :0.047676119953393936, mask: 0.16891196370124817 ===================
epoch no : 3, batch no : 60, total loss : 0.31769752502441406,  classifier :0.04324555769562721, mask: 0.12959803640842438 ===================
epoch no : 3, batch no : 61, total loss : 0.3894273340702057,  classifier :0.05404083430767059, mask: 0.15452492237091064 ===================
epoch no : 3, batch no : 62, total loss : 0.40755993127822876,  classifier :0.037951964884996414, mask: 0.16350187361240387 ===================
epoch no : 3, batch no : 63, total loss : 0.39168795943260193,  classifier :0.05887146666646004, mask: 0.14762412011623383 ===================
epoch no : 3, batch no : 64, total loss : 0.3752070963382721,  classifier :0.057286009192466736, mask: 0.14305534958839417 ===================
epoch no : 3, batch no : 65, total loss : 0.37704378366470337,  classifier :0.04509548470377922, mask: 0.13986055552959442 ===================
epoch no : 3, batch no : 66, total loss : 0.32572710514068604,  classifier :0.03926462680101395, mask: 0.15034139156341553 ===================
epoch no : 3, batch no : 67, total loss : 0.3705715537071228,  classifier :0.051689453423023224, mask: 0.13687320053577423 ===================
epoch no : 3, batch no : 68, total loss : 0.41145578026771545,  classifier :0.04842270910739899, mask: 0.1696077436208725 ===================
epoch no : 3, batch no : 69, total loss : 0.3415760099887848,  classifier :0.04562946781516075, mask: 0.14817221462726593 ===================
epoch no : 3, batch no : 70, total loss : 0.3680960237979889,  classifier :0.04760889708995819, mask: 0.11907627433538437 ===================
epoch no : 3, batch no : 71, total loss : 0.32650819420814514,  classifier :0.045795053243637085, mask: 0.12358607351779938 ===================
epoch no : 3, batch no : 72, total loss : 0.2959568202495575,  classifier :0.041905537247657776, mask: 0.11805406957864761 ===================
epoch no : 3, batch no : 73, total loss : 0.35948535799980164,  classifier :0.049012504518032074, mask: 0.1191578209400177 ===================
epoch no : 3, batch no : 74, total loss : 0.4481963515281677,  classifier :0.05606638640165329, mask: 0.16526740789413452 ===================
epoch no : 3, batch no : 75, total loss : 0.35298043489456177,  classifier :0.053252577781677246, mask: 0.13298021256923676 ===================
epoch no : 3, batch no : 76, total loss : 0.3669898808002472,  classifier :0.04735685512423515, mask: 0.14718779921531677 ===================
epoch no : 3, batch no : 77, total loss : 0.39231550693511963,  classifier :0.05113760754466057, mask: 0.16228802502155304 ===================
epoch no : 3, batch no : 78, total loss : 0.386807382106781,  classifier :0.04489370808005333, mask: 0.14737273752689362 ===================
epoch no : 3, batch no : 79, total loss : 0.39630529284477234,  classifier :0.06809943914413452, mask: 0.16297698020935059 ===================
epoch no : 3, batch no : 80, total loss : 0.41608163714408875,  classifier :0.04693853482604027, mask: 0.15547296404838562 ===================
epoch no : 3, batch no : 81, total loss : 0.4400012195110321,  classifier :0.06456691771745682, mask: 0.14402692019939423 ===================
epoch no : 3, batch no : 82, total loss : 0.3272645175457001,  classifier :0.05683379992842674, mask: 0.12914550304412842 ===================
epoch no : 3, batch no : 83, total loss : 0.3933985233306885,  classifier :0.04211781546473503, mask: 0.1280839592218399 ===================
epoch no : 3, batch no : 84, total loss : 0.3907160758972168,  classifier :0.056120697408914566, mask: 0.1461254507303238 ===================
epoch no : 3, batch no : 85, total loss : 0.4252435266971588,  classifier :0.06379707157611847, mask: 0.14648814499378204 ===================
epoch no : 3, batch no : 86, total loss : 0.5512949824333191,  classifier :0.04833018034696579, mask: 0.23377349972724915 ===================
epoch no : 3, batch no : 87, total loss : 0.4272911250591278,  classifier :0.05673043802380562, mask: 0.18810009956359863 ===================
epoch no : 3, batch no : 88, total loss : 0.33847475051879883,  classifier :0.06001914665102959, mask: 0.12372017651796341 ===================
epoch no : 3, batch no : 89, total loss : 0.4114241600036621,  classifier :0.05549394711852074, mask: 0.13785633444786072 ===================
epoch no : 3, batch no : 90, total loss : 0.43855932354927063,  classifier :0.05501243472099304, mask: 0.1477028876543045 ===================
epoch no : 3, batch no : 91, total loss : 0.4329264163970947,  classifier :0.05393623188138008, mask: 0.13038302958011627 ===================
epoch no : 3, batch no : 92, total loss : 0.3024902045726776,  classifier :0.04797423258423805, mask: 0.14316658675670624 ===================
epoch no : 3, batch no : 93, total loss : 0.31582796573638916,  classifier :0.048871465027332306, mask: 0.14382658898830414 ===================
epoch no : 3, batch no : 94, total loss : 0.4170638620853424,  classifier :0.06438630819320679, mask: 0.1541098654270172 ===================
epoch no : 3, batch no : 95, total loss : 0.33202365040779114,  classifier :0.04734685644507408, mask: 0.11797273904085159 ===================
epoch no : 3, batch no : 96, total loss : 0.31451719999313354,  classifier :0.032116394490003586, mask: 0.12251826375722885 ===================
epoch no : 3, batch no : 97, total loss : 0.4298001825809479,  classifier :0.05245337262749672, mask: 0.16092124581336975 ===================
epoch no : 3, batch no : 98, total loss : 0.45080849528312683,  classifier :0.04311293363571167, mask: 0.18766170740127563 ===================
epoch no : 3, batch no : 99, total loss : 0.3024488091468811,  classifier :0.0632537305355072, mask: 0.11121537536382675 ===================
epoch no : 3, batch no : 100, total loss : 0.31449899077415466,  classifier :0.03982480987906456, mask: 0.1409594565629959 ===================
epoch no : 3, batch no : 101, total loss : 0.33450329303741455,  classifier :0.05651075765490532, mask: 0.12119517475366592 ===================
epoch no : 3, batch no : 102, total loss : 0.3198113441467285,  classifier :0.03844187408685684, mask: 0.15840141475200653 ===================
epoch no : 3, batch no : 103, total loss : 0.35721418261528015,  classifier :0.04852333664894104, mask: 0.12942813336849213 ===================
epoch no : 3, batch no : 104, total loss : 0.33378368616104126,  classifier :0.03839203342795372, mask: 0.10917071998119354 ===================
epoch no : 3, batch no : 105, total loss : 0.33063599467277527,  classifier :0.044803306460380554, mask: 0.11860440671443939 ===================
epoch no : 3, batch no : 106, total loss : 0.39590126276016235,  classifier :0.04207819327712059, mask: 0.11847621947526932 ===================
epoch no : 3, batch no : 107, total loss : 0.34966808557510376,  classifier :0.04889451712369919, mask: 0.11840825527906418 ===================
epoch no : 3, batch no : 108, total loss : 0.39734187722206116,  classifier :0.05348243936896324, mask: 0.1480260193347931 ===================
epoch no : 3, batch no : 109, total loss : 0.3844171464443207,  classifier :0.037200361490249634, mask: 0.17209559679031372 ===================
epoch no : 3, batch no : 110, total loss : 0.3915964663028717,  classifier :0.043877530843019485, mask: 0.13928529620170593 ===================
epoch no : 3, batch no : 111, total loss : 0.3696140944957733,  classifier :0.0504387766122818, mask: 0.13655968010425568 ===================
epoch no : 3, batch no : 112, total loss : 0.555961012840271,  classifier :0.055085256695747375, mask: 0.21083016693592072 ===================
epoch no : 3, batch no : 113, total loss : 0.40579062700271606,  classifier :0.04885830730199814, mask: 0.15110376477241516 ===================
epoch no : 3, batch no : 114, total loss : 0.3271855413913727,  classifier :0.037345293909311295, mask: 0.10943055152893066 ===================
epoch no : 3, batch no : 115, total loss : 0.36315852403640747,  classifier :0.059668730944395065, mask: 0.12661561369895935 ===================
epoch no : 3, batch no : 116, total loss : 0.3238506317138672,  classifier :0.0408700630068779, mask: 0.11308992654085159 ===================
epoch no : 3, batch no : 117, total loss : 0.40094825625419617,  classifier :0.05580305680632591, mask: 0.1477234959602356 ===================
epoch no : 3, batch no : 118, total loss : 0.3708456754684448,  classifier :0.050351712852716446, mask: 0.12358565628528595 ===================
epoch no : 3, batch no : 119, total loss : 0.3799320161342621,  classifier :0.038093097507953644, mask: 0.14298807084560394 ===================
epoch no : 3, batch no : 120, total loss : 0.4072366952896118,  classifier :0.04424194246530533, mask: 0.12183298170566559 ===================
epoch no : 3, batch no : 121, total loss : 0.44502437114715576,  classifier :0.06696180254220963, mask: 0.16001611948013306 ===================
epoch no : 3, batch no : 122, total loss : 0.37930458784103394,  classifier :0.05132147669792175, mask: 0.12636078894138336 ===================
epoch no : 3, batch no : 123, total loss : 0.4697591960430145,  classifier :0.1045309454202652, mask: 0.15187637507915497 ===================
epoch no : 3, batch no : 124, total loss : 0.3512461185455322,  classifier :0.046839650720357895, mask: 0.1420198529958725 ===================
epoch no : 3, batch no : 125, total loss : 0.34655269980430603,  classifier :0.05633758381009102, mask: 0.11806749552488327 ===================
epoch no : 3, batch no : 126, total loss : 0.37264758348464966,  classifier :0.0702204555273056, mask: 0.11583657562732697 ===================
epoch no : 3, batch no : 127, total loss : 0.5236752033233643,  classifier :0.044688597321510315, mask: 0.19979873299598694 ===================
epoch no : 3, batch no : 128, total loss : 0.38709262013435364,  classifier :0.04439172148704529, mask: 0.21115466952323914 ===================
epoch no : 3, batch no : 129, total loss : 0.44297853112220764,  classifier :0.0661071166396141, mask: 0.1375797539949417 ===================
epoch no : 3, batch no : 130, total loss : 0.39204609394073486,  classifier :0.05470017343759537, mask: 0.17855960130691528 ===================
epoch no : 3, batch no : 131, total loss : 0.40713316202163696,  classifier :0.050078749656677246, mask: 0.14637112617492676 ===================
epoch no : 3, batch no : 132, total loss : 0.39551064372062683,  classifier :0.04917028173804283, mask: 0.1498374044895172 ===================
epoch no : 3, batch no : 133, total loss : 0.3512636423110962,  classifier :0.049684442579746246, mask: 0.1451222151517868 ===================
epoch no : 3, batch no : 134, total loss : 0.31942233443260193,  classifier :0.05441451072692871, mask: 0.14039330184459686 ===================
epoch no : 3, batch no : 135, total loss : 0.30222222208976746,  classifier :0.04134218394756317, mask: 0.12726230919361115 ===================
epoch no : 3, batch no : 136, total loss : 0.4095926582813263,  classifier :0.059800341725349426, mask: 0.16322997212409973 ===================
epoch no : 3, batch no : 137, total loss : 0.3319327235221863,  classifier :0.04761701822280884, mask: 0.11275853961706161 ===================
epoch no : 3, batch no : 138, total loss : 0.3899106979370117,  classifier :0.047975752502679825, mask: 0.1475778967142105 ===================
epoch no : 3, batch no : 139, total loss : 0.3856933116912842,  classifier :0.04048555716872215, mask: 0.1090003252029419 ===================
epoch no : 3, batch no : 140, total loss : 0.499592661857605,  classifier :0.050014201551675797, mask: 0.18517209589481354 ===================
epoch no : 3, batch no : 141, total loss : 0.35558199882507324,  classifier :0.050436925143003464, mask: 0.14880305528640747 ===================
epoch no : 3, batch no : 142, total loss : 0.3465091288089752,  classifier :0.046912696212530136, mask: 0.11776003986597061 ===================
epoch no : 3, batch no : 143, total loss : 0.49249067902565,  classifier :0.0486273430287838, mask: 0.1735728681087494 ===================
epoch no : 3, batch no : 144, total loss : 0.4665754735469818,  classifier :0.06703148782253265, mask: 0.15467222034931183 ===================
epoch no : 3, batch no : 145, total loss : 0.381021648645401,  classifier :0.05171498656272888, mask: 0.15418775379657745 ===================
epoch no : 3, batch no : 146, total loss : 0.3729594349861145,  classifier :0.06109074503183365, mask: 0.11506875604391098 ===================
epoch no : 3, batch no : 147, total loss : 0.4087136387825012,  classifier :0.04122602939605713, mask: 0.15795136988162994 ===================
epoch no : 3, batch no : 148, total loss : 0.46217653155326843,  classifier :0.051455624401569366, mask: 0.15826372802257538 ===================
epoch no : 3, batch no : 149, total loss : 0.3996586799621582,  classifier :0.0683375895023346, mask: 0.13968196511268616 ===================
epoch no : 3, batch no : 150, total loss : 0.3626437783241272,  classifier :0.045704323798418045, mask: 0.13346509635448456 ===================
epoch no : 3, batch no : 151, total loss : 0.34771767258644104,  classifier :0.05196354165673256, mask: 0.1179058775305748 ===================
epoch no : 3, batch no : 152, total loss : 0.26915332674980164,  classifier :0.050791818648576736, mask: 0.11049440503120422 ===================
epoch no : 3, batch no : 153, total loss : 0.3137013912200928,  classifier :0.04312966763973236, mask: 0.1519637554883957 ===================
epoch no : 3, batch no : 154, total loss : 0.340914785861969,  classifier :0.05668249726295471, mask: 0.13617932796478271 ===================
epoch no : 3, batch no : 155, total loss : 0.3348012864589691,  classifier :0.03829501196742058, mask: 0.17616845667362213 ===================
epoch no : 3, batch no : 156, total loss : 0.35082122683525085,  classifier :0.05795562267303467, mask: 0.13867639005184174 ===================
epoch no : 3, batch no : 157, total loss : 0.389125257730484,  classifier :0.04280164837837219, mask: 0.1389612853527069 ===================
epoch no : 3, batch no : 158, total loss : 0.3140586018562317,  classifier :0.04001348093152046, mask: 0.16265825927257538 ===================
epoch no : 3, batch no : 159, total loss : 0.3792533278465271,  classifier :0.04707605391740799, mask: 0.15885858237743378 ===================
epoch no : 3, batch no : 160, total loss : 0.33098822832107544,  classifier :0.04708133265376091, mask: 0.1556779146194458 ===================
epoch no : 3, batch no : 161, total loss : 0.39812082052230835,  classifier :0.04794001206755638, mask: 0.14907336235046387 ===================
epoch no : 3, batch no : 162, total loss : 0.387182354927063,  classifier :0.0437023788690567, mask: 0.1538461446762085 ===================
epoch no : 3, batch no : 163, total loss : 0.33260780572891235,  classifier :0.04235761612653732, mask: 0.12740594148635864 ===================
epoch no : 3, batch no : 164, total loss : 0.4115905463695526,  classifier :0.06754761189222336, mask: 0.15295998752117157 ===================
epoch no : 3, batch no : 165, total loss : 0.30289846658706665,  classifier :0.04249269515275955, mask: 0.1265261024236679 ===================
epoch no : 3, batch no : 166, total loss : 0.3453463912010193,  classifier :0.0449397973716259, mask: 0.1327500343322754 ===================
epoch no : 3, batch no : 167, total loss : 0.41214513778686523,  classifier :0.03914403170347214, mask: 0.17099066078662872 ===================
epoch no : 3, batch no : 168, total loss : 0.3021664321422577,  classifier :0.04119455814361572, mask: 0.11253878474235535 ===================
epoch no : 3, batch no : 169, total loss : 0.32974064350128174,  classifier :0.03876547887921333, mask: 0.13409006595611572 ===================
epoch no : 3, batch no : 170, total loss : 0.2700416147708893,  classifier :0.037154778838157654, mask: 0.11412642151117325 ===================
epoch no : 3, batch no : 171, total loss : 0.35097938776016235,  classifier :0.04020349681377411, mask: 0.16614612936973572 ===================
epoch no : 3, batch no : 172, total loss : 0.3436211049556732,  classifier :0.044550083577632904, mask: 0.12114840000867844 ===================
epoch no : 3, batch no : 173, total loss : 0.32352936267852783,  classifier :0.04038360342383385, mask: 0.14665040373802185 ===================
epoch no : 3, batch no : 174, total loss : 0.4309895932674408,  classifier :0.05358852446079254, mask: 0.1799738109111786 ===================
epoch no : 3, batch no : 175, total loss : 0.2785610258579254,  classifier :0.04735120013356209, mask: 0.11635131388902664 ===================
epoch no : 3, batch no : 176, total loss : 0.3444017469882965,  classifier :0.04132155701518059, mask: 0.14552970230579376 ===================
epoch no : 3, batch no : 177, total loss : 0.41328221559524536,  classifier :0.05534056946635246, mask: 0.14510588347911835 ===================
epoch no : 3, batch no : 178, total loss : 0.4205523133277893,  classifier :0.05357889458537102, mask: 0.17214183509349823 ===================
epoch no : 3, batch no : 179, total loss : 0.48884502053260803,  classifier :0.07320652902126312, mask: 0.1666882485151291 ===================
epoch no : 3, batch no : 180, total loss : 0.32553815841674805,  classifier :0.0503469780087471, mask: 0.11248299479484558 ===================
epoch no : 3, batch no : 181, total loss : 0.320938378572464,  classifier :0.0483722947537899, mask: 0.13748224079608917 ===================
epoch no : 3, batch no : 182, total loss : 0.29976555705070496,  classifier :0.055440742522478104, mask: 0.10893290489912033 ===================
epoch no : 3, batch no : 183, total loss : 0.317827969789505,  classifier :0.03855760395526886, mask: 0.1184508204460144 ===================
epoch no : 3, batch no : 184, total loss : 0.310159295797348,  classifier :0.053585924208164215, mask: 0.1092219278216362 ===================
epoch no : 3, batch no : 185, total loss : 0.3877040147781372,  classifier :0.04363224655389786, mask: 0.1380719244480133 ===================
epoch no : 3, batch no : 186, total loss : 0.3499986231327057,  classifier :0.0402425192296505, mask: 0.12311627715826035 ===================
epoch no : 3, batch no : 187, total loss : 0.33887597918510437,  classifier :0.053891781717538834, mask: 0.1288256198167801 ===================
epoch no : 3, batch no : 188, total loss : 0.38797613978385925,  classifier :0.0490855872631073, mask: 0.15889659523963928 ===================
epoch no : 3, batch no : 189, total loss : 0.3448243737220764,  classifier :0.04697023704648018, mask: 0.1229802593588829 ===================
epoch no : 3, batch no : 190, total loss : 0.3642372190952301,  classifier :0.04670334234833717, mask: 0.14134645462036133 ===================
epoch no : 3, batch no : 191, total loss : 0.36960411071777344,  classifier :0.038349296897649765, mask: 0.14454229176044464 ===================
epoch no : 3, batch no : 192, total loss : 0.40448030829429626,  classifier :0.0411013700067997, mask: 0.15625810623168945 ===================
epoch no : 3, batch no : 193, total loss : 0.3222159147262573,  classifier :0.05017183721065521, mask: 0.12580148875713348 ===================
epoch no : 3, batch no : 194, total loss : 0.32080498337745667,  classifier :0.040433887392282486, mask: 0.12401416897773743 ===================
epoch no : 3, batch no : 195, total loss : 0.38210979104042053,  classifier :0.05263882875442505, mask: 0.16016416251659393 ===================
epoch no : 3, batch no : 196, total loss : 0.4052141308784485,  classifier :0.052480392158031464, mask: 0.161747008562088 ===================
epoch no : 3, batch no : 197, total loss : 0.4589082598686218,  classifier :0.051740095019340515, mask: 0.17629818618297577 ===================
epoch no : 3, batch no : 198, total loss : 0.4997778832912445,  classifier :0.04544895514845848, mask: 0.15704859793186188 ===================
epoch no : 3, batch no : 199, total loss : 0.41158127784729004,  classifier :0.05375249683856964, mask: 0.1302218735218048 ===================
epoch no : 3, batch no : 200, total loss : 0.4064762592315674,  classifier :0.06495214998722076, mask: 0.148715078830719 ===================
epoch no : 3, batch no : 201, total loss : 0.34870076179504395,  classifier :0.0458071306347847, mask: 0.14445269107818604 ===================
epoch no : 3, batch no : 202, total loss : 0.285044401884079,  classifier :0.04171396791934967, mask: 0.10992033779621124 ===================
epoch no : 3, batch no : 203, total loss : 0.3806058168411255,  classifier :0.04193318635225296, mask: 0.1420813500881195 ===================
epoch no : 3, batch no : 204, total loss : 0.3350908160209656,  classifier :0.043499503284692764, mask: 0.1423775553703308 ===================
epoch no : 3, batch no : 205, total loss : 0.30884110927581787,  classifier :0.0378912016749382, mask: 0.16108979284763336 ===================
epoch no : 3, batch no : 206, total loss : 0.28656700253486633,  classifier :0.0452934168279171, mask: 0.12289082258939743 ===================
epoch no : 3, batch no : 207, total loss : 0.3323340117931366,  classifier :0.052154503762722015, mask: 0.13806883990764618 ===================
epoch no : 3, batch no : 208, total loss : 0.3576398193836212,  classifier :0.048395950347185135, mask: 0.15525363385677338 ===================
epoch no : 3, batch no : 209, total loss : 0.2909814417362213,  classifier :0.03480955958366394, mask: 0.11909719556570053 ===================
epoch no : 3, batch no : 210, total loss : 0.4314001798629761,  classifier :0.05911857634782791, mask: 0.1516457498073578 ===================
epoch no : 3, batch no : 211, total loss : 0.41708916425704956,  classifier :0.04288350045681, mask: 0.18584159016609192 ===================
epoch no : 3, batch no : 212, total loss : 0.27004626393318176,  classifier :0.04318448156118393, mask: 0.09449218958616257 ===================
epoch no : 3, batch no : 213, total loss : 0.3185116648674011,  classifier :0.04426638409495354, mask: 0.11994855850934982 ===================
epoch no : 3, batch no : 214, total loss : 0.44566404819488525,  classifier :0.0429840125143528, mask: 0.1479199379682541 ===================
epoch no : 3, batch no : 215, total loss : 0.3265102207660675,  classifier :0.03907831758260727, mask: 0.11058437079191208 ===================
epoch no : 3, batch no : 216, total loss : 0.3580174148082733,  classifier :0.04668340086936951, mask: 0.1223047599196434 ===================
epoch no : 3, batch no : 217, total loss : 0.3880701959133148,  classifier :0.04034721478819847, mask: 0.13950245082378387 ===================
epoch no : 3, batch no : 218, total loss : 0.3404538333415985,  classifier :0.04772355780005455, mask: 0.12093651294708252 ===================
epoch no : 3, batch no : 219, total loss : 0.33863240480422974,  classifier :0.054693397134542465, mask: 0.11802558600902557 ===================
epoch no : 3, batch no : 220, total loss : 0.3051624894142151,  classifier :0.03592390567064285, mask: 0.10893968492746353 ===================
epoch no : 3, batch no : 221, total loss : 0.27075815200805664,  classifier :0.0434277169406414, mask: 0.09213277697563171 ===================
epoch no : 3, batch no : 222, total loss : 0.46798470616340637,  classifier :0.05341451242566109, mask: 0.1910736858844757 ===================
epoch no : 3, batch no : 223, total loss : 0.41991177201271057,  classifier :0.06697560846805573, mask: 0.1845809817314148 ===================
epoch no : 3, batch no : 224, total loss : 0.38785845041275024,  classifier :0.04062046855688095, mask: 0.1548527181148529 ===================
epoch no : 3, batch no : 225, total loss : 0.30541619658470154,  classifier :0.040459420531988144, mask: 0.13364242017269135 ===================
epoch no : 3, batch no : 226, total loss : 0.35896262526512146,  classifier :0.03564413636922836, mask: 0.14490310847759247 ===================
epoch no : 3, batch no : 227, total loss : 0.3914867341518402,  classifier :0.05797506123781204, mask: 0.1495772749185562 ===================
epoch no : 3, batch no : 228, total loss : 0.4177386164665222,  classifier :0.04181308671832085, mask: 0.2132038027048111 ===================
epoch no : 3, batch no : 229, total loss : 0.3540964722633362,  classifier :0.055455103516578674, mask: 0.13561800122261047 ===================
epoch no : 3, batch no : 230, total loss : 0.3529893755912781,  classifier :0.03937366604804993, mask: 0.1299958974123001 ===================
epoch no : 3, batch no : 231, total loss : 0.4315538704395294,  classifier :0.037705425173044205, mask: 0.18559403717517853 ===================
epoch no : 3, batch no : 232, total loss : 0.381727397441864,  classifier :0.04568558558821678, mask: 0.17994624376296997 ===================
epoch no : 3, batch no : 233, total loss : 0.3103347420692444,  classifier :0.05144624784588814, mask: 0.12684513628482819 ===================
epoch no : 3, batch no : 234, total loss : 0.28511694073677063,  classifier :0.036310553550720215, mask: 0.09804937243461609 ===================
epoch no : 3, batch no : 235, total loss : 0.4120830297470093,  classifier :0.04235055297613144, mask: 0.14291071891784668 ===================
epoch no : 3, batch no : 236, total loss : 0.45132479071617126,  classifier :0.04614705592393875, mask: 0.17017672955989838 ===================
epoch no : 3, batch no : 237, total loss : 0.4253174662590027,  classifier :0.041185133159160614, mask: 0.16213944554328918 ===================
epoch no : 3, batch no : 238, total loss : 0.34313100576400757,  classifier :0.04972422122955322, mask: 0.1492973417043686 ===================
epoch no : 3, batch no : 239, total loss : 0.338781476020813,  classifier :0.03368517383933067, mask: 0.13522778451442719 ===================
epoch no : 3, batch no : 240, total loss : 0.3065490126609802,  classifier :0.04202362895011902, mask: 0.1379145234823227 ===================
epoch no : 3, batch no : 241, total loss : 0.34793347120285034,  classifier :0.050459764897823334, mask: 0.1248595267534256 ===================
epoch no : 3, batch no : 242, total loss : 0.3011058270931244,  classifier :0.056002866476774216, mask: 0.10167887806892395 ===================
epoch no : 3, batch no : 243, total loss : 0.34497031569480896,  classifier :0.0508774034678936, mask: 0.13176976144313812 ===================
epoch no : 3, batch no : 244, total loss : 0.3320792615413666,  classifier :0.05764007568359375, mask: 0.11048275977373123 ===================
epoch no : 3, batch no : 245, total loss : 0.35325974225997925,  classifier :0.04901980981230736, mask: 0.12421569973230362 ===================
epoch no : 3, batch no : 246, total loss : 0.3182765245437622,  classifier :0.042180683463811874, mask: 0.10858989506959915 ===================
epoch no : 3, batch no : 247, total loss : 0.3653600811958313,  classifier :0.04292553290724754, mask: 0.12301582843065262 ===================
epoch no : 3, batch no : 248, total loss : 0.40226343274116516,  classifier :0.05805404856801033, mask: 0.17200270295143127 ===================
epoch no : 3, batch no : 249, total loss : 0.40659552812576294,  classifier :0.04814137890934944, mask: 0.15692618489265442 ===================
epoch no : 3, batch no : 250, total loss : 0.3693199157714844,  classifier :0.04686003923416138, mask: 0.14666105806827545 ===================
epoch no : 3, batch no : 251, total loss : 0.3271425664424896,  classifier :0.0458560474216938, mask: 0.1373945027589798 ===================
epoch no : 3, batch no : 252, total loss : 0.32471081614494324,  classifier :0.05739198252558708, mask: 0.11833903938531876 ===================
epoch no : 3, batch no : 253, total loss : 0.27096492052078247,  classifier :0.03316647186875343, mask: 0.11089837551116943 ===================
epoch no : 3, batch no : 254, total loss : 0.28846538066864014,  classifier :0.03953763470053673, mask: 0.11929067224264145 ===================
epoch no : 3, batch no : 255, total loss : 0.31531012058258057,  classifier :0.036862265318632126, mask: 0.11952653527259827 ===================
epoch no : 3, batch no : 256, total loss : 0.3364669978618622,  classifier :0.03962128981947899, mask: 0.12714363634586334 ===================
epoch no : 3, batch no : 257, total loss : 0.39184632897377014,  classifier :0.052314236760139465, mask: 0.14632824063301086 ===================
epoch no : 3, batch no : 258, total loss : 0.31446346640586853,  classifier :0.04097485542297363, mask: 0.11871767044067383 ===================
epoch no : 3, batch no : 259, total loss : 0.5342685580253601,  classifier :0.055415526032447815, mask: 0.1774945855140686 ===================
epoch no : 3, batch no : 260, total loss : 0.36358386278152466,  classifier :0.040841761976480484, mask: 0.13895612955093384 ===================
epoch no : 3, batch no : 261, total loss : 0.3617333471775055,  classifier :0.036448437720537186, mask: 0.1323985457420349 ===================
epoch no : 3, batch no : 262, total loss : 0.39814817905426025,  classifier :0.04014690965414047, mask: 0.1536947786808014 ===================
epoch no : 3, batch no : 263, total loss : 0.3803942799568176,  classifier :0.05684247612953186, mask: 0.14316469430923462 ===================
epoch no : 3, batch no : 264, total loss : 0.3058743178844452,  classifier :0.04037174955010414, mask: 0.10324285924434662 ===================
epoch no : 3, batch no : 265, total loss : 0.3033770024776459,  classifier :0.03312241658568382, mask: 0.12323378771543503 ===================
epoch no : 3, batch no : 266, total loss : 0.4601176381111145,  classifier :0.05554645135998726, mask: 0.187735915184021 ===================
epoch no : 3, batch no : 267, total loss : 0.34650105237960815,  classifier :0.045316390693187714, mask: 0.12958280742168427 ===================
epoch no : 3, batch no : 268, total loss : 0.35589340329170227,  classifier :0.03720023110508919, mask: 0.1578623205423355 ===================
epoch no : 3, batch no : 269, total loss : 0.356566458940506,  classifier :0.04939666762948036, mask: 0.12172368913888931 ===================
epoch no : 3, batch no : 270, total loss : 0.37641826272010803,  classifier :0.04718976840376854, mask: 0.14404703676700592 ===================
epoch no : 3, batch no : 271, total loss : 0.2961962819099426,  classifier :0.03503608703613281, mask: 0.12823237478733063 ===================
epoch no : 3, batch no : 272, total loss : 0.29687270522117615,  classifier :0.03099869191646576, mask: 0.12535253167152405 ===================
epoch no : 3, batch no : 273, total loss : 0.4121156334877014,  classifier :0.045337777584791183, mask: 0.13592521846294403 ===================
epoch no : 3, batch no : 274, total loss : 0.4033656120300293,  classifier :0.04715209826827049, mask: 0.16430428624153137 ===================
epoch no : 3, batch no : 275, total loss : 0.34889134764671326,  classifier :0.04529835656285286, mask: 0.146827831864357 ===================
epoch no : 3, batch no : 276, total loss : 0.3413724899291992,  classifier :0.054485853761434555, mask: 0.141460120677948 ===================
epoch no : 3, batch no : 277, total loss : 0.3962768316268921,  classifier :0.044880256056785583, mask: 0.16326405107975006 ===================
epoch no : 3, batch no : 278, total loss : 0.33749228715896606,  classifier :0.04170359671115875, mask: 0.1322726458311081 ===================
epoch no : 3, batch no : 279, total loss : 0.24610984325408936,  classifier :0.034609243273735046, mask: 0.10440871119499207 ===================
epoch no : 3, batch no : 280, total loss : 0.3633584976196289,  classifier :0.049310844391584396, mask: 0.17028675973415375 ===================
epoch no : 3, batch no : 281, total loss : 0.3206513822078705,  classifier :0.03843742981553078, mask: 0.13352538645267487 ===================
epoch no : 3, batch no : 282, total loss : 0.36615124344825745,  classifier :0.0511418879032135, mask: 0.12301038205623627 ===================
epoch no : 3, batch no : 283, total loss : 0.4409765899181366,  classifier :0.06119760870933533, mask: 0.15384109318256378 ===================
epoch no : 3, batch no : 284, total loss : 0.32929545640945435,  classifier :0.034336306154727936, mask: 0.12663306295871735 ===================
epoch no : 3, batch no : 285, total loss : 0.35195931792259216,  classifier :0.03654357045888901, mask: 0.12687811255455017 ===================
epoch no : 3, batch no : 286, total loss : 0.43717682361602783,  classifier :0.05300230160355568, mask: 0.1754526048898697 ===================
epoch no : 3, batch no : 287, total loss : 0.32830455899238586,  classifier :0.03782156854867935, mask: 0.14533329010009766 ===================
epoch no : 3, batch no : 288, total loss : 0.35450369119644165,  classifier :0.046471044421195984, mask: 0.1365147829055786 ===================
epoch no : 3, batch no : 289, total loss : 0.5190457701683044,  classifier :0.04230014979839325, mask: 0.18032078444957733 ===================
epoch no : 3, batch no : 290, total loss : 0.3894176185131073,  classifier :0.04577450454235077, mask: 0.14897765219211578 ===================
epoch no : 3, batch no : 291, total loss : 0.36345985531806946,  classifier :0.04674641042947769, mask: 0.15719948709011078 ===================
epoch no : 3, batch no : 292, total loss : 0.3835350275039673,  classifier :0.038964904844760895, mask: 0.16068094968795776 ===================
epoch no : 3, batch no : 293, total loss : 0.34281086921691895,  classifier :0.046116963028907776, mask: 0.13674256205558777 ===================
epoch no : 3, batch no : 294, total loss : 0.37238746881484985,  classifier :0.06578850001096725, mask: 0.1349128782749176 ===================
epoch no : 3, batch no : 295, total loss : 0.4270777702331543,  classifier :0.06651630997657776, mask: 0.17281796038150787 ===================
epoch no : 3, batch no : 296, total loss : 0.26874467730522156,  classifier :0.038407932966947556, mask: 0.12001658976078033 ===================
epoch no : 3, batch no : 297, total loss : 0.334369421005249,  classifier :0.039070844650268555, mask: 0.14559487998485565 ===================
epoch no : 3, batch no : 298, total loss : 0.31294897198677063,  classifier :0.02966437302529812, mask: 0.12470516562461853 ===================
epoch no : 3, batch no : 299, total loss : 0.33428776264190674,  classifier :0.048785578459501266, mask: 0.12593711912631989 ===================
epoch no : 3, batch no : 300, total loss : 0.30718642473220825,  classifier :0.05358795449137688, mask: 0.1176186054944992 ===================
epoch no : 3, batch no : 301, total loss : 0.40237167477607727,  classifier :0.05150897055864334, mask: 0.13659638166427612 ===================
epoch no : 3, batch no : 302, total loss : 0.33435216546058655,  classifier :0.05036276578903198, mask: 0.11283722519874573 ===================
epoch no : 3, batch no : 303, total loss : 0.3257010877132416,  classifier :0.035894714295864105, mask: 0.1380312740802765 ===================
epoch no : 3, batch no : 304, total loss : 0.32426413893699646,  classifier :0.03800559043884277, mask: 0.12851065397262573 ===================
epoch no : 3, batch no : 305, total loss : 0.32287484407424927,  classifier :0.05719223991036415, mask: 0.1315353661775589 ===================
epoch no : 3, batch no : 306, total loss : 0.3879987299442291,  classifier :0.055097874253988266, mask: 0.16894520819187164 ===================
epoch no : 3, batch no : 307, total loss : 0.423449844121933,  classifier :0.052230704575777054, mask: 0.16219674050807953 ===================
epoch no : 3, batch no : 308, total loss : 0.4225325584411621,  classifier :0.06961839646100998, mask: 0.14692732691764832 ===================
epoch no : 3, batch no : 309, total loss : 0.40951552987098694,  classifier :0.0399005189538002, mask: 0.16301129758358002 ===================
epoch no : 3, batch no : 310, total loss : 0.3058960735797882,  classifier :0.04732741042971611, mask: 0.1223633736371994 ===================
epoch no : 3, batch no : 311, total loss : 0.5164899826049805,  classifier :0.061998624354600906, mask: 0.20858605206012726 ===================
epoch no : 3, batch no : 312, total loss : 0.5056415796279907,  classifier :0.06377773731946945, mask: 0.18831676244735718 ===================
epoch no : 3, batch no : 313, total loss : 0.45951467752456665,  classifier :0.06462457776069641, mask: 0.15364116430282593 ===================
epoch no : 3, batch no : 314, total loss : 0.29933232069015503,  classifier :0.0434647873044014, mask: 0.13413438200950623 ===================
epoch no : 3, batch no : 315, total loss : 0.30693909525871277,  classifier :0.051850538700819016, mask: 0.11933524161577225 ===================
epoch no : 3, batch no : 316, total loss : 0.4206756055355072,  classifier :0.04622919484972954, mask: 0.16920572519302368 ===================
epoch no : 3, batch no : 317, total loss : 0.41758161783218384,  classifier :0.06266975402832031, mask: 0.1491042822599411 ===================
epoch no : 3, batch no : 318, total loss : 0.31264036893844604,  classifier :0.042564764618873596, mask: 0.13613753020763397 ===================
epoch no : 3, batch no : 319, total loss : 0.33077239990234375,  classifier :0.04325900226831436, mask: 0.1386413723230362 ===================
epoch no : 3, batch no : 320, total loss : 0.3194413483142853,  classifier :0.03729494661092758, mask: 0.12226785719394684 ===================
epoch no : 3, batch no : 321, total loss : 0.3912636935710907,  classifier :0.03530912846326828, mask: 0.15454158186912537 ===================
epoch no : 3, batch no : 322, total loss : 0.3113420903682709,  classifier :0.04239846393465996, mask: 0.10005676001310349 ===================
epoch no : 3, batch no : 323, total loss : 0.4013049006462097,  classifier :0.05516555532813072, mask: 0.13674944639205933 ===================
epoch no : 3, batch no : 324, total loss : 0.41279157996177673,  classifier :0.04714158549904823, mask: 0.15289373695850372 ===================
epoch no : 3, batch no : 325, total loss : 0.3694595992565155,  classifier :0.04208233579993248, mask: 0.14547742903232574 ===================
epoch no : 3, batch no : 326, total loss : 0.35343697667121887,  classifier :0.04665367305278778, mask: 0.1296321600675583 ===================
epoch no : 3, batch no : 327, total loss : 0.36260053515434265,  classifier :0.04543774202466011, mask: 0.14383503794670105 ===================
epoch no : 3, batch no : 328, total loss : 0.3839253783226013,  classifier :0.04862949997186661, mask: 0.19171670079231262 ===================
epoch no : 3, batch no : 329, total loss : 0.25811174511909485,  classifier :0.03986966609954834, mask: 0.11130459606647491 ===================
epoch no : 3, batch no : 330, total loss : 0.3149329125881195,  classifier :0.04966902732849121, mask: 0.13235770165920258 ===================
epoch no : 3, batch no : 331, total loss : 0.3774850070476532,  classifier :0.05437556654214859, mask: 0.13327674567699432 ===================
epoch no : 3, batch no : 332, total loss : 0.3459179401397705,  classifier :0.044896334409713745, mask: 0.1510743349790573 ===================
epoch no : 3, batch no : 333, total loss : 0.410257488489151,  classifier :0.03610074892640114, mask: 0.17684492468833923 ===================
epoch no : 3, batch no : 334, total loss : 0.3805743157863617,  classifier :0.04962799325585365, mask: 0.16682147979736328 ===================
epoch no : 3, batch no : 335, total loss : 0.3227943778038025,  classifier :0.03948776796460152, mask: 0.13699160516262054 ===================
epoch no : 3, batch no : 336, total loss : 0.3492153286933899,  classifier :0.0379696860909462, mask: 0.1276310682296753 ===================
epoch no : 3, batch no : 337, total loss : 0.3128586709499359,  classifier :0.04792964458465576, mask: 0.12847007811069489 ===================
epoch no : 3, batch no : 338, total loss : 0.28946638107299805,  classifier :0.03808384761214256, mask: 0.11812423169612885 ===================
epoch no : 3, batch no : 339, total loss : 0.31666064262390137,  classifier :0.03323837369680405, mask: 0.11340121924877167 ===================
epoch no : 3, batch no : 340, total loss : 0.3453340232372284,  classifier :0.04459848999977112, mask: 0.1486448496580124 ===================
epoch no : 3, batch no : 341, total loss : 0.2729317843914032,  classifier :0.04299435764551163, mask: 0.1178160309791565 ===================
epoch no : 3, batch no : 342, total loss : 0.25513026118278503,  classifier :0.03541132062673569, mask: 0.11197588592767715 ===================
epoch no : 3, batch no : 343, total loss : 0.2715926468372345,  classifier :0.03141983598470688, mask: 0.11650702357292175 ===================
epoch no : 3, batch no : 344, total loss : 0.3465321660041809,  classifier :0.04263157770037651, mask: 0.14099837839603424 ===================
epoch no : 3, batch no : 345, total loss : 0.29834187030792236,  classifier :0.03515547513961792, mask: 0.12242809683084488 ===================
epoch no : 3, batch no : 346, total loss : 0.35748907923698425,  classifier :0.053678419440984726, mask: 0.14840896427631378 ===================
epoch no : 3, batch no : 347, total loss : 0.32524704933166504,  classifier :0.053485576063394547, mask: 0.11808633804321289 ===================
epoch no : 3, batch no : 348, total loss : 0.3301752507686615,  classifier :0.041610341519117355, mask: 0.12557217478752136 ===================
epoch no : 3, batch no : 349, total loss : 0.32827600836753845,  classifier :0.05532265082001686, mask: 0.1272764652967453 ===================
epoch no : 3, batch no : 350, total loss : 0.3575495183467865,  classifier :0.05404936894774437, mask: 0.13138583302497864 ===================
epoch no : 3, batch no : 351, total loss : 0.31140637397766113,  classifier :0.05124058946967125, mask: 0.1300704926252365 ===================
epoch no : 3, batch no : 352, total loss : 0.34151479601860046,  classifier :0.037430357187986374, mask: 0.1446000337600708 ===================
epoch no : 3, batch no : 353, total loss : 0.318884015083313,  classifier :0.05902409553527832, mask: 0.11349686980247498 ===================
epoch no : 3, batch no : 354, total loss : 0.3038065731525421,  classifier :0.03304228559136391, mask: 0.09785541892051697 ===================
epoch no : 3, batch no : 355, total loss : 0.3336659371852875,  classifier :0.04970673844218254, mask: 0.11286060512065887 ===================
epoch no : 3, batch no : 356, total loss : 0.38034719228744507,  classifier :0.04760970547795296, mask: 0.1683599352836609 ===================
epoch no : 3, batch no : 357, total loss : 0.3968561887741089,  classifier :0.054963115602731705, mask: 0.14649835228919983 ===================
epoch no : 3, batch no : 358, total loss : 0.46194911003112793,  classifier :0.05013439059257507, mask: 0.1815839409828186 ===================
epoch no : 3, batch no : 359, total loss : 0.32424232363700867,  classifier :0.04339450225234032, mask: 0.14119473099708557 ===================
epoch no : 3, batch no : 360, total loss : 0.34142446517944336,  classifier :0.0392620824277401, mask: 0.1428757607936859 ===================
epoch no : 3, batch no : 361, total loss : 0.29667040705680847,  classifier :0.040818676352500916, mask: 0.10950358211994171 ===================
epoch no : 3, batch no : 362, total loss : 0.5192559361457825,  classifier :0.07416527718305588, mask: 0.20516616106033325 ===================
epoch no : 3, batch no : 363, total loss : 0.35588881373405457,  classifier :0.03796377405524254, mask: 0.13203902542591095 ===================
epoch no : 3, batch no : 364, total loss : 0.37259218096733093,  classifier :0.041690893471241, mask: 0.13136199116706848 ===================
epoch no : 3, batch no : 365, total loss : 0.5657493472099304,  classifier :0.04528103396296501, mask: 0.19077853858470917 ===================
epoch no : 3, batch no : 366, total loss : 0.4691839814186096,  classifier :0.06888784468173981, mask: 0.17512500286102295 ===================
epoch no : 3, batch no : 367, total loss : 0.3326914608478546,  classifier :0.04392421990633011, mask: 0.11549738049507141 ===================
epoch no : 3, batch no : 368, total loss : 0.3990520238876343,  classifier :0.041818149387836456, mask: 0.1302020400762558 ===================
epoch no : 3, batch no : 369, total loss : 0.4963788390159607,  classifier :0.07936830818653107, mask: 0.16408635675907135 ===================
epoch no : 3, batch no : 370, total loss : 0.4057754576206207,  classifier :0.04043646529316902, mask: 0.15437154471874237 ===================
epoch no : 3, batch no : 371, total loss : 0.35998645424842834,  classifier :0.04014415293931961, mask: 0.14085355401039124 ===================
epoch no : 3, batch no : 372, total loss : 0.31905806064605713,  classifier :0.036711644381284714, mask: 0.12838071584701538 ===================
epoch no : 3, batch no : 373, total loss : 0.419217050075531,  classifier :0.037739913910627365, mask: 0.1632174253463745 ===================
epoch no : 3, batch no : 374, total loss : 0.30676838755607605,  classifier :0.028942972421646118, mask: 0.1241823211312294 ===================
epoch no : 3, batch no : 375, total loss : 0.4028853476047516,  classifier :0.054810818284749985, mask: 0.17057567834854126 ===================
epoch no : 3, batch no : 376, total loss : 0.3169974386692047,  classifier :0.04006790369749069, mask: 0.11632130295038223 ===================
epoch no : 3, batch no : 377, total loss : 0.3488026559352875,  classifier :0.04914354160428047, mask: 0.12423641979694366 ===================
epoch no : 3, batch no : 378, total loss : 0.39742904901504517,  classifier :0.0623842254281044, mask: 0.13974258303642273 ===================
epoch no : 3, batch no : 379, total loss : 0.35091882944107056,  classifier :0.057923100888729095, mask: 0.16155314445495605 ===================
epoch no : 3, batch no : 380, total loss : 0.31204754114151,  classifier :0.040126409381628036, mask: 0.11954779922962189 ===================
epoch no : 3, batch no : 381, total loss : 0.2901853621006012,  classifier :0.04524882882833481, mask: 0.11312393099069595 ===================
epoch no : 3, batch no : 382, total loss : 0.36737290024757385,  classifier :0.06155599281191826, mask: 0.13451825082302094 ===================
epoch no : 3, batch no : 383, total loss : 0.31771931052207947,  classifier :0.03105989284813404, mask: 0.13263395428657532 ===================
epoch no : 3, batch no : 384, total loss : 0.34537702798843384,  classifier :0.04387922212481499, mask: 0.12803542613983154 ===================
epoch no : 3, batch no : 385, total loss : 0.3038530945777893,  classifier :0.03881710022687912, mask: 0.11809667199850082 ===================
epoch no : 3, batch no : 386, total loss : 0.37220218777656555,  classifier :0.033270563930273056, mask: 0.16229555010795593 ===================
epoch no : 3, batch no : 387, total loss : 0.37935546040534973,  classifier :0.07033514231443405, mask: 0.14521047472953796 ===================
epoch no : 3, batch no : 388, total loss : 0.33214592933654785,  classifier :0.03556312620639801, mask: 0.15174709260463715 ===================
epoch no : 3, batch no : 389, total loss : 0.3373112380504608,  classifier :0.047018419951200485, mask: 0.12079325318336487 ===================
epoch no : 3, batch no : 390, total loss : 0.32466787099838257,  classifier :0.04861968010663986, mask: 0.11935035139322281 ===================
epoch no : 3, batch no : 391, total loss : 0.25999194383621216,  classifier :0.035097576677799225, mask: 0.11437853425741196 ===================
epoch no : 3, batch no : 392, total loss : 0.3006557524204254,  classifier :0.040700118988752365, mask: 0.11346550285816193 ===================
epoch no : 3, batch no : 393, total loss : 0.3446607291698456,  classifier :0.028087563812732697, mask: 0.1551327407360077 ===================
epoch no : 3, batch no : 394, total loss : 0.41269105672836304,  classifier :0.04974964261054993, mask: 0.16137048602104187 ===================
epoch no : 3, batch no : 395, total loss : 0.34220796823501587,  classifier :0.034146178513765335, mask: 0.13473987579345703 ===================
epoch no : 3, batch no : 396, total loss : 0.3828733563423157,  classifier :0.05374783277511597, mask: 0.14426857233047485 ===================
epoch no : 3, batch no : 397, total loss : 0.2569654583930969,  classifier :0.034896500408649445, mask: 0.10615243017673492 ===================
epoch no : 3, batch no : 398, total loss : 0.5092383027076721,  classifier :0.05648188292980194, mask: 0.24123643338680267 ===================
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch no : 4, batch no : 0, total loss : 0.6700478792190552,  classifier :0.07925228774547577, mask: 0.2362961769104004 ===================
epoch no : 4, batch no : 1, total loss : 0.3599267899990082,  classifier :0.04740710183978081, mask: 0.12655599415302277 ===================
epoch no : 4, batch no : 2, total loss : 0.3465745151042938,  classifier :0.06499273329973221, mask: 0.1408081352710724 ===================
epoch no : 4, batch no : 3, total loss : 0.3191576600074768,  classifier :0.03271501138806343, mask: 0.1470438688993454 ===================
epoch no : 4, batch no : 4, total loss : 0.3819933235645294,  classifier :0.046458903700113297, mask: 0.1361849457025528 ===================
epoch no : 4, batch no : 5, total loss : 0.26440027356147766,  classifier :0.04239067807793617, mask: 0.08909444510936737 ===================
epoch no : 4, batch no : 6, total loss : 0.3337726593017578,  classifier :0.03951248899102211, mask: 0.14038246870040894 ===================
epoch no : 4, batch no : 7, total loss : 0.298950731754303,  classifier :0.041711386293172836, mask: 0.12008225917816162 ===================
epoch no : 4, batch no : 8, total loss : 0.313985139131546,  classifier :0.03401097655296326, mask: 0.14798510074615479 ===================
epoch no : 4, batch no : 9, total loss : 0.23761913180351257,  classifier :0.03620496764779091, mask: 0.10518565773963928 ===================
epoch no : 4, batch no : 10, total loss : 0.3404086232185364,  classifier :0.04261261597275734, mask: 0.14659802615642548 ===================
epoch no : 4, batch no : 11, total loss : 0.29107755422592163,  classifier :0.03794741630554199, mask: 0.11488424986600876 ===================
epoch no : 4, batch no : 12, total loss : 0.31774312257766724,  classifier :0.026882635429501534, mask: 0.11503884196281433 ===================
epoch no : 4, batch no : 13, total loss : 0.40090346336364746,  classifier :0.036663156002759933, mask: 0.14608897268772125 ===================
epoch no : 4, batch no : 14, total loss : 0.4030466675758362,  classifier :0.03715968877077103, mask: 0.13036681711673737 ===================
epoch no : 4, batch no : 15, total loss : 0.40090978145599365,  classifier :0.03638536483049393, mask: 0.2019929438829422 ===================
epoch no : 4, batch no : 16, total loss : 0.3449861407279968,  classifier :0.0381847582757473, mask: 0.13995684683322906 ===================
epoch no : 4, batch no : 17, total loss : 0.40688517689704895,  classifier :0.04195115715265274, mask: 0.16050158441066742 ===================
epoch no : 4, batch no : 18, total loss : 0.2990244925022125,  classifier :0.038091544061899185, mask: 0.11636106669902802 ===================
epoch no : 4, batch no : 19, total loss : 0.34935423731803894,  classifier :0.0405435748398304, mask: 0.11389724165201187 ===================
epoch no : 4, batch no : 20, total loss : 0.40288522839546204,  classifier :0.05637577176094055, mask: 0.13563568890094757 ===================
epoch no : 4, batch no : 21, total loss : 0.3907082974910736,  classifier :0.051327772438526154, mask: 0.13552530109882355 ===================
epoch no : 4, batch no : 22, total loss : 0.32863447070121765,  classifier :0.05074933171272278, mask: 0.1492910534143448 ===================
epoch no : 4, batch no : 23, total loss : 0.2892013490200043,  classifier :0.04467945918440819, mask: 0.11326229572296143 ===================
epoch no : 4, batch no : 24, total loss : 0.32546156644821167,  classifier :0.039749402552843094, mask: 0.13677674531936646 ===================
epoch no : 4, batch no : 25, total loss : 0.3437824249267578,  classifier :0.0336109921336174, mask: 0.15281519293785095 ===================
epoch no : 4, batch no : 26, total loss : 0.3797399699687958,  classifier :0.04720771685242653, mask: 0.15823017060756683 ===================
epoch no : 4, batch no : 27, total loss : 0.2639404535293579,  classifier :0.040258292108774185, mask: 0.1135682761669159 ===================
epoch no : 4, batch no : 28, total loss : 0.29703882336616516,  classifier :0.03803100436925888, mask: 0.1119052842259407 ===================
epoch no : 4, batch no : 29, total loss : 0.28262004256248474,  classifier :0.03530164808034897, mask: 0.09600381553173065 ===================
epoch no : 4, batch no : 30, total loss : 0.35039621591567993,  classifier :0.04331422969698906, mask: 0.1393856257200241 ===================
epoch no : 4, batch no : 31, total loss : 0.2561051547527313,  classifier :0.03735751658678055, mask: 0.09027992933988571 ===================
epoch no : 4, batch no : 32, total loss : 0.34593236446380615,  classifier :0.04202411323785782, mask: 0.14098070561885834 ===================
epoch no : 4, batch no : 33, total loss : 0.4711609184741974,  classifier :0.039841122925281525, mask: 0.17521871626377106 ===================
epoch no : 4, batch no : 34, total loss : 0.2804669141769409,  classifier :0.044397857040166855, mask: 0.11070128530263901 ===================
epoch no : 4, batch no : 35, total loss : 0.40156814455986023,  classifier :0.05557701736688614, mask: 0.17392072081565857 ===================
epoch no : 4, batch no : 36, total loss : 0.33428454399108887,  classifier :0.039774443954229355, mask: 0.12495201826095581 ===================
epoch no : 4, batch no : 37, total loss : 0.35400116443634033,  classifier :0.04616741091012955, mask: 0.15405043959617615 ===================
epoch no : 4, batch no : 38, total loss : 0.3076029121875763,  classifier :0.038226641714572906, mask: 0.1255970150232315 ===================
epoch no : 4, batch no : 39, total loss : 0.29526492953300476,  classifier :0.03791079297661781, mask: 0.10418740659952164 ===================
epoch no : 4, batch no : 40, total loss : 0.3445259928703308,  classifier :0.04776863753795624, mask: 0.12009018659591675 ===================
epoch no : 4, batch no : 41, total loss : 0.2711881399154663,  classifier :0.03528007119894028, mask: 0.09284859150648117 ===================
epoch no : 4, batch no : 42, total loss : 0.3160151243209839,  classifier :0.0361088402569294, mask: 0.12037941813468933 ===================
epoch no : 4, batch no : 43, total loss : 0.30017685890197754,  classifier :0.03867816552519798, mask: 0.10748090595006943 ===================
epoch no : 4, batch no : 44, total loss : 0.31272590160369873,  classifier :0.04332772642374039, mask: 0.09709649533033371 ===================
epoch no : 4, batch no : 45, total loss : 0.4417099058628082,  classifier :0.06745107471942902, mask: 0.20323039591312408 ===================
epoch no : 4, batch no : 46, total loss : 0.3633498251438141,  classifier :0.034390922635793686, mask: 0.15095064043998718 ===================
epoch no : 4, batch no : 47, total loss : 0.347759872674942,  classifier :0.041991617530584335, mask: 0.13919414579868317 ===================
epoch no : 4, batch no : 48, total loss : 0.3446807861328125,  classifier :0.03828534856438637, mask: 0.15175767242908478 ===================
epoch no : 4, batch no : 49, total loss : 0.2809367775917053,  classifier :0.03128952160477638, mask: 0.09634528309106827 ===================
epoch no : 4, batch no : 50, total loss : 0.41146185994148254,  classifier :0.06045044586062431, mask: 0.16430914402008057 ===================
epoch no : 4, batch no : 51, total loss : 0.3126477599143982,  classifier :0.04621974006295204, mask: 0.1327330321073532 ===================
epoch no : 4, batch no : 52, total loss : 0.2916497588157654,  classifier :0.03313886746764183, mask: 0.11778932809829712 ===================
epoch no : 4, batch no : 53, total loss : 0.31921494007110596,  classifier :0.06206204742193222, mask: 0.12734144926071167 ===================
epoch no : 4, batch no : 54, total loss : 0.3717076778411865,  classifier :0.04414186626672745, mask: 0.17589549720287323 ===================
epoch no : 4, batch no : 55, total loss : 0.31735607981681824,  classifier :0.046428654342889786, mask: 0.13149894773960114 ===================
epoch no : 4, batch no : 56, total loss : 0.30604106187820435,  classifier :0.033620305359363556, mask: 0.10776042193174362 ===================
epoch no : 4, batch no : 57, total loss : 0.3396087884902954,  classifier :0.04203718900680542, mask: 0.1368541419506073 ===================
epoch no : 4, batch no : 58, total loss : 0.4074554145336151,  classifier :0.046391479671001434, mask: 0.15158219635486603 ===================
epoch no : 4, batch no : 59, total loss : 0.42059874534606934,  classifier :0.046691134572029114, mask: 0.16721874475479126 ===================
epoch no : 4, batch no : 60, total loss : 0.3991583585739136,  classifier :0.06566315144300461, mask: 0.13972505927085876 ===================
epoch no : 4, batch no : 61, total loss : 0.32743555307388306,  classifier :0.05541237071156502, mask: 0.12007448822259903 ===================
epoch no : 4, batch no : 62, total loss : 0.29684945940971375,  classifier :0.041179437190294266, mask: 0.12922073900699615 ===================
epoch no : 4, batch no : 63, total loss : 0.3087506890296936,  classifier :0.04580060765147209, mask: 0.12709422409534454 ===================
epoch no : 4, batch no : 64, total loss : 0.39920681715011597,  classifier :0.055242739617824554, mask: 0.14362090826034546 ===================
epoch no : 4, batch no : 65, total loss : 0.36307066679000854,  classifier :0.03738291934132576, mask: 0.14761027693748474 ===================
epoch no : 4, batch no : 66, total loss : 0.3073168694972992,  classifier :0.04543221369385719, mask: 0.13331979513168335 ===================
epoch no : 4, batch no : 67, total loss : 0.33659952878952026,  classifier :0.04010200500488281, mask: 0.13848599791526794 ===================
epoch no : 4, batch no : 68, total loss : 0.296207457780838,  classifier :0.03451171889901161, mask: 0.12941092252731323 ===================
epoch no : 4, batch no : 69, total loss : 0.31467607617378235,  classifier :0.053714651614427567, mask: 0.12416147440671921 ===================
epoch no : 4, batch no : 70, total loss : 0.2700200378894806,  classifier :0.03767538443207741, mask: 0.1082477942109108 ===================
epoch no : 4, batch no : 71, total loss : 0.3525833189487457,  classifier :0.05186302959918976, mask: 0.13603360950946808 ===================
epoch no : 4, batch no : 72, total loss : 0.33716702461242676,  classifier :0.04063909128308296, mask: 0.1315888911485672 ===================
epoch no : 4, batch no : 73, total loss : 0.39096906781196594,  classifier :0.03521580994129181, mask: 0.15853390097618103 ===================
epoch no : 4, batch no : 74, total loss : 0.31927546858787537,  classifier :0.042905353009700775, mask: 0.13419480621814728 ===================
epoch no : 4, batch no : 75, total loss : 0.3441978693008423,  classifier :0.03379325941205025, mask: 0.13535350561141968 ===================
epoch no : 4, batch no : 76, total loss : 0.349312424659729,  classifier :0.0538494698703289, mask: 0.12895172834396362 ===================
epoch no : 4, batch no : 77, total loss : 0.35337841510772705,  classifier :0.04654365032911301, mask: 0.1380627304315567 ===================
epoch no : 4, batch no : 78, total loss : 0.33834952116012573,  classifier :0.046055473387241364, mask: 0.09968730062246323 ===================
epoch no : 4, batch no : 79, total loss : 0.31391745805740356,  classifier :0.030191481113433838, mask: 0.1222456619143486 ===================
epoch no : 4, batch no : 80, total loss : 0.42348429560661316,  classifier :0.03740190342068672, mask: 0.18937981128692627 ===================
epoch no : 4, batch no : 81, total loss : 0.28175538778305054,  classifier :0.03175952658057213, mask: 0.09498416632413864 ===================
epoch no : 4, batch no : 82, total loss : 0.37052372097969055,  classifier :0.04830601438879967, mask: 0.14250677824020386 ===================
epoch no : 4, batch no : 83, total loss : 0.46093761920928955,  classifier :0.06942011415958405, mask: 0.19527168571949005 ===================
epoch no : 4, batch no : 84, total loss : 0.2960019111633301,  classifier :0.056807614862918854, mask: 0.11344100534915924 ===================
epoch no : 4, batch no : 85, total loss : 0.2807854413986206,  classifier :0.03488776087760925, mask: 0.10795605927705765 ===================
epoch no : 4, batch no : 86, total loss : 0.3141654133796692,  classifier :0.04829372838139534, mask: 0.12418792396783829 ===================
epoch no : 4, batch no : 87, total loss : 0.2604036033153534,  classifier :0.04014189541339874, mask: 0.11587554216384888 ===================
epoch no : 4, batch no : 88, total loss : 0.36850079894065857,  classifier :0.04111458733677864, mask: 0.15831269323825836 ===================
epoch no : 4, batch no : 89, total loss : 0.47537872195243835,  classifier :0.047741711139678955, mask: 0.1382739245891571 ===================
epoch no : 4, batch no : 90, total loss : 0.3260806202888489,  classifier :0.03502621501684189, mask: 0.13279016315937042 ===================
epoch no : 4, batch no : 91, total loss : 0.30269595980644226,  classifier :0.06739263981580734, mask: 0.11457768082618713 ===================
epoch no : 4, batch no : 92, total loss : 0.28081101179122925,  classifier :0.05137385427951813, mask: 0.10685911774635315 ===================
epoch no : 4, batch no : 93, total loss : 0.4104536771774292,  classifier :0.04280886426568031, mask: 0.1536644995212555 ===================
epoch no : 4, batch no : 94, total loss : 0.36598291993141174,  classifier :0.03506075218319893, mask: 0.14467620849609375 ===================
epoch no : 4, batch no : 95, total loss : 0.3067193329334259,  classifier :0.05011201277375221, mask: 0.08971896767616272 ===================
epoch no : 4, batch no : 96, total loss : 0.3342961072921753,  classifier :0.04454375058412552, mask: 0.13903801143169403 ===================
epoch no : 4, batch no : 97, total loss : 0.36558738350868225,  classifier :0.03498765826225281, mask: 0.13655811548233032 ===================
epoch no : 4, batch no : 98, total loss : 0.291069895029068,  classifier :0.03726222738623619, mask: 0.12075992673635483 ===================
epoch no : 4, batch no : 99, total loss : 0.33571478724479675,  classifier :0.031403325498104095, mask: 0.1320236325263977 ===================
epoch no : 4, batch no : 100, total loss : 0.35750487446784973,  classifier :0.04546842351555824, mask: 0.140123188495636 ===================
epoch no : 4, batch no : 101, total loss : 0.36507463455200195,  classifier :0.06981223821640015, mask: 0.11562413722276688 ===================
epoch no : 4, batch no : 102, total loss : 0.28149205446243286,  classifier :0.03022332675755024, mask: 0.10623075067996979 ===================
epoch no : 4, batch no : 103, total loss : 0.4858494699001312,  classifier :0.05344456806778908, mask: 0.1632567197084427 ===================
epoch no : 4, batch no : 104, total loss : 0.3000417649745941,  classifier :0.04023518040776253, mask: 0.11586470156908035 ===================
epoch no : 4, batch no : 105, total loss : 0.3661676347255707,  classifier :0.052105341106653214, mask: 0.16810539364814758 ===================
epoch no : 4, batch no : 106, total loss : 0.36382997035980225,  classifier :0.03916527330875397, mask: 0.15317974984645844 ===================
epoch no : 4, batch no : 107, total loss : 0.27712294459342957,  classifier :0.03880026936531067, mask: 0.11047812551259995 ===================
epoch no : 4, batch no : 108, total loss : 0.35544875264167786,  classifier :0.041987091302871704, mask: 0.12670409679412842 ===================
epoch no : 4, batch no : 109, total loss : 0.3343566358089447,  classifier :0.04878382012248039, mask: 0.12611255049705505 ===================
epoch no : 4, batch no : 110, total loss : 0.3365667462348938,  classifier :0.04328656941652298, mask: 0.15296094119548798 ===================
epoch no : 4, batch no : 111, total loss : 0.28641706705093384,  classifier :0.0416116900742054, mask: 0.0993347093462944 ===================
epoch no : 4, batch no : 112, total loss : 0.36647599935531616,  classifier :0.05205098167061806, mask: 0.14830219745635986 ===================
epoch no : 4, batch no : 113, total loss : 0.4003913998603821,  classifier :0.05597896873950958, mask: 0.16660606861114502 ===================
epoch no : 4, batch no : 114, total loss : 0.36601510643959045,  classifier :0.034121036529541016, mask: 0.15351206064224243 ===================
epoch no : 4, batch no : 115, total loss : 0.3041776120662689,  classifier :0.04564987123012543, mask: 0.12306947261095047 ===================
epoch no : 4, batch no : 116, total loss : 0.28762418031692505,  classifier :0.03271201625466347, mask: 0.10236004739999771 ===================
epoch no : 4, batch no : 117, total loss : 0.2929273843765259,  classifier :0.04435374587774277, mask: 0.13068926334381104 ===================
epoch no : 4, batch no : 118, total loss : 0.43056049942970276,  classifier :0.0501449853181839, mask: 0.1754482090473175 ===================
epoch no : 4, batch no : 119, total loss : 0.3573155403137207,  classifier :0.04455190151929855, mask: 0.14642265439033508 ===================
epoch no : 4, batch no : 120, total loss : 0.32532763481140137,  classifier :0.043403107672929764, mask: 0.136056587100029 ===================
epoch no : 4, batch no : 121, total loss : 0.30491408705711365,  classifier :0.04366099089384079, mask: 0.15087510645389557 ===================
epoch no : 4, batch no : 122, total loss : 0.28369492292404175,  classifier :0.034139394760131836, mask: 0.11770199239253998 ===================
epoch no : 4, batch no : 123, total loss : 0.34839993715286255,  classifier :0.04394473508000374, mask: 0.13586971163749695 ===================
epoch no : 4, batch no : 124, total loss : 0.36441120505332947,  classifier :0.03665432706475258, mask: 0.12076671421527863 ===================
epoch no : 4, batch no : 125, total loss : 0.32190775871276855,  classifier :0.03282732516527176, mask: 0.1426279991865158 ===================
epoch no : 4, batch no : 126, total loss : 0.2983434498310089,  classifier :0.03352818265557289, mask: 0.11813788115978241 ===================
epoch no : 4, batch no : 127, total loss : 0.3364626467227936,  classifier :0.046613212674856186, mask: 0.1260225474834442 ===================
epoch no : 4, batch no : 128, total loss : 0.28266844153404236,  classifier :0.042463984340429306, mask: 0.11408504098653793 ===================
epoch no : 4, batch no : 129, total loss : 0.35074320435523987,  classifier :0.054592546075582504, mask: 0.12020140886306763 ===================
epoch no : 4, batch no : 130, total loss : 0.39240315556526184,  classifier :0.048951394855976105, mask: 0.14577914774417877 ===================
epoch no : 4, batch no : 131, total loss : 0.4065772294998169,  classifier :0.04006575420498848, mask: 0.1825156807899475 ===================
epoch no : 4, batch no : 132, total loss : 0.28681841492652893,  classifier :0.03543135151267052, mask: 0.12322486191987991 ===================
epoch no : 4, batch no : 133, total loss : 0.30106574296951294,  classifier :0.04938117042183876, mask: 0.12428218871355057 ===================
epoch no : 4, batch no : 134, total loss : 0.32133108377456665,  classifier :0.033521268516778946, mask: 0.1450767070055008 ===================
epoch no : 4, batch no : 135, total loss : 0.34265080094337463,  classifier :0.0387243889272213, mask: 0.15019354224205017 ===================
epoch no : 4, batch no : 136, total loss : 0.3568648397922516,  classifier :0.04891078546643257, mask: 0.14742298424243927 ===================
epoch no : 4, batch no : 137, total loss : 0.3766827881336212,  classifier :0.03360983729362488, mask: 0.16272631287574768 ===================
epoch no : 4, batch no : 138, total loss : 0.3396962881088257,  classifier :0.04212746024131775, mask: 0.11655039340257645 ===================
epoch no : 4, batch no : 139, total loss : 0.280840128660202,  classifier :0.03829324617981911, mask: 0.10795945674180984 ===================
epoch no : 4, batch no : 140, total loss : 0.2729823589324951,  classifier :0.0341317355632782, mask: 0.1002185270190239 ===================
epoch no : 4, batch no : 141, total loss : 0.31303659081459045,  classifier :0.044316038489341736, mask: 0.11452754586935043 ===================
epoch no : 4, batch no : 142, total loss : 0.3744085133075714,  classifier :0.04653405025601387, mask: 0.13684122264385223 ===================
epoch no : 4, batch no : 143, total loss : 0.2946580946445465,  classifier :0.034793585538864136, mask: 0.11079985648393631 ===================
epoch no : 4, batch no : 144, total loss : 0.28813832998275757,  classifier :0.04229277744889259, mask: 0.11035739630460739 ===================
epoch no : 4, batch no : 145, total loss : 0.29647862911224365,  classifier :0.03575138375163078, mask: 0.11321420222520828 ===================
epoch no : 4, batch no : 146, total loss : 0.289090096950531,  classifier :0.03891090676188469, mask: 0.133694589138031 ===================
epoch no : 4, batch no : 147, total loss : 0.3824672996997833,  classifier :0.05963970720767975, mask: 0.11323943734169006 ===================
epoch no : 4, batch no : 148, total loss : 0.30199357867240906,  classifier :0.04025895148515701, mask: 0.11619888246059418 ===================
epoch no : 4, batch no : 149, total loss : 0.3845478892326355,  classifier :0.032113876193761826, mask: 0.12559011578559875 ===================
epoch no : 4, batch no : 150, total loss : 0.4609297513961792,  classifier :0.05003201588988304, mask: 0.19035162031650543 ===================
epoch no : 4, batch no : 151, total loss : 0.33478450775146484,  classifier :0.0348203144967556, mask: 0.16514679789543152 ===================
epoch no : 4, batch no : 152, total loss : 0.29097336530685425,  classifier :0.04643651098012924, mask: 0.11032970249652863 ===================
epoch no : 4, batch no : 153, total loss : 0.3210119307041168,  classifier :0.03468583896756172, mask: 0.14644043147563934 ===================
epoch no : 4, batch no : 154, total loss : 0.26849284768104553,  classifier :0.0386841744184494, mask: 0.0955934077501297 ===================
epoch no : 4, batch no : 155, total loss : 0.4133831858634949,  classifier :0.039535705000162125, mask: 0.1761317104101181 ===================
epoch no : 4, batch no : 156, total loss : 0.34970489144325256,  classifier :0.043337371200323105, mask: 0.15102936327457428 ===================
epoch no : 4, batch no : 157, total loss : 0.30195432901382446,  classifier :0.02747167833149433, mask: 0.12410930544137955 ===================
epoch no : 4, batch no : 158, total loss : 0.45959851145744324,  classifier :0.07020711153745651, mask: 0.1883644163608551 ===================
epoch no : 4, batch no : 159, total loss : 0.3971988558769226,  classifier :0.04969990253448486, mask: 0.12080589681863785 ===================
epoch no : 4, batch no : 160, total loss : 0.39111706614494324,  classifier :0.03642818331718445, mask: 0.13928087055683136 ===================
epoch no : 4, batch no : 161, total loss : 0.31275466084480286,  classifier :0.054805099964141846, mask: 0.11224871128797531 ===================
epoch no : 4, batch no : 162, total loss : 0.2719588279724121,  classifier :0.04116266965866089, mask: 0.10482457280158997 ===================
epoch no : 4, batch no : 163, total loss : 0.2954542934894562,  classifier :0.03669039532542229, mask: 0.13022689521312714 ===================
epoch no : 4, batch no : 164, total loss : 0.3404427468776703,  classifier :0.040084633976221085, mask: 0.1199912428855896 ===================
epoch no : 4, batch no : 165, total loss : 0.3425200283527374,  classifier :0.03837655857205391, mask: 0.14371952414512634 ===================
epoch no : 4, batch no : 166, total loss : 0.36419978737831116,  classifier :0.06485770642757416, mask: 0.12583811581134796 ===================
epoch no : 4, batch no : 167, total loss : 0.3267419636249542,  classifier :0.03874191641807556, mask: 0.13205422461032867 ===================
epoch no : 4, batch no : 168, total loss : 0.32818087935447693,  classifier :0.032743144780397415, mask: 0.13870695233345032 ===================
epoch no : 4, batch no : 169, total loss : 0.34250393509864807,  classifier :0.041212838143110275, mask: 0.15689311921596527 ===================
epoch no : 4, batch no : 170, total loss : 0.3908812999725342,  classifier :0.056267719715833664, mask: 0.1558719277381897 ===================
epoch no : 4, batch no : 171, total loss : 0.29777032136917114,  classifier :0.03130257874727249, mask: 0.10985588282346725 ===================
epoch no : 4, batch no : 172, total loss : 0.38851726055145264,  classifier :0.037596557289361954, mask: 0.13070140779018402 ===================
epoch no : 4, batch no : 173, total loss : 0.5274713039398193,  classifier :0.07412347942590714, mask: 0.20678327977657318 ===================
epoch no : 4, batch no : 174, total loss : 0.3324045240879059,  classifier :0.0530272051692009, mask: 0.12701371312141418 ===================
epoch no : 4, batch no : 175, total loss : 0.28809353709220886,  classifier :0.034087806940078735, mask: 0.10938683152198792 ===================
epoch no : 4, batch no : 176, total loss : 0.2876768410205841,  classifier :0.044170401990413666, mask: 0.12494528293609619 ===================
epoch no : 4, batch no : 177, total loss : 0.3100278973579407,  classifier :0.032079096883535385, mask: 0.12413253635168076 ===================
epoch no : 4, batch no : 178, total loss : 0.29825064539909363,  classifier :0.03228343650698662, mask: 0.16104501485824585 ===================
epoch no : 4, batch no : 179, total loss : 0.44195178151130676,  classifier :0.061051253229379654, mask: 0.1736113578081131 ===================
epoch no : 4, batch no : 180, total loss : 0.2915073037147522,  classifier :0.03776157647371292, mask: 0.1193355992436409 ===================
epoch no : 4, batch no : 181, total loss : 0.24096906185150146,  classifier :0.030200457200407982, mask: 0.09891878813505173 ===================
epoch no : 4, batch no : 182, total loss : 0.2695002555847168,  classifier :0.03990980610251427, mask: 0.11353517323732376 ===================
epoch no : 4, batch no : 183, total loss : 0.35297346115112305,  classifier :0.047011394053697586, mask: 0.1156947985291481 ===================
epoch no : 4, batch no : 184, total loss : 0.3916051685810089,  classifier :0.037161096930503845, mask: 0.15393565595149994 ===================
epoch no : 4, batch no : 185, total loss : 0.3086836338043213,  classifier :0.03287265822291374, mask: 0.10393454879522324 ===================
epoch no : 4, batch no : 186, total loss : 0.3809086084365845,  classifier :0.033803753554821014, mask: 0.15951836109161377 ===================
epoch no : 4, batch no : 187, total loss : 0.32339581847190857,  classifier :0.03369523212313652, mask: 0.14488966763019562 ===================
epoch no : 4, batch no : 188, total loss : 0.4377918243408203,  classifier :0.0518505796790123, mask: 0.17263445258140564 ===================
epoch no : 4, batch no : 189, total loss : 0.37993985414505005,  classifier :0.04610948637127876, mask: 0.15671777725219727 ===================
epoch no : 4, batch no : 190, total loss : 0.2670009434223175,  classifier :0.03320987522602081, mask: 0.1110818088054657 ===================
epoch no : 4, batch no : 191, total loss : 0.27571865916252136,  classifier :0.03970485180616379, mask: 0.09992575645446777 ===================
epoch no : 4, batch no : 192, total loss : 0.3765799403190613,  classifier :0.05982355400919914, mask: 0.13083982467651367 ===================
epoch no : 4, batch no : 193, total loss : 0.4399968683719635,  classifier :0.06004675105214119, mask: 0.15959693491458893 ===================
epoch no : 4, batch no : 194, total loss : 0.43066316843032837,  classifier :0.03911254182457924, mask: 0.16428281366825104 ===================
epoch no : 4, batch no : 195, total loss : 0.34828612208366394,  classifier :0.051717888563871384, mask: 0.14125780761241913 ===================
epoch no : 4, batch no : 196, total loss : 0.35698485374450684,  classifier :0.06995359063148499, mask: 0.13331694900989532 ===================
epoch no : 4, batch no : 197, total loss : 0.29243913292884827,  classifier :0.03328807279467583, mask: 0.13613170385360718 ===================
epoch no : 4, batch no : 198, total loss : 0.2756894528865814,  classifier :0.04662267491221428, mask: 0.10395609587430954 ===================
epoch no : 4, batch no : 199, total loss : 0.26557180285453796,  classifier :0.03832855075597763, mask: 0.10155989229679108 ===================
epoch no : 4, batch no : 200, total loss : 0.36492982506752014,  classifier :0.03467131778597832, mask: 0.14304155111312866 ===================
epoch no : 4, batch no : 201, total loss : 0.3626108765602112,  classifier :0.048278287053108215, mask: 0.1500106155872345 ===================
epoch no : 4, batch no : 202, total loss : 0.4736698269844055,  classifier :0.0604960061609745, mask: 0.1947607696056366 ===================
epoch no : 4, batch no : 203, total loss : 0.45861032605171204,  classifier :0.042488012462854385, mask: 0.16235215961933136 ===================
epoch no : 4, batch no : 204, total loss : 0.3281162977218628,  classifier :0.04596688598394394, mask: 0.12082086503505707 ===================
epoch no : 4, batch no : 205, total loss : 0.35092225670814514,  classifier :0.04637126252055168, mask: 0.13208553194999695 ===================
epoch no : 4, batch no : 206, total loss : 0.2724788188934326,  classifier :0.043684981763362885, mask: 0.11428838968276978 ===================
epoch no : 4, batch no : 207, total loss : 0.3369525372982025,  classifier :0.047930117696523666, mask: 0.14546868205070496 ===================
epoch no : 4, batch no : 208, total loss : 0.375868558883667,  classifier :0.047441620379686356, mask: 0.14866028726100922 ===================
epoch no : 4, batch no : 209, total loss : 0.2512601315975189,  classifier :0.02576916292309761, mask: 0.11634382605552673 ===================
epoch no : 4, batch no : 210, total loss : 0.36370381712913513,  classifier :0.041470713913440704, mask: 0.17411434650421143 ===================
epoch no : 4, batch no : 211, total loss : 0.2942282259464264,  classifier :0.03165270760655403, mask: 0.11014078557491302 ===================
epoch no : 4, batch no : 212, total loss : 0.29870933294296265,  classifier :0.03763698413968086, mask: 0.10726793855428696 ===================
epoch no : 4, batch no : 213, total loss : 0.3029467463493347,  classifier :0.05591912940144539, mask: 0.1257392168045044 ===================
epoch no : 4, batch no : 214, total loss : 0.3408355712890625,  classifier :0.053110916167497635, mask: 0.13895191252231598 ===================
epoch no : 4, batch no : 215, total loss : 0.3097957372665405,  classifier :0.0414883978664875, mask: 0.11945618689060211 ===================
epoch no : 4, batch no : 216, total loss : 0.3338506519794464,  classifier :0.04254220798611641, mask: 0.12673570215702057 ===================
epoch no : 4, batch no : 217, total loss : 0.39362868666648865,  classifier :0.04374179616570473, mask: 0.16291554272174835 ===================
epoch no : 4, batch no : 218, total loss : 0.42557984590530396,  classifier :0.043114107102155685, mask: 0.12570378184318542 ===================
epoch no : 4, batch no : 219, total loss : 0.4739043712615967,  classifier :0.05606925114989281, mask: 0.18484194576740265 ===================
epoch no : 4, batch no : 220, total loss : 0.3957022726535797,  classifier :0.04188084602355957, mask: 0.16748294234275818 ===================
epoch no : 4, batch no : 221, total loss : 0.2570526897907257,  classifier :0.04077804833650589, mask: 0.10135694593191147 ===================
epoch no : 4, batch no : 222, total loss : 0.30413228273391724,  classifier :0.0522787943482399, mask: 0.10873695462942123 ===================
epoch no : 4, batch no : 223, total loss : 0.30637016892433167,  classifier :0.03425075486302376, mask: 0.10502620786428452 ===================
epoch no : 4, batch no : 224, total loss : 0.38333818316459656,  classifier :0.051970697939395905, mask: 0.15203699469566345 ===================
epoch no : 4, batch no : 225, total loss : 0.3092535138130188,  classifier :0.04329190403223038, mask: 0.1186625137925148 ===================
epoch no : 4, batch no : 226, total loss : 0.2589400112628937,  classifier :0.041066933423280716, mask: 0.10823836922645569 ===================
epoch no : 4, batch no : 227, total loss : 0.3416493535041809,  classifier :0.04162413999438286, mask: 0.1359311193227768 ===================
epoch no : 4, batch no : 228, total loss : 0.35405683517456055,  classifier :0.041972480714321136, mask: 0.14673268795013428 ===================
epoch no : 4, batch no : 229, total loss : 0.3874056339263916,  classifier :0.03840704634785652, mask: 0.1353611797094345 ===================
epoch no : 4, batch no : 230, total loss : 0.3157980740070343,  classifier :0.04102307930588722, mask: 0.11833719164133072 ===================
epoch no : 4, batch no : 231, total loss : 0.36739978194236755,  classifier :0.04390663653612137, mask: 0.151304692029953 ===================
epoch no : 4, batch no : 232, total loss : 0.269278347492218,  classifier :0.038135185837745667, mask: 0.09318803995847702 ===================
epoch no : 4, batch no : 233, total loss : 0.3185926377773285,  classifier :0.035751424729824066, mask: 0.14512819051742554 ===================
epoch no : 4, batch no : 234, total loss : 0.2762833833694458,  classifier :0.04378737881779671, mask: 0.12376811355352402 ===================
epoch no : 4, batch no : 235, total loss : 0.27476051449775696,  classifier :0.029488593339920044, mask: 0.1101214587688446 ===================
epoch no : 4, batch no : 236, total loss : 0.30329129099845886,  classifier :0.030911799520254135, mask: 0.13983388245105743 ===================
epoch no : 4, batch no : 237, total loss : 0.30249717831611633,  classifier :0.05205988511443138, mask: 0.1193419024348259 ===================
epoch no : 4, batch no : 238, total loss : 0.2471037209033966,  classifier :0.03874453529715538, mask: 0.11286209523677826 ===================
epoch no : 4, batch no : 239, total loss : 0.2688545286655426,  classifier :0.030670272186398506, mask: 0.12178100645542145 ===================
epoch no : 4, batch no : 240, total loss : 0.2881357967853546,  classifier :0.03199578449130058, mask: 0.0999738797545433 ===================
epoch no : 4, batch no : 241, total loss : 0.36563369631767273,  classifier :0.06274835765361786, mask: 0.14072845876216888 ===================
epoch no : 4, batch no : 242, total loss : 0.2976105511188507,  classifier :0.031749531626701355, mask: 0.12530672550201416 ===================
epoch no : 4, batch no : 243, total loss : 0.4203166663646698,  classifier :0.039125122129917145, mask: 0.16182392835617065 ===================
epoch no : 4, batch no : 244, total loss : 0.2965531647205353,  classifier :0.03352561220526695, mask: 0.10959482938051224 ===================
epoch no : 4, batch no : 245, total loss : 0.26889869570732117,  classifier :0.033643689006567, mask: 0.12340115010738373 ===================
epoch no : 4, batch no : 246, total loss : 0.26844364404678345,  classifier :0.03543210029602051, mask: 0.10536373406648636 ===================
epoch no : 4, batch no : 247, total loss : 0.28110456466674805,  classifier :0.04914689436554909, mask: 0.10487370193004608 ===================
epoch no : 4, batch no : 248, total loss : 0.3471083641052246,  classifier :0.04578136280179024, mask: 0.13273216784000397 ===================
epoch no : 4, batch no : 249, total loss : 0.2886967957019806,  classifier :0.046939849853515625, mask: 0.11360574513673782 ===================
epoch no : 4, batch no : 250, total loss : 0.27055296301841736,  classifier :0.04568826034665108, mask: 0.11185959726572037 ===================
epoch no : 4, batch no : 251, total loss : 0.31495553255081177,  classifier :0.043080512434244156, mask: 0.1048470139503479 ===================
epoch no : 4, batch no : 252, total loss : 0.3044530749320984,  classifier :0.039781879633665085, mask: 0.14295323193073273 ===================
epoch no : 4, batch no : 253, total loss : 0.4750194549560547,  classifier :0.05940975993871689, mask: 0.21383823454380035 ===================
epoch no : 4, batch no : 254, total loss : 0.29120689630508423,  classifier :0.029387496411800385, mask: 0.15265074372291565 ===================
epoch no : 4, batch no : 255, total loss : 0.3567259907722473,  classifier :0.032089490443468094, mask: 0.16305890679359436 ===================
epoch no : 4, batch no : 256, total loss : 0.3717382252216339,  classifier :0.04073203355073929, mask: 0.15357214212417603 ===================
epoch no : 4, batch no : 257, total loss : 0.3214019536972046,  classifier :0.050052348524332047, mask: 0.12106462568044662 ===================
epoch no : 4, batch no : 258, total loss : 0.4248594641685486,  classifier :0.045624420046806335, mask: 0.20146358013153076 ===================
epoch no : 4, batch no : 259, total loss : 0.4036821126937866,  classifier :0.053753580898046494, mask: 0.14945034682750702 ===================
epoch no : 4, batch no : 260, total loss : 0.3256663978099823,  classifier :0.0414450541138649, mask: 0.14621149003505707 ===================
epoch no : 4, batch no : 261, total loss : 0.3938536047935486,  classifier :0.04532896727323532, mask: 0.15476453304290771 ===================
epoch no : 4, batch no : 262, total loss : 0.465567409992218,  classifier :0.0449686124920845, mask: 0.1933533251285553 ===================
epoch no : 4, batch no : 263, total loss : 0.5167741775512695,  classifier :0.05794626846909523, mask: 0.20453767478466034 ===================
epoch no : 4, batch no : 264, total loss : 0.4304903447628021,  classifier :0.06224814057350159, mask: 0.17214258015155792 ===================
epoch no : 4, batch no : 265, total loss : 0.3066770136356354,  classifier :0.03942570090293884, mask: 0.12153120338916779 ===================
epoch no : 4, batch no : 266, total loss : 0.3587194085121155,  classifier :0.03980439156293869, mask: 0.15807783603668213 ===================
epoch no : 4, batch no : 267, total loss : 0.3487180471420288,  classifier :0.03634006902575493, mask: 0.14500319957733154 ===================
epoch no : 4, batch no : 268, total loss : 0.3552463948726654,  classifier :0.04680238664150238, mask: 0.14524196088314056 ===================
epoch no : 4, batch no : 269, total loss : 0.333404541015625,  classifier :0.0397801510989666, mask: 0.13573332130908966 ===================
epoch no : 4, batch no : 270, total loss : 0.2961238622665405,  classifier :0.06717696040868759, mask: 0.11941152811050415 ===================
epoch no : 4, batch no : 271, total loss : 0.24538946151733398,  classifier :0.03783222287893295, mask: 0.10810285806655884 ===================
epoch no : 4, batch no : 272, total loss : 0.31912967562675476,  classifier :0.03807620704174042, mask: 0.136818990111351 ===================
epoch no : 4, batch no : 273, total loss : 0.27615439891815186,  classifier :0.02852165326476097, mask: 0.13090887665748596 ===================
epoch no : 4, batch no : 274, total loss : 0.31649497151374817,  classifier :0.06287644803524017, mask: 0.14034806191921234 ===================
epoch no : 4, batch no : 275, total loss : 0.308445006608963,  classifier :0.043023139238357544, mask: 0.08762945234775543 ===================
epoch no : 4, batch no : 276, total loss : 0.33149269223213196,  classifier :0.03872257471084595, mask: 0.12728790938854218 ===================
epoch no : 4, batch no : 277, total loss : 0.3256062865257263,  classifier :0.043934352695941925, mask: 0.13911877572536469 ===================
epoch no : 4, batch no : 278, total loss : 0.36077719926834106,  classifier :0.05131790414452553, mask: 0.1520230621099472 ===================
epoch no : 4, batch no : 279, total loss : 0.27640268206596375,  classifier :0.038285717368125916, mask: 0.1088663712143898 ===================
epoch no : 4, batch no : 280, total loss : 0.2833654582500458,  classifier :0.03588665649294853, mask: 0.12202184647321701 ===================
epoch no : 4, batch no : 281, total loss : 0.29793453216552734,  classifier :0.041087858378887177, mask: 0.1299753040075302 ===================
epoch no : 4, batch no : 282, total loss : 0.3301887810230255,  classifier :0.03052409365773201, mask: 0.16046616435050964 ===================
epoch no : 4, batch no : 283, total loss : 0.280926913022995,  classifier :0.04292170703411102, mask: 0.10523580759763718 ===================
epoch no : 4, batch no : 284, total loss : 0.4100717008113861,  classifier :0.07539953291416168, mask: 0.15297232568264008 ===================
epoch no : 4, batch no : 285, total loss : 0.23009489476680756,  classifier :0.027119901031255722, mask: 0.09670771658420563 ===================
epoch no : 4, batch no : 286, total loss : 0.29405200481414795,  classifier :0.031074633821845055, mask: 0.10602565854787827 ===================
epoch no : 4, batch no : 287, total loss : 0.3872852921485901,  classifier :0.026463843882083893, mask: 0.14241741597652435 ===================
epoch no : 4, batch no : 288, total loss : 0.38416558504104614,  classifier :0.049733199179172516, mask: 0.17228060960769653 ===================
epoch no : 4, batch no : 289, total loss : 0.2756105065345764,  classifier :0.04009168967604637, mask: 0.12200721353292465 ===================
epoch no : 4, batch no : 290, total loss : 0.3260738253593445,  classifier :0.054387837648391724, mask: 0.12166392803192139 ===================
epoch no : 4, batch no : 291, total loss : 0.3142894506454468,  classifier :0.029563579708337784, mask: 0.12864530086517334 ===================
epoch no : 4, batch no : 292, total loss : 0.34198182821273804,  classifier :0.04091493785381317, mask: 0.1355309933423996 ===================
epoch no : 4, batch no : 293, total loss : 0.24933438003063202,  classifier :0.03264867886900902, mask: 0.11002035439014435 ===================
epoch no : 4, batch no : 294, total loss : 0.32478952407836914,  classifier :0.03521764650940895, mask: 0.13779820501804352 ===================
epoch no : 4, batch no : 295, total loss : 0.3398309350013733,  classifier :0.027970755472779274, mask: 0.1302085816860199 ===================
epoch no : 4, batch no : 296, total loss : 0.29994258284568787,  classifier :0.04493420198559761, mask: 0.12340375781059265 ===================
epoch no : 4, batch no : 297, total loss : 0.3629089593887329,  classifier :0.05057685449719429, mask: 0.15749455988407135 ===================
epoch no : 4, batch no : 298, total loss : 0.3305310606956482,  classifier :0.03514639288187027, mask: 0.12393765896558762 ===================
epoch no : 4, batch no : 299, total loss : 0.38244378566741943,  classifier :0.03892972692847252, mask: 0.15122269093990326 ===================
epoch no : 4, batch no : 300, total loss : 0.32393091917037964,  classifier :0.03575468063354492, mask: 0.15051816403865814 ===================
epoch no : 4, batch no : 301, total loss : 0.29068630933761597,  classifier :0.04635202884674072, mask: 0.13043364882469177 ===================
epoch no : 4, batch no : 302, total loss : 0.3750799000263214,  classifier :0.05916226655244827, mask: 0.13452258706092834 ===================
epoch no : 4, batch no : 303, total loss : 0.23830899596214294,  classifier :0.03421458229422569, mask: 0.10115089267492294 ===================
epoch no : 4, batch no : 304, total loss : 0.3409998416900635,  classifier :0.05834950506687164, mask: 0.13765503466129303 ===================
epoch no : 4, batch no : 305, total loss : 0.283476322889328,  classifier :0.03203349933028221, mask: 0.12306997925043106 ===================
epoch no : 4, batch no : 306, total loss : 0.3445911407470703,  classifier :0.04400462284684181, mask: 0.12634898722171783 ===================
epoch no : 4, batch no : 307, total loss : 0.33769965171813965,  classifier :0.0366964228451252, mask: 0.14552584290504456 ===================
epoch no : 4, batch no : 308, total loss : 0.3638414442539215,  classifier :0.03768320009112358, mask: 0.1737091839313507 ===================
epoch no : 4, batch no : 309, total loss : 0.33025410771369934,  classifier :0.0341588594019413, mask: 0.12396621704101562 ===================
epoch no : 4, batch no : 310, total loss : 0.305835098028183,  classifier :0.030594900250434875, mask: 0.12621571123600006 ===================
epoch no : 4, batch no : 311, total loss : 0.3303929269313812,  classifier :0.040530726313591, mask: 0.13542577624320984 ===================
epoch no : 4, batch no : 312, total loss : 0.3655085265636444,  classifier :0.04832782223820686, mask: 0.14737460017204285 ===================
epoch no : 4, batch no : 313, total loss : 0.27725908160209656,  classifier :0.04860621318221092, mask: 0.11399979144334793 ===================
epoch no : 4, batch no : 314, total loss : 0.310109406709671,  classifier :0.043388813734054565, mask: 0.11653674393892288 ===================
epoch no : 4, batch no : 315, total loss : 0.31824028491973877,  classifier :0.03361019492149353, mask: 0.11435665190219879 ===================
epoch no : 4, batch no : 316, total loss : 0.3068889379501343,  classifier :0.03523702174425125, mask: 0.12462394684553146 ===================
epoch no : 4, batch no : 317, total loss : 0.319446861743927,  classifier :0.0397583469748497, mask: 0.13008275628089905 ===================
epoch no : 4, batch no : 318, total loss : 0.2974676191806793,  classifier :0.04277205839753151, mask: 0.11746643483638763 ===================
epoch no : 4, batch no : 319, total loss : 0.24321117997169495,  classifier :0.02728942036628723, mask: 0.0975601002573967 ===================
epoch no : 4, batch no : 320, total loss : 0.2997477650642395,  classifier :0.059603314846754074, mask: 0.10486752539873123 ===================
epoch no : 4, batch no : 321, total loss : 0.25489193201065063,  classifier :0.02795514091849327, mask: 0.10758300125598907 ===================
epoch no : 4, batch no : 322, total loss : 0.3193892538547516,  classifier :0.03678358718752861, mask: 0.13713786005973816 ===================
epoch no : 4, batch no : 323, total loss : 0.2764538526535034,  classifier :0.035171423107385635, mask: 0.11725587397813797 ===================
epoch no : 4, batch no : 324, total loss : 0.3146464228630066,  classifier :0.05387303978204727, mask: 0.12720751762390137 ===================
epoch no : 4, batch no : 325, total loss : 0.3534870147705078,  classifier :0.04597068950533867, mask: 0.15647609531879425 ===================
epoch no : 4, batch no : 326, total loss : 0.32310396432876587,  classifier :0.02503376267850399, mask: 0.17801247537136078 ===================
epoch no : 4, batch no : 327, total loss : 0.3235345184803009,  classifier :0.03480011224746704, mask: 0.12825877964496613 ===================
epoch no : 4, batch no : 328, total loss : 0.26540735363960266,  classifier :0.03154945746064186, mask: 0.10099364817142487 ===================
epoch no : 4, batch no : 329, total loss : 0.2351386994123459,  classifier :0.02866468019783497, mask: 0.10809902101755142 ===================
epoch no : 4, batch no : 330, total loss : 0.2658837139606476,  classifier :0.03264402225613594, mask: 0.10860858112573624 ===================
epoch no : 4, batch no : 331, total loss : 0.2821403443813324,  classifier :0.04514116793870926, mask: 0.1106327474117279 ===================
epoch no : 4, batch no : 332, total loss : 0.33597832918167114,  classifier :0.04450690373778343, mask: 0.15618206560611725 ===================
epoch no : 4, batch no : 333, total loss : 0.3798152804374695,  classifier :0.03478100895881653, mask: 0.1724761724472046 ===================
epoch no : 4, batch no : 334, total loss : 0.2946586608886719,  classifier :0.03224354237318039, mask: 0.13129611313343048 ===================
epoch no : 4, batch no : 335, total loss : 0.3158669173717499,  classifier :0.029708722606301308, mask: 0.1457572877407074 ===================
epoch no : 4, batch no : 336, total loss : 0.30397850275039673,  classifier :0.04020470380783081, mask: 0.10844891518354416 ===================
epoch no : 4, batch no : 337, total loss : 0.3279041349887848,  classifier :0.036186207085847855, mask: 0.13415507972240448 ===================
epoch no : 4, batch no : 338, total loss : 0.287471204996109,  classifier :0.029760751873254776, mask: 0.1252295821905136 ===================
epoch no : 4, batch no : 339, total loss : 0.266065776348114,  classifier :0.03277100622653961, mask: 0.1156664565205574 ===================
epoch no : 4, batch no : 340, total loss : 0.32001426815986633,  classifier :0.029004396870732307, mask: 0.1896817684173584 ===================
epoch no : 4, batch no : 341, total loss : 0.3327573239803314,  classifier :0.029284341260790825, mask: 0.11823831498622894 ===================
epoch no : 4, batch no : 342, total loss : 0.2817062735557556,  classifier :0.025641651824116707, mask: 0.13033796846866608 ===================
epoch no : 4, batch no : 343, total loss : 0.3079238831996918,  classifier :0.035171449184417725, mask: 0.12484966963529587 ===================
epoch no : 4, batch no : 344, total loss : 0.28208237886428833,  classifier :0.037319283932447433, mask: 0.1194300577044487 ===================
epoch no : 4, batch no : 345, total loss : 0.3291471302509308,  classifier :0.05210421234369278, mask: 0.12641604244709015 ===================
epoch no : 4, batch no : 346, total loss : 0.34220626950263977,  classifier :0.043725162744522095, mask: 0.1384180188179016 ===================
epoch no : 4, batch no : 347, total loss : 0.28357914090156555,  classifier :0.03991110250353813, mask: 0.1336452215909958 ===================
epoch no : 4, batch no : 348, total loss : 0.4297929108142853,  classifier :0.03575078770518303, mask: 0.1876373291015625 ===================
epoch no : 4, batch no : 349, total loss : 0.31976091861724854,  classifier :0.04225902631878853, mask: 0.1451273262500763 ===================
epoch no : 4, batch no : 350, total loss : 0.3804449141025543,  classifier :0.039566896855831146, mask: 0.16142503917217255 ===================
epoch no : 4, batch no : 351, total loss : 0.3347282409667969,  classifier :0.03861948475241661, mask: 0.14315274357795715 ===================
epoch no : 4, batch no : 352, total loss : 0.26516398787498474,  classifier :0.03388693556189537, mask: 0.113222137093544 ===================
epoch no : 4, batch no : 353, total loss : 0.28601476550102234,  classifier :0.0386151559650898, mask: 0.1093376949429512 ===================
epoch no : 4, batch no : 354, total loss : 0.37895411252975464,  classifier :0.054589759558439255, mask: 0.14071780443191528 ===================
epoch no : 4, batch no : 355, total loss : 0.30985745787620544,  classifier :0.04243478551506996, mask: 0.13091713190078735 ===================
epoch no : 4, batch no : 356, total loss : 0.3442939817905426,  classifier :0.044921163469552994, mask: 0.14735837280750275 ===================
epoch no : 4, batch no : 357, total loss : 0.3093789219856262,  classifier :0.03729748725891113, mask: 0.11445213854312897 ===================
epoch no : 4, batch no : 358, total loss : 0.3321930766105652,  classifier :0.04199417307972908, mask: 0.14436045289039612 ===================
epoch no : 4, batch no : 359, total loss : 0.23085838556289673,  classifier :0.035908591002225876, mask: 0.10037662833929062 ===================
epoch no : 4, batch no : 360, total loss : 0.3762202560901642,  classifier :0.04402538761496544, mask: 0.15061655640602112 ===================
epoch no : 4, batch no : 361, total loss : 0.26468750834465027,  classifier :0.03869365155696869, mask: 0.10890459269285202 ===================
epoch no : 4, batch no : 362, total loss : 0.3162733316421509,  classifier :0.027083076536655426, mask: 0.14062631130218506 ===================
epoch no : 4, batch no : 363, total loss : 0.30877387523651123,  classifier :0.03983490914106369, mask: 0.10768909752368927 ===================
epoch no : 4, batch no : 364, total loss : 0.33190786838531494,  classifier :0.05200528725981712, mask: 0.11463389545679092 ===================
epoch no : 4, batch no : 365, total loss : 0.31515565514564514,  classifier :0.0408809520304203, mask: 0.13178208470344543 ===================
epoch no : 4, batch no : 366, total loss : 0.3972972333431244,  classifier :0.056081175804138184, mask: 0.14871099591255188 ===================
epoch no : 4, batch no : 367, total loss : 0.2823069095611572,  classifier :0.03506482392549515, mask: 0.10103314369916916 ===================
epoch no : 4, batch no : 368, total loss : 0.29801443219184875,  classifier :0.032813772559165955, mask: 0.12057378143072128 ===================
epoch no : 4, batch no : 369, total loss : 0.3302565813064575,  classifier :0.05750025063753128, mask: 0.125791534781456 ===================
epoch no : 4, batch no : 370, total loss : 0.29018929600715637,  classifier :0.03384466841816902, mask: 0.12565390765666962 ===================
epoch no : 4, batch no : 371, total loss : 0.37123560905456543,  classifier :0.04607445001602173, mask: 0.14569297432899475 ===================
epoch no : 4, batch no : 372, total loss : 0.4204031825065613,  classifier :0.04346245154738426, mask: 0.19601549208164215 ===================
epoch no : 4, batch no : 373, total loss : 0.3533115088939667,  classifier :0.027321403846144676, mask: 0.1463450938463211 ===================
epoch no : 4, batch no : 374, total loss : 0.33730289340019226,  classifier :0.035471707582473755, mask: 0.12601236999034882 ===================
epoch no : 4, batch no : 375, total loss : 0.3145928680896759,  classifier :0.03826061263680458, mask: 0.11580552160739899 ===================
epoch no : 4, batch no : 376, total loss : 0.2547336220741272,  classifier :0.03839603811502457, mask: 0.10988672077655792 ===================
epoch no : 4, batch no : 377, total loss : 0.3765600919723511,  classifier :0.035769786685705185, mask: 0.16152027249336243 ===================
epoch no : 4, batch no : 378, total loss : 0.28853780031204224,  classifier :0.029765857383608818, mask: 0.11284381151199341 ===================
epoch no : 4, batch no : 379, total loss : 0.29351720213890076,  classifier :0.03400444611907005, mask: 0.14111317694187164 ===================
epoch no : 4, batch no : 380, total loss : 0.28892338275909424,  classifier :0.027861274778842926, mask: 0.12088149785995483 ===================
epoch no : 4, batch no : 381, total loss : 0.2559873163700104,  classifier :0.03549591451883316, mask: 0.10139729082584381 ===================
epoch no : 4, batch no : 382, total loss : 0.26318222284317017,  classifier :0.029530495405197144, mask: 0.12067952752113342 ===================
epoch no : 4, batch no : 383, total loss : 0.3486109972000122,  classifier :0.03905067220330238, mask: 0.14807577431201935 ===================
epoch no : 4, batch no : 384, total loss : 0.277717262506485,  classifier :0.03771505132317543, mask: 0.12670542299747467 ===================
epoch no : 4, batch no : 385, total loss : 0.27246198058128357,  classifier :0.03355366736650467, mask: 0.1061587706208229 ===================
epoch no : 4, batch no : 386, total loss : 0.3117915093898773,  classifier :0.034026578068733215, mask: 0.13160037994384766 ===================
epoch no : 4, batch no : 387, total loss : 0.30375584959983826,  classifier :0.03993182256817818, mask: 0.11847919970750809 ===================
epoch no : 4, batch no : 388, total loss : 0.3124183118343353,  classifier :0.04035957157611847, mask: 0.130819171667099 ===================
epoch no : 4, batch no : 389, total loss : 0.2331106960773468,  classifier :0.031495146453380585, mask: 0.09094130247831345 ===================
epoch no : 4, batch no : 390, total loss : 0.26365944743156433,  classifier :0.027097512036561966, mask: 0.102288156747818 ===================
epoch no : 4, batch no : 391, total loss : 0.3217591941356659,  classifier :0.030031656846404076, mask: 0.12747274339199066 ===================
epoch no : 4, batch no : 392, total loss : 0.24213962256908417,  classifier :0.030365949496626854, mask: 0.09586168825626373 ===================
epoch no : 4, batch no : 393, total loss : 0.34264257550239563,  classifier :0.0362745076417923, mask: 0.16243073344230652 ===================
epoch no : 4, batch no : 394, total loss : 0.4023219645023346,  classifier :0.04199608415365219, mask: 0.1291656792163849 ===================
epoch no : 4, batch no : 395, total loss : 0.3833157420158386,  classifier :0.03646889701485634, mask: 0.14529302716255188 ===================
epoch no : 4, batch no : 396, total loss : 0.35531026124954224,  classifier :0.04043140634894371, mask: 0.15319722890853882 ===================
epoch no : 4, batch no : 397, total loss : 0.32306766510009766,  classifier :0.050160448998212814, mask: 0.13021250069141388 ===================
epoch no : 4, batch no : 398, total loss : 0.3800837993621826,  classifier :0.03183608874678612, mask: 0.20258481800556183 ===================
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch no : 5, batch no : 0, total loss : 0.41436538100242615,  classifier :0.055490393191576004, mask: 0.1454400271177292 ===================
epoch no : 5, batch no : 1, total loss : 0.30597615242004395,  classifier :0.03212076053023338, mask: 0.13187675178050995 ===================
epoch no : 5, batch no : 2, total loss : 0.30045104026794434,  classifier :0.049555957317352295, mask: 0.13537493348121643 ===================
epoch no : 5, batch no : 3, total loss : 0.2700512111186981,  classifier :0.03527574613690376, mask: 0.10149002820253372 ===================
epoch no : 5, batch no : 4, total loss : 0.26855480670928955,  classifier :0.0288399551063776, mask: 0.11213617026805878 ===================
epoch no : 5, batch no : 5, total loss : 0.2587292194366455,  classifier :0.0333857461810112, mask: 0.10096927732229233 ===================
epoch no : 5, batch no : 6, total loss : 0.25273990631103516,  classifier :0.030207611620426178, mask: 0.08973119407892227 ===================
epoch no : 5, batch no : 7, total loss : 0.3427882492542267,  classifier :0.04707511514425278, mask: 0.17524953186511993 ===================
epoch no : 5, batch no : 8, total loss : 0.30815157294273376,  classifier :0.029929611831903458, mask: 0.12357743829488754 ===================
epoch no : 5, batch no : 9, total loss : 0.2066602259874344,  classifier :0.03089759312570095, mask: 0.07791269570589066 ===================
epoch no : 5, batch no : 10, total loss : 0.40527328848838806,  classifier :0.03553197905421257, mask: 0.1251382827758789 ===================
epoch no : 5, batch no : 11, total loss : 0.3529292345046997,  classifier :0.0328805036842823, mask: 0.1256375014781952 ===================
epoch no : 5, batch no : 12, total loss : 0.3282638490200043,  classifier :0.06393101811408997, mask: 0.11589553952217102 ===================
epoch no : 5, batch no : 13, total loss : 0.32408976554870605,  classifier :0.029683126136660576, mask: 0.13683176040649414 ===================
epoch no : 5, batch no : 14, total loss : 0.302592933177948,  classifier :0.03446540981531143, mask: 0.11954697221517563 ===================
epoch no : 5, batch no : 15, total loss : 0.2948507070541382,  classifier :0.03504005819559097, mask: 0.1313875913619995 ===================
epoch no : 5, batch no : 16, total loss : 0.27742841839790344,  classifier :0.03637642040848732, mask: 0.1041945368051529 ===================
epoch no : 5, batch no : 17, total loss : 0.2612782418727875,  classifier :0.038272447884082794, mask: 0.10604362189769745 ===================
epoch no : 5, batch no : 18, total loss : 0.2672252655029297,  classifier :0.03191041573882103, mask: 0.11458985507488251 ===================
epoch no : 5, batch no : 19, total loss : 0.35355645418167114,  classifier :0.040365688502788544, mask: 0.13833700120449066 ===================
epoch no : 5, batch no : 20, total loss : 0.22178779542446136,  classifier :0.03415326029062271, mask: 0.08704282343387604 ===================
epoch no : 5, batch no : 21, total loss : 0.23613563179969788,  classifier :0.030078373849391937, mask: 0.10898034274578094 ===================
epoch no : 5, batch no : 22, total loss : 0.29999715089797974,  classifier :0.04451890289783478, mask: 0.10601888597011566 ===================
epoch no : 5, batch no : 23, total loss : 0.3269433379173279,  classifier :0.03391579911112785, mask: 0.10340973734855652 ===================
epoch no : 5, batch no : 24, total loss : 0.3065648674964905,  classifier :0.031223764643073082, mask: 0.11448174715042114 ===================
epoch no : 5, batch no : 25, total loss : 0.2776953876018524,  classifier :0.03443409129977226, mask: 0.10589609295129776 ===================
epoch no : 5, batch no : 26, total loss : 0.3313579559326172,  classifier :0.03182114660739899, mask: 0.14149276912212372 ===================
epoch no : 5, batch no : 27, total loss : 0.2432473748922348,  classifier :0.03450891375541687, mask: 0.11054334789514542 ===================
epoch no : 5, batch no : 28, total loss : 0.2750411629676819,  classifier :0.032873284071683884, mask: 0.13806995749473572 ===================
epoch no : 5, batch no : 29, total loss : 0.40300288796424866,  classifier :0.03038889914751053, mask: 0.20089790225028992 ===================
epoch no : 5, batch no : 30, total loss : 0.323688805103302,  classifier :0.03278657793998718, mask: 0.15742290019989014 ===================
epoch no : 5, batch no : 31, total loss : 0.266411691904068,  classifier :0.0331905223429203, mask: 0.11093082278966904 ===================
epoch no : 5, batch no : 32, total loss : 0.27876925468444824,  classifier :0.03150671347975731, mask: 0.16319023072719574 ===================
epoch no : 5, batch no : 33, total loss : 0.30365413427352905,  classifier :0.031282082200050354, mask: 0.13173320889472961 ===================
epoch no : 5, batch no : 34, total loss : 0.3761735260486603,  classifier :0.047541294246912, mask: 0.12396681308746338 ===================
epoch no : 5, batch no : 35, total loss : 0.30887746810913086,  classifier :0.04405440017580986, mask: 0.12455866485834122 ===================
epoch no : 5, batch no : 36, total loss : 0.2857474088668823,  classifier :0.03153199329972267, mask: 0.10555679351091385 ===================
epoch no : 5, batch no : 37, total loss : 0.397289514541626,  classifier :0.06223238632082939, mask: 0.14114877581596375 ===================
epoch no : 5, batch no : 38, total loss : 0.2943645417690277,  classifier :0.03708465024828911, mask: 0.12652093172073364 ===================
epoch no : 5, batch no : 39, total loss : 0.3277234733104706,  classifier :0.041456907987594604, mask: 0.14409343898296356 ===================
epoch no : 5, batch no : 40, total loss : 0.3571286201477051,  classifier :0.0343756265938282, mask: 0.1385682076215744 ===================
epoch no : 5, batch no : 41, total loss : 0.3109007477760315,  classifier :0.02970176748931408, mask: 0.1346658319234848 ===================
epoch no : 5, batch no : 42, total loss : 0.3247966468334198,  classifier :0.04008584842085838, mask: 0.16116972267627716 ===================
epoch no : 5, batch no : 43, total loss : 0.3216148912906647,  classifier :0.0533757321536541, mask: 0.129928857088089 ===================
epoch no : 5, batch no : 44, total loss : 0.3241118788719177,  classifier :0.03435644134879112, mask: 0.14870814979076385 ===================
epoch no : 5, batch no : 45, total loss : 0.32022011280059814,  classifier :0.03127646446228027, mask: 0.142838254570961 ===================
epoch no : 5, batch no : 46, total loss : 0.2511402666568756,  classifier :0.029725531116127968, mask: 0.12363818287849426 ===================
epoch no : 5, batch no : 47, total loss : 0.29512500762939453,  classifier :0.02859589271247387, mask: 0.14726215600967407 ===================
epoch no : 5, batch no : 48, total loss : 0.25495877861976624,  classifier :0.05427154526114464, mask: 0.08741100877523422 ===================
epoch no : 5, batch no : 49, total loss : 0.2946280241012573,  classifier :0.028373928740620613, mask: 0.11766023933887482 ===================
epoch no : 5, batch no : 50, total loss : 0.31865909695625305,  classifier :0.025492630898952484, mask: 0.13476349413394928 ===================
epoch no : 5, batch no : 51, total loss : 0.2417156994342804,  classifier :0.04779050126671791, mask: 0.09946013242006302 ===================
epoch no : 5, batch no : 52, total loss : 0.27733051776885986,  classifier :0.031843457370996475, mask: 0.10652301460504532 ===================
epoch no : 5, batch no : 53, total loss : 0.3036626875400543,  classifier :0.04656948149204254, mask: 0.11560054868459702 ===================
epoch no : 5, batch no : 54, total loss : 0.27763426303863525,  classifier :0.04645806923508644, mask: 0.11352938413619995 ===================
epoch no : 5, batch no : 55, total loss : 0.4655936062335968,  classifier :0.046112604439258575, mask: 0.15949074923992157 ===================
epoch no : 5, batch no : 56, total loss : 0.3149767518043518,  classifier :0.03132999688386917, mask: 0.1360335350036621 ===================
epoch no : 5, batch no : 57, total loss : 0.36189767718315125,  classifier :0.03315214440226555, mask: 0.14500321447849274 ===================
epoch no : 5, batch no : 58, total loss : 0.5627625584602356,  classifier :0.049655038863420486, mask: 0.20952245593070984 ===================
epoch no : 5, batch no : 59, total loss : 0.3453752100467682,  classifier :0.03734690323472023, mask: 0.15704332292079926 ===================
epoch no : 5, batch no : 60, total loss : 0.32172834873199463,  classifier :0.05526895448565483, mask: 0.12850335240364075 ===================
epoch no : 5, batch no : 61, total loss : 0.3102458417415619,  classifier :0.03972569480538368, mask: 0.10959681868553162 ===================
epoch no : 5, batch no : 62, total loss : 0.317982017993927,  classifier :0.03284047171473503, mask: 0.15923157334327698 ===================
epoch no : 5, batch no : 63, total loss : 0.3259781002998352,  classifier :0.030595386400818825, mask: 0.1510375589132309 ===================
epoch no : 5, batch no : 64, total loss : 0.3436746895313263,  classifier :0.047559913247823715, mask: 0.1512310951948166 ===================
epoch no : 5, batch no : 65, total loss : 0.31444790959358215,  classifier :0.03967730700969696, mask: 0.13026098906993866 ===================
epoch no : 5, batch no : 66, total loss : 0.2778778076171875,  classifier :0.03621681034564972, mask: 0.10962782800197601 ===================
epoch no : 5, batch no : 67, total loss : 0.31183841824531555,  classifier :0.032896921038627625, mask: 0.1220220997929573 ===================
epoch no : 5, batch no : 68, total loss : 0.2681642174720764,  classifier :0.03170469403266907, mask: 0.115140400826931 ===================
epoch no : 5, batch no : 69, total loss : 0.29830652475357056,  classifier :0.03852503374218941, mask: 0.1246834546327591 ===================
epoch no : 5, batch no : 70, total loss : 0.2833128869533539,  classifier :0.03582041710615158, mask: 0.13150915503501892 ===================
epoch no : 5, batch no : 71, total loss : 0.24270370602607727,  classifier :0.03765963390469551, mask: 0.10464449971914291 ===================
epoch no : 5, batch no : 72, total loss : 0.38255584239959717,  classifier :0.03670690581202507, mask: 0.1660691797733307 ===================
epoch no : 5, batch no : 73, total loss : 0.34589889645576477,  classifier :0.032950010150671005, mask: 0.15754087269306183 ===================
epoch no : 5, batch no : 74, total loss : 0.2872527241706848,  classifier :0.03939596563577652, mask: 0.12427109479904175 ===================
epoch no : 5, batch no : 75, total loss : 0.3197597861289978,  classifier :0.04384275898337364, mask: 0.1097511425614357 ===================
epoch no : 5, batch no : 76, total loss : 0.37847232818603516,  classifier :0.051083315163850784, mask: 0.1513933539390564 ===================
epoch no : 5, batch no : 77, total loss : 0.2808436155319214,  classifier :0.027627049013972282, mask: 0.11816725134849548 ===================
epoch no : 5, batch no : 78, total loss : 0.3477986752986908,  classifier :0.03787567466497421, mask: 0.11573095619678497 ===================
epoch no : 5, batch no : 79, total loss : 0.2676294147968292,  classifier :0.029109351336956024, mask: 0.12474235147237778 ===================
epoch no : 5, batch no : 80, total loss : 0.40285998582839966,  classifier :0.06616620719432831, mask: 0.16541017591953278 ===================
epoch no : 5, batch no : 81, total loss : 0.2268654853105545,  classifier :0.03568640723824501, mask: 0.09210733324289322 ===================
epoch no : 5, batch no : 82, total loss : 0.2873479723930359,  classifier :0.027664903551340103, mask: 0.11804493516683578 ===================
epoch no : 5, batch no : 83, total loss : 0.31158533692359924,  classifier :0.031473129987716675, mask: 0.13259881734848022 ===================
epoch no : 5, batch no : 84, total loss : 0.3824426531791687,  classifier :0.0451403483748436, mask: 0.1402219980955124 ===================
epoch no : 5, batch no : 85, total loss : 0.3289743959903717,  classifier :0.03664198890328407, mask: 0.11556156724691391 ===================
epoch no : 5, batch no : 86, total loss : 0.26540541648864746,  classifier :0.030741192400455475, mask: 0.11064257472753525 ===================
epoch no : 5, batch no : 87, total loss : 0.2920110821723938,  classifier :0.03898169845342636, mask: 0.11368196457624435 ===================
epoch no : 5, batch no : 88, total loss : 0.4054124355316162,  classifier :0.05288463085889816, mask: 0.1521911472082138 ===================
epoch no : 5, batch no : 89, total loss : 0.26453354954719543,  classifier :0.034335892647504807, mask: 0.10618235915899277 ===================
epoch no : 5, batch no : 90, total loss : 0.2901385724544525,  classifier :0.035704635083675385, mask: 0.13881129026412964 ===================
epoch no : 5, batch no : 91, total loss : 0.28311118483543396,  classifier :0.034510448575019836, mask: 0.12461342662572861 ===================
epoch no : 5, batch no : 92, total loss : 0.23258504271507263,  classifier :0.03189520537853241, mask: 0.10052728652954102 ===================
epoch no : 5, batch no : 93, total loss : 0.30550485849380493,  classifier :0.03584916889667511, mask: 0.12761563062667847 ===================
epoch no : 5, batch no : 94, total loss : 0.39512747526168823,  classifier :0.05873362347483635, mask: 0.15378117561340332 ===================
epoch no : 5, batch no : 95, total loss : 0.31319355964660645,  classifier :0.0301213301718235, mask: 0.15795956552028656 ===================
epoch no : 5, batch no : 96, total loss : 0.3265267610549927,  classifier :0.027531936764717102, mask: 0.1545259654521942 ===================
epoch no : 5, batch no : 97, total loss : 0.3205954432487488,  classifier :0.028530243784189224, mask: 0.13965220749378204 ===================
epoch no : 5, batch no : 98, total loss : 0.2995021343231201,  classifier :0.03399667143821716, mask: 0.12076924741268158 ===================
epoch no : 5, batch no : 99, total loss : 0.24289922416210175,  classifier :0.03400373458862305, mask: 0.10605546087026596 ===================
epoch no : 5, batch no : 100, total loss : 0.3695638179779053,  classifier :0.033992644399404526, mask: 0.15913927555084229 ===================
epoch no : 5, batch no : 101, total loss : 0.310025691986084,  classifier :0.04465406388044357, mask: 0.12363040447235107 ===================
epoch no : 5, batch no : 102, total loss : 0.24670125544071198,  classifier :0.03281014412641525, mask: 0.1103203296661377 ===================
epoch no : 5, batch no : 103, total loss : 0.3100058138370514,  classifier :0.035749394446611404, mask: 0.14052605628967285 ===================
epoch no : 5, batch no : 104, total loss : 0.2957409620285034,  classifier :0.04182106629014015, mask: 0.13201190531253815 ===================
epoch no : 5, batch no : 105, total loss : 0.28295210003852844,  classifier :0.04143333435058594, mask: 0.11072934418916702 ===================
epoch no : 5, batch no : 106, total loss : 0.30590471625328064,  classifier :0.046202581375837326, mask: 0.12874773144721985 ===================
epoch no : 5, batch no : 107, total loss : 0.3067246675491333,  classifier :0.037095021456480026, mask: 0.12306203693151474 ===================
epoch no : 5, batch no : 108, total loss : 0.32160359621047974,  classifier :0.031158216297626495, mask: 0.14269337058067322 ===================
epoch no : 5, batch no : 109, total loss : 0.3659520745277405,  classifier :0.03520183265209198, mask: 0.15594197809696198 ===================
epoch no : 5, batch no : 110, total loss : 0.31327924132347107,  classifier :0.04130297526717186, mask: 0.12632174789905548 ===================
epoch no : 5, batch no : 111, total loss : 0.3043406903743744,  classifier :0.034529685974121094, mask: 0.1387125700712204 ===================
epoch no : 5, batch no : 112, total loss : 0.2618292272090912,  classifier :0.025590142235159874, mask: 0.14650064706802368 ===================
epoch no : 5, batch no : 113, total loss : 0.27921196818351746,  classifier :0.03341641277074814, mask: 0.10059282928705215 ===================
epoch no : 5, batch no : 114, total loss : 0.40096423029899597,  classifier :0.06804593652486801, mask: 0.1716643124818802 ===================
epoch no : 5, batch no : 115, total loss : 0.3474632799625397,  classifier :0.030156971886754036, mask: 0.10037168860435486 ===================
epoch no : 5, batch no : 116, total loss : 0.3039211630821228,  classifier :0.0298796147108078, mask: 0.12313651293516159 ===================
epoch no : 5, batch no : 117, total loss : 0.32715630531311035,  classifier :0.03431855887174606, mask: 0.14314964413642883 ===================
epoch no : 5, batch no : 118, total loss : 0.5031291246414185,  classifier :0.04328387975692749, mask: 0.21684379875659943 ===================
epoch no : 5, batch no : 119, total loss : 0.3786867558956146,  classifier :0.055349286645650864, mask: 0.167353555560112 ===================
epoch no : 5, batch no : 120, total loss : 0.2349594086408615,  classifier :0.040597543120384216, mask: 0.1074800118803978 ===================
epoch no : 5, batch no : 121, total loss : 0.3069494366645813,  classifier :0.04113275930285454, mask: 0.10118597000837326 ===================
epoch no : 5, batch no : 122, total loss : 0.2427273988723755,  classifier :0.02905735746026039, mask: 0.09926296770572662 ===================
epoch no : 5, batch no : 123, total loss : 0.2643122971057892,  classifier :0.03924467787146568, mask: 0.12389509379863739 ===================
epoch no : 5, batch no : 124, total loss : 0.3104186952114105,  classifier :0.0396236926317215, mask: 0.12419679760932922 ===================
epoch no : 5, batch no : 125, total loss : 0.2791411578655243,  classifier :0.049596041440963745, mask: 0.11655023694038391 ===================
epoch no : 5, batch no : 126, total loss : 0.2588280141353607,  classifier :0.03792455047369003, mask: 0.10479091852903366 ===================
epoch no : 5, batch no : 127, total loss : 0.2699721157550812,  classifier :0.03007378987967968, mask: 0.12218738347291946 ===================
epoch no : 5, batch no : 128, total loss : 0.3615037202835083,  classifier :0.030958587303757668, mask: 0.19329534471035004 ===================
epoch no : 5, batch no : 129, total loss : 0.32089853286743164,  classifier :0.050808679312467575, mask: 0.13342075049877167 ===================
epoch no : 5, batch no : 130, total loss : 0.4785799980163574,  classifier :0.03482556715607643, mask: 0.17799906432628632 ===================
epoch no : 5, batch no : 131, total loss : 0.30377644300460815,  classifier :0.03311165049672127, mask: 0.11630436033010483 ===================
epoch no : 5, batch no : 132, total loss : 0.32450711727142334,  classifier :0.04366559907793999, mask: 0.12586073577404022 ===================
epoch no : 5, batch no : 133, total loss : 0.2877483367919922,  classifier :0.03896642103791237, mask: 0.1338512897491455 ===================
epoch no : 5, batch no : 134, total loss : 0.32004082202911377,  classifier :0.03138676658272743, mask: 0.1594414860010147 ===================
epoch no : 5, batch no : 135, total loss : 0.29589614272117615,  classifier :0.036699388176202774, mask: 0.13763917982578278 ===================
epoch no : 5, batch no : 136, total loss : 0.3210940361022949,  classifier :0.025974806398153305, mask: 0.1523323357105255 ===================
epoch no : 5, batch no : 137, total loss : 0.2675686478614807,  classifier :0.030986076220870018, mask: 0.0990242063999176 ===================
epoch no : 5, batch no : 138, total loss : 0.26544347405433655,  classifier :0.035423729568719864, mask: 0.11471741646528244 ===================
epoch no : 5, batch no : 139, total loss : 0.30903688073158264,  classifier :0.038874562829732895, mask: 0.13993139564990997 ===================
epoch no : 5, batch no : 140, total loss : 0.24931097030639648,  classifier :0.04019157588481903, mask: 0.10163827240467072 ===================
epoch no : 5, batch no : 141, total loss : 0.30854496359825134,  classifier :0.02812356688082218, mask: 0.13551326096057892 ===================
epoch no : 5, batch no : 142, total loss : 0.2248452752828598,  classifier :0.021975837647914886, mask: 0.10566262900829315 ===================
epoch no : 5, batch no : 143, total loss : 0.304858535528183,  classifier :0.04677603766322136, mask: 0.10442526638507843 ===================
epoch no : 5, batch no : 144, total loss : 0.2852596640586853,  classifier :0.029922477900981903, mask: 0.09234880656003952 ===================
epoch no : 5, batch no : 145, total loss : 0.3947659730911255,  classifier :0.045365020632743835, mask: 0.18092936277389526 ===================
epoch no : 5, batch no : 146, total loss : 0.346316933631897,  classifier :0.03409511223435402, mask: 0.14444538950920105 ===================
epoch no : 5, batch no : 147, total loss : 0.2922123670578003,  classifier :0.039156146347522736, mask: 0.1305750459432602 ===================
epoch no : 5, batch no : 148, total loss : 0.34025076031684875,  classifier :0.03663227707147598, mask: 0.15308621525764465 ===================
epoch no : 5, batch no : 149, total loss : 0.2538585960865021,  classifier :0.02872788906097412, mask: 0.10583636164665222 ===================
epoch no : 5, batch no : 150, total loss : 0.25690633058547974,  classifier :0.02904856577515602, mask: 0.09226725250482559 ===================
epoch no : 5, batch no : 151, total loss : 0.26960694789886475,  classifier :0.0392182357609272, mask: 0.09785603731870651 ===================
epoch no : 5, batch no : 152, total loss : 0.29374849796295166,  classifier :0.029582198709249496, mask: 0.12327142804861069 ===================
epoch no : 5, batch no : 153, total loss : 0.31619375944137573,  classifier :0.043337274342775345, mask: 0.11289147287607193 ===================
epoch no : 5, batch no : 154, total loss : 0.30478447675704956,  classifier :0.030603880062699318, mask: 0.13089366257190704 ===================
epoch no : 5, batch no : 155, total loss : 0.2794383764266968,  classifier :0.032244086265563965, mask: 0.12215617299079895 ===================
epoch no : 5, batch no : 156, total loss : 0.4820830523967743,  classifier :0.05896937474608421, mask: 0.19344495236873627 ===================
epoch no : 5, batch no : 157, total loss : 0.33605045080184937,  classifier :0.03828643262386322, mask: 0.14142651855945587 ===================
epoch no : 5, batch no : 158, total loss : 0.363827109336853,  classifier :0.036660872399806976, mask: 0.16875942051410675 ===================
epoch no : 5, batch no : 159, total loss : 0.38888272643089294,  classifier :0.054040588438510895, mask: 0.14308221638202667 ===================
epoch no : 5, batch no : 160, total loss : 0.40390443801879883,  classifier :0.03273463249206543, mask: 0.13963425159454346 ===================
epoch no : 5, batch no : 161, total loss : 0.35085201263427734,  classifier :0.03792795538902283, mask: 0.13027432560920715 ===================
epoch no : 5, batch no : 162, total loss : 0.30111536383628845,  classifier :0.029092149809002876, mask: 0.11845409870147705 ===================
epoch no : 5, batch no : 163, total loss : 0.3411533832550049,  classifier :0.030464667826890945, mask: 0.14937804639339447 ===================
epoch no : 5, batch no : 164, total loss : 0.2713838815689087,  classifier :0.02821674942970276, mask: 0.09908053278923035 ===================
epoch no : 5, batch no : 165, total loss : 0.36803990602493286,  classifier :0.036372676491737366, mask: 0.12876483798027039 ===================
epoch no : 5, batch no : 166, total loss : 0.44931912422180176,  classifier :0.041010502725839615, mask: 0.16495543718338013 ===================
epoch no : 5, batch no : 167, total loss : 0.3670029044151306,  classifier :0.032410986721515656, mask: 0.159649059176445 ===================
epoch no : 5, batch no : 168, total loss : 0.24459786713123322,  classifier :0.038773197680711746, mask: 0.10808411985635757 ===================
epoch no : 5, batch no : 169, total loss : 0.3141058385372162,  classifier :0.03388282656669617, mask: 0.10271861404180527 ===================
epoch no : 5, batch no : 170, total loss : 0.32519420981407166,  classifier :0.03593458607792854, mask: 0.1293857842683792 ===================
epoch no : 5, batch no : 171, total loss : 0.23517493903636932,  classifier :0.0421353355050087, mask: 0.09771186858415604 ===================
epoch no : 5, batch no : 172, total loss : 0.2605801820755005,  classifier :0.030589299276471138, mask: 0.11474904417991638 ===================
epoch no : 5, batch no : 173, total loss : 0.26537859439849854,  classifier :0.028528016060590744, mask: 0.10930632799863815 ===================
epoch no : 5, batch no : 174, total loss : 0.3346952497959137,  classifier :0.030941911041736603, mask: 0.15403681993484497 ===================
epoch no : 5, batch no : 175, total loss : 0.2883707880973816,  classifier :0.04720102623105049, mask: 0.10308705270290375 ===================
epoch no : 5, batch no : 176, total loss : 0.26630672812461853,  classifier :0.04291500523686409, mask: 0.11281240731477737 ===================
epoch no : 5, batch no : 177, total loss : 0.3869774341583252,  classifier :0.03302802890539169, mask: 0.23358874022960663 ===================
epoch no : 5, batch no : 178, total loss : 0.35788294672966003,  classifier :0.047201186418533325, mask: 0.17044217884540558 ===================
epoch no : 5, batch no : 179, total loss : 0.2882345914840698,  classifier :0.04287995770573616, mask: 0.11948239803314209 ===================
epoch no : 5, batch no : 180, total loss : 0.23953275382518768,  classifier :0.030192889273166656, mask: 0.11181093007326126 ===================
epoch no : 5, batch no : 181, total loss : 0.36178338527679443,  classifier :0.037956371903419495, mask: 0.14566031098365784 ===================
epoch no : 5, batch no : 182, total loss : 0.24341516196727753,  classifier :0.02331390045583248, mask: 0.1231028288602829 ===================
epoch no : 5, batch no : 183, total loss : 0.3302726745605469,  classifier :0.05821370705962181, mask: 0.13218457996845245 ===================
epoch no : 5, batch no : 184, total loss : 0.2991150915622711,  classifier :0.027212033048272133, mask: 0.11532168090343475 ===================
epoch no : 5, batch no : 185, total loss : 0.3412747085094452,  classifier :0.05026629567146301, mask: 0.11829598993062973 ===================
epoch no : 5, batch no : 186, total loss : 0.35613593459129333,  classifier :0.03051941841840744, mask: 0.17386174201965332 ===================
epoch no : 5, batch no : 187, total loss : 0.3247833549976349,  classifier :0.03427747264504433, mask: 0.15041624009609222 ===================
epoch no : 5, batch no : 188, total loss : 0.28581905364990234,  classifier :0.0426875501871109, mask: 0.11865542083978653 ===================
epoch no : 5, batch no : 189, total loss : 0.39237985014915466,  classifier :0.038345880806446075, mask: 0.17653889954090118 ===================
epoch no : 5, batch no : 190, total loss : 0.30725881457328796,  classifier :0.0477551631629467, mask: 0.11555580794811249 ===================
epoch no : 5, batch no : 191, total loss : 0.3561975657939911,  classifier :0.04036569595336914, mask: 0.1391884684562683 ===================
epoch no : 5, batch no : 192, total loss : 0.30638834834098816,  classifier :0.031240539625287056, mask: 0.16651874780654907 ===================
epoch no : 5, batch no : 193, total loss : 0.3188866078853607,  classifier :0.0340048223733902, mask: 0.15349914133548737 ===================
epoch no : 5, batch no : 194, total loss : 0.281691312789917,  classifier :0.0299074649810791, mask: 0.12245458364486694 ===================
epoch no : 5, batch no : 195, total loss : 0.2530141770839691,  classifier :0.03793058544397354, mask: 0.10406887531280518 ===================
epoch no : 5, batch no : 196, total loss : 0.33350178599357605,  classifier :0.02821359969675541, mask: 0.16923877596855164 ===================
epoch no : 5, batch no : 197, total loss : 0.20417001843452454,  classifier :0.040093060582876205, mask: 0.09126344323158264 ===================
epoch no : 5, batch no : 198, total loss : 0.22951343655586243,  classifier :0.02952665463089943, mask: 0.10477807372808456 ===================
epoch no : 5, batch no : 199, total loss : 0.2203565239906311,  classifier :0.02437630109488964, mask: 0.09752532094717026 ===================
epoch no : 5, batch no : 200, total loss : 0.23453356325626373,  classifier :0.02489394322037697, mask: 0.1038975864648819 ===================
epoch no : 5, batch no : 201, total loss : 0.3343081474304199,  classifier :0.025990968570113182, mask: 0.13262461125850677 ===================
epoch no : 5, batch no : 202, total loss : 0.2695663869380951,  classifier :0.02793840318918228, mask: 0.11888587474822998 ===================
epoch no : 5, batch no : 203, total loss : 0.20811030268669128,  classifier :0.030650893226265907, mask: 0.07867249846458435 ===================
epoch no : 5, batch no : 204, total loss : 0.320356160402298,  classifier :0.03370184451341629, mask: 0.11498881131410599 ===================
epoch no : 5, batch no : 205, total loss : 0.28199464082717896,  classifier :0.037670500576496124, mask: 0.12081339210271835 ===================
epoch no : 5, batch no : 206, total loss : 0.28247880935668945,  classifier :0.02771933376789093, mask: 0.10547130554914474 ===================
epoch no : 5, batch no : 207, total loss : 0.2908916473388672,  classifier :0.03754730895161629, mask: 0.10994376242160797 ===================
epoch no : 5, batch no : 208, total loss : 0.44308361411094666,  classifier :0.053704675287008286, mask: 0.1752764880657196 ===================
epoch no : 5, batch no : 209, total loss : 0.2779409885406494,  classifier :0.039164189249277115, mask: 0.11156143248081207 ===================
epoch no : 5, batch no : 210, total loss : 0.2703261971473694,  classifier :0.04578390717506409, mask: 0.116597980260849 ===================
epoch no : 5, batch no : 211, total loss : 0.2952633202075958,  classifier :0.02812151610851288, mask: 0.1300291270017624 ===================
epoch no : 5, batch no : 212, total loss : 0.26341551542282104,  classifier :0.019640911370515823, mask: 0.12528131902217865 ===================
epoch no : 5, batch no : 213, total loss : 0.26886221766471863,  classifier :0.026325000450015068, mask: 0.11148331314325333 ===================
epoch no : 5, batch no : 214, total loss : 0.33917054533958435,  classifier :0.04677349328994751, mask: 0.12937915325164795 ===================
epoch no : 5, batch no : 215, total loss : 0.24851743876934052,  classifier :0.027765989303588867, mask: 0.10573573410511017 ===================
epoch no : 5, batch no : 216, total loss : 0.23776084184646606,  classifier :0.0335952453315258, mask: 0.10501592606306076 ===================
epoch no : 5, batch no : 217, total loss : 0.23988644778728485,  classifier :0.0362522192299366, mask: 0.09057985991239548 ===================
epoch no : 5, batch no : 218, total loss : 0.2743164598941803,  classifier :0.0397825688123703, mask: 0.11414171010255814 ===================
epoch no : 5, batch no : 219, total loss : 0.2909810245037079,  classifier :0.030075622722506523, mask: 0.1142226830124855 ===================
epoch no : 5, batch no : 220, total loss : 0.34072446823120117,  classifier :0.03224298730492592, mask: 0.1406899243593216 ===================
epoch no : 5, batch no : 221, total loss : 0.3005170226097107,  classifier :0.039464373141527176, mask: 0.14010776579380035 ===================
epoch no : 5, batch no : 222, total loss : 0.3421832323074341,  classifier :0.048707377165555954, mask: 0.16970683634281158 ===================
epoch no : 5, batch no : 223, total loss : 0.3900962769985199,  classifier :0.06053512915968895, mask: 0.16864430904388428 ===================
epoch no : 5, batch no : 224, total loss : 0.244121715426445,  classifier :0.03026207536458969, mask: 0.11176703125238419 ===================
epoch no : 5, batch no : 225, total loss : 0.28584685921669006,  classifier :0.026087284088134766, mask: 0.12524749338626862 ===================
epoch no : 5, batch no : 226, total loss : 0.29610469937324524,  classifier :0.029729299247264862, mask: 0.1180797591805458 ===================
epoch no : 5, batch no : 227, total loss : 0.2814588248729706,  classifier :0.02485566772520542, mask: 0.10645366460084915 ===================
epoch no : 5, batch no : 228, total loss : 0.22227859497070312,  classifier :0.02432149648666382, mask: 0.0984240174293518 ===================
epoch no : 5, batch no : 229, total loss : 0.2889978289604187,  classifier :0.040999993681907654, mask: 0.11561474949121475 ===================
epoch no : 5, batch no : 230, total loss : 0.3479260802268982,  classifier :0.03266604244709015, mask: 0.1383638232946396 ===================
epoch no : 5, batch no : 231, total loss : 0.2550932466983795,  classifier :0.0455593466758728, mask: 0.0884743258357048 ===================
epoch no : 5, batch no : 232, total loss : 0.2929215133190155,  classifier :0.028661001473665237, mask: 0.11576139181852341 ===================
epoch no : 5, batch no : 233, total loss : 0.2928561866283417,  classifier :0.03828701749444008, mask: 0.10433556139469147 ===================
epoch no : 5, batch no : 234, total loss : 0.2777986228466034,  classifier :0.02847646363079548, mask: 0.1190667599439621 ===================
epoch no : 5, batch no : 235, total loss : 0.26983994245529175,  classifier :0.041178058832883835, mask: 0.10746516287326813 ===================
epoch no : 5, batch no : 236, total loss : 0.3796064257621765,  classifier :0.04144291952252388, mask: 0.1323063224554062 ===================
epoch no : 5, batch no : 237, total loss : 0.44207221269607544,  classifier :0.028046924620866776, mask: 0.17905700206756592 ===================
epoch no : 5, batch no : 238, total loss : 0.25133299827575684,  classifier :0.04306292161345482, mask: 0.10292933136224747 ===================
epoch no : 5, batch no : 239, total loss : 0.27010416984558105,  classifier :0.033846449106931686, mask: 0.1253184676170349 ===================
epoch no : 5, batch no : 240, total loss : 0.19290076196193695,  classifier :0.03362458944320679, mask: 0.08481266349554062 ===================
epoch no : 5, batch no : 241, total loss : 0.3213300108909607,  classifier :0.036914851516485214, mask: 0.11811882257461548 ===================
epoch no : 5, batch no : 242, total loss : 0.3025342524051666,  classifier :0.04460569843649864, mask: 0.11965817213058472 ===================
epoch no : 5, batch no : 243, total loss : 0.3481900095939636,  classifier :0.039036110043525696, mask: 0.1412738412618637 ===================
epoch no : 5, batch no : 244, total loss : 0.2556239068508148,  classifier :0.02634974755346775, mask: 0.09088345617055893 ===================
epoch no : 5, batch no : 245, total loss : 0.313407301902771,  classifier :0.032487425953149796, mask: 0.12400682270526886 ===================
epoch no : 5, batch no : 246, total loss : 0.3773592412471771,  classifier :0.03813117370009422, mask: 0.1372983604669571 ===================
epoch no : 5, batch no : 247, total loss : 0.39380571246147156,  classifier :0.04199633374810219, mask: 0.17429855465888977 ===================
epoch no : 5, batch no : 248, total loss : 0.38165560364723206,  classifier :0.047516580671072006, mask: 0.16349951922893524 ===================
epoch no : 5, batch no : 249, total loss : 0.35075676441192627,  classifier :0.04283026233315468, mask: 0.14437372982501984 ===================
epoch no : 5, batch no : 250, total loss : 0.25173765420913696,  classifier :0.0274962130934, mask: 0.10250642150640488 ===================
epoch no : 5, batch no : 251, total loss : 0.32203829288482666,  classifier :0.036983538419008255, mask: 0.16818413138389587 ===================
epoch no : 5, batch no : 252, total loss : 0.2806122303009033,  classifier :0.0292370542883873, mask: 0.11185111850500107 ===================
epoch no : 5, batch no : 253, total loss : 0.27449363470077515,  classifier :0.03652646020054817, mask: 0.11461267620325089 ===================
epoch no : 5, batch no : 254, total loss : 0.34189486503601074,  classifier :0.052049025893211365, mask: 0.16499078273773193 ===================
epoch no : 5, batch no : 255, total loss : 0.325112521648407,  classifier :0.04375055059790611, mask: 0.15652191638946533 ===================
epoch no : 5, batch no : 256, total loss : 0.29453375935554504,  classifier :0.03353920578956604, mask: 0.1315835863351822 ===================
epoch no : 5, batch no : 257, total loss : 0.2808985412120819,  classifier :0.03497062996029854, mask: 0.11296257376670837 ===================
epoch no : 5, batch no : 258, total loss : 0.21149449050426483,  classifier :0.02531363256275654, mask: 0.08830563724040985 ===================
epoch no : 5, batch no : 259, total loss : 0.24660393595695496,  classifier :0.027012230828404427, mask: 0.12733094394207 ===================
epoch no : 5, batch no : 260, total loss : 0.2853803336620331,  classifier :0.02941715531051159, mask: 0.11798122525215149 ===================
epoch no : 5, batch no : 261, total loss : 0.3404577076435089,  classifier :0.03695826977491379, mask: 0.13543486595153809 ===================
epoch no : 5, batch no : 262, total loss : 0.2526070773601532,  classifier :0.027999890968203545, mask: 0.12123864889144897 ===================
epoch no : 5, batch no : 263, total loss : 0.2747059166431427,  classifier :0.049037523567676544, mask: 0.107040174305439 ===================
epoch no : 5, batch no : 264, total loss : 0.23038887977600098,  classifier :0.031840790063142776, mask: 0.09774930775165558 ===================
epoch no : 5, batch no : 265, total loss : 0.31076744198799133,  classifier :0.03267888352274895, mask: 0.12683288753032684 ===================
epoch no : 5, batch no : 266, total loss : 0.26435375213623047,  classifier :0.042487967759370804, mask: 0.1052418127655983 ===================
epoch no : 5, batch no : 267, total loss : 0.2242969274520874,  classifier :0.033183109015226364, mask: 0.10352320969104767 ===================
epoch no : 5, batch no : 268, total loss : 0.29478123784065247,  classifier :0.029549265280365944, mask: 0.16815100610256195 ===================
epoch no : 5, batch no : 269, total loss : 0.40364620089530945,  classifier :0.045031823217868805, mask: 0.1574956178665161 ===================
epoch no : 5, batch no : 270, total loss : 0.264515221118927,  classifier :0.029406892135739326, mask: 0.10932385921478271 ===================
epoch no : 5, batch no : 271, total loss : 0.2901930809020996,  classifier :0.038689762353897095, mask: 0.11060966551303864 ===================
epoch no : 5, batch no : 272, total loss : 0.29993122816085815,  classifier :0.0286861602216959, mask: 0.09984437376260757 ===================
epoch no : 5, batch no : 273, total loss : 0.3996884822845459,  classifier :0.04337596893310547, mask: 0.1333155632019043 ===================
epoch no : 5, batch no : 274, total loss : 0.3111107349395752,  classifier :0.0524451807141304, mask: 0.1330043375492096 ===================
epoch no : 5, batch no : 275, total loss : 0.2918185591697693,  classifier :0.03579581528902054, mask: 0.11268892884254456 ===================
epoch no : 5, batch no : 276, total loss : 0.2865481972694397,  classifier :0.036512590944767, mask: 0.11145687848329544 ===================
epoch no : 5, batch no : 277, total loss : 0.27109381556510925,  classifier :0.028692426159977913, mask: 0.10780499875545502 ===================
epoch no : 5, batch no : 278, total loss : 0.2755919396877289,  classifier :0.032990578562021255, mask: 0.12231160700321198 ===================
epoch no : 5, batch no : 279, total loss : 0.24976150691509247,  classifier :0.04018920287489891, mask: 0.1063292995095253 ===================
epoch no : 5, batch no : 280, total loss : 0.2951743006706238,  classifier :0.029569437727332115, mask: 0.13896732032299042 ===================
epoch no : 5, batch no : 281, total loss : 0.2708278298377991,  classifier :0.031087595969438553, mask: 0.10997490584850311 ===================
epoch no : 5, batch no : 282, total loss : 0.35425058007240295,  classifier :0.03324084356427193, mask: 0.11228933185338974 ===================
epoch no : 5, batch no : 283, total loss : 0.41865670680999756,  classifier :0.03365902602672577, mask: 0.12681138515472412 ===================
epoch no : 5, batch no : 284, total loss : 0.3536626696586609,  classifier :0.041896481066942215, mask: 0.1368519514799118 ===================
epoch no : 5, batch no : 285, total loss : 0.26251184940338135,  classifier :0.038111504167318344, mask: 0.11076828092336655 ===================
epoch no : 5, batch no : 286, total loss : 0.29694512486457825,  classifier :0.043374668806791306, mask: 0.1103360503911972 ===================
epoch no : 5, batch no : 287, total loss : 0.2659795582294464,  classifier :0.039602022618055344, mask: 0.11663653701543808 ===================
epoch no : 5, batch no : 288, total loss : 0.23667126893997192,  classifier :0.02878449484705925, mask: 0.08738411217927933 ===================
epoch no : 5, batch no : 289, total loss : 0.2626657485961914,  classifier :0.0397554449737072, mask: 0.1076166108250618 ===================
epoch no : 5, batch no : 290, total loss : 0.2560664117336273,  classifier :0.03517591953277588, mask: 0.10109622776508331 ===================
epoch no : 5, batch no : 291, total loss : 0.2539360225200653,  classifier :0.044778697192668915, mask: 0.09847738593816757 ===================
epoch no : 5, batch no : 292, total loss : 0.3171435594558716,  classifier :0.04149762913584709, mask: 0.12753677368164062 ===================
epoch no : 5, batch no : 293, total loss : 0.29607954621315,  classifier :0.03819701820611954, mask: 0.11377419531345367 ===================
epoch no : 5, batch no : 294, total loss : 0.2265428751707077,  classifier :0.034877583384513855, mask: 0.10974084585905075 ===================
epoch no : 5, batch no : 295, total loss : 0.3200700879096985,  classifier :0.02592865191400051, mask: 0.13550542294979095 ===================
epoch no : 5, batch no : 296, total loss : 0.28007370233535767,  classifier :0.032045528292655945, mask: 0.13744355738162994 ===================
epoch no : 5, batch no : 297, total loss : 0.37529805302619934,  classifier :0.03359756991267204, mask: 0.18139468133449554 ===================
epoch no : 5, batch no : 298, total loss : 0.29432183504104614,  classifier :0.04215296730399132, mask: 0.1061709001660347 ===================
epoch no : 5, batch no : 299, total loss : 0.2551164925098419,  classifier :0.03598538786172867, mask: 0.09516026824712753 ===================
epoch no : 5, batch no : 300, total loss : 0.2846726179122925,  classifier :0.03393077105283737, mask: 0.1519572138786316 ===================
epoch no : 5, batch no : 301, total loss : 0.27215781807899475,  classifier :0.028399966657161713, mask: 0.12537948787212372 ===================
epoch no : 5, batch no : 302, total loss : 0.24177131056785583,  classifier :0.0315057672560215, mask: 0.11180571466684341 ===================
epoch no : 5, batch no : 303, total loss : 0.2986180782318115,  classifier :0.0321807861328125, mask: 0.12925037741661072 ===================
epoch no : 5, batch no : 304, total loss : 0.24217168986797333,  classifier :0.03684469312429428, mask: 0.10461384057998657 ===================
epoch no : 5, batch no : 305, total loss : 0.289980947971344,  classifier :0.032103531062603, mask: 0.11663447320461273 ===================
epoch no : 5, batch no : 306, total loss : 0.33386802673339844,  classifier :0.033838216215372086, mask: 0.13572145998477936 ===================
epoch no : 5, batch no : 307, total loss : 0.3122422695159912,  classifier :0.049335964024066925, mask: 0.12306390702724457 ===================
epoch no : 5, batch no : 308, total loss : 0.27840176224708557,  classifier :0.035225529223680496, mask: 0.11269878596067429 ===================
epoch no : 5, batch no : 309, total loss : 0.3470275402069092,  classifier :0.04531620070338249, mask: 0.15918757021427155 ===================
epoch no : 5, batch no : 310, total loss : 0.30670350790023804,  classifier :0.042361389845609665, mask: 0.13390707969665527 ===================
epoch no : 5, batch no : 311, total loss : 0.2678667902946472,  classifier :0.029103778302669525, mask: 0.11115758866071701 ===================
epoch no : 5, batch no : 312, total loss : 0.32749804854393005,  classifier :0.03855033218860626, mask: 0.15984052419662476 ===================
epoch no : 5, batch no : 313, total loss : 0.24661506712436676,  classifier :0.029672373086214066, mask: 0.10884871333837509 ===================
epoch no : 5, batch no : 314, total loss : 0.2722497284412384,  classifier :0.027296047657728195, mask: 0.12211114168167114 ===================
epoch no : 5, batch no : 315, total loss : 0.38449594378471375,  classifier :0.03945820406079292, mask: 0.1843879520893097 ===================
epoch no : 5, batch no : 316, total loss : 0.26518380641937256,  classifier :0.033939458429813385, mask: 0.11444094777107239 ===================
epoch no : 5, batch no : 317, total loss : 0.36569321155548096,  classifier :0.030307777225971222, mask: 0.1476360261440277 ===================
epoch no : 5, batch no : 318, total loss : 0.2648235559463501,  classifier :0.027200957760214806, mask: 0.1060657873749733 ===================
epoch no : 5, batch no : 319, total loss : 0.30232173204421997,  classifier :0.034876901656389236, mask: 0.10697063058614731 ===================
epoch no : 5, batch no : 320, total loss : 0.29094594717025757,  classifier :0.03504973277449608, mask: 0.13733774423599243 ===================
epoch no : 5, batch no : 321, total loss : 0.27693605422973633,  classifier :0.035368941724300385, mask: 0.12957577407360077 ===================
epoch no : 5, batch no : 322, total loss : 0.3045348525047302,  classifier :0.0417766273021698, mask: 0.13736183941364288 ===================
epoch no : 5, batch no : 323, total loss : 0.4040064811706543,  classifier :0.06064635515213013, mask: 0.1621299535036087 ===================
epoch no : 5, batch no : 324, total loss : 0.30140605568885803,  classifier :0.03639368340373039, mask: 0.11992312967777252 ===================
epoch no : 5, batch no : 325, total loss : 0.40424641966819763,  classifier :0.04850735887885094, mask: 0.12968377768993378 ===================
epoch no : 5, batch no : 326, total loss : 0.3500673472881317,  classifier :0.05885445326566696, mask: 0.1252426654100418 ===================
epoch no : 5, batch no : 327, total loss : 0.3031628727912903,  classifier :0.04280323162674904, mask: 0.1359589695930481 ===================
epoch no : 5, batch no : 328, total loss : 0.2843056321144104,  classifier :0.04096042364835739, mask: 0.1182701513171196 ===================
epoch no : 5, batch no : 329, total loss : 0.29093846678733826,  classifier :0.041208844631910324, mask: 0.12057524174451828 ===================
epoch no : 5, batch no : 330, total loss : 0.2306394726037979,  classifier :0.025197729468345642, mask: 0.09170730412006378 ===================
epoch no : 5, batch no : 331, total loss : 0.3408644497394562,  classifier :0.029520895332098007, mask: 0.15620024502277374 ===================
epoch no : 5, batch no : 332, total loss : 0.3763299286365509,  classifier :0.049684423953294754, mask: 0.13879144191741943 ===================
epoch no : 5, batch no : 333, total loss : 0.2240602672100067,  classifier :0.026197610422968864, mask: 0.08241879940032959 ===================
epoch no : 5, batch no : 334, total loss : 0.33916500210762024,  classifier :0.03368568420410156, mask: 0.17281612753868103 ===================
epoch no : 5, batch no : 335, total loss : 0.294435977935791,  classifier :0.029081284999847412, mask: 0.13153274357318878 ===================
epoch no : 5, batch no : 336, total loss : 0.2569617033004761,  classifier :0.03558897599577904, mask: 0.10123918205499649 ===================
epoch no : 5, batch no : 337, total loss : 0.2665218412876129,  classifier :0.032196082174777985, mask: 0.1067754402756691 ===================
epoch no : 5, batch no : 338, total loss : 0.30601587891578674,  classifier :0.0240958109498024, mask: 0.12151946872472763 ===================
epoch no : 5, batch no : 339, total loss : 0.39367255568504333,  classifier :0.06260935217142105, mask: 0.13435788452625275 ===================
epoch no : 5, batch no : 340, total loss : 0.25466492772102356,  classifier :0.03247576206922531, mask: 0.11084887385368347 ===================
epoch no : 5, batch no : 341, total loss : 0.2598118484020233,  classifier :0.023812806233763695, mask: 0.11488804966211319 ===================
epoch no : 5, batch no : 342, total loss : 0.31889480352401733,  classifier :0.050753798335790634, mask: 0.13493329286575317 ===================
epoch no : 5, batch no : 343, total loss : 0.32657870650291443,  classifier :0.03247161582112312, mask: 0.15105637907981873 ===================
epoch no : 5, batch no : 344, total loss : 0.26875337958335876,  classifier :0.032789167016744614, mask: 0.09720713645219803 ===================
epoch no : 5, batch no : 345, total loss : 0.2882295548915863,  classifier :0.031419821083545685, mask: 0.13279154896736145 ===================
epoch no : 5, batch no : 346, total loss : 0.28033149242401123,  classifier :0.025383930653333664, mask: 0.11609295010566711 ===================
epoch no : 5, batch no : 347, total loss : 0.4004143178462982,  classifier :0.04349313676357269, mask: 0.14564038813114166 ===================
epoch no : 5, batch no : 348, total loss : 0.30690667033195496,  classifier :0.03381800651550293, mask: 0.11707692593336105 ===================
epoch no : 5, batch no : 349, total loss : 0.25526466965675354,  classifier :0.024867238476872444, mask: 0.10804977267980576 ===================
epoch no : 5, batch no : 350, total loss : 0.2999729812145233,  classifier :0.026595912873744965, mask: 0.12984788417816162 ===================
epoch no : 5, batch no : 351, total loss : 0.31056272983551025,  classifier :0.04925268515944481, mask: 0.12080413103103638 ===================
epoch no : 5, batch no : 352, total loss : 0.24662528932094574,  classifier :0.028935296460986137, mask: 0.09105201065540314 ===================
epoch no : 5, batch no : 353, total loss : 0.2710196077823639,  classifier :0.032847121357917786, mask: 0.11697448790073395 ===================
epoch no : 5, batch no : 354, total loss : 0.3807690739631653,  classifier :0.03701816499233246, mask: 0.20441578328609467 ===================
epoch no : 5, batch no : 355, total loss : 0.28969070315361023,  classifier :0.03290387615561485, mask: 0.12914961576461792 ===================
epoch no : 5, batch no : 356, total loss : 0.32851967215538025,  classifier :0.029954880475997925, mask: 0.1447833925485611 ===================
epoch no : 5, batch no : 357, total loss : 0.41598621010780334,  classifier :0.03632229566574097, mask: 0.15781889855861664 ===================
epoch no : 5, batch no : 358, total loss : 0.3040353059768677,  classifier :0.04003049433231354, mask: 0.12561066448688507 ===================
epoch no : 5, batch no : 359, total loss : 0.2597830593585968,  classifier :0.032664887607097626, mask: 0.12195485085248947 ===================
epoch no : 5, batch no : 360, total loss : 0.29429391026496887,  classifier :0.03383883088827133, mask: 0.1373206377029419 ===================
epoch no : 5, batch no : 361, total loss : 0.2581769824028015,  classifier :0.036448217928409576, mask: 0.11175554245710373 ===================
epoch no : 5, batch no : 362, total loss : 0.3117974102497101,  classifier :0.044950008392333984, mask: 0.12111550569534302 ===================
epoch no : 5, batch no : 363, total loss : 0.2789894938468933,  classifier :0.03799527883529663, mask: 0.1066562756896019 ===================
epoch no : 5, batch no : 364, total loss : 0.24039945006370544,  classifier :0.024727586656808853, mask: 0.10010471194982529 ===================
epoch no : 5, batch no : 365, total loss : 0.25903281569480896,  classifier :0.03515937924385071, mask: 0.10902737081050873 ===================
epoch no : 5, batch no : 366, total loss : 0.33531856536865234,  classifier :0.03397637605667114, mask: 0.14335420727729797 ===================
epoch no : 5, batch no : 367, total loss : 0.3301593065261841,  classifier :0.04174910485744476, mask: 0.13633911311626434 ===================
epoch no : 5, batch no : 368, total loss : 0.3399074077606201,  classifier :0.029061920940876007, mask: 0.1371583193540573 ===================
epoch no : 5, batch no : 369, total loss : 0.27841833233833313,  classifier :0.04174530506134033, mask: 0.11082009971141815 ===================
epoch no : 5, batch no : 370, total loss : 0.2896369993686676,  classifier :0.0362292043864727, mask: 0.1122002899646759 ===================
epoch no : 5, batch no : 371, total loss : 0.26764217019081116,  classifier :0.03277948126196861, mask: 0.10408720374107361 ===================
epoch no : 5, batch no : 372, total loss : 0.3484185039997101,  classifier :0.04347141832113266, mask: 0.1425849199295044 ===================
epoch no : 5, batch no : 373, total loss : 0.36606481671333313,  classifier :0.027995476499199867, mask: 0.16509254276752472 ===================
epoch no : 5, batch no : 374, total loss : 0.371648907661438,  classifier :0.03374764323234558, mask: 0.16124850511550903 ===================
epoch no : 5, batch no : 375, total loss : 0.27907538414001465,  classifier :0.05216531082987785, mask: 0.09907365590333939 ===================
epoch no : 5, batch no : 376, total loss : 0.30522865056991577,  classifier :0.039054691791534424, mask: 0.10483241081237793 ===================
epoch no : 5, batch no : 377, total loss : 0.3473709225654602,  classifier :0.03982880339026451, mask: 0.15211635828018188 ===================
epoch no : 5, batch no : 378, total loss : 0.33546382188796997,  classifier :0.03294427692890167, mask: 0.12470241636037827 ===================
epoch no : 5, batch no : 379, total loss : 0.3121647238731384,  classifier :0.030418066307902336, mask: 0.12486403435468674 ===================
epoch no : 5, batch no : 380, total loss : 0.25998398661613464,  classifier :0.047165900468826294, mask: 0.10688933730125427 ===================
epoch no : 5, batch no : 381, total loss : 0.3899223506450653,  classifier :0.058382999151945114, mask: 0.15773160755634308 ===================
epoch no : 5, batch no : 382, total loss : 0.3253752589225769,  classifier :0.04526875168085098, mask: 0.12620367109775543 ===================
epoch no : 5, batch no : 383, total loss : 0.24952484667301178,  classifier :0.033767472952604294, mask: 0.1098959818482399 ===================
epoch no : 5, batch no : 384, total loss : 0.3214721381664276,  classifier :0.04861907288432121, mask: 0.1471123844385147 ===================
epoch no : 5, batch no : 385, total loss : 0.3638867735862732,  classifier :0.03238994628190994, mask: 0.1671695113182068 ===================
epoch no : 5, batch no : 386, total loss : 0.36454668641090393,  classifier :0.038804493844509125, mask: 0.12616175413131714 ===================
epoch no : 5, batch no : 387, total loss : 0.29623207449913025,  classifier :0.03840743005275726, mask: 0.10903797298669815 ===================
epoch no : 5, batch no : 388, total loss : 0.2491627335548401,  classifier :0.03637288883328438, mask: 0.10236071795225143 ===================
epoch no : 5, batch no : 389, total loss : 0.2505781650543213,  classifier :0.029562590643763542, mask: 0.11452242732048035 ===================
epoch no : 5, batch no : 390, total loss : 0.236719012260437,  classifier :0.02641282044351101, mask: 0.1166146844625473 ===================
epoch no : 5, batch no : 391, total loss : 0.39657267928123474,  classifier :0.035339172929525375, mask: 0.14302465319633484 ===================
epoch no : 5, batch no : 392, total loss : 0.23423820734024048,  classifier :0.026890380308032036, mask: 0.10079212486743927 ===================
epoch no : 5, batch no : 393, total loss : 0.24673765897750854,  classifier :0.04278134927153587, mask: 0.08911819010972977 ===================
epoch no : 5, batch no : 394, total loss : 0.2637898623943329,  classifier :0.027136892080307007, mask: 0.12975992262363434 ===================
epoch no : 5, batch no : 395, total loss : 0.3065600097179413,  classifier :0.04412847012281418, mask: 0.14018061757087708 ===================
epoch no : 5, batch no : 396, total loss : 0.3397711217403412,  classifier :0.04552481323480606, mask: 0.13032099604606628 ===================
epoch no : 5, batch no : 397, total loss : 0.3909972906112671,  classifier :0.03445129469037056, mask: 0.13638116419315338 ===================
epoch no : 5, batch no : 398, total loss : 0.3244670629501343,  classifier :0.04089929163455963, mask: 0.12538428604602814 ===================
creating index...
index created!
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
Test:  [   0/3188]  eta: 0:37:15  model_time: 0.1316 (0.1316)  evaluator_time: 0.0309 (0.0309)  time: 0.7013  data: 0.4034  max mem: 9500
Test:  [ 100/3188]  eta: 0:12:27  model_time: 0.0998 (0.1017)  evaluator_time: 0.0130 (0.0132)  time: 0.2376  data: 0.0048  max mem: 9500
Test:  [ 200/3188]  eta: 0:11:47  model_time: 0.1049 (0.1012)  evaluator_time: 0.0125 (0.0125)  time: 0.2379  data: 0.0045  max mem: 9500
Test:  [ 300/3188]  eta: 0:11:21  model_time: 0.1067 (0.1016)  evaluator_time: 0.0094 (0.0119)  time: 0.2402  data: 0.0044  max mem: 9500
Test:  [ 400/3188]  eta: 0:11:02  model_time: 0.1021 (0.1029)  evaluator_time: 0.0114 (0.0121)  time: 0.2347  data: 0.0046  max mem: 9500
Test:  [ 500/3188]  eta: 0:10:42  model_time: 0.1019 (0.1035)  evaluator_time: 0.0094 (0.0122)  time: 0.2313  data: 0.0047  max mem: 9500
Test:  [ 600/3188]  eta: 0:10:23  model_time: 0.1100 (0.1047)  evaluator_time: 0.0099 (0.0122)  time: 0.2471  data: 0.0047  max mem: 9500
Test:  [ 700/3188]  eta: 0:09:56  model_time: 0.1045 (0.1044)  evaluator_time: 0.0101 (0.0121)  time: 0.2373  data: 0.0043  max mem: 9500
Test:  [ 800/3188]  eta: 0:09:29  model_time: 0.1040 (0.1041)  evaluator_time: 0.0097 (0.0118)  time: 0.2313  data: 0.0046  max mem: 9500
Test:  [ 900/3188]  eta: 0:09:05  model_time: 0.0999 (0.1041)  evaluator_time: 0.0101 (0.0119)  time: 0.2391  data: 0.0047  max mem: 9500
Test:  [1000/3188]  eta: 0:08:42  model_time: 0.1087 (0.1043)  evaluator_time: 0.0120 (0.0120)  time: 0.2526  data: 0.0054  max mem: 9500
Test:  [1100/3188]  eta: 0:08:20  model_time: 0.1076 (0.1046)  evaluator_time: 0.0101 (0.0121)  time: 0.2397  data: 0.0044  max mem: 9500
Test:  [1200/3188]  eta: 0:07:57  model_time: 0.1045 (0.1048)  evaluator_time: 0.0099 (0.0121)  time: 0.2366  data: 0.0045  max mem: 9500
Test:  [1300/3188]  eta: 0:07:32  model_time: 0.1005 (0.1046)  evaluator_time: 0.0098 (0.0120)  time: 0.2295  data: 0.0047  max mem: 9500
Test:  [1400/3188]  eta: 0:07:07  model_time: 0.1064 (0.1045)  evaluator_time: 0.0093 (0.0120)  time: 0.2407  data: 0.0051  max mem: 9500
Test:  [1500/3188]  eta: 0:06:43  model_time: 0.1047 (0.1043)  evaluator_time: 0.0120 (0.0119)  time: 0.2355  data: 0.0047  max mem: 9500
Test:  [1600/3188]  eta: 0:06:19  model_time: 0.1037 (0.1043)  evaluator_time: 0.0103 (0.0119)  time: 0.2351  data: 0.0046  max mem: 9500
Test:  [1700/3188]  eta: 0:05:54  model_time: 0.1008 (0.1042)  evaluator_time: 0.0087 (0.0117)  time: 0.2263  data: 0.0046  max mem: 9500
Test:  [1800/3188]  eta: 0:05:30  model_time: 0.1019 (0.1039)  evaluator_time: 0.0094 (0.0117)  time: 0.2292  data: 0.0047  max mem: 9500
Test:  [1900/3188]  eta: 0:05:06  model_time: 0.1046 (0.1038)  evaluator_time: 0.0086 (0.0117)  time: 0.2340  data: 0.0051  max mem: 9500
Test:  [2000/3188]  eta: 0:04:42  model_time: 0.1034 (0.1038)  evaluator_time: 0.0118 (0.0118)  time: 0.2356  data: 0.0051  max mem: 9500
Test:  [2100/3188]  eta: 0:04:19  model_time: 0.1122 (0.1039)  evaluator_time: 0.0141 (0.0119)  time: 0.2532  data: 0.0056  max mem: 9500
Test:  [2200/3188]  eta: 0:03:52  model_time: 0.0565 (0.1024)  evaluator_time: 0.0106 (0.0118)  time: 0.1452  data: 0.0053  max mem: 9500
Test:  [2300/3188]  eta: 0:03:25  model_time: 0.0560 (0.1004)  evaluator_time: 0.0091 (0.0118)  time: 0.1531  data: 0.0052  max mem: 9500
Test:  [2400/3188]  eta: 0:02:59  model_time: 0.0552 (0.0986)  evaluator_time: 0.0075 (0.0117)  time: 0.1361  data: 0.0050  max mem: 9500
Test:  [2500/3188]  eta: 0:02:34  model_time: 0.0556 (0.0971)  evaluator_time: 0.0094 (0.0117)  time: 0.1613  data: 0.0054  max mem: 9500
Test:  [2600/3188]  eta: 0:02:10  model_time: 0.0555 (0.0955)  evaluator_time: 0.0092 (0.0116)  time: 0.1429  data: 0.0051  max mem: 9500
Test:  [2700/3188]  eta: 0:01:46  model_time: 0.0565 (0.0941)  evaluator_time: 0.0110 (0.0116)  time: 0.1438  data: 0.0051  max mem: 9500
Test:  [2800/3188]  eta: 0:01:23  model_time: 0.0561 (0.0927)  evaluator_time: 0.0104 (0.0115)  time: 0.1463  data: 0.0049  max mem: 9500
Test:  [2900/3188]  eta: 0:01:01  model_time: 0.0555 (0.0915)  evaluator_time: 0.0093 (0.0115)  time: 0.1409  data: 0.0050  max mem: 9500
Test:  [3000/3188]  eta: 0:00:39  model_time: 0.0856 (0.0908)  evaluator_time: 0.0071 (0.0115)  time: 0.2012  data: 0.0051  max mem: 9500
Test:  [3100/3188]  eta: 0:00:18  model_time: 0.0882 (0.0907)  evaluator_time: 0.0109 (0.0114)  time: 0.2130  data: 0.0056  max mem: 9500
Test:  [3187/3188]  eta: 0:00:00  model_time: 0.0880 (0.0907)  evaluator_time: 0.0097 (0.0114)  time: 0.2116  data: 0.0053  max mem: 9500
Test: Total time: 0:11:15 (0.2118 s / it)
Averaged stats: model_time: 0.0880 (0.0907)  evaluator_time: 0.0097 (0.0114)
Accumulating evaluation results...
DONE-test (t=1.57s).
Accumulating evaluation results...
DONE-test (t=1.57s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.725
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.918
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.875
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.819
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.831
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.831
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.831
IoU metric: segm
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.740
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.918
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.883
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.740
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.825
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.837
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.837
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.837
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch no : 6, batch no : 0, total loss : 0.26262718439102173,  classifier :0.04382802173495293, mask: 0.10466201603412628 ===================
epoch no : 6, batch no : 1, total loss : 0.26435425877571106,  classifier :0.03239638730883598, mask: 0.1196209043264389 ===================
epoch no : 6, batch no : 2, total loss : 0.27728796005249023,  classifier :0.033941954374313354, mask: 0.12704241275787354 ===================
epoch no : 6, batch no : 3, total loss : 0.24775876104831696,  classifier :0.02820688486099243, mask: 0.10993345826864243 ===================
epoch no : 6, batch no : 4, total loss : 0.3364271819591522,  classifier :0.035216741263866425, mask: 0.14922256767749786 ===================
epoch no : 6, batch no : 5, total loss : 0.2797917127609253,  classifier :0.03165961429476738, mask: 0.1142624020576477 ===================
epoch no : 6, batch no : 6, total loss : 0.3453853726387024,  classifier :0.04184857755899429, mask: 0.13513046503067017 ===================
epoch no : 6, batch no : 7, total loss : 0.30682554841041565,  classifier :0.03685929626226425, mask: 0.11301514506340027 ===================
epoch no : 6, batch no : 8, total loss : 0.3073049485683441,  classifier :0.03457663208246231, mask: 0.1075318232178688 ===================
epoch no : 6, batch no : 9, total loss : 0.3557993471622467,  classifier :0.03332945704460144, mask: 0.138027623295784 ===================
epoch no : 6, batch no : 10, total loss : 0.2959246337413788,  classifier :0.035148609429597855, mask: 0.09201796352863312 ===================
epoch no : 6, batch no : 11, total loss : 0.25388553738594055,  classifier :0.03278472274541855, mask: 0.10050898790359497 ===================
epoch no : 6, batch no : 12, total loss : 0.301040917634964,  classifier :0.028636036440730095, mask: 0.15384621918201447 ===================
epoch no : 6, batch no : 13, total loss : 0.2917700409889221,  classifier :0.052210818976163864, mask: 0.1098458394408226 ===================
epoch no : 6, batch no : 14, total loss : 0.2347840964794159,  classifier :0.035468388348817825, mask: 0.11261695623397827 ===================
epoch no : 6, batch no : 15, total loss : 0.265067994594574,  classifier :0.022032197564840317, mask: 0.1357431262731552 ===================
epoch no : 6, batch no : 16, total loss : 0.4271496832370758,  classifier :0.026861589401960373, mask: 0.18337522447109222 ===================
epoch no : 6, batch no : 17, total loss : 0.242587149143219,  classifier :0.03356742486357689, mask: 0.11546605080366135 ===================
epoch no : 6, batch no : 18, total loss : 0.2317037135362625,  classifier :0.022536136209964752, mask: 0.10904917865991592 ===================
epoch no : 6, batch no : 19, total loss : 0.24839869141578674,  classifier :0.026422327384352684, mask: 0.10874828696250916 ===================
epoch no : 6, batch no : 20, total loss : 0.2867569625377655,  classifier :0.04321759566664696, mask: 0.1048966497182846 ===================
epoch no : 6, batch no : 21, total loss : 0.3368092179298401,  classifier :0.03958597779273987, mask: 0.14259642362594604 ===================
epoch no : 6, batch no : 22, total loss : 0.2766188085079193,  classifier :0.03634141758084297, mask: 0.1019059345126152 ===================
epoch no : 6, batch no : 23, total loss : 0.2734837532043457,  classifier :0.036845169961452484, mask: 0.09665096551179886 ===================
epoch no : 6, batch no : 24, total loss : 0.2336786538362503,  classifier :0.029631659388542175, mask: 0.1053929477930069 ===================
epoch no : 6, batch no : 25, total loss : 0.326089471578598,  classifier :0.03680548816919327, mask: 0.12519307434558868 ===================
epoch no : 6, batch no : 26, total loss : 0.27384158968925476,  classifier :0.028825201094150543, mask: 0.1230858713388443 ===================
epoch no : 6, batch no : 27, total loss : 0.2691132426261902,  classifier :0.03651581332087517, mask: 0.11751559376716614 ===================
epoch no : 6, batch no : 28, total loss : 0.21138353645801544,  classifier :0.026140602305531502, mask: 0.08430396765470505 ===================
epoch no : 6, batch no : 29, total loss : 0.22041137516498566,  classifier :0.03259215131402016, mask: 0.08246246725320816 ===================
epoch no : 6, batch no : 30, total loss : 0.2753903269767761,  classifier :0.04514331743121147, mask: 0.11791867762804031 ===================
epoch no : 6, batch no : 31, total loss : 0.34080561995506287,  classifier :0.030448831617832184, mask: 0.1493883728981018 ===================
epoch no : 6, batch no : 32, total loss : 0.3028007447719574,  classifier :0.034477729350328445, mask: 0.1415220946073532 ===================
epoch no : 6, batch no : 33, total loss : 0.30371132493019104,  classifier :0.026936154812574387, mask: 0.13047020137310028 ===================
epoch no : 6, batch no : 34, total loss : 0.2565479874610901,  classifier :0.037306178361177444, mask: 0.08397883176803589 ===================
epoch no : 6, batch no : 35, total loss : 0.30515339970588684,  classifier :0.03222334012389183, mask: 0.11432760208845139 ===================
epoch no : 6, batch no : 36, total loss : 0.2351071983575821,  classifier :0.022486669942736626, mask: 0.10107243806123734 ===================
epoch no : 6, batch no : 37, total loss : 0.39383941888809204,  classifier :0.03824147209525108, mask: 0.14405818283557892 ===================
epoch no : 6, batch no : 38, total loss : 0.3362869322299957,  classifier :0.03268345445394516, mask: 0.12635786831378937 ===================
epoch no : 6, batch no : 39, total loss : 0.33575984835624695,  classifier :0.03612826019525528, mask: 0.1322450488805771 ===================
epoch no : 6, batch no : 40, total loss : 0.27467095851898193,  classifier :0.03591232746839523, mask: 0.10119599848985672 ===================
epoch no : 6, batch no : 41, total loss : 0.250259667634964,  classifier :0.028332160785794258, mask: 0.09867729991674423 ===================
epoch no : 6, batch no : 42, total loss : 0.2997487187385559,  classifier :0.03894339129328728, mask: 0.1158343032002449 ===================
epoch no : 6, batch no : 43, total loss : 0.3025442063808441,  classifier :0.035083405673503876, mask: 0.116816945374012 ===================
epoch no : 6, batch no : 44, total loss : 0.3653951585292816,  classifier :0.031997356563806534, mask: 0.13570041954517365 ===================
epoch no : 6, batch no : 45, total loss : 0.32195159792900085,  classifier :0.023778840899467468, mask: 0.15466748178005219 ===================
epoch no : 6, batch no : 46, total loss : 0.3304736912250519,  classifier :0.031676534563302994, mask: 0.15676623582839966 ===================
epoch no : 6, batch no : 47, total loss : 0.2729414105415344,  classifier :0.02975267544388771, mask: 0.11081941425800323 ===================
epoch no : 6, batch no : 48, total loss : 0.30255958437919617,  classifier :0.03934818133711815, mask: 0.1206907406449318 ===================
epoch no : 6, batch no : 49, total loss : 0.2782856523990631,  classifier :0.03199849650263786, mask: 0.1144372820854187 ===================
epoch no : 6, batch no : 50, total loss : 0.27894946932792664,  classifier :0.02331875078380108, mask: 0.1104678213596344 ===================
epoch no : 6, batch no : 51, total loss : 0.3122366666793823,  classifier :0.04166615381836891, mask: 0.1325981765985489 ===================
epoch no : 6, batch no : 52, total loss : 0.29334592819213867,  classifier :0.03288484737277031, mask: 0.14901073276996613 ===================
epoch no : 6, batch no : 53, total loss : 0.28264883160591125,  classifier :0.034837089478969574, mask: 0.10228914022445679 ===================
epoch no : 6, batch no : 54, total loss : 0.24758033454418182,  classifier :0.03636476397514343, mask: 0.10701721906661987 ===================
epoch no : 6, batch no : 55, total loss : 0.2818658649921417,  classifier :0.029856843873858452, mask: 0.1141006350517273 ===================
epoch no : 6, batch no : 56, total loss : 0.35503607988357544,  classifier :0.044321708381175995, mask: 0.1616145372390747 ===================
epoch no : 6, batch no : 57, total loss : 0.31443145871162415,  classifier :0.04046952351927757, mask: 0.12683452665805817 ===================
epoch no : 6, batch no : 58, total loss : 0.25173625349998474,  classifier :0.027764523401856422, mask: 0.09119810163974762 ===================
epoch no : 6, batch no : 59, total loss : 0.29078343510627747,  classifier :0.04198694974184036, mask: 0.11902875453233719 ===================
epoch no : 6, batch no : 60, total loss : 0.30266180634498596,  classifier :0.030706651508808136, mask: 0.1434221714735031 ===================
epoch no : 6, batch no : 61, total loss : 0.24602137506008148,  classifier :0.027128208428621292, mask: 0.11211676895618439 ===================
epoch no : 6, batch no : 62, total loss : 0.3469756245613098,  classifier :0.030485238879919052, mask: 0.15631623566150665 ===================
epoch no : 6, batch no : 63, total loss : 0.23972903192043304,  classifier :0.02626369334757328, mask: 0.11520618200302124 ===================
epoch no : 6, batch no : 64, total loss : 0.27031856775283813,  classifier :0.038862161338329315, mask: 0.11259523034095764 ===================
epoch no : 6, batch no : 65, total loss : 0.238363578915596,  classifier :0.04151058942079544, mask: 0.09324748069047928 ===================
epoch no : 6, batch no : 66, total loss : 0.237069770693779,  classifier :0.028919653967022896, mask: 0.09584338217973709 ===================
epoch no : 6, batch no : 67, total loss : 0.2953445315361023,  classifier :0.03364482894539833, mask: 0.10660630464553833 ===================
epoch no : 6, batch no : 68, total loss : 0.264082133769989,  classifier :0.020681818947196007, mask: 0.11954799294471741 ===================
epoch no : 6, batch no : 69, total loss : 0.33104100823402405,  classifier :0.036112137138843536, mask: 0.13271141052246094 ===================
epoch no : 6, batch no : 70, total loss : 0.28570523858070374,  classifier :0.030270740389823914, mask: 0.12156787514686584 ===================
epoch no : 6, batch no : 71, total loss : 0.28816795349121094,  classifier :0.03200158104300499, mask: 0.11387460678815842 ===================
epoch no : 6, batch no : 72, total loss : 0.27620771527290344,  classifier :0.03989425301551819, mask: 0.1302870512008667 ===================
epoch no : 6, batch no : 73, total loss : 0.28842800855636597,  classifier :0.03578514978289604, mask: 0.12273190915584564 ===================
epoch no : 6, batch no : 74, total loss : 0.3223192095756531,  classifier :0.026608414947986603, mask: 0.13699382543563843 ===================
epoch no : 6, batch no : 75, total loss : 0.2633369565010071,  classifier :0.04235164821147919, mask: 0.11804612725973129 ===================
epoch no : 6, batch no : 76, total loss : 0.2238537222146988,  classifier :0.033089570701122284, mask: 0.09823838621377945 ===================
epoch no : 6, batch no : 77, total loss : 0.25519421696662903,  classifier :0.03617627173662186, mask: 0.10357972234487534 ===================
epoch no : 6, batch no : 78, total loss : 0.2386435717344284,  classifier :0.029271144419908524, mask: 0.11964775621891022 ===================
epoch no : 6, batch no : 79, total loss : 0.24592363834381104,  classifier :0.02226301282644272, mask: 0.10054304450750351 ===================
epoch no : 6, batch no : 80, total loss : 0.2883566617965698,  classifier :0.025382425636053085, mask: 0.14827004075050354 ===================
epoch no : 6, batch no : 81, total loss : 0.29195165634155273,  classifier :0.04153623804450035, mask: 0.14646680653095245 ===================
epoch no : 6, batch no : 82, total loss : 0.21718831360340118,  classifier :0.022050481289625168, mask: 0.0942019671201706 ===================
epoch no : 6, batch no : 83, total loss : 0.2916630506515503,  classifier :0.0400487445294857, mask: 0.12584048509597778 ===================
epoch no : 6, batch no : 84, total loss : 0.2958984375,  classifier :0.03436246141791344, mask: 0.11526510119438171 ===================
epoch no : 6, batch no : 85, total loss : 0.28924131393432617,  classifier :0.036166220903396606, mask: 0.11333747953176498 ===================
epoch no : 6, batch no : 86, total loss : 0.2666885554790497,  classifier :0.030215522274374962, mask: 0.09998506307601929 ===================
epoch no : 6, batch no : 87, total loss : 0.3369888961315155,  classifier :0.02261277474462986, mask: 0.13398140668869019 ===================
epoch no : 6, batch no : 88, total loss : 0.24600356817245483,  classifier :0.03604266792535782, mask: 0.09860944747924805 ===================
epoch no : 6, batch no : 89, total loss : 0.22329369187355042,  classifier :0.024873772636055946, mask: 0.08583693951368332 ===================
epoch no : 6, batch no : 90, total loss : 0.2619483470916748,  classifier :0.030086765065789223, mask: 0.12796500325202942 ===================
epoch no : 6, batch no : 91, total loss : 0.23506197333335876,  classifier :0.028434595093131065, mask: 0.09828400611877441 ===================
epoch no : 6, batch no : 92, total loss : 0.3049134612083435,  classifier :0.03461918607354164, mask: 0.12906476855278015 ===================
epoch no : 6, batch no : 93, total loss : 0.23070503771305084,  classifier :0.026948213577270508, mask: 0.10723245143890381 ===================
epoch no : 6, batch no : 94, total loss : 0.2515573501586914,  classifier :0.022435903549194336, mask: 0.1175961121916771 ===================
epoch no : 6, batch no : 95, total loss : 0.3244054615497589,  classifier :0.04149669036269188, mask: 0.13477130234241486 ===================
epoch no : 6, batch no : 96, total loss : 0.25173744559288025,  classifier :0.034983836114406586, mask: 0.10838668793439865 ===================
epoch no : 6, batch no : 97, total loss : 0.22352156043052673,  classifier :0.02241046354174614, mask: 0.09503203630447388 ===================
epoch no : 6, batch no : 98, total loss : 0.19640608131885529,  classifier :0.022125255316495895, mask: 0.08943471312522888 ===================
epoch no : 6, batch no : 99, total loss : 0.3046773672103882,  classifier :0.042010705918073654, mask: 0.13481256365776062 ===================
epoch no : 6, batch no : 100, total loss : 0.3121718168258667,  classifier :0.03861841559410095, mask: 0.09230329096317291 ===================
epoch no : 6, batch no : 101, total loss : 0.25262436270713806,  classifier :0.028857585042715073, mask: 0.10236205905675888 ===================
epoch no : 6, batch no : 102, total loss : 0.25066807866096497,  classifier :0.022715074941515923, mask: 0.10366301238536835 ===================
epoch no : 6, batch no : 103, total loss : 0.34525415301322937,  classifier :0.04099593684077263, mask: 0.1265709102153778 ===================
epoch no : 6, batch no : 104, total loss : 0.31896182894706726,  classifier :0.0333707258105278, mask: 0.12042539566755295 ===================
epoch no : 6, batch no : 105, total loss : 0.2868843078613281,  classifier :0.02956702932715416, mask: 0.11804961413145065 ===================
epoch no : 6, batch no : 106, total loss : 0.2812369763851166,  classifier :0.03777715191245079, mask: 0.11695528775453568 ===================
epoch no : 6, batch no : 107, total loss : 0.26278430223464966,  classifier :0.02664916403591633, mask: 0.1117849126458168 ===================
epoch no : 6, batch no : 108, total loss : 0.33642300963401794,  classifier :0.04972453787922859, mask: 0.130970761179924 ===================
epoch no : 6, batch no : 109, total loss : 0.28861474990844727,  classifier :0.029734501615166664, mask: 0.1359330713748932 ===================
epoch no : 6, batch no : 110, total loss : 0.30285412073135376,  classifier :0.029913367703557014, mask: 0.13320891559123993 ===================
epoch no : 6, batch no : 111, total loss : 0.24555478990077972,  classifier :0.04385976493358612, mask: 0.09119372069835663 ===================
epoch no : 6, batch no : 112, total loss : 0.328239381313324,  classifier :0.03759929537773132, mask: 0.14257089793682098 ===================
epoch no : 6, batch no : 113, total loss : 0.2908482849597931,  classifier :0.027451224625110626, mask: 0.1252342015504837 ===================
epoch no : 6, batch no : 114, total loss : 0.3264194130897522,  classifier :0.028756149113178253, mask: 0.14084485173225403 ===================
epoch no : 6, batch no : 115, total loss : 0.27628281712532043,  classifier :0.033742863684892654, mask: 0.11515024304389954 ===================
epoch no : 6, batch no : 116, total loss : 0.22715522348880768,  classifier :0.030045324936509132, mask: 0.09914777427911758 ===================
epoch no : 6, batch no : 117, total loss : 0.31175291538238525,  classifier :0.027169067412614822, mask: 0.15870220959186554 ===================
epoch no : 6, batch no : 118, total loss : 0.29531624913215637,  classifier :0.03584201633930206, mask: 0.10791020840406418 ===================
epoch no : 6, batch no : 119, total loss : 0.25116315484046936,  classifier :0.04154496639966965, mask: 0.10083533823490143 ===================
epoch no : 6, batch no : 120, total loss : 0.3990795314311981,  classifier :0.031136279925704002, mask: 0.15989777445793152 ===================
epoch no : 6, batch no : 121, total loss : 0.3224482238292694,  classifier :0.03266005218029022, mask: 0.13060526549816132 ===================
epoch no : 6, batch no : 122, total loss : 0.3375699818134308,  classifier :0.0334036760032177, mask: 0.1528111696243286 ===================
epoch no : 6, batch no : 123, total loss : 0.36741289496421814,  classifier :0.04519616812467575, mask: 0.14381222426891327 ===================
epoch no : 6, batch no : 124, total loss : 0.3002902865409851,  classifier :0.037675779312849045, mask: 0.10797405987977982 ===================
epoch no : 6, batch no : 125, total loss : 0.3481454849243164,  classifier :0.040053680539131165, mask: 0.15158358216285706 ===================
epoch no : 6, batch no : 126, total loss : 0.21702581644058228,  classifier :0.03246224671602249, mask: 0.08640733361244202 ===================
epoch no : 6, batch no : 127, total loss : 0.3227212131023407,  classifier :0.029616057872772217, mask: 0.10364337265491486 ===================
epoch no : 6, batch no : 128, total loss : 0.26365208625793457,  classifier :0.04070289060473442, mask: 0.09569798409938812 ===================
epoch no : 6, batch no : 129, total loss : 0.24708521366119385,  classifier :0.034817714244127274, mask: 0.10479561984539032 ===================
epoch no : 6, batch no : 130, total loss : 0.30826443433761597,  classifier :0.024860288947820663, mask: 0.14422976970672607 ===================
epoch no : 6, batch no : 131, total loss : 0.32266461849212646,  classifier :0.03727947175502777, mask: 0.14381730556488037 ===================
epoch no : 6, batch no : 132, total loss : 0.3002835512161255,  classifier :0.03720888867974281, mask: 0.1036377102136612 ===================
epoch no : 6, batch no : 133, total loss : 0.34281617403030396,  classifier :0.042319994419813156, mask: 0.12000072747468948 ===================
epoch no : 6, batch no : 134, total loss : 0.33657437562942505,  classifier :0.03573949635028839, mask: 0.1536855846643448 ===================
epoch no : 6, batch no : 135, total loss : 0.3296605050563812,  classifier :0.053883954882621765, mask: 0.12174873799085617 ===================
epoch no : 6, batch no : 136, total loss : 0.28595787286758423,  classifier :0.03929458558559418, mask: 0.1333940476179123 ===================
epoch no : 6, batch no : 137, total loss : 0.3010442852973938,  classifier :0.02273896336555481, mask: 0.16126209497451782 ===================
epoch no : 6, batch no : 138, total loss : 0.27870264649391174,  classifier :0.036527782678604126, mask: 0.13207831978797913 ===================
epoch no : 6, batch no : 139, total loss : 0.2941056191921234,  classifier :0.03047305718064308, mask: 0.1434929072856903 ===================
epoch no : 6, batch no : 140, total loss : 0.30367493629455566,  classifier :0.03160446137189865, mask: 0.15385521948337555 ===================
epoch no : 6, batch no : 141, total loss : 0.2569566071033478,  classifier :0.02542560175061226, mask: 0.08867757022380829 ===================
epoch no : 6, batch no : 142, total loss : 0.2778075635433197,  classifier :0.035183485597372055, mask: 0.10315418243408203 ===================
epoch no : 6, batch no : 143, total loss : 0.31039610505104065,  classifier :0.038622573018074036, mask: 0.12614232301712036 ===================
epoch no : 6, batch no : 144, total loss : 0.3551742434501648,  classifier :0.02828138694167137, mask: 0.1678645759820938 ===================
epoch no : 6, batch no : 145, total loss : 0.3028199374675751,  classifier :0.025185272097587585, mask: 0.12963441014289856 ===================
epoch no : 6, batch no : 146, total loss : 0.26325100660324097,  classifier :0.02860793098807335, mask: 0.11620443314313889 ===================
epoch no : 6, batch no : 147, total loss : 0.2957994043827057,  classifier :0.029074788093566895, mask: 0.1098809689283371 ===================
epoch no : 6, batch no : 148, total loss : 0.36612576246261597,  classifier :0.035089340060949326, mask: 0.13555186986923218 ===================
epoch no : 6, batch no : 149, total loss : 0.2517649531364441,  classifier :0.02107981964945793, mask: 0.12070997059345245 ===================
epoch no : 6, batch no : 150, total loss : 0.2300603836774826,  classifier :0.023032139986753464, mask: 0.10357017070055008 ===================
epoch no : 6, batch no : 151, total loss : 0.2792307138442993,  classifier :0.035967353731393814, mask: 0.13153702020645142 ===================
epoch no : 6, batch no : 152, total loss : 0.26223018765449524,  classifier :0.026639463379979134, mask: 0.10416477173566818 ===================
epoch no : 6, batch no : 153, total loss : 0.26785653829574585,  classifier :0.026252150535583496, mask: 0.12623660266399384 ===================
epoch no : 6, batch no : 154, total loss : 0.33506685495376587,  classifier :0.035095613449811935, mask: 0.15770961344242096 ===================
epoch no : 6, batch no : 155, total loss : 0.2825794517993927,  classifier :0.030061446130275726, mask: 0.11575356870889664 ===================
epoch no : 6, batch no : 156, total loss : 0.2911887466907501,  classifier :0.021638259291648865, mask: 0.16030645370483398 ===================
epoch no : 6, batch no : 157, total loss : 0.32083675265312195,  classifier :0.03740372508764267, mask: 0.137363001704216 ===================
epoch no : 6, batch no : 158, total loss : 0.31711825728416443,  classifier :0.03378796949982643, mask: 0.1284903585910797 ===================
epoch no : 6, batch no : 159, total loss : 0.2589927911758423,  classifier :0.03272496908903122, mask: 0.11983491480350494 ===================
epoch no : 6, batch no : 160, total loss : 0.3247773349285126,  classifier :0.05592598021030426, mask: 0.1310344934463501 ===================
epoch no : 6, batch no : 161, total loss : 0.24021290242671967,  classifier :0.026769697666168213, mask: 0.11647654324769974 ===================
epoch no : 6, batch no : 162, total loss : 0.31862133741378784,  classifier :0.037003953009843826, mask: 0.13157705962657928 ===================
epoch no : 6, batch no : 163, total loss : 0.3237886428833008,  classifier :0.026958081871271133, mask: 0.12204896658658981 ===================
epoch no : 6, batch no : 164, total loss : 0.4348697066307068,  classifier :0.026029588654637337, mask: 0.18836651742458344 ===================
epoch no : 6, batch no : 165, total loss : 0.29864001274108887,  classifier :0.0492372028529644, mask: 0.11219223588705063 ===================
epoch no : 6, batch no : 166, total loss : 0.37134942412376404,  classifier :0.02624373883008957, mask: 0.1840997189283371 ===================
epoch no : 6, batch no : 167, total loss : 0.3014177680015564,  classifier :0.029483236372470856, mask: 0.11400691419839859 ===================
epoch no : 6, batch no : 168, total loss : 0.33448588848114014,  classifier :0.03201350197196007, mask: 0.14701515436172485 ===================
epoch no : 6, batch no : 169, total loss : 0.3488650619983673,  classifier :0.036962930113077164, mask: 0.1514481157064438 ===================
epoch no : 6, batch no : 170, total loss : 0.2903379499912262,  classifier :0.030827978625893593, mask: 0.13053418695926666 ===================
epoch no : 6, batch no : 171, total loss : 0.2292618453502655,  classifier :0.03668271377682686, mask: 0.0826033353805542 ===================
epoch no : 6, batch no : 172, total loss : 0.2435779869556427,  classifier :0.02068893425166607, mask: 0.09912475943565369 ===================
epoch no : 6, batch no : 173, total loss : 0.2669583857059479,  classifier :0.030474437400698662, mask: 0.11495587974786758 ===================
epoch no : 6, batch no : 174, total loss : 0.21441809833049774,  classifier :0.04365468770265579, mask: 0.08212937414646149 ===================
epoch no : 6, batch no : 175, total loss : 0.2834833264350891,  classifier :0.03348686173558235, mask: 0.13289855420589447 ===================
epoch no : 6, batch no : 176, total loss : 0.27741655707359314,  classifier :0.03753117844462395, mask: 0.10668200254440308 ===================
epoch no : 6, batch no : 177, total loss : 0.2727554142475128,  classifier :0.033456165343523026, mask: 0.10176491737365723 ===================
epoch no : 6, batch no : 178, total loss : 0.2640741765499115,  classifier :0.026558056473731995, mask: 0.13483117520809174 ===================
epoch no : 6, batch no : 179, total loss : 0.29413849115371704,  classifier :0.040830884128808975, mask: 0.1349429339170456 ===================
epoch no : 6, batch no : 180, total loss : 0.23299679160118103,  classifier :0.021565604954957962, mask: 0.11109557002782822 ===================
epoch no : 6, batch no : 181, total loss : 0.29926109313964844,  classifier :0.058867134153842926, mask: 0.11040885001420975 ===================
epoch no : 6, batch no : 182, total loss : 0.27503514289855957,  classifier :0.023818984627723694, mask: 0.1286064237356186 ===================
epoch no : 6, batch no : 183, total loss : 0.2624778151512146,  classifier :0.03364139795303345, mask: 0.12385673075914383 ===================
epoch no : 6, batch no : 184, total loss : 0.20461273193359375,  classifier :0.03188852593302727, mask: 0.09645712375640869 ===================
epoch no : 6, batch no : 185, total loss : 0.2230720967054367,  classifier :0.03429913893342018, mask: 0.11312974989414215 ===================
epoch no : 6, batch no : 186, total loss : 0.22792956233024597,  classifier :0.028850266709923744, mask: 0.08606529235839844 ===================
epoch no : 6, batch no : 187, total loss : 0.2494494616985321,  classifier :0.028379354625940323, mask: 0.11337507516145706 ===================
epoch no : 6, batch no : 188, total loss : 0.2280091643333435,  classifier :0.03707485273480415, mask: 0.10156778246164322 ===================
epoch no : 6, batch no : 189, total loss : 0.2711360454559326,  classifier :0.023947689682245255, mask: 0.10988735407590866 ===================
epoch no : 6, batch no : 190, total loss : 0.35776814818382263,  classifier :0.05275900289416313, mask: 0.13167965412139893 ===================
epoch no : 6, batch no : 191, total loss : 0.3631756901741028,  classifier :0.0383477658033371, mask: 0.13382504880428314 ===================
epoch no : 6, batch no : 192, total loss : 0.27654606103897095,  classifier :0.02657027542591095, mask: 0.10823837667703629 ===================
epoch no : 6, batch no : 193, total loss : 0.28599780797958374,  classifier :0.03874143585562706, mask: 0.10687710344791412 ===================
epoch no : 6, batch no : 194, total loss : 0.26776909828186035,  classifier :0.027916735038161278, mask: 0.1124693900346756 ===================
epoch no : 6, batch no : 195, total loss : 0.2623484432697296,  classifier :0.03741299733519554, mask: 0.10959917306900024 ===================
epoch no : 6, batch no : 196, total loss : 0.2879643738269806,  classifier :0.033145781606435776, mask: 0.11524169147014618 ===================
epoch no : 6, batch no : 197, total loss : 0.34455132484436035,  classifier :0.0299365296959877, mask: 0.14376144111156464 ===================
epoch no : 6, batch no : 198, total loss : 0.3022880554199219,  classifier :0.03468974307179451, mask: 0.12613758444786072 ===================
epoch no : 6, batch no : 199, total loss : 0.25117507576942444,  classifier :0.03541044890880585, mask: 0.11548454314470291 ===================
epoch no : 6, batch no : 200, total loss : 0.2619662284851074,  classifier :0.03110048547387123, mask: 0.09809929877519608 ===================
epoch no : 6, batch no : 201, total loss : 0.28878888487815857,  classifier :0.02560451254248619, mask: 0.1109825149178505 ===================
epoch no : 6, batch no : 202, total loss : 0.38734105229377747,  classifier :0.03724643960595131, mask: 0.14613144099712372 ===================
epoch no : 6, batch no : 203, total loss : 0.38095414638519287,  classifier :0.03186790645122528, mask: 0.15363800525665283 ===================
epoch no : 6, batch no : 204, total loss : 0.2952563464641571,  classifier :0.038492508232593536, mask: 0.11256809532642365 ===================
epoch no : 6, batch no : 205, total loss : 0.2794515788555145,  classifier :0.035836901515722275, mask: 0.11712206155061722 ===================
epoch no : 6, batch no : 206, total loss : 0.27549800276756287,  classifier :0.03561132028698921, mask: 0.10357688367366791 ===================
epoch no : 6, batch no : 207, total loss : 0.25018152594566345,  classifier :0.0262179933488369, mask: 0.09700590372085571 ===================
epoch no : 6, batch no : 208, total loss : 0.2976997196674347,  classifier :0.029012206941843033, mask: 0.11302023380994797 ===================
epoch no : 6, batch no : 209, total loss : 0.29889804124832153,  classifier :0.024247292429208755, mask: 0.12381818890571594 ===================
epoch no : 6, batch no : 210, total loss : 0.4077560603618622,  classifier :0.04845526069402695, mask: 0.17099681496620178 ===================
epoch no : 6, batch no : 211, total loss : 0.26857253909111023,  classifier :0.030099699273705482, mask: 0.10812148451805115 ===================
epoch no : 6, batch no : 212, total loss : 0.43947938084602356,  classifier :0.049167700111866, mask: 0.2236827313899994 ===================
epoch no : 6, batch no : 213, total loss : 0.25561997294425964,  classifier :0.02371259778738022, mask: 0.11113008111715317 ===================
epoch no : 6, batch no : 214, total loss : 0.25871261954307556,  classifier :0.03630213811993599, mask: 0.10915377736091614 ===================
epoch no : 6, batch no : 215, total loss : 0.32848024368286133,  classifier :0.028552884235978127, mask: 0.14635342359542847 ===================
epoch no : 6, batch no : 216, total loss : 0.2335963398218155,  classifier :0.04174062982201576, mask: 0.09699064493179321 ===================
epoch no : 6, batch no : 217, total loss : 0.29969918727874756,  classifier :0.030193572863936424, mask: 0.12466659396886826 ===================
epoch no : 6, batch no : 218, total loss : 0.2759512662887573,  classifier :0.02257618121802807, mask: 0.13540886342525482 ===================
epoch no : 6, batch no : 219, total loss : 0.22374100983142853,  classifier :0.027604930102825165, mask: 0.09035203605890274 ===================
epoch no : 6, batch no : 220, total loss : 0.2649340033531189,  classifier :0.026829367503523827, mask: 0.11162162572145462 ===================
epoch no : 6, batch no : 221, total loss : 0.3304039537906647,  classifier :0.01737564615905285, mask: 0.17302438616752625 ===================
epoch no : 6, batch no : 222, total loss : 0.3543042540550232,  classifier :0.027081472799181938, mask: 0.1295412927865982 ===================
epoch no : 6, batch no : 223, total loss : 0.2789663076400757,  classifier :0.026675792410969734, mask: 0.13466787338256836 ===================
epoch no : 6, batch no : 224, total loss : 0.2951217293739319,  classifier :0.025155240669846535, mask: 0.14917047321796417 ===================
epoch no : 6, batch no : 225, total loss : 0.25834646821022034,  classifier :0.03195533528923988, mask: 0.12675143778324127 ===================
epoch no : 6, batch no : 226, total loss : 0.3822726309299469,  classifier :0.043082673102617264, mask: 0.18103715777397156 ===================
epoch no : 6, batch no : 227, total loss : 0.3732416033744812,  classifier :0.05420217663049698, mask: 0.14907465875148773 ===================
epoch no : 6, batch no : 228, total loss : 0.32320332527160645,  classifier :0.023757701739668846, mask: 0.16351032257080078 ===================
epoch no : 6, batch no : 229, total loss : 0.22744497656822205,  classifier :0.025204891338944435, mask: 0.102338045835495 ===================
epoch no : 6, batch no : 230, total loss : 0.24965372681617737,  classifier :0.028059927746653557, mask: 0.1113285943865776 ===================
epoch no : 6, batch no : 231, total loss : 0.30656352639198303,  classifier :0.04442377761006355, mask: 0.12846355140209198 ===================
epoch no : 6, batch no : 232, total loss : 0.3176213204860687,  classifier :0.03959361091256142, mask: 0.1188095211982727 ===================
epoch no : 6, batch no : 233, total loss : 0.21222731471061707,  classifier :0.02937380038201809, mask: 0.0882108062505722 ===================
epoch no : 6, batch no : 234, total loss : 0.28112366795539856,  classifier :0.032763659954071045, mask: 0.13108938932418823 ===================
epoch no : 6, batch no : 235, total loss : 0.28308191895484924,  classifier :0.03875212371349335, mask: 0.1294335275888443 ===================
epoch no : 6, batch no : 236, total loss : 0.3079140782356262,  classifier :0.021598704159259796, mask: 0.14788734912872314 ===================
epoch no : 6, batch no : 237, total loss : 0.23570062220096588,  classifier :0.029383882880210876, mask: 0.0964883491396904 ===================
epoch no : 6, batch no : 238, total loss : 0.29258695244789124,  classifier :0.04486435279250145, mask: 0.11897078901529312 ===================
epoch no : 6, batch no : 239, total loss : 0.2476397603750229,  classifier :0.02558784745633602, mask: 0.11206375807523727 ===================
epoch no : 6, batch no : 240, total loss : 0.24027401208877563,  classifier :0.033871471881866455, mask: 0.1055976077914238 ===================
epoch no : 6, batch no : 241, total loss : 0.31700199842453003,  classifier :0.04686066135764122, mask: 0.1381869912147522 ===================
epoch no : 6, batch no : 242, total loss : 0.22179573774337769,  classifier :0.022373531013727188, mask: 0.11142779141664505 ===================
epoch no : 6, batch no : 243, total loss : 0.24833032488822937,  classifier :0.04042702913284302, mask: 0.09231054037809372 ===================
epoch no : 6, batch no : 244, total loss : 0.23515136539936066,  classifier :0.029557306319475174, mask: 0.10327217727899551 ===================
epoch no : 6, batch no : 245, total loss : 0.2452262043952942,  classifier :0.03580091521143913, mask: 0.11341406404972076 ===================
epoch no : 6, batch no : 246, total loss : 0.29055047035217285,  classifier :0.0313064381480217, mask: 0.12569931149482727 ===================
epoch no : 6, batch no : 247, total loss : 0.2796778678894043,  classifier :0.03257211670279503, mask: 0.10662674903869629 ===================
epoch no : 6, batch no : 248, total loss : 0.35830435156822205,  classifier :0.04612204059958458, mask: 0.14239293336868286 ===================
epoch no : 6, batch no : 249, total loss : 0.2214372605085373,  classifier :0.030580617487430573, mask: 0.10419707000255585 ===================
epoch no : 6, batch no : 250, total loss : 0.2830566465854645,  classifier :0.028512921184301376, mask: 0.12646906077861786 ===================
epoch no : 6, batch no : 251, total loss : 0.27282512187957764,  classifier :0.031016234308481216, mask: 0.14227788150310516 ===================
epoch no : 6, batch no : 252, total loss : 0.3120422065258026,  classifier :0.03283122181892395, mask: 0.12343950569629669 ===================
epoch no : 6, batch no : 253, total loss : 0.22775937616825104,  classifier :0.029020505025982857, mask: 0.09320135414600372 ===================
epoch no : 6, batch no : 254, total loss : 0.268879234790802,  classifier :0.028741436079144478, mask: 0.12437648326158524 ===================
epoch no : 6, batch no : 255, total loss : 0.32785454392433167,  classifier :0.05776996910572052, mask: 0.1061854362487793 ===================
epoch no : 6, batch no : 256, total loss : 0.2494317591190338,  classifier :0.022362202405929565, mask: 0.08350808918476105 ===================
epoch no : 6, batch no : 257, total loss : 0.398175448179245,  classifier :0.057522065937519073, mask: 0.1924736201763153 ===================
epoch no : 6, batch no : 258, total loss : 0.4160778820514679,  classifier :0.03197399526834488, mask: 0.17466017603874207 ===================
epoch no : 6, batch no : 259, total loss : 0.2714126706123352,  classifier :0.04601052403450012, mask: 0.12074796110391617 ===================
epoch no : 6, batch no : 260, total loss : 0.26332467794418335,  classifier :0.03545613959431648, mask: 0.09954646974802017 ===================
epoch no : 6, batch no : 261, total loss : 0.2277330756187439,  classifier :0.02935085818171501, mask: 0.08950825780630112 ===================
epoch no : 6, batch no : 262, total loss : 0.2985418438911438,  classifier :0.03634485974907875, mask: 0.12048686295747757 ===================
epoch no : 6, batch no : 263, total loss : 0.32495924830436707,  classifier :0.03742976859211922, mask: 0.15496420860290527 ===================
epoch no : 6, batch no : 264, total loss : 0.2677153944969177,  classifier :0.04279569536447525, mask: 0.12573377788066864 ===================
epoch no : 6, batch no : 265, total loss : 0.2589168846607208,  classifier :0.06899754703044891, mask: 0.08856210112571716 ===================
epoch no : 6, batch no : 266, total loss : 0.22807727754116058,  classifier :0.03179796785116196, mask: 0.09860757738351822 ===================
epoch no : 6, batch no : 267, total loss : 0.26070162653923035,  classifier :0.020481927320361137, mask: 0.11422175914049149 ===================
epoch no : 6, batch no : 268, total loss : 0.24250243604183197,  classifier :0.027363380417227745, mask: 0.0979895293712616 ===================
epoch no : 6, batch no : 269, total loss : 0.22354339063167572,  classifier :0.02608146332204342, mask: 0.10771077126264572 ===================
epoch no : 6, batch no : 270, total loss : 0.2475624531507492,  classifier :0.02311541698873043, mask: 0.11138048022985458 ===================
epoch no : 6, batch no : 271, total loss : 0.26436758041381836,  classifier :0.0448274165391922, mask: 0.09569229185581207 ===================
epoch no : 6, batch no : 272, total loss : 0.2943677306175232,  classifier :0.02871502749621868, mask: 0.12670904397964478 ===================
epoch no : 6, batch no : 273, total loss : 0.21258050203323364,  classifier :0.027595704421401024, mask: 0.08605707436800003 ===================
epoch no : 6, batch no : 274, total loss : 0.1988825500011444,  classifier :0.030114831402897835, mask: 0.09111350774765015 ===================
epoch no : 6, batch no : 275, total loss : 0.25447553396224976,  classifier :0.02980143204331398, mask: 0.11382655054330826 ===================
epoch no : 6, batch no : 276, total loss : 0.31505393981933594,  classifier :0.040345631539821625, mask: 0.13275660574436188 ===================
epoch no : 6, batch no : 277, total loss : 0.3048268258571625,  classifier :0.05293179303407669, mask: 0.12585234642028809 ===================
epoch no : 6, batch no : 278, total loss : 0.25332504510879517,  classifier :0.0396350733935833, mask: 0.11988978087902069 ===================
epoch no : 6, batch no : 279, total loss : 0.36522796750068665,  classifier :0.038032472133636475, mask: 0.15672335028648376 ===================
epoch no : 6, batch no : 280, total loss : 0.22510309517383575,  classifier :0.029656441882252693, mask: 0.10097222775220871 ===================
epoch no : 6, batch no : 281, total loss : 0.23930689692497253,  classifier :0.03318984806537628, mask: 0.09683766216039658 ===================
epoch no : 6, batch no : 282, total loss : 0.35992392897605896,  classifier :0.03682664409279823, mask: 0.1537608951330185 ===================
epoch no : 6, batch no : 283, total loss : 0.3729645907878876,  classifier :0.043988533318042755, mask: 0.11711057275533676 ===================
epoch no : 6, batch no : 284, total loss : 0.2921164631843567,  classifier :0.03534138947725296, mask: 0.12289519608020782 ===================
epoch no : 6, batch no : 285, total loss : 0.2762541174888611,  classifier :0.026486925780773163, mask: 0.10778924077749252 ===================
epoch no : 6, batch no : 286, total loss : 0.35736849904060364,  classifier :0.02938295528292656, mask: 0.15071357786655426 ===================
epoch no : 6, batch no : 287, total loss : 0.3216632306575775,  classifier :0.03503863513469696, mask: 0.13491091132164001 ===================
epoch no : 6, batch no : 288, total loss : 0.2237677276134491,  classifier :0.02728917822241783, mask: 0.09862294048070908 ===================
epoch no : 6, batch no : 289, total loss : 0.25557786226272583,  classifier :0.03393964469432831, mask: 0.10810007154941559 ===================
epoch no : 6, batch no : 290, total loss : 0.26812344789505005,  classifier :0.024938276037573814, mask: 0.1294599175453186 ===================
epoch no : 6, batch no : 291, total loss : 0.25844117999076843,  classifier :0.04016087204217911, mask: 0.11173085123300552 ===================
epoch no : 6, batch no : 292, total loss : 0.23531199991703033,  classifier :0.03649920970201492, mask: 0.08249572664499283 ===================
epoch no : 6, batch no : 293, total loss : 0.255603551864624,  classifier :0.03153115510940552, mask: 0.092656709253788 ===================
epoch no : 6, batch no : 294, total loss : 0.3110949993133545,  classifier :0.025637689977884293, mask: 0.11785661429166794 ===================
epoch no : 6, batch no : 295, total loss : 0.2292422503232956,  classifier :0.022876113653182983, mask: 0.11015217006206512 ===================
epoch no : 6, batch no : 296, total loss : 0.2892809808254242,  classifier :0.02929060347378254, mask: 0.12157566845417023 ===================
epoch no : 6, batch no : 297, total loss : 0.2606993615627289,  classifier :0.04592190310359001, mask: 0.0860365778207779 ===================
epoch no : 6, batch no : 298, total loss : 0.24978584051132202,  classifier :0.024531887844204903, mask: 0.11082536727190018 ===================
epoch no : 6, batch no : 299, total loss : 0.2576697766780853,  classifier :0.023736998438835144, mask: 0.11250510811805725 ===================
epoch no : 6, batch no : 300, total loss : 0.2727515697479248,  classifier :0.026846343651413918, mask: 0.10774686932563782 ===================
epoch no : 6, batch no : 301, total loss : 0.25656765699386597,  classifier :0.043357476592063904, mask: 0.09071746468544006 ===================
epoch no : 6, batch no : 302, total loss : 0.2997609078884125,  classifier :0.039379868656396866, mask: 0.10478556156158447 ===================
epoch no : 6, batch no : 303, total loss : 0.2989899516105652,  classifier :0.03584260493516922, mask: 0.14523373544216156 ===================
epoch no : 6, batch no : 304, total loss : 0.2580852210521698,  classifier :0.04472123086452484, mask: 0.10647634416818619 ===================
epoch no : 6, batch no : 305, total loss : 0.27024590969085693,  classifier :0.03795800358057022, mask: 0.10222029685974121 ===================
epoch no : 6, batch no : 306, total loss : 0.3437400460243225,  classifier :0.027739640325307846, mask: 0.15831811726093292 ===================
epoch no : 6, batch no : 307, total loss : 0.2814025282859802,  classifier :0.028303811326622963, mask: 0.0883854478597641 ===================
epoch no : 6, batch no : 308, total loss : 0.2943373918533325,  classifier :0.04722290486097336, mask: 0.09388334304094315 ===================
epoch no : 6, batch no : 309, total loss : 0.24639250338077545,  classifier :0.027783228084445, mask: 0.11131305992603302 ===================
epoch no : 6, batch no : 310, total loss : 0.2890661954879761,  classifier :0.02720535546541214, mask: 0.12447090446949005 ===================
epoch no : 6, batch no : 311, total loss : 0.49390989542007446,  classifier :0.049915656447410583, mask: 0.20399393141269684 ===================
epoch no : 6, batch no : 312, total loss : 0.44388359785079956,  classifier :0.040015753358602524, mask: 0.20318692922592163 ===================
epoch no : 6, batch no : 313, total loss : 0.3947005569934845,  classifier :0.04495922103524208, mask: 0.19294776022434235 ===================
epoch no : 6, batch no : 314, total loss : 0.24063082039356232,  classifier :0.026210330426692963, mask: 0.11323991417884827 ===================
epoch no : 6, batch no : 315, total loss : 0.30391547083854675,  classifier :0.046241238713264465, mask: 0.11165934056043625 ===================
epoch no : 6, batch no : 316, total loss : 0.26131609082221985,  classifier :0.03316355496644974, mask: 0.11449849605560303 ===================
epoch no : 6, batch no : 317, total loss : 0.23204298317432404,  classifier :0.030413605272769928, mask: 0.09378328174352646 ===================
epoch no : 6, batch no : 318, total loss : 0.25968578457832336,  classifier :0.03706551715731621, mask: 0.10904631018638611 ===================
epoch no : 6, batch no : 319, total loss : 0.1936679631471634,  classifier :0.02590138278901577, mask: 0.08928930759429932 ===================
epoch no : 6, batch no : 320, total loss : 0.3528798520565033,  classifier :0.05193357914686203, mask: 0.14323022961616516 ===================
epoch no : 6, batch no : 321, total loss : 0.2825046479701996,  classifier :0.029540058225393295, mask: 0.15331654250621796 ===================
epoch no : 6, batch no : 322, total loss : 0.2998031973838806,  classifier :0.03397510573267937, mask: 0.14637461304664612 ===================
epoch no : 6, batch no : 323, total loss : 0.3929979205131531,  classifier :0.0643133819103241, mask: 0.13385015726089478 ===================
epoch no : 6, batch no : 324, total loss : 0.3154124617576599,  classifier :0.03452020511031151, mask: 0.14834950864315033 ===================
epoch no : 6, batch no : 325, total loss : 0.33919933438301086,  classifier :0.037673305720090866, mask: 0.13292214274406433 ===================
epoch no : 6, batch no : 326, total loss : 0.3138265907764435,  classifier :0.026158185675740242, mask: 0.1377941519021988 ===================
epoch no : 6, batch no : 327, total loss : 0.2810607850551605,  classifier :0.029633749276399612, mask: 0.13126395642757416 ===================
epoch no : 6, batch no : 328, total loss : 0.27853238582611084,  classifier :0.03525586426258087, mask: 0.10780418664216995 ===================
epoch no : 6, batch no : 329, total loss : 0.304179847240448,  classifier :0.03352968394756317, mask: 0.13222166895866394 ===================
epoch no : 6, batch no : 330, total loss : 0.2748022675514221,  classifier :0.025184765458106995, mask: 0.11775923520326614 ===================
epoch no : 6, batch no : 331, total loss : 0.29272958636283875,  classifier :0.0336221382021904, mask: 0.1436205953359604 ===================
epoch no : 6, batch no : 332, total loss : 0.28306153416633606,  classifier :0.0277352686971426, mask: 0.11458937078714371 ===================
epoch no : 6, batch no : 333, total loss : 0.27035602927207947,  classifier :0.029548581689596176, mask: 0.13181939721107483 ===================
epoch no : 6, batch no : 334, total loss : 0.2677493691444397,  classifier :0.026313725858926773, mask: 0.09842473268508911 ===================
epoch no : 6, batch no : 335, total loss : 0.21986646950244904,  classifier :0.037419404834508896, mask: 0.08085254579782486 ===================
epoch no : 6, batch no : 336, total loss : 0.2826886475086212,  classifier :0.03690902516245842, mask: 0.13150857388973236 ===================
epoch no : 6, batch no : 337, total loss : 0.29067763686180115,  classifier :0.02645128220319748, mask: 0.11779659241437912 ===================
epoch no : 6, batch no : 338, total loss : 0.2308834046125412,  classifier :0.020523566752672195, mask: 0.11561036854982376 ===================
epoch no : 6, batch no : 339, total loss : 0.4476654529571533,  classifier :0.0320432074368, mask: 0.2066543698310852 ===================
epoch no : 6, batch no : 340, total loss : 0.25588732957839966,  classifier :0.021746236830949783, mask: 0.1155182346701622 ===================
epoch no : 6, batch no : 341, total loss : 0.26084843277931213,  classifier :0.02819719724357128, mask: 0.11503859609365463 ===================
epoch no : 6, batch no : 342, total loss : 0.29500824213027954,  classifier :0.03053821064531803, mask: 0.12430033832788467 ===================
epoch no : 6, batch no : 343, total loss : 0.21248379349708557,  classifier :0.022824617102742195, mask: 0.09365101903676987 ===================
epoch no : 6, batch no : 344, total loss : 0.21880997717380524,  classifier :0.022220507264137268, mask: 0.08950154483318329 ===================
epoch no : 6, batch no : 345, total loss : 0.21267089247703552,  classifier :0.02961098402738571, mask: 0.09814079850912094 ===================
epoch no : 6, batch no : 346, total loss : 0.26339757442474365,  classifier :0.024973992258310318, mask: 0.11139044910669327 ===================
epoch no : 6, batch no : 347, total loss : 0.2299296110868454,  classifier :0.028324410319328308, mask: 0.0910685807466507 ===================
epoch no : 6, batch no : 348, total loss : 0.34303247928619385,  classifier :0.025888051837682724, mask: 0.16751937568187714 ===================
epoch no : 6, batch no : 349, total loss : 0.18777981400489807,  classifier :0.027857080101966858, mask: 0.08619777113199234 ===================
epoch no : 6, batch no : 350, total loss : 0.2707543969154358,  classifier :0.035462990403175354, mask: 0.09942131489515305 ===================
epoch no : 6, batch no : 351, total loss : 0.2537090480327606,  classifier :0.03165489807724953, mask: 0.11213768273591995 ===================
epoch no : 6, batch no : 352, total loss : 0.2604190409183502,  classifier :0.030332766473293304, mask: 0.10862791538238525 ===================
epoch no : 6, batch no : 353, total loss : 0.28181684017181396,  classifier :0.025155631825327873, mask: 0.11912377923727036 ===================
epoch no : 6, batch no : 354, total loss : 0.25018051266670227,  classifier :0.032386086881160736, mask: 0.1037866473197937 ===================
epoch no : 6, batch no : 355, total loss : 0.22418656945228577,  classifier :0.027826936915516853, mask: 0.09307344257831573 ===================
epoch no : 6, batch no : 356, total loss : 0.21141952276229858,  classifier :0.025037609040737152, mask: 0.09431811422109604 ===================
epoch no : 6, batch no : 357, total loss : 0.3114313781261444,  classifier :0.029287882149219513, mask: 0.13833920657634735 ===================
epoch no : 6, batch no : 358, total loss : 0.25282952189445496,  classifier :0.022138169035315514, mask: 0.1007281169295311 ===================
epoch no : 6, batch no : 359, total loss : 0.3032554090023041,  classifier :0.02386980876326561, mask: 0.132854163646698 ===================
epoch no : 6, batch no : 360, total loss : 0.23097002506256104,  classifier :0.03007340244948864, mask: 0.1036941185593605 ===================
epoch no : 6, batch no : 361, total loss : 0.29740574955940247,  classifier :0.03386760130524635, mask: 0.12389397621154785 ===================
epoch no : 6, batch no : 362, total loss : 0.31756722927093506,  classifier :0.031966909766197205, mask: 0.11932322382926941 ===================
epoch no : 6, batch no : 363, total loss : 0.32204410433769226,  classifier :0.03382573649287224, mask: 0.12954062223434448 ===================
epoch no : 6, batch no : 364, total loss : 0.25795406103134155,  classifier :0.030149169266223907, mask: 0.11794998496770859 ===================
epoch no : 6, batch no : 365, total loss : 0.22776366770267487,  classifier :0.02682814933359623, mask: 0.09756813198328018 ===================
epoch no : 6, batch no : 366, total loss : 0.2214556634426117,  classifier :0.028206683695316315, mask: 0.09121102094650269 ===================
epoch no : 6, batch no : 367, total loss : 0.24758289754390717,  classifier :0.029709650203585625, mask: 0.110272116959095 ===================
epoch no : 6, batch no : 368, total loss : 0.33866146206855774,  classifier :0.03276924043893814, mask: 0.16079837083816528 ===================
epoch no : 6, batch no : 369, total loss : 0.2487761676311493,  classifier :0.020658250898122787, mask: 0.11526002734899521 ===================
epoch no : 6, batch no : 370, total loss : 0.23527118563652039,  classifier :0.042531464248895645, mask: 0.09705688804388046 ===================
epoch no : 6, batch no : 371, total loss : 0.19817692041397095,  classifier :0.02543175406754017, mask: 0.08650322258472443 ===================
epoch no : 6, batch no : 372, total loss : 0.2430465966463089,  classifier :0.030550416558980942, mask: 0.12829561531543732 ===================
epoch no : 6, batch no : 373, total loss : 0.23119494318962097,  classifier :0.034645337611436844, mask: 0.10211148858070374 ===================
epoch no : 6, batch no : 374, total loss : 0.2974328100681305,  classifier :0.031783562153577805, mask: 0.12546098232269287 ===================
epoch no : 6, batch no : 375, total loss : 0.27724704146385193,  classifier :0.027841156348586082, mask: 0.11006242036819458 ===================
epoch no : 6, batch no : 376, total loss : 0.22963657975196838,  classifier :0.022469302639365196, mask: 0.10789904743432999 ===================
epoch no : 6, batch no : 377, total loss : 0.2541988492012024,  classifier :0.029018379747867584, mask: 0.12179715186357498 ===================
epoch no : 6, batch no : 378, total loss : 0.23735065758228302,  classifier :0.026527689769864082, mask: 0.09842778742313385 ===================
epoch no : 6, batch no : 379, total loss : 0.2812694311141968,  classifier :0.03299543261528015, mask: 0.12262019515037537 ===================
epoch no : 6, batch no : 380, total loss : 0.35308340191841125,  classifier :0.033780910074710846, mask: 0.12436394393444061 ===================
epoch no : 6, batch no : 381, total loss : 0.24676409363746643,  classifier :0.03150700405240059, mask: 0.0915503278374672 ===================
epoch no : 6, batch no : 382, total loss : 0.27826496958732605,  classifier :0.04254595562815666, mask: 0.10930487513542175 ===================
epoch no : 6, batch no : 383, total loss : 0.3137841522693634,  classifier :0.05389365926384926, mask: 0.11115232855081558 ===================
epoch no : 6, batch no : 384, total loss : 0.25270360708236694,  classifier :0.024451224133372307, mask: 0.10976070165634155 ===================
epoch no : 6, batch no : 385, total loss : 0.26744475960731506,  classifier :0.032511308789253235, mask: 0.11354599893093109 ===================
epoch no : 6, batch no : 386, total loss : 0.23757745325565338,  classifier :0.03490718454122543, mask: 0.11050086468458176 ===================
epoch no : 6, batch no : 387, total loss : 0.22403372824192047,  classifier :0.02264178916811943, mask: 0.096866175532341 ===================
epoch no : 6, batch no : 388, total loss : 0.33269768953323364,  classifier :0.02773519791662693, mask: 0.1869155764579773 ===================
epoch no : 6, batch no : 389, total loss : 0.3063603341579437,  classifier :0.021013014018535614, mask: 0.19373223185539246 ===================
epoch no : 6, batch no : 390, total loss : 0.24637597799301147,  classifier :0.02679203636944294, mask: 0.11157487332820892 ===================
epoch no : 6, batch no : 391, total loss : 0.2647895812988281,  classifier :0.029218384996056557, mask: 0.11372603476047516 ===================
epoch no : 6, batch no : 392, total loss : 0.2526302933692932,  classifier :0.03199395537376404, mask: 0.10952432453632355 ===================
epoch no : 6, batch no : 393, total loss : 0.257808119058609,  classifier :0.02399679832160473, mask: 0.10712572932243347 ===================
epoch no : 6, batch no : 394, total loss : 0.23457041382789612,  classifier :0.024880513548851013, mask: 0.09977327287197113 ===================
epoch no : 6, batch no : 395, total loss : 0.24701239168643951,  classifier :0.026431206613779068, mask: 0.11162819713354111 ===================
epoch no : 6, batch no : 396, total loss : 0.22928114235401154,  classifier :0.03803567588329315, mask: 0.0927947536110878 ===================
epoch no : 6, batch no : 397, total loss : 0.20593205094337463,  classifier :0.026747269555926323, mask: 0.09694156050682068 ===================
epoch no : 6, batch no : 398, total loss : 0.3160131573677063,  classifier :0.02752828225493431, mask: 0.1412251591682434 ===================
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch no : 7, batch no : 0, total loss : 0.34571748971939087,  classifier :0.03124065510928631, mask: 0.1194954589009285 ===================
epoch no : 7, batch no : 1, total loss : 0.24950064718723297,  classifier :0.0298269372433424, mask: 0.0904354527592659 ===================
epoch no : 7, batch no : 2, total loss : 0.212326779961586,  classifier :0.03556255251169205, mask: 0.0863751769065857 ===================
epoch no : 7, batch no : 3, total loss : 0.22310298681259155,  classifier :0.03838060796260834, mask: 0.08393470197916031 ===================
epoch no : 7, batch no : 4, total loss : 0.34765052795410156,  classifier :0.03083837777376175, mask: 0.1550779640674591 ===================
epoch no : 7, batch no : 5, total loss : 0.27746742963790894,  classifier :0.022076362743973732, mask: 0.13061270117759705 ===================
epoch no : 7, batch no : 6, total loss : 0.2282256782054901,  classifier :0.020931480452418327, mask: 0.11841502040624619 ===================
epoch no : 7, batch no : 7, total loss : 0.19111046195030212,  classifier :0.0171860009431839, mask: 0.09685775637626648 ===================
epoch no : 7, batch no : 8, total loss : 0.22321021556854248,  classifier :0.026398450136184692, mask: 0.11335206776857376 ===================
epoch no : 7, batch no : 9, total loss : 0.21401900053024292,  classifier :0.025426261126995087, mask: 0.10456582903862 ===================
epoch no : 7, batch no : 10, total loss : 0.23577308654785156,  classifier :0.0259107518941164, mask: 0.10741885006427765 ===================
epoch no : 7, batch no : 11, total loss : 0.2707827389240265,  classifier :0.034364648163318634, mask: 0.11789018660783768 ===================
epoch no : 7, batch no : 12, total loss : 0.25375694036483765,  classifier :0.02127707749605179, mask: 0.1025489941239357 ===================
epoch no : 7, batch no : 13, total loss : 0.19756172597408295,  classifier :0.025569302961230278, mask: 0.08237546682357788 ===================
epoch no : 7, batch no : 14, total loss : 0.26475417613983154,  classifier :0.03660065308213234, mask: 0.09692439436912537 ===================
epoch no : 7, batch no : 15, total loss : 0.41978129744529724,  classifier :0.03754445165395737, mask: 0.16413992643356323 ===================
epoch no : 7, batch no : 16, total loss : 0.296374648809433,  classifier :0.0343768410384655, mask: 0.12597349286079407 ===================
epoch no : 7, batch no : 17, total loss : 0.30298158526420593,  classifier :0.03443371504545212, mask: 0.15107811987400055 ===================
epoch no : 7, batch no : 18, total loss : 0.2303275465965271,  classifier :0.027210352942347527, mask: 0.10705029219388962 ===================
epoch no : 7, batch no : 19, total loss : 0.32835766673088074,  classifier :0.041932135820388794, mask: 0.16271576285362244 ===================
epoch no : 7, batch no : 20, total loss : 0.3168356120586395,  classifier :0.026481814682483673, mask: 0.13985282182693481 ===================
epoch no : 7, batch no : 21, total loss : 0.3551449775695801,  classifier :0.03264573961496353, mask: 0.15646900236606598 ===================
epoch no : 7, batch no : 22, total loss : 0.34398627281188965,  classifier :0.030232394114136696, mask: 0.17924122512340546 ===================
epoch no : 7, batch no : 23, total loss : 0.36799168586730957,  classifier :0.04972817003726959, mask: 0.1328546702861786 ===================
epoch no : 7, batch no : 24, total loss : 0.36761733889579773,  classifier :0.04095868021249771, mask: 0.19045747816562653 ===================
epoch no : 7, batch no : 25, total loss : 0.29695212841033936,  classifier :0.03525663912296295, mask: 0.12938301265239716 ===================
epoch no : 7, batch no : 26, total loss : 0.2831307053565979,  classifier :0.02714299038052559, mask: 0.1622980684041977 ===================
epoch no : 7, batch no : 27, total loss : 0.22143246233463287,  classifier :0.022416071966290474, mask: 0.10545236617326736 ===================
epoch no : 7, batch no : 28, total loss : 0.24231718480587006,  classifier :0.04219159483909607, mask: 0.0916750580072403 ===================
epoch no : 7, batch no : 29, total loss : 0.2667168974876404,  classifier :0.021114671602845192, mask: 0.11440590769052505 ===================
epoch no : 7, batch no : 30, total loss : 0.17568016052246094,  classifier :0.02567601390182972, mask: 0.0872703269124031 ===================
epoch no : 7, batch no : 31, total loss : 0.26060912013053894,  classifier :0.024844130501151085, mask: 0.11853045970201492 ===================
epoch no : 7, batch no : 32, total loss : 0.3059411942958832,  classifier :0.0266671534627676, mask: 0.14308854937553406 ===================
epoch no : 7, batch no : 33, total loss : 0.26462605595588684,  classifier :0.02797902561724186, mask: 0.09648127853870392 ===================
epoch no : 7, batch no : 34, total loss : 0.28544920682907104,  classifier :0.0314796045422554, mask: 0.09580711275339127 ===================
epoch no : 7, batch no : 35, total loss : 0.22879549860954285,  classifier :0.033034443855285645, mask: 0.08177667111158371 ===================
epoch no : 7, batch no : 36, total loss : 0.23956696689128876,  classifier :0.03718262538313866, mask: 0.11834046244621277 ===================
epoch no : 7, batch no : 37, total loss : 0.24550294876098633,  classifier :0.027294451370835304, mask: 0.11492416262626648 ===================
epoch no : 7, batch no : 38, total loss : 0.20369946956634521,  classifier :0.030674394220113754, mask: 0.09935556352138519 ===================
epoch no : 7, batch no : 39, total loss : 0.30148154497146606,  classifier :0.033604416996240616, mask: 0.1257437914609909 ===================
epoch no : 7, batch no : 40, total loss : 0.29991263151168823,  classifier :0.04301219806075096, mask: 0.11767678707838058 ===================
epoch no : 7, batch no : 41, total loss : 0.3359367847442627,  classifier :0.04141663759946823, mask: 0.14283020794391632 ===================
epoch no : 7, batch no : 42, total loss : 0.5256111025810242,  classifier :0.04746163263916969, mask: 0.21107898652553558 ===================
epoch no : 7, batch no : 43, total loss : 0.36153170466423035,  classifier :0.03120741806924343, mask: 0.17533808946609497 ===================
epoch no : 7, batch no : 44, total loss : 0.2306039035320282,  classifier :0.02577817440032959, mask: 0.08968967199325562 ===================
epoch no : 7, batch no : 45, total loss : 0.2296326458454132,  classifier :0.03547198697924614, mask: 0.10950886458158493 ===================
epoch no : 7, batch no : 46, total loss : 0.1912025660276413,  classifier :0.031180063262581825, mask: 0.08087587356567383 ===================
epoch no : 7, batch no : 47, total loss : 0.31780803203582764,  classifier :0.030143676325678825, mask: 0.14122797548770905 ===================
epoch no : 7, batch no : 48, total loss : 0.21870844066143036,  classifier :0.028083113953471184, mask: 0.08708274364471436 ===================
epoch no : 7, batch no : 49, total loss : 0.290438711643219,  classifier :0.027600569650530815, mask: 0.10504215955734253 ===================
epoch no : 7, batch no : 50, total loss : 0.23937468230724335,  classifier :0.02321687340736389, mask: 0.09981480240821838 ===================
epoch no : 7, batch no : 51, total loss : 0.2396739423274994,  classifier :0.019948281347751617, mask: 0.11563661694526672 ===================
epoch no : 7, batch no : 52, total loss : 0.25999724864959717,  classifier :0.04362044110894203, mask: 0.10380303114652634 ===================
epoch no : 7, batch no : 53, total loss : 0.2536291182041168,  classifier :0.038462888449430466, mask: 0.10787660628557205 ===================
epoch no : 7, batch no : 54, total loss : 0.29608550667762756,  classifier :0.03409748896956444, mask: 0.12097427994012833 ===================
epoch no : 7, batch no : 55, total loss : 0.2505294680595398,  classifier :0.024825138971209526, mask: 0.10321146249771118 ===================
epoch no : 7, batch no : 56, total loss : 0.2814151644706726,  classifier :0.0406479649245739, mask: 0.10429102927446365 ===================
epoch no : 7, batch no : 57, total loss : 0.2792374789714813,  classifier :0.03354530408978462, mask: 0.09521915763616562 ===================
epoch no : 7, batch no : 58, total loss : 0.2773759067058563,  classifier :0.022400066256523132, mask: 0.12686890363693237 ===================
epoch no : 7, batch no : 59, total loss : 0.29618188738822937,  classifier :0.027561631053686142, mask: 0.14617957174777985 ===================
epoch no : 7, batch no : 60, total loss : 0.23413251340389252,  classifier :0.032861195504665375, mask: 0.111358642578125 ===================
epoch no : 7, batch no : 61, total loss : 0.2408618927001953,  classifier :0.03346984088420868, mask: 0.09383241087198257 ===================
epoch no : 7, batch no : 62, total loss : 0.21070879697799683,  classifier :0.023692313581705093, mask: 0.0931561291217804 ===================
epoch no : 7, batch no : 63, total loss : 0.24768806993961334,  classifier :0.01714567467570305, mask: 0.10349369049072266 ===================
epoch no : 7, batch no : 64, total loss : 0.28624802827835083,  classifier :0.03401513770222664, mask: 0.1089644506573677 ===================
epoch no : 7, batch no : 65, total loss : 0.3319821357727051,  classifier :0.028521863743662834, mask: 0.15202385187149048 ===================
epoch no : 7, batch no : 66, total loss : 0.20186839997768402,  classifier :0.018707264214754105, mask: 0.09600844979286194 ===================
epoch no : 7, batch no : 67, total loss : 0.29599499702453613,  classifier :0.02776096947491169, mask: 0.14193610846996307 ===================
epoch no : 7, batch no : 68, total loss : 0.26619741320610046,  classifier :0.026339663192629814, mask: 0.11738655716180801 ===================
epoch no : 7, batch no : 69, total loss : 0.38184699416160583,  classifier :0.04950074106454849, mask: 0.14480064809322357 ===================
epoch no : 7, batch no : 70, total loss : 0.22399161756038666,  classifier :0.032127805054187775, mask: 0.09814935177564621 ===================
epoch no : 7, batch no : 71, total loss : 0.24699193239212036,  classifier :0.035917673259973526, mask: 0.1002763882279396 ===================
epoch no : 7, batch no : 72, total loss : 0.28455260396003723,  classifier :0.023362765088677406, mask: 0.13916486501693726 ===================
epoch no : 7, batch no : 73, total loss : 0.2843896746635437,  classifier :0.03496607393026352, mask: 0.13357099890708923 ===================
epoch no : 7, batch no : 74, total loss : 0.2001972198486328,  classifier :0.03380489721894264, mask: 0.09042929857969284 ===================
epoch no : 7, batch no : 75, total loss : 0.26026496291160583,  classifier :0.026758380234241486, mask: 0.11603274196386337 ===================
epoch no : 7, batch no : 76, total loss : 0.23187439143657684,  classifier :0.024303874000906944, mask: 0.11481618881225586 ===================
epoch no : 7, batch no : 77, total loss : 0.22837333381175995,  classifier :0.02454782836139202, mask: 0.0997566506266594 ===================
epoch no : 7, batch no : 78, total loss : 0.2454475611448288,  classifier :0.034498412162065506, mask: 0.11208340525627136 ===================
epoch no : 7, batch no : 79, total loss : 0.2639283835887909,  classifier :0.02548391744494438, mask: 0.11426112055778503 ===================
epoch no : 7, batch no : 80, total loss : 0.23638014495372772,  classifier :0.02502046711742878, mask: 0.09778130054473877 ===================
epoch no : 7, batch no : 81, total loss : 0.30625277757644653,  classifier :0.026889082044363022, mask: 0.1221710816025734 ===================
epoch no : 7, batch no : 82, total loss : 0.2527580261230469,  classifier :0.016947414726018906, mask: 0.12373904138803482 ===================
epoch no : 7, batch no : 83, total loss : 0.2884601354598999,  classifier :0.027178578078746796, mask: 0.1169818714261055 ===================
epoch no : 7, batch no : 84, total loss : 0.28147754073143005,  classifier :0.02904132939875126, mask: 0.10346296429634094 ===================
epoch no : 7, batch no : 85, total loss : 0.342033326625824,  classifier :0.043551817536354065, mask: 0.13569635152816772 ===================
epoch no : 7, batch no : 86, total loss : 0.32783204317092896,  classifier :0.03555280342698097, mask: 0.14707468450069427 ===================
epoch no : 7, batch no : 87, total loss : 0.3363873362541199,  classifier :0.03562750294804573, mask: 0.14796292781829834 ===================
epoch no : 7, batch no : 88, total loss : 0.23413223028182983,  classifier :0.03200095146894455, mask: 0.1063934862613678 ===================
epoch no : 7, batch no : 89, total loss : 0.3705507218837738,  classifier :0.03157836198806763, mask: 0.18676769733428955 ===================
epoch no : 7, batch no : 90, total loss : 0.30061620473861694,  classifier :0.031114524230360985, mask: 0.12507720291614532 ===================
epoch no : 7, batch no : 91, total loss : 0.25926926732063293,  classifier :0.03189494088292122, mask: 0.11701371520757675 ===================
epoch no : 7, batch no : 92, total loss : 0.2247169017791748,  classifier :0.02792053483426571, mask: 0.10755443572998047 ===================
epoch no : 7, batch no : 93, total loss : 0.24825163185596466,  classifier :0.02972486801445484, mask: 0.1010311171412468 ===================
epoch no : 7, batch no : 94, total loss : 0.24427412450313568,  classifier :0.024924710392951965, mask: 0.08724697679281235 ===================
epoch no : 7, batch no : 95, total loss : 0.27518483996391296,  classifier :0.024138860404491425, mask: 0.11455614864826202 ===================
epoch no : 7, batch no : 96, total loss : 0.2338937669992447,  classifier :0.03574894741177559, mask: 0.0926399677991867 ===================
epoch no : 7, batch no : 97, total loss : 0.250529021024704,  classifier :0.039987001568078995, mask: 0.09910676628351212 ===================
epoch no : 7, batch no : 98, total loss : 0.2936732769012451,  classifier :0.030780553817749023, mask: 0.1118244007229805 ===================
epoch no : 7, batch no : 99, total loss : 0.22836469113826752,  classifier :0.036525651812553406, mask: 0.11400863528251648 ===================
epoch no : 7, batch no : 100, total loss : 0.2576434910297394,  classifier :0.033402565866708755, mask: 0.11186254769563675 ===================
epoch no : 7, batch no : 101, total loss : 0.1931900978088379,  classifier :0.02831379324197769, mask: 0.08674092590808868 ===================
epoch no : 7, batch no : 102, total loss : 0.2112163007259369,  classifier :0.025656867772340775, mask: 0.0899113267660141 ===================
epoch no : 7, batch no : 103, total loss : 0.28114786744117737,  classifier :0.024955030530691147, mask: 0.11152897030115128 ===================
epoch no : 7, batch no : 104, total loss : 0.2850683331489563,  classifier :0.028137870132923126, mask: 0.12357496470212936 ===================
epoch no : 7, batch no : 105, total loss : 0.2558126151561737,  classifier :0.024184247478842735, mask: 0.11357540637254715 ===================
epoch no : 7, batch no : 106, total loss : 0.3016985058784485,  classifier :0.033289842307567596, mask: 0.1261904239654541 ===================
epoch no : 7, batch no : 107, total loss : 0.27304941415786743,  classifier :0.02941408008337021, mask: 0.114403136074543 ===================
epoch no : 7, batch no : 108, total loss : 0.28134235739707947,  classifier :0.02809060737490654, mask: 0.15058507025241852 ===================
epoch no : 7, batch no : 109, total loss : 0.2937481105327606,  classifier :0.03725270926952362, mask: 0.11735723912715912 ===================
epoch no : 7, batch no : 110, total loss : 0.22747096419334412,  classifier :0.025055058300495148, mask: 0.1023530587553978 ===================
epoch no : 7, batch no : 111, total loss : 0.23308928310871124,  classifier :0.01982015185058117, mask: 0.09934873878955841 ===================
epoch no : 7, batch no : 112, total loss : 0.2048325538635254,  classifier :0.026123356074094772, mask: 0.09448704868555069 ===================
epoch no : 7, batch no : 113, total loss : 0.25755152106285095,  classifier :0.02348925918340683, mask: 0.12185271829366684 ===================
epoch no : 7, batch no : 114, total loss : 0.26316362619400024,  classifier :0.04024890810251236, mask: 0.10616409033536911 ===================
epoch no : 7, batch no : 115, total loss : 0.31121426820755005,  classifier :0.035453423857688904, mask: 0.12121255695819855 ===================
epoch no : 7, batch no : 116, total loss : 0.3068183660507202,  classifier :0.03198038786649704, mask: 0.11657682061195374 ===================
epoch no : 7, batch no : 117, total loss : 0.27325302362442017,  classifier :0.03087443672120571, mask: 0.09010858833789825 ===================
epoch no : 7, batch no : 118, total loss : 0.26138192415237427,  classifier :0.029364323243498802, mask: 0.09947408735752106 ===================
epoch no : 7, batch no : 119, total loss : 0.21942397952079773,  classifier :0.029502607882022858, mask: 0.087466299533844 ===================
epoch no : 7, batch no : 120, total loss : 0.26727116107940674,  classifier :0.032682713121175766, mask: 0.10792607814073563 ===================
epoch no : 7, batch no : 121, total loss : 0.28563302755355835,  classifier :0.02751619555056095, mask: 0.13110119104385376 ===================
epoch no : 7, batch no : 122, total loss : 0.23266813158988953,  classifier :0.019976666197180748, mask: 0.09515445679426193 ===================
epoch no : 7, batch no : 123, total loss : 0.23142747581005096,  classifier :0.021858638152480125, mask: 0.0916779413819313 ===================
epoch no : 7, batch no : 124, total loss : 0.27290990948677063,  classifier :0.03237311169505119, mask: 0.12209659814834595 ===================
epoch no : 7, batch no : 125, total loss : 0.29284045100212097,  classifier :0.03337913006544113, mask: 0.11934284120798111 ===================
epoch no : 7, batch no : 126, total loss : 0.28373461961746216,  classifier :0.03759702295064926, mask: 0.11401469260454178 ===================
epoch no : 7, batch no : 127, total loss : 0.20981928706169128,  classifier :0.023473938927054405, mask: 0.09895175695419312 ===================
epoch no : 7, batch no : 128, total loss : 0.3241105377674103,  classifier :0.033994853496551514, mask: 0.15221558511257172 ===================
epoch no : 7, batch no : 129, total loss : 0.24872146546840668,  classifier :0.037069957703351974, mask: 0.10091840475797653 ===================
epoch no : 7, batch no : 130, total loss : 0.25905802845954895,  classifier :0.025269879028201103, mask: 0.09218025952577591 ===================
epoch no : 7, batch no : 131, total loss : 0.3092005252838135,  classifier :0.02682168409228325, mask: 0.1199224665760994 ===================
epoch no : 7, batch no : 132, total loss : 0.29984572529792786,  classifier :0.038458388298749924, mask: 0.15572060644626617 ===================
epoch no : 7, batch no : 133, total loss : 0.27151957154273987,  classifier :0.029714230448007584, mask: 0.11613357067108154 ===================
epoch no : 7, batch no : 134, total loss : 0.25853821635246277,  classifier :0.01916152983903885, mask: 0.11329668760299683 ===================
epoch no : 7, batch no : 135, total loss : 0.23340032994747162,  classifier :0.02330179698765278, mask: 0.09937696158885956 ===================
epoch no : 7, batch no : 136, total loss : 0.31356504559516907,  classifier :0.02920769713819027, mask: 0.14986805617809296 ===================
epoch no : 7, batch no : 137, total loss : 0.22817115485668182,  classifier :0.026949672028422356, mask: 0.10096866637468338 ===================
epoch no : 7, batch no : 138, total loss : 0.23018978536128998,  classifier :0.025065356865525246, mask: 0.11213158071041107 ===================
epoch no : 7, batch no : 139, total loss : 0.22377297282218933,  classifier :0.027692796662449837, mask: 0.11508909612894058 ===================
epoch no : 7, batch no : 140, total loss : 0.29984965920448303,  classifier :0.026099994778633118, mask: 0.1649155616760254 ===================
epoch no : 7, batch no : 141, total loss : 0.20143306255340576,  classifier :0.020698871463537216, mask: 0.09898681938648224 ===================
epoch no : 7, batch no : 142, total loss : 0.3026668429374695,  classifier :0.03231878951191902, mask: 0.14131608605384827 ===================
epoch no : 7, batch no : 143, total loss : 0.23749662935733795,  classifier :0.027427949011325836, mask: 0.1180926188826561 ===================
epoch no : 7, batch no : 144, total loss : 0.2535693943500519,  classifier :0.020717071369290352, mask: 0.13966374099254608 ===================
epoch no : 7, batch no : 145, total loss : 0.23716868460178375,  classifier :0.02279183454811573, mask: 0.09794047474861145 ===================
epoch no : 7, batch no : 146, total loss : 0.268710196018219,  classifier :0.021030329167842865, mask: 0.11044955253601074 ===================
epoch no : 7, batch no : 147, total loss : 0.2700881063938141,  classifier :0.03260321170091629, mask: 0.11065169423818588 ===================
epoch no : 7, batch no : 148, total loss : 0.20589351654052734,  classifier :0.0330616757273674, mask: 0.09144425392150879 ===================
epoch no : 7, batch no : 149, total loss : 0.2702750861644745,  classifier :0.0394388847053051, mask: 0.12236351519823074 ===================
epoch no : 7, batch no : 150, total loss : 0.245514377951622,  classifier :0.02524593099951744, mask: 0.1286235898733139 ===================
epoch no : 7, batch no : 151, total loss : 0.24535049498081207,  classifier :0.028041446581482887, mask: 0.09697447717189789 ===================
epoch no : 7, batch no : 152, total loss : 0.22008515894412994,  classifier :0.027674375101923943, mask: 0.10292661190032959 ===================
epoch no : 7, batch no : 153, total loss : 0.19882160425186157,  classifier :0.026581352576613426, mask: 0.09457749128341675 ===================
epoch no : 7, batch no : 154, total loss : 0.24756106734275818,  classifier :0.024014510214328766, mask: 0.11655769497156143 ===================
epoch no : 7, batch no : 155, total loss : 0.2994886338710785,  classifier :0.034824736416339874, mask: 0.12714841961860657 ===================
epoch no : 7, batch no : 156, total loss : 0.2824382185935974,  classifier :0.02808244153857231, mask: 0.1269841343164444 ===================
epoch no : 7, batch no : 157, total loss : 0.24334010481834412,  classifier :0.019739191979169846, mask: 0.11908324807882309 ===================
epoch no : 7, batch no : 158, total loss : 0.2464071661233902,  classifier :0.03710399195551872, mask: 0.12292671948671341 ===================
epoch no : 7, batch no : 159, total loss : 0.21869827806949615,  classifier :0.022423528134822845, mask: 0.11652658134698868 ===================
epoch no : 7, batch no : 160, total loss : 0.28935879468917847,  classifier :0.028035255149006844, mask: 0.10591304302215576 ===================
epoch no : 7, batch no : 161, total loss : 0.277570515871048,  classifier :0.025923511013388634, mask: 0.09297990053892136 ===================
epoch no : 7, batch no : 162, total loss : 0.3235672116279602,  classifier :0.03541773557662964, mask: 0.13668614625930786 ===================
epoch no : 7, batch no : 163, total loss : 0.24445438385009766,  classifier :0.032264500856399536, mask: 0.11393652111291885 ===================
epoch no : 7, batch no : 164, total loss : 0.2765655815601349,  classifier :0.0202131737023592, mask: 0.10756271332502365 ===================
epoch no : 7, batch no : 165, total loss : 0.23793268203735352,  classifier :0.030484553426504135, mask: 0.08263659477233887 ===================
epoch no : 7, batch no : 166, total loss : 0.28093695640563965,  classifier :0.03413807973265648, mask: 0.1262953281402588 ===================
epoch no : 7, batch no : 167, total loss : 0.32869669795036316,  classifier :0.01846403442323208, mask: 0.17081856727600098 ===================
epoch no : 7, batch no : 168, total loss : 0.24793921411037445,  classifier :0.03652968630194664, mask: 0.0934591293334961 ===================
epoch no : 7, batch no : 169, total loss : 0.2901057302951813,  classifier :0.03472433611750603, mask: 0.13476265966892242 ===================
epoch no : 7, batch no : 170, total loss : 0.25095510482788086,  classifier :0.03766421973705292, mask: 0.11096895486116409 ===================
epoch no : 7, batch no : 171, total loss : 0.2426915019750595,  classifier :0.03371409699320793, mask: 0.10916522145271301 ===================
epoch no : 7, batch no : 172, total loss : 0.21290776133537292,  classifier :0.023393427953124046, mask: 0.09341302514076233 ===================
epoch no : 7, batch no : 173, total loss : 0.24877873063087463,  classifier :0.02722543478012085, mask: 0.10721447318792343 ===================
epoch no : 7, batch no : 174, total loss : 0.29088547825813293,  classifier :0.03454103693366051, mask: 0.12158682942390442 ===================
epoch no : 7, batch no : 175, total loss : 0.3319733142852783,  classifier :0.03659100458025932, mask: 0.1451997458934784 ===================
epoch no : 7, batch no : 176, total loss : 0.2066470831632614,  classifier :0.02703855186700821, mask: 0.09815482050180435 ===================
epoch no : 7, batch no : 177, total loss : 0.2771053612232208,  classifier :0.028771355748176575, mask: 0.11907396465539932 ===================
epoch no : 7, batch no : 178, total loss : 0.224665105342865,  classifier :0.03013640269637108, mask: 0.09863309562206268 ===================
epoch no : 7, batch no : 179, total loss : 0.3165704905986786,  classifier :0.02963978424668312, mask: 0.12132346630096436 ===================
epoch no : 7, batch no : 180, total loss : 0.2457212507724762,  classifier :0.04277895763516426, mask: 0.10120615363121033 ===================
epoch no : 7, batch no : 181, total loss : 0.23860052227973938,  classifier :0.026634179055690765, mask: 0.1031644344329834 ===================
epoch no : 7, batch no : 182, total loss : 0.23945799469947815,  classifier :0.025522125884890556, mask: 0.10759520530700684 ===================
epoch no : 7, batch no : 183, total loss : 0.22336523234844208,  classifier :0.02355988696217537, mask: 0.09181375801563263 ===================
epoch no : 7, batch no : 184, total loss : 0.2217170149087906,  classifier :0.02286173216998577, mask: 0.08899977803230286 ===================
epoch no : 7, batch no : 185, total loss : 0.35203155875205994,  classifier :0.035024650394916534, mask: 0.16651488840579987 ===================
epoch no : 7, batch no : 186, total loss : 0.39037612080574036,  classifier :0.04311823844909668, mask: 0.1626693457365036 ===================
epoch no : 7, batch no : 187, total loss : 0.307079017162323,  classifier :0.043735381215810776, mask: 0.12334176898002625 ===================
epoch no : 7, batch no : 188, total loss : 0.2652163803577423,  classifier :0.02011924982070923, mask: 0.12173371016979218 ===================
epoch no : 7, batch no : 189, total loss : 0.3059388995170593,  classifier :0.03462984412908554, mask: 0.11556427925825119 ===================
epoch no : 7, batch no : 190, total loss : 0.3277081251144409,  classifier :0.0317247100174427, mask: 0.13400280475616455 ===================
epoch no : 7, batch no : 191, total loss : 0.37997162342071533,  classifier :0.0321539081633091, mask: 0.1472344696521759 ===================
epoch no : 7, batch no : 192, total loss : 0.31930094957351685,  classifier :0.03963366523385048, mask: 0.13142308592796326 ===================
epoch no : 7, batch no : 193, total loss : 0.2913126051425934,  classifier :0.027725469321012497, mask: 0.11983130127191544 ===================
epoch no : 7, batch no : 194, total loss : 0.28709420561790466,  classifier :0.030323965474963188, mask: 0.13448971509933472 ===================
epoch no : 7, batch no : 195, total loss : 0.2241184115409851,  classifier :0.02100381813943386, mask: 0.10953028500080109 ===================
epoch no : 7, batch no : 196, total loss : 0.22619302570819855,  classifier :0.025303231552243233, mask: 0.10564503818750381 ===================
epoch no : 7, batch no : 197, total loss : 0.20726504921913147,  classifier :0.026757724583148956, mask: 0.09769626706838608 ===================
epoch no : 7, batch no : 198, total loss : 0.2630003094673157,  classifier :0.03829276189208031, mask: 0.09921328723430634 ===================
epoch no : 7, batch no : 199, total loss : 0.2721121907234192,  classifier :0.035653918981552124, mask: 0.13125461339950562 ===================
epoch no : 7, batch no : 200, total loss : 0.2317899763584137,  classifier :0.021136164665222168, mask: 0.11462868005037308 ===================
epoch no : 7, batch no : 201, total loss : 0.2518746256828308,  classifier :0.040475066751241684, mask: 0.11173988878726959 ===================
epoch no : 7, batch no : 202, total loss : 0.27536541223526,  classifier :0.022889431565999985, mask: 0.12646646797657013 ===================
epoch no : 7, batch no : 203, total loss : 0.22033582627773285,  classifier :0.0317731648683548, mask: 0.08287069201469421 ===================
epoch no : 7, batch no : 204, total loss : 0.22141534090042114,  classifier :0.022469833493232727, mask: 0.09048392623662949 ===================
epoch no : 7, batch no : 205, total loss : 0.2840315103530884,  classifier :0.03590766340494156, mask: 0.11602749675512314 ===================
epoch no : 7, batch no : 206, total loss : 0.23904412984848022,  classifier :0.0453648716211319, mask: 0.107577845454216 ===================
epoch no : 7, batch no : 207, total loss : 0.18691140413284302,  classifier :0.020882783457636833, mask: 0.0928213968873024 ===================
epoch no : 7, batch no : 208, total loss : 0.40100350975990295,  classifier :0.050267294049263, mask: 0.18088924884796143 ===================
epoch no : 7, batch no : 209, total loss : 0.318228542804718,  classifier :0.03335053101181984, mask: 0.1260751634836197 ===================
epoch no : 7, batch no : 210, total loss : 0.31519195437431335,  classifier :0.041488166898489, mask: 0.14319051802158356 ===================
epoch no : 7, batch no : 211, total loss : 0.2846110761165619,  classifier :0.034931935369968414, mask: 0.12226803600788116 ===================
epoch no : 7, batch no : 212, total loss : 0.2619412839412689,  classifier :0.020032599568367004, mask: 0.10938534140586853 ===================
epoch no : 7, batch no : 213, total loss : 0.36892589926719666,  classifier :0.025367647409439087, mask: 0.1755717545747757 ===================
epoch no : 7, batch no : 214, total loss : 0.26126399636268616,  classifier :0.03227037563920021, mask: 0.09630987048149109 ===================
epoch no : 7, batch no : 215, total loss : 0.22120442986488342,  classifier :0.026541735976934433, mask: 0.08243893831968307 ===================
epoch no : 7, batch no : 216, total loss : 0.2235959768295288,  classifier :0.028017496690154076, mask: 0.07895383983850479 ===================
epoch no : 7, batch no : 217, total loss : 0.27562934160232544,  classifier :0.029348615556955338, mask: 0.10292637348175049 ===================
epoch no : 7, batch no : 218, total loss : 0.33333128690719604,  classifier :0.02796442061662674, mask: 0.14358995854854584 ===================
epoch no : 7, batch no : 219, total loss : 0.28028860688209534,  classifier :0.01901639625430107, mask: 0.10329698026180267 ===================
epoch no : 7, batch no : 220, total loss : 0.2868191599845886,  classifier :0.02755219303071499, mask: 0.12040208280086517 ===================
epoch no : 7, batch no : 221, total loss : 0.2515659034252167,  classifier :0.032576825469732285, mask: 0.10006499290466309 ===================
epoch no : 7, batch no : 222, total loss : 0.2570272982120514,  classifier :0.03418821096420288, mask: 0.11355678737163544 ===================
epoch no : 7, batch no : 223, total loss : 0.20742808282375336,  classifier :0.030861927196383476, mask: 0.10061902552843094 ===================
epoch no : 7, batch no : 224, total loss : 0.28716763854026794,  classifier :0.031233957037329674, mask: 0.12246804684400558 ===================
epoch no : 7, batch no : 225, total loss : 0.3090786635875702,  classifier :0.029318420216441154, mask: 0.13080473244190216 ===================
epoch no : 7, batch no : 226, total loss : 0.2699490487575531,  classifier :0.02688097581267357, mask: 0.14037610590457916 ===================
epoch no : 7, batch no : 227, total loss : 0.2592829167842865,  classifier :0.034130774438381195, mask: 0.12775938212871552 ===================
epoch no : 7, batch no : 228, total loss : 0.24974462389945984,  classifier :0.028865011408925056, mask: 0.11158883571624756 ===================
epoch no : 7, batch no : 229, total loss : 0.33437293767929077,  classifier :0.03189142793416977, mask: 0.17480458319187164 ===================
epoch no : 7, batch no : 230, total loss : 0.3362354636192322,  classifier :0.023221487179398537, mask: 0.14290791749954224 ===================
epoch no : 7, batch no : 231, total loss : 0.2970227301120758,  classifier :0.02821400761604309, mask: 0.12503595650196075 ===================
epoch no : 7, batch no : 232, total loss : 0.24151034653186798,  classifier :0.03532253950834274, mask: 0.0986863449215889 ===================
epoch no : 7, batch no : 233, total loss : 0.2529395520687103,  classifier :0.02859111689031124, mask: 0.13211041688919067 ===================
epoch no : 7, batch no : 234, total loss : 0.3046877682209015,  classifier :0.029514536261558533, mask: 0.15677334368228912 ===================
epoch no : 7, batch no : 235, total loss : 0.2129867970943451,  classifier :0.02928800694644451, mask: 0.10300539433956146 ===================
epoch no : 7, batch no : 236, total loss : 0.2047702670097351,  classifier :0.03279350697994232, mask: 0.08301333338022232 ===================
epoch no : 7, batch no : 237, total loss : 0.2134600579738617,  classifier :0.028543446213006973, mask: 0.11112293601036072 ===================
epoch no : 7, batch no : 238, total loss : 0.2682272493839264,  classifier :0.026954233646392822, mask: 0.10293341428041458 ===================
epoch no : 7, batch no : 239, total loss : 0.24656158685684204,  classifier :0.02706494927406311, mask: 0.0853511169552803 ===================
epoch no : 7, batch no : 240, total loss : 0.3074702024459839,  classifier :0.045121852308511734, mask: 0.14574381709098816 ===================
epoch no : 7, batch no : 241, total loss : 0.22300966084003448,  classifier :0.02442333661019802, mask: 0.1101200133562088 ===================
epoch no : 7, batch no : 242, total loss : 0.22790087759494781,  classifier :0.02830738201737404, mask: 0.09792283922433853 ===================
epoch no : 7, batch no : 243, total loss : 0.23640397191047668,  classifier :0.023831883445382118, mask: 0.08736571669578552 ===================
epoch no : 7, batch no : 244, total loss : 0.26235419511795044,  classifier :0.03388412669301033, mask: 0.10775404423475266 ===================
epoch no : 7, batch no : 245, total loss : 0.27556112408638,  classifier :0.02782384492456913, mask: 0.1277822107076645 ===================
epoch no : 7, batch no : 246, total loss : 0.34625375270843506,  classifier :0.039596278220415115, mask: 0.14029036462306976 ===================
epoch no : 7, batch no : 247, total loss : 0.4146447777748108,  classifier :0.036074765026569366, mask: 0.18594703078269958 ===================
epoch no : 7, batch no : 248, total loss : 0.3218163549900055,  classifier :0.030214529484510422, mask: 0.1401740461587906 ===================
epoch no : 7, batch no : 249, total loss : 0.3105268180370331,  classifier :0.04318847507238388, mask: 0.12885871529579163 ===================
epoch no : 7, batch no : 250, total loss : 0.29193004965782166,  classifier :0.05124747380614281, mask: 0.10873585939407349 ===================
epoch no : 7, batch no : 251, total loss : 0.22202171385288239,  classifier :0.02883639745414257, mask: 0.08659137040376663 ===================
epoch no : 7, batch no : 252, total loss : 0.28476616740226746,  classifier :0.031222769990563393, mask: 0.12694121897220612 ===================
epoch no : 7, batch no : 253, total loss : 0.29165974259376526,  classifier :0.03763863071799278, mask: 0.12429619580507278 ===================
epoch no : 7, batch no : 254, total loss : 0.20038659870624542,  classifier :0.019161738455295563, mask: 0.08595433831214905 ===================
epoch no : 7, batch no : 255, total loss : 0.21063236892223358,  classifier :0.03281385451555252, mask: 0.09689958393573761 ===================
epoch no : 7, batch no : 256, total loss : 0.2579648792743683,  classifier :0.028894692659378052, mask: 0.12077999860048294 ===================
epoch no : 7, batch no : 257, total loss : 0.3125101625919342,  classifier :0.027147648856043816, mask: 0.1424373835325241 ===================
epoch no : 7, batch no : 258, total loss : 0.21774843335151672,  classifier :0.02690783329308033, mask: 0.10397985577583313 ===================
epoch no : 7, batch no : 259, total loss : 0.2837333381175995,  classifier :0.024865882471203804, mask: 0.1025703102350235 ===================
epoch no : 7, batch no : 260, total loss : 0.33857107162475586,  classifier :0.031151792034506798, mask: 0.13694316148757935 ===================
epoch no : 7, batch no : 261, total loss : 0.25189700722694397,  classifier :0.019450940191745758, mask: 0.12940660119056702 ===================
epoch no : 7, batch no : 262, total loss : 0.23516444861888885,  classifier :0.024066317826509476, mask: 0.10337749123573303 ===================
epoch no : 7, batch no : 263, total loss : 0.23155729472637177,  classifier :0.02221873216331005, mask: 0.10036779195070267 ===================
epoch no : 7, batch no : 264, total loss : 0.24906711280345917,  classifier :0.027287283912301064, mask: 0.11978231370449066 ===================
epoch no : 7, batch no : 265, total loss : 0.29136309027671814,  classifier :0.026454420760273933, mask: 0.1311219483613968 ===================
epoch no : 7, batch no : 266, total loss : 0.24065086245536804,  classifier :0.021668551489710808, mask: 0.11034253239631653 ===================
epoch no : 7, batch no : 267, total loss : 0.26398026943206787,  classifier :0.02330745942890644, mask: 0.13995161652565002 ===================
epoch no : 7, batch no : 268, total loss : 0.21870750188827515,  classifier :0.03235834091901779, mask: 0.09577275812625885 ===================
epoch no : 7, batch no : 269, total loss : 0.27939268946647644,  classifier :0.02914089895784855, mask: 0.10519040375947952 ===================
epoch no : 7, batch no : 270, total loss : 0.24070653319358826,  classifier :0.021840279921889305, mask: 0.11312239617109299 ===================
epoch no : 7, batch no : 271, total loss : 0.1920173466205597,  classifier :0.01946987956762314, mask: 0.09057699143886566 ===================
epoch no : 7, batch no : 272, total loss : 0.2540322542190552,  classifier :0.024706315249204636, mask: 0.12690214812755585 ===================
epoch no : 7, batch no : 273, total loss : 0.32134944200515747,  classifier :0.03070727363228798, mask: 0.1622447967529297 ===================
epoch no : 7, batch no : 274, total loss : 0.26929858326911926,  classifier :0.02678504027426243, mask: 0.11230029910802841 ===================
epoch no : 7, batch no : 275, total loss : 0.2926512360572815,  classifier :0.02410515584051609, mask: 0.14267030358314514 ===================
epoch no : 7, batch no : 276, total loss : 0.3209846615791321,  classifier :0.03401337191462517, mask: 0.14250992238521576 ===================
epoch no : 7, batch no : 277, total loss : 0.21922147274017334,  classifier :0.022407976910471916, mask: 0.09775743633508682 ===================
epoch no : 7, batch no : 278, total loss : 0.23236291110515594,  classifier :0.029025454074144363, mask: 0.1149510070681572 ===================
epoch no : 7, batch no : 279, total loss : 0.23427091538906097,  classifier :0.02818448282778263, mask: 0.10560498386621475 ===================
epoch no : 7, batch no : 280, total loss : 0.2443828582763672,  classifier :0.04939991235733032, mask: 0.08809532970190048 ===================
epoch no : 7, batch no : 281, total loss : 0.3766319751739502,  classifier :0.04667467251420021, mask: 0.16344702243804932 ===================
epoch no : 7, batch no : 282, total loss : 0.23567070066928864,  classifier :0.0203944593667984, mask: 0.1172560602426529 ===================
epoch no : 7, batch no : 283, total loss : 0.24486799538135529,  classifier :0.021791167557239532, mask: 0.11112232506275177 ===================
epoch no : 7, batch no : 284, total loss : 0.2962070107460022,  classifier :0.02959565445780754, mask: 0.12874393165111542 ===================
epoch no : 7, batch no : 285, total loss : 0.193388894200325,  classifier :0.02133486419916153, mask: 0.08933448791503906 ===================
epoch no : 7, batch no : 286, total loss : 0.24779266119003296,  classifier :0.029202992096543312, mask: 0.09998291730880737 ===================
epoch no : 7, batch no : 287, total loss : 0.22994364798069,  classifier :0.025443455204367638, mask: 0.08480897545814514 ===================
epoch no : 7, batch no : 288, total loss : 0.2485518753528595,  classifier :0.032767392694950104, mask: 0.10126317292451859 ===================
epoch no : 7, batch no : 289, total loss : 0.313631147146225,  classifier :0.01763777807354927, mask: 0.19037333130836487 ===================
epoch no : 7, batch no : 290, total loss : 0.34360507130622864,  classifier :0.03827118128538132, mask: 0.15882733464241028 ===================
epoch no : 7, batch no : 291, total loss : 0.21686312556266785,  classifier :0.02985185943543911, mask: 0.11049768328666687 ===================
epoch no : 7, batch no : 292, total loss : 0.3050302267074585,  classifier :0.031232072040438652, mask: 0.12739312648773193 ===================
epoch no : 7, batch no : 293, total loss : 0.4449484050273895,  classifier :0.035511136054992676, mask: 0.17593218386173248 ===================
epoch no : 7, batch no : 294, total loss : 0.2811165750026703,  classifier :0.020398974418640137, mask: 0.12843456864356995 ===================
epoch no : 7, batch no : 295, total loss : 0.2803707718849182,  classifier :0.026350149884819984, mask: 0.13484446704387665 ===================
epoch no : 7, batch no : 296, total loss : 0.24810199439525604,  classifier :0.030326994135975838, mask: 0.10810933262109756 ===================
epoch no : 7, batch no : 297, total loss : 0.306001752614975,  classifier :0.028910044580698013, mask: 0.1055217757821083 ===================
epoch no : 7, batch no : 298, total loss : 0.2520424425601959,  classifier :0.026905866339802742, mask: 0.10836508125066757 ===================
epoch no : 7, batch no : 299, total loss : 0.2397274523973465,  classifier :0.030635494738817215, mask: 0.11119310557842255 ===================
epoch no : 7, batch no : 300, total loss : 0.2318045198917389,  classifier :0.019747549667954445, mask: 0.1155303418636322 ===================
epoch no : 7, batch no : 301, total loss : 0.183968648314476,  classifier :0.026108745485544205, mask: 0.08633175492286682 ===================
epoch no : 7, batch no : 302, total loss : 0.29876062273979187,  classifier :0.026078276336193085, mask: 0.13370202481746674 ===================
epoch no : 7, batch no : 303, total loss : 0.2703661024570465,  classifier :0.03972798213362694, mask: 0.10133659094572067 ===================
epoch no : 7, batch no : 304, total loss : 0.2419854700565338,  classifier :0.02561277337372303, mask: 0.0878308042883873 ===================
epoch no : 7, batch no : 305, total loss : 0.25313469767570496,  classifier :0.029325587674975395, mask: 0.11215389519929886 ===================
epoch no : 7, batch no : 306, total loss : 0.2321949303150177,  classifier :0.01876119151711464, mask: 0.11754094809293747 ===================
epoch no : 7, batch no : 307, total loss : 0.2760806381702423,  classifier :0.0342571847140789, mask: 0.13837678730487823 ===================
epoch no : 7, batch no : 308, total loss : 0.2688174247741699,  classifier :0.03220087289810181, mask: 0.09524014592170715 ===================
epoch no : 7, batch no : 309, total loss : 0.26609793305397034,  classifier :0.02862956002354622, mask: 0.12294741719961166 ===================
epoch no : 7, batch no : 310, total loss : 0.26351290941238403,  classifier :0.029679303988814354, mask: 0.12352097034454346 ===================
epoch no : 7, batch no : 311, total loss : 0.272859662771225,  classifier :0.02971404232084751, mask: 0.10571081191301346 ===================
epoch no : 7, batch no : 312, total loss : 0.3457871377468109,  classifier :0.025515269488096237, mask: 0.1238505020737648 ===================
epoch no : 7, batch no : 313, total loss : 0.29644542932510376,  classifier :0.03292560204863548, mask: 0.1279093474149704 ===================
epoch no : 7, batch no : 314, total loss : 0.24443931877613068,  classifier :0.029401876032352448, mask: 0.1071227565407753 ===================
epoch no : 7, batch no : 315, total loss : 0.26644185185432434,  classifier :0.02982073649764061, mask: 0.1117360070347786 ===================
epoch no : 7, batch no : 316, total loss : 0.24648019671440125,  classifier :0.023029673844575882, mask: 0.10327744483947754 ===================
epoch no : 7, batch no : 317, total loss : 0.26781004667282104,  classifier :0.02771255001425743, mask: 0.1303918957710266 ===================
epoch no : 7, batch no : 318, total loss : 0.27041301131248474,  classifier :0.020198741927742958, mask: 0.11386426538228989 ===================
epoch no : 7, batch no : 319, total loss : 0.3140046000480652,  classifier :0.028344782069325447, mask: 0.11500300467014313 ===================
epoch no : 7, batch no : 320, total loss : 0.2951422929763794,  classifier :0.02528340369462967, mask: 0.15807035565376282 ===================
epoch no : 7, batch no : 321, total loss : 0.2684233486652374,  classifier :0.026646899059414864, mask: 0.11131936311721802 ===================
epoch no : 7, batch no : 322, total loss : 0.25699689984321594,  classifier :0.03148043155670166, mask: 0.11293142288923264 ===================
epoch no : 7, batch no : 323, total loss : 0.22471889853477478,  classifier :0.029176870360970497, mask: 0.09403320401906967 ===================
epoch no : 7, batch no : 324, total loss : 0.32310551404953003,  classifier :0.029908331111073494, mask: 0.15108823776245117 ===================
epoch no : 7, batch no : 325, total loss : 0.24883770942687988,  classifier :0.02150178700685501, mask: 0.14829133450984955 ===================
epoch no : 7, batch no : 326, total loss : 0.28272396326065063,  classifier :0.03439391031861305, mask: 0.12906068563461304 ===================
epoch no : 7, batch no : 327, total loss : 0.28173545002937317,  classifier :0.036324210464954376, mask: 0.13567663729190826 ===================
epoch no : 7, batch no : 328, total loss : 0.2831672430038452,  classifier :0.031165840104222298, mask: 0.12604312598705292 ===================
epoch no : 7, batch no : 329, total loss : 0.42559024691581726,  classifier :0.05923909693956375, mask: 0.14677897095680237 ===================
epoch no : 7, batch no : 330, total loss : 0.3895190358161926,  classifier :0.047961849719285965, mask: 0.13739337027072906 ===================
epoch no : 7, batch no : 331, total loss : 0.26313215494155884,  classifier :0.03584974631667137, mask: 0.11382484436035156 ===================
epoch no : 7, batch no : 332, total loss : 0.23565109074115753,  classifier :0.024832168594002724, mask: 0.09103111922740936 ===================
epoch no : 7, batch no : 333, total loss : 0.30806198716163635,  classifier :0.035310111939907074, mask: 0.12508845329284668 ===================
epoch no : 7, batch no : 334, total loss : 0.2129611372947693,  classifier :0.027092337608337402, mask: 0.09755054861307144 ===================
epoch no : 7, batch no : 335, total loss : 0.32376471161842346,  classifier :0.03190527483820915, mask: 0.123253233730793 ===================
epoch no : 7, batch no : 336, total loss : 0.2273777425289154,  classifier :0.02305055409669876, mask: 0.09289808571338654 ===================
epoch no : 7, batch no : 337, total loss : 0.2680373191833496,  classifier :0.03351440280675888, mask: 0.09524212032556534 ===================
epoch no : 7, batch no : 338, total loss : 0.2569691836833954,  classifier :0.02539568953216076, mask: 0.0965178906917572 ===================
epoch no : 7, batch no : 339, total loss : 0.2846258580684662,  classifier :0.03035011701285839, mask: 0.11140061169862747 ===================
epoch no : 7, batch no : 340, total loss : 0.2736072540283203,  classifier :0.03816404193639755, mask: 0.12592197954654694 ===================
epoch no : 7, batch no : 341, total loss : 0.2647421658039093,  classifier :0.028600847348570824, mask: 0.1072990894317627 ===================
epoch no : 7, batch no : 342, total loss : 0.302883505821228,  classifier :0.021659592166543007, mask: 0.12601888179779053 ===================
epoch no : 7, batch no : 343, total loss : 0.27039822936058044,  classifier :0.03968959301710129, mask: 0.09664567559957504 ===================
epoch no : 7, batch no : 344, total loss : 0.29366958141326904,  classifier :0.034705474972724915, mask: 0.12747083604335785 ===================
epoch no : 7, batch no : 345, total loss : 0.22368071973323822,  classifier :0.032300665974617004, mask: 0.0912204161286354 ===================
epoch no : 7, batch no : 346, total loss : 0.31887564063072205,  classifier :0.04190129041671753, mask: 0.11919347941875458 ===================
epoch no : 7, batch no : 347, total loss : 0.24286800622940063,  classifier :0.03175189346075058, mask: 0.11293374747037888 ===================
epoch no : 7, batch no : 348, total loss : 0.23622964322566986,  classifier :0.03304566815495491, mask: 0.09787174314260483 ===================
epoch no : 7, batch no : 349, total loss : 0.38344594836235046,  classifier :0.050053421407938004, mask: 0.1718994379043579 ===================
epoch no : 7, batch no : 350, total loss : 0.23492302000522614,  classifier :0.026358885690569878, mask: 0.09125545620918274 ===================
epoch no : 7, batch no : 351, total loss : 0.27883732318878174,  classifier :0.03247963637113571, mask: 0.0920766219496727 ===================
epoch no : 7, batch no : 352, total loss : 0.3093573749065399,  classifier :0.023600494489073753, mask: 0.12254132330417633 ===================
epoch no : 7, batch no : 353, total loss : 0.2564051151275635,  classifier :0.02783803641796112, mask: 0.10351014137268066 ===================
epoch no : 7, batch no : 354, total loss : 0.17752967774868011,  classifier :0.023309051990509033, mask: 0.07632298022508621 ===================
epoch no : 7, batch no : 355, total loss : 0.2600630819797516,  classifier :0.043343883007764816, mask: 0.10563286393880844 ===================
epoch no : 7, batch no : 356, total loss : 0.25957396626472473,  classifier :0.037009112536907196, mask: 0.11476489156484604 ===================
epoch no : 7, batch no : 357, total loss : 0.2285040318965912,  classifier :0.022310491651296616, mask: 0.1090291291475296 ===================
epoch no : 7, batch no : 358, total loss : 0.262626975774765,  classifier :0.024532733485102654, mask: 0.11091311275959015 ===================
epoch no : 7, batch no : 359, total loss : 0.25084593892097473,  classifier :0.029569240286946297, mask: 0.10533300042152405 ===================
epoch no : 7, batch no : 360, total loss : 0.2296561449766159,  classifier :0.023531610146164894, mask: 0.09713888168334961 ===================
epoch no : 7, batch no : 361, total loss : 0.2987297773361206,  classifier :0.03972463682293892, mask: 0.14226371049880981 ===================
epoch no : 7, batch no : 362, total loss : 0.250284343957901,  classifier :0.03219755366444588, mask: 0.14517690241336823 ===================
epoch no : 7, batch no : 363, total loss : 0.3061304986476898,  classifier :0.032777491956949234, mask: 0.15241388976573944 ===================
epoch no : 7, batch no : 364, total loss : 0.2052229344844818,  classifier :0.021813640370965004, mask: 0.0933283120393753 ===================
epoch no : 7, batch no : 365, total loss : 0.23661856353282928,  classifier :0.026266764849424362, mask: 0.10683707147836685 ===================
epoch no : 7, batch no : 366, total loss : 0.24579653143882751,  classifier :0.02872243896126747, mask: 0.11886720359325409 ===================
epoch no : 7, batch no : 367, total loss : 0.24390091001987457,  classifier :0.02370203100144863, mask: 0.10876275599002838 ===================
epoch no : 7, batch no : 368, total loss : 0.21269714832305908,  classifier :0.025669485330581665, mask: 0.09922965615987778 ===================
epoch no : 7, batch no : 369, total loss : 0.2897065281867981,  classifier :0.026454143226146698, mask: 0.1286717802286148 ===================
epoch no : 7, batch no : 370, total loss : 0.30967190861701965,  classifier :0.024023354053497314, mask: 0.11389675736427307 ===================
epoch no : 7, batch no : 371, total loss : 0.2991101145744324,  classifier :0.02903713844716549, mask: 0.12720976769924164 ===================
epoch no : 7, batch no : 372, total loss : 0.288629412651062,  classifier :0.0290986318141222, mask: 0.108945332467556 ===================
epoch no : 7, batch no : 373, total loss : 0.2726196050643921,  classifier :0.038947027176618576, mask: 0.11948571354150772 ===================
epoch no : 7, batch no : 374, total loss : 0.2278621345758438,  classifier :0.023384328931570053, mask: 0.09756501019001007 ===================
epoch no : 7, batch no : 375, total loss : 0.2136918008327484,  classifier :0.027105558663606644, mask: 0.08001262694597244 ===================
epoch no : 7, batch no : 376, total loss : 0.2140824794769287,  classifier :0.024953672662377357, mask: 0.09809189289808273 ===================
epoch no : 7, batch no : 377, total loss : 0.25185224413871765,  classifier :0.01869318261742592, mask: 0.09821278601884842 ===================
epoch no : 7, batch no : 378, total loss : 0.2574641704559326,  classifier :0.022648973390460014, mask: 0.11505760252475739 ===================
epoch no : 7, batch no : 379, total loss : 0.20768320560455322,  classifier :0.02248508669435978, mask: 0.09110033512115479 ===================
epoch no : 7, batch no : 380, total loss : 0.22109359502792358,  classifier :0.02435993030667305, mask: 0.12427978217601776 ===================
epoch no : 7, batch no : 381, total loss : 0.28511056303977966,  classifier :0.04221230372786522, mask: 0.0972791537642479 ===================
epoch no : 7, batch no : 382, total loss : 0.21760909259319305,  classifier :0.025862397626042366, mask: 0.08457940816879272 ===================
epoch no : 7, batch no : 383, total loss : 0.2535184323787689,  classifier :0.02741686813533306, mask: 0.10320563614368439 ===================
epoch no : 7, batch no : 384, total loss : 0.22605787217617035,  classifier :0.02344224788248539, mask: 0.10249274969100952 ===================
epoch no : 7, batch no : 385, total loss : 0.23413579165935516,  classifier :0.026913270354270935, mask: 0.1158524826169014 ===================
epoch no : 7, batch no : 386, total loss : 0.3041203022003174,  classifier :0.026721980422735214, mask: 0.15609592199325562 ===================
epoch no : 7, batch no : 387, total loss : 0.3013836443424225,  classifier :0.02892901748418808, mask: 0.13708922266960144 ===================
epoch no : 7, batch no : 388, total loss : 0.2843877673149109,  classifier :0.02325846627354622, mask: 0.10563470423221588 ===================
epoch no : 7, batch no : 389, total loss : 0.22926358878612518,  classifier :0.024518370628356934, mask: 0.09963759034872055 ===================
epoch no : 7, batch no : 390, total loss : 0.2680676579475403,  classifier :0.02643098495900631, mask: 0.14242154359817505 ===================
epoch no : 7, batch no : 391, total loss : 0.19070610404014587,  classifier :0.020196085795760155, mask: 0.0966920405626297 ===================
epoch no : 7, batch no : 392, total loss : 0.27687183022499084,  classifier :0.038937296718358994, mask: 0.1254415661096573 ===================
epoch no : 7, batch no : 393, total loss : 0.25517696142196655,  classifier :0.03393056243658066, mask: 0.12212012708187103 ===================
epoch no : 7, batch no : 394, total loss : 0.27063876390457153,  classifier :0.033211518079042435, mask: 0.11413168162107468 ===================
epoch no : 7, batch no : 395, total loss : 0.23559805750846863,  classifier :0.027179792523384094, mask: 0.10793661326169968 ===================
epoch no : 7, batch no : 396, total loss : 0.2620943486690521,  classifier :0.02716858685016632, mask: 0.1215764507651329 ===================
epoch no : 7, batch no : 397, total loss : 0.2482706606388092,  classifier :0.037808191031217575, mask: 0.13091574609279633 ===================
epoch no : 7, batch no : 398, total loss : 0.22065845131874084,  classifier :0.038891904056072235, mask: 0.09754359722137451 ===================
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch no : 8, batch no : 0, total loss : 0.25193488597869873,  classifier :0.028045233339071274, mask: 0.11656966060400009 ===================
epoch no : 8, batch no : 1, total loss : 0.25794315338134766,  classifier :0.03485378250479698, mask: 0.10737864673137665 ===================
epoch no : 8, batch no : 2, total loss : 0.22238412499427795,  classifier :0.026200320571660995, mask: 0.08449020981788635 ===================
epoch no : 8, batch no : 3, total loss : 0.19208014011383057,  classifier :0.02509578876197338, mask: 0.07980967313051224 ===================
epoch no : 8, batch no : 4, total loss : 0.22232314944267273,  classifier :0.031191334128379822, mask: 0.10137002170085907 ===================
epoch no : 8, batch no : 5, total loss : 0.2228880077600479,  classifier :0.03353692218661308, mask: 0.08736709505319595 ===================
epoch no : 8, batch no : 6, total loss : 0.2769915759563446,  classifier :0.03302231803536415, mask: 0.12826301157474518 ===================
epoch no : 8, batch no : 7, total loss : 0.2896648645401001,  classifier :0.025090446695685387, mask: 0.122672900557518 ===================
epoch no : 8, batch no : 8, total loss : 0.24302613735198975,  classifier :0.02252918668091297, mask: 0.09316617995500565 ===================
epoch no : 8, batch no : 9, total loss : 0.2131619155406952,  classifier :0.02891487441956997, mask: 0.08196063339710236 ===================
epoch no : 8, batch no : 10, total loss : 0.2106582522392273,  classifier :0.02341340482234955, mask: 0.09924968332052231 ===================
epoch no : 8, batch no : 11, total loss : 0.26924484968185425,  classifier :0.026903849095106125, mask: 0.1387074887752533 ===================
epoch no : 8, batch no : 12, total loss : 0.2369181364774704,  classifier :0.023105783388018608, mask: 0.11400620639324188 ===================
epoch no : 8, batch no : 13, total loss : 0.23229378461837769,  classifier :0.023068632930517197, mask: 0.09019934386014938 ===================
epoch no : 8, batch no : 14, total loss : 0.2459251433610916,  classifier :0.03483501821756363, mask: 0.10378796607255936 ===================
epoch no : 8, batch no : 15, total loss : 0.2271879017353058,  classifier :0.022874286398291588, mask: 0.08834970742464066 ===================
epoch no : 8, batch no : 16, total loss : 0.23722651600837708,  classifier :0.024390634149312973, mask: 0.09232525527477264 ===================
epoch no : 8, batch no : 17, total loss : 0.3037492334842682,  classifier :0.03619491681456566, mask: 0.10624197125434875 ===================
epoch no : 8, batch no : 18, total loss : 0.34700119495391846,  classifier :0.03557538986206055, mask: 0.1585613638162613 ===================
epoch no : 8, batch no : 19, total loss : 0.29810070991516113,  classifier :0.026458323001861572, mask: 0.13075675070285797 ===================
epoch no : 8, batch no : 20, total loss : 0.3036525547504425,  classifier :0.032669976353645325, mask: 0.1442386358976364 ===================
epoch no : 8, batch no : 21, total loss : 0.24226325750350952,  classifier :0.030811969190835953, mask: 0.11295074969530106 ===================
epoch no : 8, batch no : 22, total loss : 0.2719959318637848,  classifier :0.023111628368496895, mask: 0.14595858752727509 ===================
epoch no : 8, batch no : 23, total loss : 0.2393578141927719,  classifier :0.02158619835972786, mask: 0.09108507633209229 ===================
epoch no : 8, batch no : 24, total loss : 0.23122037947177887,  classifier :0.028335783630609512, mask: 0.09072273224592209 ===================
epoch no : 8, batch no : 25, total loss : 0.25584185123443604,  classifier :0.02977954037487507, mask: 0.11652915179729462 ===================
epoch no : 8, batch no : 26, total loss : 0.30656898021698,  classifier :0.04615311697125435, mask: 0.14456807076931 ===================
epoch no : 8, batch no : 27, total loss : 0.24717484414577484,  classifier :0.024395430460572243, mask: 0.12405333667993546 ===================
epoch no : 8, batch no : 28, total loss : 0.18686214089393616,  classifier :0.02447906695306301, mask: 0.10405570268630981 ===================
epoch no : 8, batch no : 29, total loss : 0.18009045720100403,  classifier :0.02407146617770195, mask: 0.08800093084573746 ===================
epoch no : 8, batch no : 30, total loss : 0.33978015184402466,  classifier :0.057187315076589584, mask: 0.13811476528644562 ===================
epoch no : 8, batch no : 31, total loss : 0.20366522669792175,  classifier :0.028960615396499634, mask: 0.0949728786945343 ===================
epoch no : 8, batch no : 32, total loss : 0.22260531783103943,  classifier :0.02494201250374317, mask: 0.09631267935037613 ===================
epoch no : 8, batch no : 33, total loss : 0.23816733062267303,  classifier :0.025451337918639183, mask: 0.11325664818286896 ===================
epoch no : 8, batch no : 34, total loss : 0.18543478846549988,  classifier :0.019439589232206345, mask: 0.0917600616812706 ===================
epoch no : 8, batch no : 35, total loss : 0.2869984209537506,  classifier :0.04505297914147377, mask: 0.10284372419118881 ===================
epoch no : 8, batch no : 36, total loss : 0.27126961946487427,  classifier :0.0265532024204731, mask: 0.11766024678945541 ===================
epoch no : 8, batch no : 37, total loss : 0.2366068810224533,  classifier :0.022709107026457787, mask: 0.09418436139822006 ===================
epoch no : 8, batch no : 38, total loss : 0.23393630981445312,  classifier :0.021155428141355515, mask: 0.11613192409276962 ===================
epoch no : 8, batch no : 39, total loss : 0.30253690481185913,  classifier :0.03601491451263428, mask: 0.10237491875886917 ===================
epoch no : 8, batch no : 40, total loss : 0.3175055682659149,  classifier :0.029687318950891495, mask: 0.12288457155227661 ===================
epoch no : 8, batch no : 41, total loss : 0.36025261878967285,  classifier :0.03193565085530281, mask: 0.12045640498399734 ===================
epoch no : 8, batch no : 42, total loss : 0.3224128484725952,  classifier :0.023714853450655937, mask: 0.13006018102169037 ===================
epoch no : 8, batch no : 43, total loss : 0.27224746346473694,  classifier :0.02352842688560486, mask: 0.10942643880844116 ===================
epoch no : 8, batch no : 44, total loss : 0.2127329260110855,  classifier :0.023261595517396927, mask: 0.08873233944177628 ===================
epoch no : 8, batch no : 45, total loss : 0.25652530789375305,  classifier :0.024310102686285973, mask: 0.11589103192090988 ===================
epoch no : 8, batch no : 46, total loss : 0.17469465732574463,  classifier :0.025162480771541595, mask: 0.08744794130325317 ===================
epoch no : 8, batch no : 47, total loss : 0.25004395842552185,  classifier :0.028840167447924614, mask: 0.11427866667509079 ===================
epoch no : 8, batch no : 48, total loss : 0.2675435543060303,  classifier :0.029509248211979866, mask: 0.11523927748203278 ===================
epoch no : 8, batch no : 49, total loss : 0.21940049529075623,  classifier :0.021962735801935196, mask: 0.10008715093135834 ===================
epoch no : 8, batch no : 50, total loss : 0.3124804198741913,  classifier :0.03669464588165283, mask: 0.13941481709480286 ===================
epoch no : 8, batch no : 51, total loss : 0.2683565318584442,  classifier :0.023066341876983643, mask: 0.12923920154571533 ===================
epoch no : 8, batch no : 52, total loss : 0.23312200605869293,  classifier :0.024538280442357063, mask: 0.1048518642783165 ===================
epoch no : 8, batch no : 53, total loss : 0.2258608043193817,  classifier :0.02569202147424221, mask: 0.10795392096042633 ===================
epoch no : 8, batch no : 54, total loss : 0.22585409879684448,  classifier :0.02502894029021263, mask: 0.11423621326684952 ===================
epoch no : 8, batch no : 55, total loss : 0.26167938113212585,  classifier :0.022513501346111298, mask: 0.13960722088813782 ===================
epoch no : 8, batch no : 56, total loss : 0.24552983045578003,  classifier :0.023300563916563988, mask: 0.12706542015075684 ===================
epoch no : 8, batch no : 57, total loss : 0.24421849846839905,  classifier :0.02930317260324955, mask: 0.12385095655918121 ===================
epoch no : 8, batch no : 58, total loss : 0.22216592729091644,  classifier :0.024928707629442215, mask: 0.09786295145750046 ===================
epoch no : 8, batch no : 59, total loss : 0.31964126229286194,  classifier :0.025084491819143295, mask: 0.12775878608226776 ===================
epoch no : 8, batch no : 60, total loss : 0.22911809384822845,  classifier :0.026522211730480194, mask: 0.08950689435005188 ===================
epoch no : 8, batch no : 61, total loss : 0.3166399598121643,  classifier :0.03745318204164505, mask: 0.15078623592853546 ===================
epoch no : 8, batch no : 62, total loss : 0.2445583939552307,  classifier :0.02119830995798111, mask: 0.09811554849147797 ===================
epoch no : 8, batch no : 63, total loss : 0.2658345699310303,  classifier :0.026686016470193863, mask: 0.11469652503728867 ===================
epoch no : 8, batch no : 64, total loss : 0.2980412244796753,  classifier :0.021073339506983757, mask: 0.15278957784175873 ===================
epoch no : 8, batch no : 65, total loss : 0.2349800318479538,  classifier :0.01705509051680565, mask: 0.1030784621834755 ===================
epoch no : 8, batch no : 66, total loss : 0.23916621506214142,  classifier :0.029862668365240097, mask: 0.10092969983816147 ===================
epoch no : 8, batch no : 67, total loss : 0.23588860034942627,  classifier :0.02357766032218933, mask: 0.11915761232376099 ===================
epoch no : 8, batch no : 68, total loss : 0.24163828790187836,  classifier :0.030085455626249313, mask: 0.10313467681407928 ===================
epoch no : 8, batch no : 69, total loss : 0.25862517952919006,  classifier :0.02545998990535736, mask: 0.1383383423089981 ===================
epoch no : 8, batch no : 70, total loss : 0.23007293045520782,  classifier :0.01806037873029709, mask: 0.10816995054483414 ===================
epoch no : 8, batch no : 71, total loss : 0.28189095854759216,  classifier :0.03261779248714447, mask: 0.1268763244152069 ===================
epoch no : 8, batch no : 72, total loss : 0.2203197479248047,  classifier :0.02468954585492611, mask: 0.0915372297167778 ===================
epoch no : 8, batch no : 73, total loss : 0.17236539721488953,  classifier :0.022399580106139183, mask: 0.09002538025379181 ===================
epoch no : 8, batch no : 74, total loss : 0.2636629641056061,  classifier :0.032016124576330185, mask: 0.10667537152767181 ===================
epoch no : 8, batch no : 75, total loss : 0.2671021819114685,  classifier :0.026156866922974586, mask: 0.12020314484834671 ===================
epoch no : 8, batch no : 76, total loss : 0.3054186999797821,  classifier :0.023897698149085045, mask: 0.15993686020374298 ===================
epoch no : 8, batch no : 77, total loss : 0.27020734548568726,  classifier :0.031156843528151512, mask: 0.12460016459226608 ===================
epoch no : 8, batch no : 78, total loss : 0.24212324619293213,  classifier :0.02260301448404789, mask: 0.12083697319030762 ===================
epoch no : 8, batch no : 79, total loss : 0.20610451698303223,  classifier :0.026207812130451202, mask: 0.085328109562397 ===================
epoch no : 8, batch no : 80, total loss : 0.217624232172966,  classifier :0.028799133375287056, mask: 0.09908262640237808 ===================
epoch no : 8, batch no : 81, total loss : 0.253438264131546,  classifier :0.023770473897457123, mask: 0.1089177057147026 ===================
epoch no : 8, batch no : 82, total loss : 0.2747360169887543,  classifier :0.022077452391386032, mask: 0.10508215427398682 ===================
epoch no : 8, batch no : 83, total loss : 0.22840070724487305,  classifier :0.027471181005239487, mask: 0.09361299872398376 ===================
epoch no : 8, batch no : 84, total loss : 0.29528510570526123,  classifier :0.034137483686208725, mask: 0.14051131904125214 ===================
epoch no : 8, batch no : 85, total loss : 0.34543201327323914,  classifier :0.04436618834733963, mask: 0.15954020619392395 ===================
epoch no : 8, batch no : 86, total loss : 0.22866670787334442,  classifier :0.022792289033532143, mask: 0.11469727754592896 ===================
epoch no : 8, batch no : 87, total loss : 0.27299731969833374,  classifier :0.029335951432585716, mask: 0.11406303942203522 ===================
epoch no : 8, batch no : 88, total loss : 0.22992704808712006,  classifier :0.047100041061639786, mask: 0.09539058804512024 ===================
epoch no : 8, batch no : 89, total loss : 0.2333177626132965,  classifier :0.021949684247374535, mask: 0.10968261957168579 ===================
epoch no : 8, batch no : 90, total loss : 0.241094172000885,  classifier :0.04065941274166107, mask: 0.09893026947975159 ===================
epoch no : 8, batch no : 91, total loss : 0.22937121987342834,  classifier :0.019938066601753235, mask: 0.1114397644996643 ===================
epoch no : 8, batch no : 92, total loss : 0.19518262147903442,  classifier :0.02187446877360344, mask: 0.09892939031124115 ===================
epoch no : 8, batch no : 93, total loss : 0.20924751460552216,  classifier :0.018580514937639236, mask: 0.10012788325548172 ===================
epoch no : 8, batch no : 94, total loss : 0.24206852912902832,  classifier :0.018788104876875877, mask: 0.11556229740381241 ===================
epoch no : 8, batch no : 95, total loss : 0.2472538948059082,  classifier :0.025604622438549995, mask: 0.11124007403850555 ===================
epoch no : 8, batch no : 96, total loss : 0.20111937820911407,  classifier :0.027244748547673225, mask: 0.09330911934375763 ===================
epoch no : 8, batch no : 97, total loss : 0.25299957394599915,  classifier :0.02937375381588936, mask: 0.12319792062044144 ===================
epoch no : 8, batch no : 98, total loss : 0.2509170472621918,  classifier :0.03150901943445206, mask: 0.11904866993427277 ===================
epoch no : 8, batch no : 99, total loss : 0.24564948678016663,  classifier :0.032082002609968185, mask: 0.1109728142619133 ===================
epoch no : 8, batch no : 100, total loss : 0.29578766226768494,  classifier :0.036989081650972366, mask: 0.11569108068943024 ===================
epoch no : 8, batch no : 101, total loss : 0.21730688214302063,  classifier :0.024429192766547203, mask: 0.0941394492983818 ===================
epoch no : 8, batch no : 102, total loss : 0.35783809423446655,  classifier :0.03452208265662193, mask: 0.15815334022045135 ===================
epoch no : 8, batch no : 103, total loss : 0.281053751707077,  classifier :0.02423902601003647, mask: 0.13333895802497864 ===================
epoch no : 8, batch no : 104, total loss : 0.19927778840065002,  classifier :0.02658635750412941, mask: 0.09197124093770981 ===================
epoch no : 8, batch no : 105, total loss : 0.25727614760398865,  classifier :0.04163578525185585, mask: 0.10871631652116776 ===================
epoch no : 8, batch no : 106, total loss : 0.22209712862968445,  classifier :0.029475871473550797, mask: 0.10545614361763 ===================
epoch no : 8, batch no : 107, total loss : 0.30546388030052185,  classifier :0.04227733612060547, mask: 0.12147320806980133 ===================
epoch no : 8, batch no : 108, total loss : 0.19186027348041534,  classifier :0.021028859540820122, mask: 0.08993817865848541 ===================
epoch no : 8, batch no : 109, total loss : 0.2883824110031128,  classifier :0.025580136105418205, mask: 0.11454757302999496 ===================
epoch no : 8, batch no : 110, total loss : 0.25955912470817566,  classifier :0.02780316025018692, mask: 0.10835430771112442 ===================
epoch no : 8, batch no : 111, total loss : 0.27646076679229736,  classifier :0.02337542176246643, mask: 0.13942037522792816 ===================
epoch no : 8, batch no : 112, total loss : 0.21810469031333923,  classifier :0.026537522673606873, mask: 0.08501053601503372 ===================
epoch no : 8, batch no : 113, total loss : 0.22627940773963928,  classifier :0.01628999412059784, mask: 0.10191866755485535 ===================
epoch no : 8, batch no : 114, total loss : 0.2910248935222626,  classifier :0.03591952845454216, mask: 0.12942560017108917 ===================
epoch no : 8, batch no : 115, total loss : 0.3348551094532013,  classifier :0.0265754833817482, mask: 0.15959228575229645 ===================
epoch no : 8, batch no : 116, total loss : 0.22779306769371033,  classifier :0.022582730278372765, mask: 0.12160909175872803 ===================
epoch no : 8, batch no : 117, total loss : 0.3251866400241852,  classifier :0.03285030648112297, mask: 0.14700908958911896 ===================
epoch no : 8, batch no : 118, total loss : 0.24368548393249512,  classifier :0.019675031304359436, mask: 0.10879086703062057 ===================
epoch no : 8, batch no : 119, total loss : 0.27112922072410583,  classifier :0.029178528115153313, mask: 0.1226838007569313 ===================
epoch no : 8, batch no : 120, total loss : 0.30284181237220764,  classifier :0.028578156605362892, mask: 0.13104026019573212 ===================
epoch no : 8, batch no : 121, total loss : 0.28900277614593506,  classifier :0.023813802748918533, mask: 0.140610009431839 ===================
epoch no : 8, batch no : 122, total loss : 0.2611577808856964,  classifier :0.028573207557201385, mask: 0.11581750214099884 ===================
epoch no : 8, batch no : 123, total loss : 0.22873006761074066,  classifier :0.019320137798786163, mask: 0.10515747219324112 ===================
epoch no : 8, batch no : 124, total loss : 0.24004824459552765,  classifier :0.024937545880675316, mask: 0.09911268204450607 ===================
epoch no : 8, batch no : 125, total loss : 0.22012552618980408,  classifier :0.025915317237377167, mask: 0.0934591144323349 ===================
epoch no : 8, batch no : 126, total loss : 0.257931113243103,  classifier :0.030903451144695282, mask: 0.1270933598279953 ===================
epoch no : 8, batch no : 127, total loss : 0.27964338660240173,  classifier :0.02608017437160015, mask: 0.12804386019706726 ===================
epoch no : 8, batch no : 128, total loss : 0.17395149171352386,  classifier :0.024705220013856888, mask: 0.07640760391950607 ===================
epoch no : 8, batch no : 129, total loss : 0.2622331380844116,  classifier :0.02654786966741085, mask: 0.10291276127099991 ===================
epoch no : 8, batch no : 130, total loss : 0.32672786712646484,  classifier :0.026382500305771828, mask: 0.11054559051990509 ===================
epoch no : 8, batch no : 131, total loss : 0.33048978447914124,  classifier :0.029801426455378532, mask: 0.1294107586145401 ===================
epoch no : 8, batch no : 132, total loss : 0.24704599380493164,  classifier :0.02953529916703701, mask: 0.11526013910770416 ===================
epoch no : 8, batch no : 133, total loss : 0.22444744408130646,  classifier :0.03742443025112152, mask: 0.09466090053319931 ===================
epoch no : 8, batch no : 134, total loss : 0.21613913774490356,  classifier :0.024273619055747986, mask: 0.10800933092832565 ===================
epoch no : 8, batch no : 135, total loss : 0.32233166694641113,  classifier :0.03746425732970238, mask: 0.12952108681201935 ===================
epoch no : 8, batch no : 136, total loss : 0.28168898820877075,  classifier :0.03434447944164276, mask: 0.11858388781547546 ===================
epoch no : 8, batch no : 137, total loss : 0.2530043125152588,  classifier :0.023865316063165665, mask: 0.12027479708194733 ===================
epoch no : 8, batch no : 138, total loss : 0.23466844856739044,  classifier :0.023566076532006264, mask: 0.10704075545072556 ===================
epoch no : 8, batch no : 139, total loss : 0.2790636718273163,  classifier :0.035162560641765594, mask: 0.11035861819982529 ===================
epoch no : 8, batch no : 140, total loss : 0.3351975083351135,  classifier :0.03224942833185196, mask: 0.15661108493804932 ===================
epoch no : 8, batch no : 141, total loss : 0.2441977858543396,  classifier :0.04836723953485489, mask: 0.09163673967123032 ===================
epoch no : 8, batch no : 142, total loss : 0.2112831175327301,  classifier :0.027902469038963318, mask: 0.09805842489004135 ===================
epoch no : 8, batch no : 143, total loss : 0.31001996994018555,  classifier :0.031582336872816086, mask: 0.1365320384502411 ===================
epoch no : 8, batch no : 144, total loss : 0.2944543659687042,  classifier :0.022502906620502472, mask: 0.1294335126876831 ===================
epoch no : 8, batch no : 145, total loss : 0.26495641469955444,  classifier :0.02802223153412342, mask: 0.10292746871709824 ===================
epoch no : 8, batch no : 146, total loss : 0.3026731610298157,  classifier :0.02877665124833584, mask: 0.1440405547618866 ===================
epoch no : 8, batch no : 147, total loss : 0.2384338676929474,  classifier :0.030389968305826187, mask: 0.09921006113290787 ===================
epoch no : 8, batch no : 148, total loss : 0.2808215618133545,  classifier :0.03541931137442589, mask: 0.1297127902507782 ===================
epoch no : 8, batch no : 149, total loss : 0.2277892678976059,  classifier :0.019126851111650467, mask: 0.09528905153274536 ===================
epoch no : 8, batch no : 150, total loss : 0.29348912835121155,  classifier :0.02675583027303219, mask: 0.13032494485378265 ===================
epoch no : 8, batch no : 151, total loss : 0.19954417645931244,  classifier :0.02118920534849167, mask: 0.08426321297883987 ===================
epoch no : 8, batch no : 152, total loss : 0.34815821051597595,  classifier :0.03157603368163109, mask: 0.1515890508890152 ===================
epoch no : 8, batch no : 153, total loss : 0.19998112320899963,  classifier :0.02482135035097599, mask: 0.08821950107812881 ===================
epoch no : 8, batch no : 154, total loss : 0.20676617324352264,  classifier :0.023758787661790848, mask: 0.11222372949123383 ===================
epoch no : 8, batch no : 155, total loss : 0.3536868393421173,  classifier :0.04827718064188957, mask: 0.14682067930698395 ===================
epoch no : 8, batch no : 156, total loss : 0.27233171463012695,  classifier :0.020896190777420998, mask: 0.1257687211036682 ===================
epoch no : 8, batch no : 157, total loss : 0.37622320652008057,  classifier :0.03636741265654564, mask: 0.1496945470571518 ===================
epoch no : 8, batch no : 158, total loss : 0.2864895164966583,  classifier :0.03493504226207733, mask: 0.11045459657907486 ===================
epoch no : 8, batch no : 159, total loss : 0.251112699508667,  classifier :0.036709412932395935, mask: 0.10380590707063675 ===================
epoch no : 8, batch no : 160, total loss : 0.228463813662529,  classifier :0.024888252839446068, mask: 0.09555861353874207 ===================
epoch no : 8, batch no : 161, total loss : 0.2662370502948761,  classifier :0.03714796155691147, mask: 0.13169725239276886 ===================
epoch no : 8, batch no : 162, total loss : 0.27114275097846985,  classifier :0.02893177978694439, mask: 0.117323137819767 ===================
epoch no : 8, batch no : 163, total loss : 0.2149432748556137,  classifier :0.026630865409970284, mask: 0.10098783671855927 ===================
epoch no : 8, batch no : 164, total loss : 0.35973823070526123,  classifier :0.04642799496650696, mask: 0.1998908370733261 ===================
epoch no : 8, batch no : 165, total loss : 0.2305038422346115,  classifier :0.023041674867272377, mask: 0.09094791859388351 ===================
epoch no : 8, batch no : 166, total loss : 0.2765626013278961,  classifier :0.03429390862584114, mask: 0.12677165865898132 ===================
epoch no : 8, batch no : 167, total loss : 0.2965530753135681,  classifier :0.05442275106906891, mask: 0.11837580054998398 ===================
epoch no : 8, batch no : 168, total loss : 0.22218568623065948,  classifier :0.018672345206141472, mask: 0.11104774475097656 ===================
epoch no : 8, batch no : 169, total loss : 0.23208323121070862,  classifier :0.02611999213695526, mask: 0.09317207336425781 ===================
epoch no : 8, batch no : 170, total loss : 0.2296103835105896,  classifier :0.028275568038225174, mask: 0.10575546324253082 ===================
epoch no : 8, batch no : 171, total loss : 0.25133031606674194,  classifier :0.01639716885983944, mask: 0.11645932495594025 ===================
epoch no : 8, batch no : 172, total loss : 0.268237829208374,  classifier :0.03317119553685188, mask: 0.11294437199831009 ===================
epoch no : 8, batch no : 173, total loss : 0.2235088348388672,  classifier :0.02187291905283928, mask: 0.10887286067008972 ===================
epoch no : 8, batch no : 174, total loss : 0.3269462585449219,  classifier :0.023255685344338417, mask: 0.15610472857952118 ===================
epoch no : 8, batch no : 175, total loss : 0.25404733419418335,  classifier :0.03349961340427399, mask: 0.09228219091892242 ===================
epoch no : 8, batch no : 176, total loss : 0.35570529103279114,  classifier :0.04704012721776962, mask: 0.15256838500499725 ===================
epoch no : 8, batch no : 177, total loss : 0.23200972378253937,  classifier :0.03565850108861923, mask: 0.1133650690317154 ===================
epoch no : 8, batch no : 178, total loss : 0.3146402835845947,  classifier :0.027559135109186172, mask: 0.13202497363090515 ===================
epoch no : 8, batch no : 179, total loss : 0.2594199776649475,  classifier :0.03572331741452217, mask: 0.08575073629617691 ===================
epoch no : 8, batch no : 180, total loss : 0.23737822473049164,  classifier :0.02449040301144123, mask: 0.10554148256778717 ===================
epoch no : 8, batch no : 181, total loss : 0.26842883229255676,  classifier :0.021389422938227654, mask: 0.1343889683485031 ===================
epoch no : 8, batch no : 182, total loss : 0.26551753282546997,  classifier :0.01976342685520649, mask: 0.12268991768360138 ===================
epoch no : 8, batch no : 183, total loss : 0.2663504481315613,  classifier :0.030520914122462273, mask: 0.10438603162765503 ===================
epoch no : 8, batch no : 184, total loss : 0.2366083264350891,  classifier :0.027720477432012558, mask: 0.11036557704210281 ===================
epoch no : 8, batch no : 185, total loss : 0.273895263671875,  classifier :0.02693123370409012, mask: 0.13056407868862152 ===================
epoch no : 8, batch no : 186, total loss : 0.29890260100364685,  classifier :0.02726641483604908, mask: 0.13471588492393494 ===================
epoch no : 8, batch no : 187, total loss : 0.2426893562078476,  classifier :0.02843947522342205, mask: 0.11781764030456543 ===================
epoch no : 8, batch no : 188, total loss : 0.19719617068767548,  classifier :0.017618531361222267, mask: 0.09021347761154175 ===================
epoch no : 8, batch no : 189, total loss : 0.23029139637947083,  classifier :0.03407631814479828, mask: 0.0963592529296875 ===================
epoch no : 8, batch no : 190, total loss : 0.23098573088645935,  classifier :0.023850280791521072, mask: 0.09954436123371124 ===================
epoch no : 8, batch no : 191, total loss : 0.34382838010787964,  classifier :0.03263475000858307, mask: 0.13638417422771454 ===================
epoch no : 8, batch no : 192, total loss : 0.36145126819610596,  classifier :0.0431777685880661, mask: 0.17943640053272247 ===================
epoch no : 8, batch no : 193, total loss : 0.1914123296737671,  classifier :0.020388547331094742, mask: 0.09812525659799576 ===================
epoch no : 8, batch no : 194, total loss : 0.29519572854042053,  classifier :0.04167455807328224, mask: 0.14122316241264343 ===================
epoch no : 8, batch no : 195, total loss : 0.2749905586242676,  classifier :0.029742835089564323, mask: 0.12657436728477478 ===================
epoch no : 8, batch no : 196, total loss : 0.2336885631084442,  classifier :0.02198416367173195, mask: 0.11506330221891403 ===================
epoch no : 8, batch no : 197, total loss : 0.2842864692211151,  classifier :0.0208536796271801, mask: 0.11965866386890411 ===================
epoch no : 8, batch no : 198, total loss : 0.323299378156662,  classifier :0.03587391972541809, mask: 0.14089633524417877 ===================
epoch no : 8, batch no : 199, total loss : 0.23915283381938934,  classifier :0.023663179948925972, mask: 0.09777342528104782 ===================
epoch no : 8, batch no : 200, total loss : 0.27693381905555725,  classifier :0.024477019906044006, mask: 0.12757693231105804 ===================
epoch no : 8, batch no : 201, total loss : 0.22509323060512543,  classifier :0.02153651975095272, mask: 0.11581215262413025 ===================
epoch no : 8, batch no : 202, total loss : 0.2411981225013733,  classifier :0.019828099757432938, mask: 0.1107606366276741 ===================
epoch no : 8, batch no : 203, total loss : 0.2286185473203659,  classifier :0.03483287990093231, mask: 0.0894148200750351 ===================
epoch no : 8, batch no : 204, total loss : 0.23536165058612823,  classifier :0.021849729120731354, mask: 0.12075003236532211 ===================
epoch no : 8, batch no : 205, total loss : 0.2131526917219162,  classifier :0.021776050329208374, mask: 0.10470278561115265 ===================
epoch no : 8, batch no : 206, total loss : 0.22242526710033417,  classifier :0.03233156353235245, mask: 0.09244468063116074 ===================
epoch no : 8, batch no : 207, total loss : 0.2706272304058075,  classifier :0.03174981102347374, mask: 0.10797406733036041 ===================
epoch no : 8, batch no : 208, total loss : 0.24807541072368622,  classifier :0.026155522093176842, mask: 0.11269582062959671 ===================
epoch no : 8, batch no : 209, total loss : 0.2872679829597473,  classifier :0.038369469344615936, mask: 0.10062988102436066 ===================
epoch no : 8, batch no : 210, total loss : 0.18868069350719452,  classifier :0.01517528761178255, mask: 0.09686935693025589 ===================
epoch no : 8, batch no : 211, total loss : 0.23964588344097137,  classifier :0.02480475790798664, mask: 0.10688073188066483 ===================
epoch no : 8, batch no : 212, total loss : 0.2202529013156891,  classifier :0.01920885220170021, mask: 0.08809889107942581 ===================
epoch no : 8, batch no : 213, total loss : 0.27038446068763733,  classifier :0.02909041941165924, mask: 0.13352476060390472 ===================
epoch no : 8, batch no : 214, total loss : 0.22726696729660034,  classifier :0.024103986099362373, mask: 0.09308817237615585 ===================
epoch no : 8, batch no : 215, total loss : 0.2579871118068695,  classifier :0.033883847296237946, mask: 0.10568443685770035 ===================
epoch no : 8, batch no : 216, total loss : 0.32807445526123047,  classifier :0.04083467274904251, mask: 0.132894366979599 ===================
epoch no : 8, batch no : 217, total loss : 0.3067494034767151,  classifier :0.0269020888954401, mask: 0.13308215141296387 ===================
epoch no : 8, batch no : 218, total loss : 0.2164471447467804,  classifier :0.03201897069811821, mask: 0.09502376616001129 ===================
epoch no : 8, batch no : 219, total loss : 0.2794342637062073,  classifier :0.029136640951037407, mask: 0.11236682534217834 ===================
epoch no : 8, batch no : 220, total loss : 0.2509308159351349,  classifier :0.02372589334845543, mask: 0.10514120012521744 ===================
epoch no : 8, batch no : 221, total loss : 0.23572097718715668,  classifier :0.02151596173644066, mask: 0.1270599067211151 ===================
epoch no : 8, batch no : 222, total loss : 0.1724846363067627,  classifier :0.020453020930290222, mask: 0.07987142354249954 ===================
epoch no : 8, batch no : 223, total loss : 0.21297065913677216,  classifier :0.025002192705869675, mask: 0.10301940888166428 ===================
epoch no : 8, batch no : 224, total loss : 0.2030671089887619,  classifier :0.02229316718876362, mask: 0.07937301695346832 ===================
epoch no : 8, batch no : 225, total loss : 0.21989911794662476,  classifier :0.026260731741786003, mask: 0.09707146137952805 ===================
epoch no : 8, batch no : 226, total loss : 0.26556646823883057,  classifier :0.017016083002090454, mask: 0.12818150222301483 ===================
epoch no : 8, batch no : 227, total loss : 0.28862881660461426,  classifier :0.029085973277688026, mask: 0.103790283203125 ===================
epoch no : 8, batch no : 228, total loss : 0.27799636125564575,  classifier :0.037438418716192245, mask: 0.09641674160957336 ===================
epoch no : 8, batch no : 229, total loss : 0.2895680069923401,  classifier :0.030531946569681168, mask: 0.11912060528993607 ===================
epoch no : 8, batch no : 230, total loss : 0.18547727167606354,  classifier :0.021663624793291092, mask: 0.0863775908946991 ===================
epoch no : 8, batch no : 231, total loss : 0.28365835547447205,  classifier :0.03394179418683052, mask: 0.13733892142772675 ===================
epoch no : 8, batch no : 232, total loss : 0.21960443258285522,  classifier :0.0395703986287117, mask: 0.10110307484865189 ===================
epoch no : 8, batch no : 233, total loss : 0.21659810841083527,  classifier :0.01963498815894127, mask: 0.1294354945421219 ===================
epoch no : 8, batch no : 234, total loss : 0.28163018822669983,  classifier :0.018372206017374992, mask: 0.11051245033740997 ===================
epoch no : 8, batch no : 235, total loss : 0.31163832545280457,  classifier :0.034471992403268814, mask: 0.13965506851673126 ===================
epoch no : 8, batch no : 236, total loss : 0.24700205028057098,  classifier :0.020507654175162315, mask: 0.12876103818416595 ===================
epoch no : 8, batch no : 237, total loss : 0.20972691476345062,  classifier :0.02039305306971073, mask: 0.1109362468123436 ===================
epoch no : 8, batch no : 238, total loss : 0.19601893424987793,  classifier :0.03250453621149063, mask: 0.09937388449907303 ===================
epoch no : 8, batch no : 239, total loss : 0.20923419296741486,  classifier :0.029639262706041336, mask: 0.08722589164972305 ===================
epoch no : 8, batch no : 240, total loss : 0.22212789952754974,  classifier :0.020712167024612427, mask: 0.0946122407913208 ===================
epoch no : 8, batch no : 241, total loss : 0.2908114790916443,  classifier :0.025071309879422188, mask: 0.12185095250606537 ===================
epoch no : 8, batch no : 242, total loss : 0.3717397451400757,  classifier :0.049128927290439606, mask: 0.15934498608112335 ===================
epoch no : 8, batch no : 243, total loss : 0.2602846920490265,  classifier :0.023708952590823174, mask: 0.12745602428913116 ===================
epoch no : 8, batch no : 244, total loss : 0.2700512707233429,  classifier :0.02775506116449833, mask: 0.1121034100651741 ===================
epoch no : 8, batch no : 245, total loss : 0.26118430495262146,  classifier :0.025708522647619247, mask: 0.1201971173286438 ===================
epoch no : 8, batch no : 246, total loss : 0.2069491147994995,  classifier :0.02593488246202469, mask: 0.09720192104578018 ===================
epoch no : 8, batch no : 247, total loss : 0.27060800790786743,  classifier :0.02324541099369526, mask: 0.13603976368904114 ===================
epoch no : 8, batch no : 248, total loss : 0.24830485880374908,  classifier :0.0223259087651968, mask: 0.1167357787489891 ===================
epoch no : 8, batch no : 249, total loss : 0.18189796805381775,  classifier :0.025361932814121246, mask: 0.08524157106876373 ===================
epoch no : 8, batch no : 250, total loss : 0.21574148535728455,  classifier :0.025391459465026855, mask: 0.10188744217157364 ===================
epoch no : 8, batch no : 251, total loss : 0.2634347379207611,  classifier :0.028608929365873337, mask: 0.1185973584651947 ===================
epoch no : 8, batch no : 252, total loss : 0.24636895954608917,  classifier :0.02264220640063286, mask: 0.10442430526018143 ===================
epoch no : 8, batch no : 253, total loss : 0.27277445793151855,  classifier :0.023221513256430626, mask: 0.14748075604438782 ===================
epoch no : 8, batch no : 254, total loss : 0.33730289340019226,  classifier :0.03464846685528755, mask: 0.1743527352809906 ===================
epoch no : 8, batch no : 255, total loss : 0.3731411099433899,  classifier :0.037289418280124664, mask: 0.1824873834848404 ===================
epoch no : 8, batch no : 256, total loss : 0.27629128098487854,  classifier :0.024634087458252907, mask: 0.12173478305339813 ===================
epoch no : 8, batch no : 257, total loss : 0.20948323607444763,  classifier :0.02387215569615364, mask: 0.09567952901124954 ===================
epoch no : 8, batch no : 258, total loss : 0.215267151594162,  classifier :0.02696342207491398, mask: 0.10757419466972351 ===================
epoch no : 8, batch no : 259, total loss : 0.36703625321388245,  classifier :0.05082317814230919, mask: 0.17716160416603088 ===================
epoch no : 8, batch no : 260, total loss : 0.24459147453308105,  classifier :0.026451462879776955, mask: 0.09991807490587234 ===================
epoch no : 8, batch no : 261, total loss : 0.23129801452159882,  classifier :0.018569543957710266, mask: 0.09183952212333679 ===================
epoch no : 8, batch no : 262, total loss : 0.2873925268650055,  classifier :0.02420194260776043, mask: 0.10650543868541718 ===================
epoch no : 8, batch no : 263, total loss : 0.22038954496383667,  classifier :0.023853808641433716, mask: 0.09916816651821136 ===================
epoch no : 8, batch no : 264, total loss : 0.1949385553598404,  classifier :0.031509265303611755, mask: 0.09126020967960358 ===================
epoch no : 8, batch no : 265, total loss : 0.21792656183242798,  classifier :0.023177774623036385, mask: 0.13200508058071136 ===================
epoch no : 8, batch no : 266, total loss : 0.2786833345890045,  classifier :0.02251427248120308, mask: 0.1604217290878296 ===================
epoch no : 8, batch no : 267, total loss : 0.2803245484828949,  classifier :0.03712848946452141, mask: 0.11656064540147781 ===================
epoch no : 8, batch no : 268, total loss : 0.2932770848274231,  classifier :0.031203018501400948, mask: 0.12334262579679489 ===================
epoch no : 8, batch no : 269, total loss : 0.2230391502380371,  classifier :0.025016963481903076, mask: 0.10690999776124954 ===================
epoch no : 8, batch no : 270, total loss : 0.2769443392753601,  classifier :0.03238080069422722, mask: 0.10811743885278702 ===================
epoch no : 8, batch no : 271, total loss : 0.20355473458766937,  classifier :0.025724854320287704, mask: 0.10353124141693115 ===================
epoch no : 8, batch no : 272, total loss : 0.21434812247753143,  classifier :0.03082622028887272, mask: 0.10830957442522049 ===================
epoch no : 8, batch no : 273, total loss : 0.26458340883255005,  classifier :0.028440065681934357, mask: 0.11820018291473389 ===================
epoch no : 8, batch no : 274, total loss : 0.21840210258960724,  classifier :0.021979503333568573, mask: 0.09543604403734207 ===================
epoch no : 8, batch no : 275, total loss : 0.2423080950975418,  classifier :0.0224203709512949, mask: 0.12757602334022522 ===================
epoch no : 8, batch no : 276, total loss : 0.25399115681648254,  classifier :0.022703541442751884, mask: 0.11824096739292145 ===================
epoch no : 8, batch no : 277, total loss : 0.21034450829029083,  classifier :0.03145365044474602, mask: 0.09095794707536697 ===================
epoch no : 8, batch no : 278, total loss : 0.296936959028244,  classifier :0.02148623764514923, mask: 0.13976798951625824 ===================
epoch no : 8, batch no : 279, total loss : 0.18654750287532806,  classifier :0.02209264412522316, mask: 0.08338938653469086 ===================
epoch no : 8, batch no : 280, total loss : 0.23576630651950836,  classifier :0.02261548489332199, mask: 0.1045481264591217 ===================
epoch no : 8, batch no : 281, total loss : 0.1543871909379959,  classifier :0.021557051688432693, mask: 0.07857872545719147 ===================
epoch no : 8, batch no : 282, total loss : 0.30457842350006104,  classifier :0.026640765368938446, mask: 0.1617906242609024 ===================
epoch no : 8, batch no : 283, total loss : 0.30840086936950684,  classifier :0.03866130858659744, mask: 0.1194196566939354 ===================
epoch no : 8, batch no : 284, total loss : 0.18088877201080322,  classifier :0.026806967332959175, mask: 0.08193038403987885 ===================
epoch no : 8, batch no : 285, total loss : 0.24321043491363525,  classifier :0.022555211558938026, mask: 0.11796954274177551 ===================
epoch no : 8, batch no : 286, total loss : 0.24704329669475555,  classifier :0.02757004275918007, mask: 0.11537814885377884 ===================
epoch no : 8, batch no : 287, total loss : 0.22537283599376678,  classifier :0.01840517297387123, mask: 0.10810121893882751 ===================
epoch no : 8, batch no : 288, total loss : 0.23352232575416565,  classifier :0.021545568481087685, mask: 0.1221158504486084 ===================
epoch no : 8, batch no : 289, total loss : 0.1995067298412323,  classifier :0.019336849451065063, mask: 0.0880371704697609 ===================
epoch no : 8, batch no : 290, total loss : 0.24504069983959198,  classifier :0.03313175588846207, mask: 0.08709658682346344 ===================
epoch no : 8, batch no : 291, total loss : 0.28778794407844543,  classifier :0.02322051301598549, mask: 0.11632275581359863 ===================
epoch no : 8, batch no : 292, total loss : 0.2962566912174225,  classifier :0.020344005897641182, mask: 0.12751732766628265 ===================
epoch no : 8, batch no : 293, total loss : 0.28300970792770386,  classifier :0.023380782455205917, mask: 0.1260562539100647 ===================
epoch no : 8, batch no : 294, total loss : 0.26724568009376526,  classifier :0.02010686881840229, mask: 0.14669294655323029 ===================
epoch no : 8, batch no : 295, total loss : 0.276336133480072,  classifier :0.02573510818183422, mask: 0.12235820293426514 ===================
epoch no : 8, batch no : 296, total loss : 0.24854065477848053,  classifier :0.03172417730093002, mask: 0.10962609946727753 ===================
epoch no : 8, batch no : 297, total loss : 0.24516995251178741,  classifier :0.02062559500336647, mask: 0.10685823857784271 ===================
epoch no : 8, batch no : 298, total loss : 0.2266230583190918,  classifier :0.03157791122794151, mask: 0.09162243455648422 ===================
epoch no : 8, batch no : 299, total loss : 0.2515318691730499,  classifier :0.021483521908521652, mask: 0.11404705047607422 ===================
epoch no : 8, batch no : 300, total loss : 0.3619158864021301,  classifier :0.023026874288916588, mask: 0.14475327730178833 ===================
epoch no : 8, batch no : 301, total loss : 0.2527771592140198,  classifier :0.022866275161504745, mask: 0.096895232796669 ===================
epoch no : 8, batch no : 302, total loss : 0.25729814171791077,  classifier :0.033055443316698074, mask: 0.10735757648944855 ===================
epoch no : 8, batch no : 303, total loss : 0.20800477266311646,  classifier :0.034804388880729675, mask: 0.10078809410333633 ===================
epoch no : 8, batch no : 304, total loss : 0.19562998414039612,  classifier :0.023446831852197647, mask: 0.09121253341436386 ===================
epoch no : 8, batch no : 305, total loss : 0.2405482828617096,  classifier :0.021631557494401932, mask: 0.08994408696889877 ===================
epoch no : 8, batch no : 306, total loss : 0.2364335060119629,  classifier :0.02535161003470421, mask: 0.09062101691961288 ===================
epoch no : 8, batch no : 307, total loss : 0.3233708143234253,  classifier :0.025304807350039482, mask: 0.09929370135068893 ===================
epoch no : 8, batch no : 308, total loss : 0.3303537666797638,  classifier :0.026307055726647377, mask: 0.13810153305530548 ===================
epoch no : 8, batch no : 309, total loss : 0.2946324050426483,  classifier :0.03311038017272949, mask: 0.1250283420085907 ===================
epoch no : 8, batch no : 310, total loss : 0.24502743780612946,  classifier :0.025558603927493095, mask: 0.09846467524766922 ===================
epoch no : 8, batch no : 311, total loss : 0.30416280031204224,  classifier :0.04631391167640686, mask: 0.1309167742729187 ===================
epoch no : 8, batch no : 312, total loss : 0.2730559706687927,  classifier :0.04199090600013733, mask: 0.12804077565670013 ===================
epoch no : 8, batch no : 313, total loss : 0.3191884458065033,  classifier :0.030332759022712708, mask: 0.1285250186920166 ===================
epoch no : 8, batch no : 314, total loss : 0.24690894782543182,  classifier :0.02450321428477764, mask: 0.11012931913137436 ===================
epoch no : 8, batch no : 315, total loss : 0.23782160878181458,  classifier :0.028201306238770485, mask: 0.10687816143035889 ===================
epoch no : 8, batch no : 316, total loss : 0.2212703675031662,  classifier :0.02793002687394619, mask: 0.09515261650085449 ===================
epoch no : 8, batch no : 317, total loss : 0.2368600219488144,  classifier :0.024629617109894753, mask: 0.09874149411916733 ===================
epoch no : 8, batch no : 318, total loss : 0.19062866270542145,  classifier :0.020121406763792038, mask: 0.08986280113458633 ===================
epoch no : 8, batch no : 319, total loss : 0.20563139021396637,  classifier :0.031090619042515755, mask: 0.0805203840136528 ===================
epoch no : 8, batch no : 320, total loss : 0.2301826775074005,  classifier :0.029627725481987, mask: 0.09122541546821594 ===================
epoch no : 8, batch no : 321, total loss : 0.30341851711273193,  classifier :0.0421278178691864, mask: 0.14199364185333252 ===================
epoch no : 8, batch no : 322, total loss : 0.19281001389026642,  classifier :0.023945342749357224, mask: 0.07955349236726761 ===================
epoch no : 8, batch no : 323, total loss : 0.31433215737342834,  classifier :0.02675330452620983, mask: 0.11943047493696213 ===================
epoch no : 8, batch no : 324, total loss : 0.27955162525177,  classifier :0.020336367189884186, mask: 0.09394025802612305 ===================
epoch no : 8, batch no : 325, total loss : 0.27764594554901123,  classifier :0.022766832262277603, mask: 0.10995879769325256 ===================
epoch no : 8, batch no : 326, total loss : 0.28296345472335815,  classifier :0.02682119607925415, mask: 0.10776825249195099 ===================
epoch no : 8, batch no : 327, total loss : 0.20969264209270477,  classifier :0.027391087263822556, mask: 0.08952910453081131 ===================
epoch no : 8, batch no : 328, total loss : 0.24144262075424194,  classifier :0.022225111722946167, mask: 0.10872002691030502 ===================
epoch no : 8, batch no : 329, total loss : 0.2151545286178589,  classifier :0.028108367696404457, mask: 0.0926646739244461 ===================
epoch no : 8, batch no : 330, total loss : 0.23155076801776886,  classifier :0.02621130272746086, mask: 0.11294494569301605 ===================
epoch no : 8, batch no : 331, total loss : 0.2891160249710083,  classifier :0.03237616643309593, mask: 0.12274951487779617 ===================
epoch no : 8, batch no : 332, total loss : 0.29819032549858093,  classifier :0.02777053974568844, mask: 0.12792254984378815 ===================
epoch no : 8, batch no : 333, total loss : 0.24521537125110626,  classifier :0.025304004549980164, mask: 0.11473137885332108 ===================
epoch no : 8, batch no : 334, total loss : 0.2229854166507721,  classifier :0.025174880400300026, mask: 0.11358236521482468 ===================
epoch no : 8, batch no : 335, total loss : 0.2401958853006363,  classifier :0.02597554586827755, mask: 0.1131075769662857 ===================
epoch no : 8, batch no : 336, total loss : 0.23260454833507538,  classifier :0.01912093721330166, mask: 0.09674690663814545 ===================
epoch no : 8, batch no : 337, total loss : 0.2067183405160904,  classifier :0.020025748759508133, mask: 0.10032131522893906 ===================
epoch no : 8, batch no : 338, total loss : 0.2504369914531708,  classifier :0.03217199817299843, mask: 0.13283784687519073 ===================
epoch no : 8, batch no : 339, total loss : 0.1996636986732483,  classifier :0.023115983232855797, mask: 0.08340108394622803 ===================
epoch no : 8, batch no : 340, total loss : 0.2435019463300705,  classifier :0.03373613953590393, mask: 0.10552646219730377 ===================
epoch no : 8, batch no : 341, total loss : 0.29000502824783325,  classifier :0.027901802211999893, mask: 0.1211368665099144 ===================
epoch no : 8, batch no : 342, total loss : 0.2563234567642212,  classifier :0.02080203779041767, mask: 0.13109660148620605 ===================
epoch no : 8, batch no : 343, total loss : 0.253989577293396,  classifier :0.03139066696166992, mask: 0.11112849414348602 ===================
epoch no : 8, batch no : 344, total loss : 0.29548269510269165,  classifier :0.02673487178981304, mask: 0.11625209450721741 ===================
epoch no : 8, batch no : 345, total loss : 0.29872065782546997,  classifier :0.02916763536632061, mask: 0.11139726638793945 ===================
epoch no : 8, batch no : 346, total loss : 0.31626296043395996,  classifier :0.025619765743613243, mask: 0.12475116550922394 ===================
epoch no : 8, batch no : 347, total loss : 0.2587336003780365,  classifier :0.02272370643913746, mask: 0.11455456912517548 ===================
epoch no : 8, batch no : 348, total loss : 0.20404298603534698,  classifier :0.02463383413851261, mask: 0.1005183532834053 ===================
epoch no : 8, batch no : 349, total loss : 0.18332675099372864,  classifier :0.018421126529574394, mask: 0.09606075286865234 ===================
epoch no : 8, batch no : 350, total loss : 0.256375253200531,  classifier :0.02318909391760826, mask: 0.12337848544120789 ===================
epoch no : 8, batch no : 351, total loss : 0.23259861767292023,  classifier :0.020194366574287415, mask: 0.12733133137226105 ===================
epoch no : 8, batch no : 352, total loss : 0.25658220052719116,  classifier :0.019387446343898773, mask: 0.16148842871189117 ===================
epoch no : 8, batch no : 353, total loss : 0.20341697335243225,  classifier :0.024525396525859833, mask: 0.10208864510059357 ===================
epoch no : 8, batch no : 354, total loss : 0.2577771842479706,  classifier :0.02257341332733631, mask: 0.11406166851520538 ===================
epoch no : 8, batch no : 355, total loss : 0.33248329162597656,  classifier :0.04463502764701843, mask: 0.1622169315814972 ===================
epoch no : 8, batch no : 356, total loss : 0.22159714996814728,  classifier :0.027144938707351685, mask: 0.09903962910175323 ===================
epoch no : 8, batch no : 357, total loss : 0.24432285130023956,  classifier :0.02886643260717392, mask: 0.12851478159427643 ===================
epoch no : 8, batch no : 358, total loss : 0.23815153539180756,  classifier :0.01866239495575428, mask: 0.10398887097835541 ===================
epoch no : 8, batch no : 359, total loss : 0.1616974025964737,  classifier :0.02168603427708149, mask: 0.0803065374493599 ===================
epoch no : 8, batch no : 360, total loss : 0.24010320007801056,  classifier :0.03130369633436203, mask: 0.09562593698501587 ===================
epoch no : 8, batch no : 361, total loss : 0.28291836380958557,  classifier :0.026366766542196274, mask: 0.09525041282176971 ===================
epoch no : 8, batch no : 362, total loss : 0.23924072086811066,  classifier :0.024691984057426453, mask: 0.08859049528837204 ===================
epoch no : 8, batch no : 363, total loss : 0.28652456402778625,  classifier :0.027819229289889336, mask: 0.14350822567939758 ===================
epoch no : 8, batch no : 364, total loss : 0.3231455683708191,  classifier :0.026816802099347115, mask: 0.13128875195980072 ===================
epoch no : 8, batch no : 365, total loss : 0.28556594252586365,  classifier :0.028333494439721107, mask: 0.1291358321905136 ===================
epoch no : 8, batch no : 366, total loss : 0.2891245186328888,  classifier :0.031018545851111412, mask: 0.14358419179916382 ===================
epoch no : 8, batch no : 367, total loss : 0.34469571709632874,  classifier :0.02826625108718872, mask: 0.13157354295253754 ===================
epoch no : 8, batch no : 368, total loss : 0.26331624388694763,  classifier :0.025693822652101517, mask: 0.1165248304605484 ===================
epoch no : 8, batch no : 369, total loss : 0.21750758588314056,  classifier :0.024508036673069, mask: 0.09292834997177124 ===================
epoch no : 8, batch no : 370, total loss : 0.25245797634124756,  classifier :0.027812348678708076, mask: 0.13906753063201904 ===================
epoch no : 8, batch no : 371, total loss : 0.20203788578510284,  classifier :0.021298527717590332, mask: 0.10084405541419983 ===================
epoch no : 8, batch no : 372, total loss : 0.24089251458644867,  classifier :0.018455585464835167, mask: 0.10334985703229904 ===================
epoch no : 8, batch no : 373, total loss : 0.313174307346344,  classifier :0.028614914044737816, mask: 0.12234329432249069 ===================
epoch no : 8, batch no : 374, total loss : 0.19966945052146912,  classifier :0.02636249177157879, mask: 0.09853727370500565 ===================
epoch no : 8, batch no : 375, total loss : 0.22133253514766693,  classifier :0.024798661470413208, mask: 0.09992539137601852 ===================
epoch no : 8, batch no : 376, total loss : 0.24286338686943054,  classifier :0.03184918686747551, mask: 0.1041848435997963 ===================
epoch no : 8, batch no : 377, total loss : 0.20062977075576782,  classifier :0.02178255282342434, mask: 0.09760827571153641 ===================
epoch no : 8, batch no : 378, total loss : 0.20395614206790924,  classifier :0.02121012844145298, mask: 0.10032422840595245 ===================
epoch no : 8, batch no : 379, total loss : 0.28475242853164673,  classifier :0.03315117582678795, mask: 0.11278844624757767 ===================
epoch no : 8, batch no : 380, total loss : 0.23519659042358398,  classifier :0.020821588113904, mask: 0.10371453315019608 ===================
epoch no : 8, batch no : 381, total loss : 0.23056989908218384,  classifier :0.02690240927040577, mask: 0.09470419585704803 ===================
epoch no : 8, batch no : 382, total loss : 0.23722204566001892,  classifier :0.01804017275571823, mask: 0.10310851782560349 ===================
epoch no : 8, batch no : 383, total loss : 0.22860410809516907,  classifier :0.03252916783094406, mask: 0.09446553140878677 ===================
epoch no : 8, batch no : 384, total loss : 0.31730014085769653,  classifier :0.0318591371178627, mask: 0.1478155553340912 ===================
epoch no : 8, batch no : 385, total loss : 0.2642298638820648,  classifier :0.031775884330272675, mask: 0.11802570521831512 ===================
epoch no : 8, batch no : 386, total loss : 0.2333974391222,  classifier :0.02158837392926216, mask: 0.09965670108795166 ===================
epoch no : 8, batch no : 387, total loss : 0.3788301944732666,  classifier :0.03643229976296425, mask: 0.14011462032794952 ===================
epoch no : 8, batch no : 388, total loss : 0.3114427626132965,  classifier :0.028283488005399704, mask: 0.11882604658603668 ===================
epoch no : 8, batch no : 389, total loss : 0.2305823415517807,  classifier :0.026176519691944122, mask: 0.09834325313568115 ===================
epoch no : 8, batch no : 390, total loss : 0.23171110451221466,  classifier :0.026480000466108322, mask: 0.0963912382721901 ===================
epoch no : 8, batch no : 391, total loss : 0.2234272062778473,  classifier :0.015660947188735008, mask: 0.10496033728122711 ===================
epoch no : 8, batch no : 392, total loss : 0.22686134278774261,  classifier :0.02909097447991371, mask: 0.1127040907740593 ===================
epoch no : 8, batch no : 393, total loss : 0.1897197961807251,  classifier :0.025665119290351868, mask: 0.08744487166404724 ===================
epoch no : 8, batch no : 394, total loss : 0.21892964839935303,  classifier :0.020674224942922592, mask: 0.09791024774312973 ===================
epoch no : 8, batch no : 395, total loss : 0.20490336418151855,  classifier :0.022602152079343796, mask: 0.08928103744983673 ===================
epoch no : 8, batch no : 396, total loss : 0.25886714458465576,  classifier :0.02052314206957817, mask: 0.10793454945087433 ===================
epoch no : 8, batch no : 397, total loss : 0.21814638376235962,  classifier :0.02552361786365509, mask: 0.08551015704870224 ===================
epoch no : 8, batch no : 398, total loss : 0.29153186082839966,  classifier :0.027675926685333252, mask: 0.1363445371389389 ===================
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch no : 9, batch no : 0, total loss : 0.2886703610420227,  classifier :0.027301078662276268, mask: 0.12712012231349945 ===================
epoch no : 9, batch no : 1, total loss : 0.288127064704895,  classifier :0.023382311686873436, mask: 0.1346644163131714 ===================
epoch no : 9, batch no : 2, total loss : 0.23811213672161102,  classifier :0.024616742506623268, mask: 0.11772048473358154 ===================
epoch no : 9, batch no : 3, total loss : 0.1909259557723999,  classifier :0.023414479568600655, mask: 0.10226871818304062 ===================
epoch no : 9, batch no : 4, total loss : 0.25287431478500366,  classifier :0.024371029809117317, mask: 0.10985489934682846 ===================
epoch no : 9, batch no : 5, total loss : 0.2876426577568054,  classifier :0.02305006794631481, mask: 0.11823819577693939 ===================
epoch no : 9, batch no : 6, total loss : 0.20569737255573273,  classifier :0.02661733701825142, mask: 0.10044105350971222 ===================
epoch no : 9, batch no : 7, total loss : 0.22606253623962402,  classifier :0.018638286739587784, mask: 0.11779540777206421 ===================
epoch no : 9, batch no : 8, total loss : 0.21545402705669403,  classifier :0.022548405453562737, mask: 0.08915417641401291 ===================
epoch no : 9, batch no : 9, total loss : 0.23601657152175903,  classifier :0.02278752066195011, mask: 0.1046987920999527 ===================
epoch no : 9, batch no : 10, total loss : 0.2664325535297394,  classifier :0.023602275177836418, mask: 0.1438920646905899 ===================
epoch no : 9, batch no : 11, total loss : 0.3633935749530792,  classifier :0.0346524640917778, mask: 0.1363218128681183 ===================
epoch no : 9, batch no : 12, total loss : 0.21542981266975403,  classifier :0.02364533208310604, mask: 0.08631177991628647 ===================
epoch no : 9, batch no : 13, total loss : 0.22569578886032104,  classifier :0.025346964597702026, mask: 0.11097223311662674 ===================
epoch no : 9, batch no : 14, total loss : 0.18859539926052094,  classifier :0.019505441188812256, mask: 0.10101889073848724 ===================
epoch no : 9, batch no : 15, total loss : 0.20321422815322876,  classifier :0.0243105236440897, mask: 0.09175819158554077 ===================
epoch no : 9, batch no : 16, total loss : 0.20716822147369385,  classifier :0.0211203433573246, mask: 0.10519254207611084 ===================
epoch no : 9, batch no : 17, total loss : 0.2857939302921295,  classifier :0.026932932436466217, mask: 0.10195043683052063 ===================
epoch no : 9, batch no : 18, total loss : 0.2449234575033188,  classifier :0.021914515644311905, mask: 0.10211197286844254 ===================
epoch no : 9, batch no : 19, total loss : 0.2421882450580597,  classifier :0.025418609380722046, mask: 0.11241085082292557 ===================
epoch no : 9, batch no : 20, total loss : 0.23837049305438995,  classifier :0.026810774579644203, mask: 0.11001871526241302 ===================
epoch no : 9, batch no : 21, total loss : 0.23497223854064941,  classifier :0.02298697456717491, mask: 0.10555209964513779 ===================
epoch no : 9, batch no : 22, total loss : 0.22287249565124512,  classifier :0.02317696437239647, mask: 0.10764334350824356 ===================
epoch no : 9, batch no : 23, total loss : 0.23400378227233887,  classifier :0.023494496941566467, mask: 0.12059880048036575 ===================
epoch no : 9, batch no : 24, total loss : 0.23059377074241638,  classifier :0.030635036528110504, mask: 0.1093285009264946 ===================
epoch no : 9, batch no : 25, total loss : 0.28629958629608154,  classifier :0.026626307517290115, mask: 0.129369854927063 ===================
epoch no : 9, batch no : 26, total loss : 0.2424042820930481,  classifier :0.027002325281500816, mask: 0.09582781046628952 ===================
epoch no : 9, batch no : 27, total loss : 0.2035536915063858,  classifier :0.028484009206295013, mask: 0.08573616296052933 ===================
epoch no : 9, batch no : 28, total loss : 0.2325820028781891,  classifier :0.02806042693555355, mask: 0.1130501925945282 ===================
epoch no : 9, batch no : 29, total loss : 0.25793179869651794,  classifier :0.03348629176616669, mask: 0.12146810442209244 ===================
epoch no : 9, batch no : 30, total loss : 0.19630861282348633,  classifier :0.023541554808616638, mask: 0.08194833993911743 ===================
epoch no : 9, batch no : 31, total loss : 0.2615429162979126,  classifier :0.027188196778297424, mask: 0.10947071760892868 ===================
epoch no : 9, batch no : 32, total loss : 0.22974589467048645,  classifier :0.02793600969016552, mask: 0.10490963608026505 ===================
epoch no : 9, batch no : 33, total loss : 0.20337682962417603,  classifier :0.024293599650263786, mask: 0.08944197744131088 ===================
epoch no : 9, batch no : 34, total loss : 0.24892465770244598,  classifier :0.040452685207128525, mask: 0.12991999089717865 ===================
epoch no : 9, batch no : 35, total loss : 0.21613338589668274,  classifier :0.023143883794546127, mask: 0.09539424628019333 ===================
epoch no : 9, batch no : 36, total loss : 0.30640482902526855,  classifier :0.04043913632631302, mask: 0.11543146520853043 ===================
epoch no : 9, batch no : 37, total loss : 0.22362889349460602,  classifier :0.02742641791701317, mask: 0.09361471980810165 ===================
epoch no : 9, batch no : 38, total loss : 0.2979860305786133,  classifier :0.03144163265824318, mask: 0.12799647450447083 ===================
epoch no : 9, batch no : 39, total loss : 0.3377252519130707,  classifier :0.021466942504048347, mask: 0.15741996467113495 ===================
epoch no : 9, batch no : 40, total loss : 0.3054390251636505,  classifier :0.033901091665029526, mask: 0.15535148978233337 ===================
epoch no : 9, batch no : 41, total loss : 0.21976523101329803,  classifier :0.02333555556833744, mask: 0.09205854684114456 ===================
epoch no : 9, batch no : 42, total loss : 0.2242085188627243,  classifier :0.03165220096707344, mask: 0.10358817130327225 ===================
epoch no : 9, batch no : 43, total loss : 0.2642914950847626,  classifier :0.02009895257651806, mask: 0.14550797641277313 ===================
epoch no : 9, batch no : 44, total loss : 0.2255353480577469,  classifier :0.031183723360300064, mask: 0.1005154475569725 ===================
epoch no : 9, batch no : 45, total loss : 0.18338802456855774,  classifier :0.019455576315522194, mask: 0.08176632970571518 ===================
epoch no : 9, batch no : 46, total loss : 0.21893754601478577,  classifier :0.019754547625780106, mask: 0.10588899254798889 ===================
epoch no : 9, batch no : 47, total loss : 0.3088749051094055,  classifier :0.02495407871901989, mask: 0.14861609041690826 ===================
epoch no : 9, batch no : 48, total loss : 0.25773999094963074,  classifier :0.017571425065398216, mask: 0.1320980191230774 ===================
epoch no : 9, batch no : 49, total loss : 0.23759211599826813,  classifier :0.024960018694400787, mask: 0.0900687724351883 ===================
epoch no : 9, batch no : 50, total loss : 0.24242158234119415,  classifier :0.017265837639570236, mask: 0.10948663204908371 ===================
epoch no : 9, batch no : 51, total loss : 0.24573487043380737,  classifier :0.03500008583068848, mask: 0.1198461502790451 ===================
epoch no : 9, batch no : 52, total loss : 0.20151250064373016,  classifier :0.01851608045399189, mask: 0.09134656935930252 ===================
epoch no : 9, batch no : 53, total loss : 0.191895991563797,  classifier :0.02094224840402603, mask: 0.09551148861646652 ===================
epoch no : 9, batch no : 54, total loss : 0.21977168321609497,  classifier :0.02324567921459675, mask: 0.10281966626644135 ===================
epoch no : 9, batch no : 55, total loss : 0.2660345137119293,  classifier :0.03076128475368023, mask: 0.10490167886018753 ===================
epoch no : 9, batch no : 56, total loss : 0.2748127281665802,  classifier :0.02224474400281906, mask: 0.12442828714847565 ===================
epoch no : 9, batch no : 57, total loss : 0.3430621922016144,  classifier :0.02582027018070221, mask: 0.1922673135995865 ===================
epoch no : 9, batch no : 58, total loss : 0.3290485739707947,  classifier :0.0340120829641819, mask: 0.1505599319934845 ===================
epoch no : 9, batch no : 59, total loss : 0.30645012855529785,  classifier :0.03212523087859154, mask: 0.12347369641065598 ===================
epoch no : 9, batch no : 60, total loss : 0.2114410102367401,  classifier :0.02013968676328659, mask: 0.09853335469961166 ===================
epoch no : 9, batch no : 61, total loss : 0.23219311237335205,  classifier :0.026422705501317978, mask: 0.11181671172380447 ===================
epoch no : 9, batch no : 62, total loss : 0.200779527425766,  classifier :0.02558724768459797, mask: 0.10939346998929977 ===================
epoch no : 9, batch no : 63, total loss : 0.21952411532402039,  classifier :0.020993558689951897, mask: 0.11568166315555573 ===================
epoch no : 9, batch no : 64, total loss : 0.21408960223197937,  classifier :0.02978578396141529, mask: 0.09196578711271286 ===================
epoch no : 9, batch no : 65, total loss : 0.1688457727432251,  classifier :0.01746988110244274, mask: 0.08219221234321594 ===================
epoch no : 9, batch no : 66, total loss : 0.22987061738967896,  classifier :0.028300954028964043, mask: 0.10623851418495178 ===================
epoch no : 9, batch no : 67, total loss : 0.2188277244567871,  classifier :0.022695785388350487, mask: 0.08378949761390686 ===================
epoch no : 9, batch no : 68, total loss : 0.2024848908185959,  classifier :0.019340956583619118, mask: 0.0866474136710167 ===================
epoch no : 9, batch no : 69, total loss : 0.18858060240745544,  classifier :0.03232599422335625, mask: 0.08525007218122482 ===================
epoch no : 9, batch no : 70, total loss : 0.2538564205169678,  classifier :0.022128574550151825, mask: 0.12954086065292358 ===================
epoch no : 9, batch no : 71, total loss : 0.20821774005889893,  classifier :0.030408430844545364, mask: 0.09688777476549149 ===================
epoch no : 9, batch no : 72, total loss : 0.21256878972053528,  classifier :0.030427835881710052, mask: 0.08475936204195023 ===================
epoch no : 9, batch no : 73, total loss : 0.18298929929733276,  classifier :0.020153537392616272, mask: 0.0798393040895462 ===================
epoch no : 9, batch no : 74, total loss : 0.2025662660598755,  classifier :0.023136189207434654, mask: 0.09350250661373138 ===================
epoch no : 9, batch no : 75, total loss : 0.22235994040966034,  classifier :0.022473514080047607, mask: 0.11492173373699188 ===================
epoch no : 9, batch no : 76, total loss : 0.2308918684720993,  classifier :0.022801227867603302, mask: 0.12112697213888168 ===================
epoch no : 9, batch no : 77, total loss : 0.23476290702819824,  classifier :0.020466946065425873, mask: 0.08775487542152405 ===================
epoch no : 9, batch no : 78, total loss : 0.2534184157848358,  classifier :0.027907906100153923, mask: 0.10740044713020325 ===================
epoch no : 9, batch no : 79, total loss : 0.3034810423851013,  classifier :0.021919207647442818, mask: 0.16704688966274261 ===================
epoch no : 9, batch no : 80, total loss : 0.24043160676956177,  classifier :0.03029448725283146, mask: 0.10205007344484329 ===================
epoch no : 9, batch no : 81, total loss : 0.18922917544841766,  classifier :0.02221839502453804, mask: 0.09942734241485596 ===================
epoch no : 9, batch no : 82, total loss : 0.26737937331199646,  classifier :0.021390238776803017, mask: 0.11178338527679443 ===================
epoch no : 9, batch no : 83, total loss : 0.27153506875038147,  classifier :0.02558531053364277, mask: 0.13871318101882935 ===================
epoch no : 9, batch no : 84, total loss : 0.1884075552225113,  classifier :0.01716507226228714, mask: 0.08804452419281006 ===================
epoch no : 9, batch no : 85, total loss : 0.19709447026252747,  classifier :0.023073425516486168, mask: 0.09065935760736465 ===================
epoch no : 9, batch no : 86, total loss : 0.20559252798557281,  classifier :0.0222274549305439, mask: 0.10172492265701294 ===================
epoch no : 9, batch no : 87, total loss : 0.242313414812088,  classifier :0.022163981571793556, mask: 0.1150248572230339 ===================
epoch no : 9, batch no : 88, total loss : 0.20359887182712555,  classifier :0.0288919098675251, mask: 0.09056504815816879 ===================
epoch no : 9, batch no : 89, total loss : 0.2488628327846527,  classifier :0.03154842555522919, mask: 0.10743435472249985 ===================
epoch no : 9, batch no : 90, total loss : 0.2544640302658081,  classifier :0.025681236758828163, mask: 0.10972277075052261 ===================
epoch no : 9, batch no : 91, total loss : 0.2710120975971222,  classifier :0.02124595083296299, mask: 0.11412229388952255 ===================
epoch no : 9, batch no : 92, total loss : 0.2050638645887375,  classifier :0.020755914971232414, mask: 0.09308231621980667 ===================
epoch no : 9, batch no : 93, total loss : 0.23328948020935059,  classifier :0.02054101601243019, mask: 0.11481950432062149 ===================
epoch no : 9, batch no : 94, total loss : 0.284807413816452,  classifier :0.03809557855129242, mask: 0.14161504805088043 ===================
epoch no : 9, batch no : 95, total loss : 0.20789997279644012,  classifier :0.02743772603571415, mask: 0.08908645063638687 ===================
epoch no : 9, batch no : 96, total loss : 0.2552782893180847,  classifier :0.019799182191491127, mask: 0.11931706219911575 ===================
epoch no : 9, batch no : 97, total loss : 0.1709563285112381,  classifier :0.020661422982811928, mask: 0.0765385702252388 ===================
epoch no : 9, batch no : 98, total loss : 0.25300222635269165,  classifier :0.020100682973861694, mask: 0.12618713080883026 ===================
epoch no : 9, batch no : 99, total loss : 0.24610407650470734,  classifier :0.0238648634403944, mask: 0.12561999261379242 ===================
epoch no : 9, batch no : 100, total loss : 0.20457910001277924,  classifier :0.019343920052051544, mask: 0.10764376074075699 ===================
epoch no : 9, batch no : 101, total loss : 0.22660444676876068,  classifier :0.021208710968494415, mask: 0.10197418928146362 ===================
epoch no : 9, batch no : 102, total loss : 0.23020440340042114,  classifier :0.01735910214483738, mask: 0.09871212393045425 ===================
epoch no : 9, batch no : 103, total loss : 0.2696045935153961,  classifier :0.017283465713262558, mask: 0.13290470838546753 ===================
epoch no : 9, batch no : 104, total loss : 0.19036798179149628,  classifier :0.017976470291614532, mask: 0.0811963602900505 ===================
epoch no : 9, batch no : 105, total loss : 0.20012517273426056,  classifier :0.017793580889701843, mask: 0.09060794115066528 ===================
epoch no : 9, batch no : 106, total loss : 0.18832027912139893,  classifier :0.01885024830698967, mask: 0.08901303261518478 ===================
epoch no : 9, batch no : 107, total loss : 0.22668494284152985,  classifier :0.026807090267539024, mask: 0.1056143194437027 ===================
epoch no : 9, batch no : 108, total loss : 0.2151118367910385,  classifier :0.03516026586294174, mask: 0.09385431557893753 ===================
epoch no : 9, batch no : 109, total loss : 0.22191716730594635,  classifier :0.021937167271971703, mask: 0.12140146642923355 ===================
epoch no : 9, batch no : 110, total loss : 0.197890043258667,  classifier :0.028408847749233246, mask: 0.08831670135259628 ===================
epoch no : 9, batch no : 111, total loss : 0.18579919636249542,  classifier :0.022328536957502365, mask: 0.08040856570005417 ===================
epoch no : 9, batch no : 112, total loss : 0.27473655343055725,  classifier :0.027273662388324738, mask: 0.14347653090953827 ===================
epoch no : 9, batch no : 113, total loss : 0.20153583586215973,  classifier :0.023988522589206696, mask: 0.09664373099803925 ===================
epoch no : 9, batch no : 114, total loss : 0.3016863465309143,  classifier :0.029442673549056053, mask: 0.12267802655696869 ===================
epoch no : 9, batch no : 115, total loss : 0.23292651772499084,  classifier :0.025776926428079605, mask: 0.10851912945508957 ===================
epoch no : 9, batch no : 116, total loss : 0.2676006853580475,  classifier :0.024587705731391907, mask: 0.12166090309619904 ===================
epoch no : 9, batch no : 117, total loss : 0.20438577234745026,  classifier :0.021667346358299255, mask: 0.09622039645910263 ===================
epoch no : 9, batch no : 118, total loss : 0.259613960981369,  classifier :0.02093745954334736, mask: 0.134774848818779 ===================
epoch no : 9, batch no : 119, total loss : 0.2186102718114853,  classifier :0.02255684696137905, mask: 0.09057804197072983 ===================
epoch no : 9, batch no : 120, total loss : 0.22859853506088257,  classifier :0.02585611492395401, mask: 0.10687094926834106 ===================
epoch no : 9, batch no : 121, total loss : 0.2580297291278839,  classifier :0.02311435155570507, mask: 0.10810891538858414 ===================
epoch no : 9, batch no : 122, total loss : 0.2265716791152954,  classifier :0.024999260902404785, mask: 0.09449813514947891 ===================
epoch no : 9, batch no : 123, total loss : 0.22566555440425873,  classifier :0.019449807703495026, mask: 0.12495812028646469 ===================
epoch no : 9, batch no : 124, total loss : 0.2226186990737915,  classifier :0.0194941908121109, mask: 0.1057245209813118 ===================
epoch no : 9, batch no : 125, total loss : 0.2961848974227905,  classifier :0.03585481643676758, mask: 0.1400076448917389 ===================
epoch no : 9, batch no : 126, total loss : 0.2094772458076477,  classifier :0.02023213542997837, mask: 0.11170696467161179 ===================
epoch no : 9, batch no : 127, total loss : 0.24118608236312866,  classifier :0.02170439437031746, mask: 0.11981872469186783 ===================
epoch no : 9, batch no : 128, total loss : 0.2222883701324463,  classifier :0.017904970794916153, mask: 0.09051844477653503 ===================
epoch no : 9, batch no : 129, total loss : 0.26058778166770935,  classifier :0.03208394721150398, mask: 0.08846504986286163 ===================
epoch no : 9, batch no : 130, total loss : 0.23911495506763458,  classifier :0.02214283123612404, mask: 0.09277854859828949 ===================
epoch no : 9, batch no : 131, total loss : 0.21869441866874695,  classifier :0.02590015158057213, mask: 0.10266268253326416 ===================
epoch no : 9, batch no : 132, total loss : 0.30839526653289795,  classifier :0.034758083522319794, mask: 0.13206137716770172 ===================
epoch no : 9, batch no : 133, total loss : 0.20603708922863007,  classifier :0.026289718225598335, mask: 0.0921218991279602 ===================
epoch no : 9, batch no : 134, total loss : 0.20515897870063782,  classifier :0.020767003297805786, mask: 0.10075186938047409 ===================
epoch no : 9, batch no : 135, total loss : 0.2511669099330902,  classifier :0.022624578326940536, mask: 0.10708023607730865 ===================
epoch no : 9, batch no : 136, total loss : 0.20839090645313263,  classifier :0.02117590233683586, mask: 0.09688030183315277 ===================
epoch no : 9, batch no : 137, total loss : 0.2172079235315323,  classifier :0.02485557086765766, mask: 0.10925621539354324 ===================
epoch no : 9, batch no : 138, total loss : 0.1930145025253296,  classifier :0.01847345009446144, mask: 0.08072368800640106 ===================
epoch no : 9, batch no : 139, total loss : 0.2582260072231293,  classifier :0.020102884620428085, mask: 0.09789879620075226 ===================
epoch no : 9, batch no : 140, total loss : 0.2723918557167053,  classifier :0.025085361674427986, mask: 0.10571806877851486 ===================
epoch no : 9, batch no : 141, total loss : 0.3019978702068329,  classifier :0.03517802804708481, mask: 0.14552846550941467 ===================
epoch no : 9, batch no : 142, total loss : 0.21093185245990753,  classifier :0.024026982486248016, mask: 0.09354991465806961 ===================
epoch no : 9, batch no : 143, total loss : 0.4093814790248871,  classifier :0.05370428413152695, mask: 0.16376778483390808 ===================
epoch no : 9, batch no : 144, total loss : 0.17535747587680817,  classifier :0.01751827262341976, mask: 0.0805399939417839 ===================
epoch no : 9, batch no : 145, total loss : 0.22756418585777283,  classifier :0.02713627927005291, mask: 0.10524675995111465 ===================
epoch no : 9, batch no : 146, total loss : 0.24062497913837433,  classifier :0.024467620998620987, mask: 0.10325773060321808 ===================
epoch no : 9, batch no : 147, total loss : 0.19194014370441437,  classifier :0.022390708327293396, mask: 0.08680587261915207 ===================
epoch no : 9, batch no : 148, total loss : 0.17575940489768982,  classifier :0.023918455466628075, mask: 0.08419125527143478 ===================
epoch no : 9, batch no : 149, total loss : 0.22506780922412872,  classifier :0.023418400436639786, mask: 0.09423039853572845 ===================
epoch no : 9, batch no : 150, total loss : 0.2540260851383209,  classifier :0.024489765986800194, mask: 0.10800295323133469 ===================
epoch no : 9, batch no : 151, total loss : 0.1937873214483261,  classifier :0.025608574971556664, mask: 0.0804673582315445 ===================
epoch no : 9, batch no : 152, total loss : 0.19298960268497467,  classifier :0.021909477189183235, mask: 0.07986494898796082 ===================
epoch no : 9, batch no : 153, total loss : 0.20386865735054016,  classifier :0.01865358091890812, mask: 0.09432430565357208 ===================
epoch no : 9, batch no : 154, total loss : 0.19121824204921722,  classifier :0.017632998526096344, mask: 0.07830750942230225 ===================
epoch no : 9, batch no : 155, total loss : 0.32232293486595154,  classifier :0.02900533750653267, mask: 0.1336248368024826 ===================
epoch no : 9, batch no : 156, total loss : 0.23843181133270264,  classifier :0.019478527829051018, mask: 0.11428690701723099 ===================
epoch no : 9, batch no : 157, total loss : 0.25173795223236084,  classifier :0.027933159843087196, mask: 0.11780871450901031 ===================
epoch no : 9, batch no : 158, total loss : 0.2007896453142166,  classifier :0.024649178609251976, mask: 0.09847328811883926 ===================
epoch no : 9, batch no : 159, total loss : 0.17600446939468384,  classifier :0.027040259912610054, mask: 0.08142051100730896 ===================
epoch no : 9, batch no : 160, total loss : 0.21320582926273346,  classifier :0.02138320356607437, mask: 0.0889894962310791 ===================
epoch no : 9, batch no : 161, total loss : 0.2818123400211334,  classifier :0.027979306876659393, mask: 0.10956297814846039 ===================
epoch no : 9, batch no : 162, total loss : 0.22773759067058563,  classifier :0.030670255422592163, mask: 0.09254893660545349 ===================
epoch no : 9, batch no : 163, total loss : 0.27663320302963257,  classifier :0.02495458722114563, mask: 0.12523026764392853 ===================
epoch no : 9, batch no : 164, total loss : 0.2097557634115219,  classifier :0.02228168025612831, mask: 0.09619039297103882 ===================
epoch no : 9, batch no : 165, total loss : 0.21719254553318024,  classifier :0.028821779415011406, mask: 0.09063995629549026 ===================
epoch no : 9, batch no : 166, total loss : 0.19655396044254303,  classifier :0.021771371364593506, mask: 0.10023025423288345 ===================
epoch no : 9, batch no : 167, total loss : 0.20000076293945312,  classifier :0.01889709196984768, mask: 0.08765331655740738 ===================
epoch no : 9, batch no : 168, total loss : 0.24721957743167877,  classifier :0.02599957585334778, mask: 0.11153905093669891 ===================
epoch no : 9, batch no : 169, total loss : 0.22263069450855255,  classifier :0.021686242893338203, mask: 0.08583568036556244 ===================
epoch no : 9, batch no : 170, total loss : 0.23729465901851654,  classifier :0.028017960488796234, mask: 0.11233299225568771 ===================
epoch no : 9, batch no : 171, total loss : 0.1925281137228012,  classifier :0.023573027923703194, mask: 0.1038195788860321 ===================
epoch no : 9, batch no : 172, total loss : 0.20475685596466064,  classifier :0.03263489156961441, mask: 0.09496515244245529 ===================
epoch no : 9, batch no : 173, total loss : 0.2460794746875763,  classifier :0.02650417573750019, mask: 0.09752991795539856 ===================
epoch no : 9, batch no : 174, total loss : 0.27900078892707825,  classifier :0.017404504120349884, mask: 0.12418472766876221 ===================
epoch no : 9, batch no : 175, total loss : 0.31056857109069824,  classifier :0.019451135769486427, mask: 0.13980795443058014 ===================
epoch no : 9, batch no : 176, total loss : 0.31319767236709595,  classifier :0.024709580466151237, mask: 0.11576950550079346 ===================
epoch no : 9, batch no : 177, total loss : 0.32208016514778137,  classifier :0.023979810997843742, mask: 0.14694638550281525 ===================
epoch no : 9, batch no : 178, total loss : 0.2660202980041504,  classifier :0.02939882129430771, mask: 0.10831494629383087 ===================
epoch no : 9, batch no : 179, total loss : 0.2679040729999542,  classifier :0.03620695322751999, mask: 0.1319979876279831 ===================
epoch no : 9, batch no : 180, total loss : 0.2445315271615982,  classifier :0.023507775738835335, mask: 0.11532813310623169 ===================
epoch no : 9, batch no : 181, total loss : 0.2028261125087738,  classifier :0.027413398027420044, mask: 0.09066598862409592 ===================
epoch no : 9, batch no : 182, total loss : 0.22922533750534058,  classifier :0.03616131469607353, mask: 0.10474525392055511 ===================
epoch no : 9, batch no : 183, total loss : 0.2993779182434082,  classifier :0.03431411460042, mask: 0.13235096633434296 ===================
epoch no : 9, batch no : 184, total loss : 0.18646210432052612,  classifier :0.015655379742383957, mask: 0.10229719430208206 ===================
epoch no : 9, batch no : 185, total loss : 0.23399777710437775,  classifier :0.026493288576602936, mask: 0.09827448427677155 ===================
epoch no : 9, batch no : 186, total loss : 0.19853296875953674,  classifier :0.024185962975025177, mask: 0.0927007645368576 ===================
epoch no : 9, batch no : 187, total loss : 0.20849624276161194,  classifier :0.026885071769356728, mask: 0.0992407575249672 ===================
epoch no : 9, batch no : 188, total loss : 0.23775477707386017,  classifier :0.022310646250844002, mask: 0.08861584961414337 ===================
epoch no : 9, batch no : 189, total loss : 0.23436212539672852,  classifier :0.023681944236159325, mask: 0.08787176012992859 ===================
epoch no : 9, batch no : 190, total loss : 0.3279983699321747,  classifier :0.03143216669559479, mask: 0.16771996021270752 ===================
epoch no : 9, batch no : 191, total loss : 0.17656046152114868,  classifier :0.029941409826278687, mask: 0.09257107228040695 ===================
epoch no : 9, batch no : 192, total loss : 0.21371319890022278,  classifier :0.027591321617364883, mask: 0.10819461196660995 ===================
epoch no : 9, batch no : 193, total loss : 0.23006412386894226,  classifier :0.020005544647574425, mask: 0.11319073289632797 ===================
epoch no : 9, batch no : 194, total loss : 0.20184063911437988,  classifier :0.024360010400414467, mask: 0.08747958391904831 ===================
epoch no : 9, batch no : 195, total loss : 0.24895727634429932,  classifier :0.02493252232670784, mask: 0.12439008802175522 ===================
epoch no : 9, batch no : 196, total loss : 0.21993818879127502,  classifier :0.022299019619822502, mask: 0.09899839013814926 ===================
epoch no : 9, batch no : 197, total loss : 0.288153737783432,  classifier :0.021611927077174187, mask: 0.12453412264585495 ===================
epoch no : 9, batch no : 198, total loss : 0.30443933606147766,  classifier :0.02967377007007599, mask: 0.12582162022590637 ===================
epoch no : 9, batch no : 199, total loss : 0.2720039188861847,  classifier :0.01661074534058571, mask: 0.09601159393787384 ===================
epoch no : 9, batch no : 200, total loss : 0.2956099212169647,  classifier :0.031465884298086166, mask: 0.13258323073387146 ===================
epoch no : 9, batch no : 201, total loss : 0.2128872126340866,  classifier :0.023565759882330894, mask: 0.10967162996530533 ===================
epoch no : 9, batch no : 202, total loss : 0.24673393368721008,  classifier :0.02263829857110977, mask: 0.12090524286031723 ===================
epoch no : 9, batch no : 203, total loss : 0.4326033294200897,  classifier :0.059844616800546646, mask: 0.18821053206920624 ===================
epoch no : 9, batch no : 204, total loss : 0.2740953862667084,  classifier :0.024777313694357872, mask: 0.13416136801242828 ===================
epoch no : 9, batch no : 205, total loss : 0.2694903314113617,  classifier :0.01751900650560856, mask: 0.13634566962718964 ===================
epoch no : 9, batch no : 206, total loss : 0.2672562301158905,  classifier :0.030778180807828903, mask: 0.11250285059213638 ===================
epoch no : 9, batch no : 207, total loss : 0.27794957160949707,  classifier :0.026386195793747902, mask: 0.1145678460597992 ===================
epoch no : 9, batch no : 208, total loss : 0.20166738331317902,  classifier :0.02047419175505638, mask: 0.09680069983005524 ===================
epoch no : 9, batch no : 209, total loss : 0.23719316720962524,  classifier :0.028373779729008675, mask: 0.11028986424207687 ===================
epoch no : 9, batch no : 210, total loss : 0.2029324173927307,  classifier :0.022721944376826286, mask: 0.09455881267786026 ===================
epoch no : 9, batch no : 211, total loss : 0.18941684067249298,  classifier :0.023106945678591728, mask: 0.09262301027774811 ===================
epoch no : 9, batch no : 212, total loss : 0.30370667576789856,  classifier :0.04924299195408821, mask: 0.1293264925479889 ===================
epoch no : 9, batch no : 213, total loss : 0.2787967324256897,  classifier :0.029561318457126617, mask: 0.12071773409843445 ===================
epoch no : 9, batch no : 214, total loss : 0.21730369329452515,  classifier :0.03048783726990223, mask: 0.09779530763626099 ===================
epoch no : 9, batch no : 215, total loss : 0.17937380075454712,  classifier :0.021229958161711693, mask: 0.08911127597093582 ===================
epoch no : 9, batch no : 216, total loss : 0.23089507222175598,  classifier :0.024282531812787056, mask: 0.09951826930046082 ===================
epoch no : 9, batch no : 217, total loss : 0.20513617992401123,  classifier :0.02001182734966278, mask: 0.09639468789100647 ===================
epoch no : 9, batch no : 218, total loss : 0.30818018317222595,  classifier :0.017025265842676163, mask: 0.16942396759986877 ===================
epoch no : 9, batch no : 219, total loss : 0.2703195810317993,  classifier :0.021452847868204117, mask: 0.11976802349090576 ===================
epoch no : 9, batch no : 220, total loss : 0.2498263716697693,  classifier :0.022141797468066216, mask: 0.10856419056653976 ===================
epoch no : 9, batch no : 221, total loss : 0.19708861410617828,  classifier :0.03258299082517624, mask: 0.09101171791553497 ===================
epoch no : 9, batch no : 222, total loss : 0.20874232053756714,  classifier :0.016638800501823425, mask: 0.10249654948711395 ===================
epoch no : 9, batch no : 223, total loss : 0.2606929838657379,  classifier :0.024441488087177277, mask: 0.12899020314216614 ===================
epoch no : 9, batch no : 224, total loss : 0.2101895660161972,  classifier :0.035886410623788834, mask: 0.09203127771615982 ===================
epoch no : 9, batch no : 225, total loss : 0.2111886739730835,  classifier :0.02934115380048752, mask: 0.08554338663816452 ===================
epoch no : 9, batch no : 226, total loss : 0.20169414579868317,  classifier :0.023407241329550743, mask: 0.08497489988803864 ===================
epoch no : 9, batch no : 227, total loss : 0.24523168802261353,  classifier :0.025427846238017082, mask: 0.10422166436910629 ===================
epoch no : 9, batch no : 228, total loss : 0.20592626929283142,  classifier :0.02102617360651493, mask: 0.10337124764919281 ===================
epoch no : 9, batch no : 229, total loss : 0.2913408875465393,  classifier :0.023693950846791267, mask: 0.1619771271944046 ===================
epoch no : 9, batch no : 230, total loss : 0.24344369769096375,  classifier :0.02493916265666485, mask: 0.10471078753471375 ===================
epoch no : 9, batch no : 231, total loss : 0.355638712644577,  classifier :0.03645123541355133, mask: 0.1566312164068222 ===================
epoch no : 9, batch no : 232, total loss : 0.26602116227149963,  classifier :0.02134671062231064, mask: 0.13431601226329803 ===================
epoch no : 9, batch no : 233, total loss : 0.28287646174430847,  classifier :0.021293234080076218, mask: 0.10993862897157669 ===================
epoch no : 9, batch no : 234, total loss : 0.23355992138385773,  classifier :0.024076178669929504, mask: 0.1062341257929802 ===================
epoch no : 9, batch no : 235, total loss : 0.21307186782360077,  classifier :0.022041460499167442, mask: 0.10354838520288467 ===================
epoch no : 9, batch no : 236, total loss : 0.18111951649188995,  classifier :0.02388881705701351, mask: 0.08820468932390213 ===================
epoch no : 9, batch no : 237, total loss : 0.19715964794158936,  classifier :0.022725796326994896, mask: 0.08579409122467041 ===================
epoch no : 9, batch no : 238, total loss : 0.19853176176548004,  classifier :0.01531240250915289, mask: 0.09125150740146637 ===================
epoch no : 9, batch no : 239, total loss : 0.26242688298225403,  classifier :0.026134023442864418, mask: 0.11214296519756317 ===================
epoch no : 9, batch no : 240, total loss : 0.22908613085746765,  classifier :0.020269501954317093, mask: 0.09084920585155487 ===================
epoch no : 9, batch no : 241, total loss : 0.24855375289916992,  classifier :0.02217864990234375, mask: 0.09126516431570053 ===================
epoch no : 9, batch no : 242, total loss : 0.3090893626213074,  classifier :0.021886222064495087, mask: 0.14191728830337524 ===================
epoch no : 9, batch no : 243, total loss : 0.1965901106595993,  classifier :0.024860214442014694, mask: 0.08730757236480713 ===================
epoch no : 9, batch no : 244, total loss : 0.23023246228694916,  classifier :0.022814027965068817, mask: 0.12948375940322876 ===================
epoch no : 9, batch no : 245, total loss : 0.19659465551376343,  classifier :0.023173436522483826, mask: 0.08531782776117325 ===================
epoch no : 9, batch no : 246, total loss : 0.22253863513469696,  classifier :0.03418244048953056, mask: 0.09985019266605377 ===================
epoch no : 9, batch no : 247, total loss : 0.21980667114257812,  classifier :0.026319334283471107, mask: 0.10361949354410172 ===================
epoch no : 9, batch no : 248, total loss : 0.2069413661956787,  classifier :0.019720247015357018, mask: 0.09748474508523941 ===================
epoch no : 9, batch no : 249, total loss : 0.21929743885993958,  classifier :0.02332352288067341, mask: 0.10067038983106613 ===================
epoch no : 9, batch no : 250, total loss : 0.21462774276733398,  classifier :0.022141460329294205, mask: 0.10405232757329941 ===================
epoch no : 9, batch no : 251, total loss : 0.2022417038679123,  classifier :0.031036533415317535, mask: 0.08624168485403061 ===================
epoch no : 9, batch no : 252, total loss : 0.19122622907161713,  classifier :0.022686854004859924, mask: 0.09093737602233887 ===================
epoch no : 9, batch no : 253, total loss : 0.24458840489387512,  classifier :0.0331883430480957, mask: 0.10704444348812103 ===================
epoch no : 9, batch no : 254, total loss : 0.29159680008888245,  classifier :0.03877214714884758, mask: 0.12852337956428528 ===================
epoch no : 9, batch no : 255, total loss : 0.260807603597641,  classifier :0.029447009786963463, mask: 0.10879188030958176 ===================
epoch no : 9, batch no : 256, total loss : 0.18660931289196014,  classifier :0.019497908651828766, mask: 0.09286685287952423 ===================
epoch no : 9, batch no : 257, total loss : 0.24538634717464447,  classifier :0.015948612242937088, mask: 0.13023421168327332 ===================
epoch no : 9, batch no : 258, total loss : 0.24495750665664673,  classifier :0.02268342487514019, mask: 0.10388582199811935 ===================
epoch no : 9, batch no : 259, total loss : 0.2464994639158249,  classifier :0.019503938034176826, mask: 0.12024252116680145 ===================
epoch no : 9, batch no : 260, total loss : 0.18991093337535858,  classifier :0.016998084262013435, mask: 0.07955404371023178 ===================
epoch no : 9, batch no : 261, total loss : 0.278089314699173,  classifier :0.028783341869711876, mask: 0.1328396201133728 ===================
epoch no : 9, batch no : 262, total loss : 0.2117558717727661,  classifier :0.023740947246551514, mask: 0.078853540122509 ===================
epoch no : 9, batch no : 263, total loss : 0.3057171404361725,  classifier :0.03426242247223854, mask: 0.13634823262691498 ===================
epoch no : 9, batch no : 264, total loss : 0.20296122133731842,  classifier :0.023112138733267784, mask: 0.10143859684467316 ===================
epoch no : 9, batch no : 265, total loss : 0.215818852186203,  classifier :0.02099175751209259, mask: 0.12944898009300232 ===================
epoch no : 9, batch no : 266, total loss : 0.2535041272640228,  classifier :0.023075152188539505, mask: 0.12500503659248352 ===================
epoch no : 9, batch no : 267, total loss : 0.21125097572803497,  classifier :0.026119360700249672, mask: 0.09646569937467575 ===================
epoch no : 9, batch no : 268, total loss : 0.24965450167655945,  classifier :0.030085889622569084, mask: 0.10126405954360962 ===================
epoch no : 9, batch no : 269, total loss : 0.3343873620033264,  classifier :0.023699235171079636, mask: 0.15298713743686676 ===================
epoch no : 9, batch no : 270, total loss : 0.3278651833534241,  classifier :0.022783048450946808, mask: 0.16631147265434265 ===================
epoch no : 9, batch no : 271, total loss : 0.23005585372447968,  classifier :0.02513144165277481, mask: 0.10470456629991531 ===================
epoch no : 9, batch no : 272, total loss : 0.2986971139907837,  classifier :0.03306636959314346, mask: 0.13206078112125397 ===================
epoch no : 9, batch no : 273, total loss : 0.18834632635116577,  classifier :0.020947525277733803, mask: 0.08922281116247177 ===================
epoch no : 9, batch no : 274, total loss : 0.25004833936691284,  classifier :0.023772822692990303, mask: 0.12456183135509491 ===================
epoch no : 9, batch no : 275, total loss : 0.1927599161863327,  classifier :0.026882696896791458, mask: 0.09691231697797775 ===================
epoch no : 9, batch no : 276, total loss : 0.3780710697174072,  classifier :0.05075238272547722, mask: 0.1623133420944214 ===================
epoch no : 9, batch no : 277, total loss : 0.20132145285606384,  classifier :0.019451629370450974, mask: 0.10543905943632126 ===================
epoch no : 9, batch no : 278, total loss : 0.22722648084163666,  classifier :0.019978925585746765, mask: 0.09628486633300781 ===================
epoch no : 9, batch no : 279, total loss : 0.253421813249588,  classifier :0.023465609177947044, mask: 0.12452700734138489 ===================
epoch no : 9, batch no : 280, total loss : 0.21227607131004333,  classifier :0.030486978590488434, mask: 0.09665045142173767 ===================
epoch no : 9, batch no : 281, total loss : 0.2151782065629959,  classifier :0.026211846619844437, mask: 0.09708145260810852 ===================
epoch no : 9, batch no : 282, total loss : 0.28823545575141907,  classifier :0.016885383054614067, mask: 0.12467476725578308 ===================
epoch no : 9, batch no : 283, total loss : 0.34547480940818787,  classifier :0.017742134630680084, mask: 0.14320790767669678 ===================
epoch no : 9, batch no : 284, total loss : 0.21973934769630432,  classifier :0.01943833753466606, mask: 0.10561946779489517 ===================
epoch no : 9, batch no : 285, total loss : 0.24516183137893677,  classifier :0.03360716998577118, mask: 0.10210959613323212 ===================
epoch no : 9, batch no : 286, total loss : 0.25482121109962463,  classifier :0.03166012838482857, mask: 0.11308367550373077 ===================
epoch no : 9, batch no : 287, total loss : 0.2155705690383911,  classifier :0.025516705587506294, mask: 0.10519921034574509 ===================
epoch no : 9, batch no : 288, total loss : 0.1977158933877945,  classifier :0.019450528547167778, mask: 0.0925208106637001 ===================
epoch no : 9, batch no : 289, total loss : 0.30040252208709717,  classifier :0.03397902473807335, mask: 0.1438159942626953 ===================
epoch no : 9, batch no : 290, total loss : 0.3129453957080841,  classifier :0.032669924199581146, mask: 0.12734109163284302 ===================
epoch no : 9, batch no : 291, total loss : 0.25807857513427734,  classifier :0.023079276084899902, mask: 0.12401961535215378 ===================
epoch no : 9, batch no : 292, total loss : 0.2113581895828247,  classifier :0.02339329943060875, mask: 0.08779845386743546 ===================
epoch no : 9, batch no : 293, total loss : 0.1918403059244156,  classifier :0.02027079649269581, mask: 0.11276248842477798 ===================
epoch no : 9, batch no : 294, total loss : 0.25395119190216064,  classifier :0.02720922790467739, mask: 0.12235651165246964 ===================
epoch no : 9, batch no : 295, total loss : 0.301352322101593,  classifier :0.024716543033719063, mask: 0.1539151668548584 ===================
epoch no : 9, batch no : 296, total loss : 0.21691370010375977,  classifier :0.02132670022547245, mask: 0.09107281267642975 ===================
epoch no : 9, batch no : 297, total loss : 0.31626182794570923,  classifier :0.03637253865599632, mask: 0.13641852140426636 ===================
epoch no : 9, batch no : 298, total loss : 0.2090875506401062,  classifier :0.03003443218767643, mask: 0.08981796354055405 ===================
epoch no : 9, batch no : 299, total loss : 0.23332525789737701,  classifier :0.02804064005613327, mask: 0.11318565905094147 ===================
epoch no : 9, batch no : 300, total loss : 0.3008672297000885,  classifier :0.030546629801392555, mask: 0.11611493676900864 ===================
epoch no : 9, batch no : 301, total loss : 0.20041631162166595,  classifier :0.021867970004677773, mask: 0.10074303299188614 ===================
epoch no : 9, batch no : 302, total loss : 0.20696085691452026,  classifier :0.018483789637684822, mask: 0.11316137760877609 ===================
epoch no : 9, batch no : 303, total loss : 0.23120199143886566,  classifier :0.020665999501943588, mask: 0.11625000834465027 ===================
epoch no : 9, batch no : 304, total loss : 0.2396751344203949,  classifier :0.02445313148200512, mask: 0.10240788757801056 ===================
epoch no : 9, batch no : 305, total loss : 0.23422496020793915,  classifier :0.02102908305823803, mask: 0.12720996141433716 ===================
epoch no : 9, batch no : 306, total loss : 0.19042421877384186,  classifier :0.022100185975432396, mask: 0.09441499412059784 ===================
epoch no : 9, batch no : 307, total loss : 0.2076060175895691,  classifier :0.023875748738646507, mask: 0.09632525593042374 ===================
epoch no : 9, batch no : 308, total loss : 0.18097028136253357,  classifier :0.02398601360619068, mask: 0.08663509041070938 ===================
epoch no : 9, batch no : 309, total loss : 0.2006167471408844,  classifier :0.020494742318987846, mask: 0.08377879112958908 ===================
epoch no : 9, batch no : 310, total loss : 0.1700572371482849,  classifier :0.02271733246743679, mask: 0.07774229347705841 ===================
epoch no : 9, batch no : 311, total loss : 0.2520853579044342,  classifier :0.023150060325860977, mask: 0.08515120297670364 ===================
epoch no : 9, batch no : 312, total loss : 0.2164195477962494,  classifier :0.018775926902890205, mask: 0.09873244166374207 ===================
epoch no : 9, batch no : 313, total loss : 0.24539360404014587,  classifier :0.02802915871143341, mask: 0.09344016760587692 ===================
epoch no : 9, batch no : 314, total loss : 0.20241357386112213,  classifier :0.020577019080519676, mask: 0.09622752666473389 ===================
epoch no : 9, batch no : 315, total loss : 0.2239292412996292,  classifier :0.027368346229195595, mask: 0.11737454682588577 ===================
epoch no : 9, batch no : 316, total loss : 0.1761777400970459,  classifier :0.017418958246707916, mask: 0.08516465127468109 ===================
epoch no : 9, batch no : 317, total loss : 0.2239639312028885,  classifier :0.02166704833507538, mask: 0.08951885998249054 ===================
epoch no : 9, batch no : 318, total loss : 0.2973286211490631,  classifier :0.03082503005862236, mask: 0.12724711000919342 ===================
epoch no : 9, batch no : 319, total loss : 0.23661793768405914,  classifier :0.0364040806889534, mask: 0.10061749815940857 ===================
epoch no : 9, batch no : 320, total loss : 0.2028115838766098,  classifier :0.018611932173371315, mask: 0.08638730645179749 ===================
epoch no : 9, batch no : 321, total loss : 0.23911501467227936,  classifier :0.02579406090080738, mask: 0.10459665209054947 ===================
epoch no : 9, batch no : 322, total loss : 0.21906517446041107,  classifier :0.02809901349246502, mask: 0.11898607760667801 ===================
epoch no : 9, batch no : 323, total loss : 0.23049019277095795,  classifier :0.024501213803887367, mask: 0.1251998394727707 ===================
epoch no : 9, batch no : 324, total loss : 0.1849363148212433,  classifier :0.023083237931132317, mask: 0.08794911205768585 ===================
epoch no : 9, batch no : 325, total loss : 0.27379703521728516,  classifier :0.023878078907728195, mask: 0.14287473261356354 ===================
epoch no : 9, batch no : 326, total loss : 0.23598267138004303,  classifier :0.022274000570178032, mask: 0.11182719469070435 ===================
epoch no : 9, batch no : 327, total loss : 0.23951929807662964,  classifier :0.024399327114224434, mask: 0.11531207710504532 ===================
epoch no : 9, batch no : 328, total loss : 0.23831301927566528,  classifier :0.022571174427866936, mask: 0.11639033257961273 ===================
epoch no : 9, batch no : 329, total loss : 0.17509771883487701,  classifier :0.018350649625062943, mask: 0.09496450424194336 ===================
epoch no : 9, batch no : 330, total loss : 0.20540761947631836,  classifier :0.02767597697675228, mask: 0.09813220053911209 ===================
epoch no : 9, batch no : 331, total loss : 0.294462114572525,  classifier :0.02676401659846306, mask: 0.14241474866867065 ===================
epoch no : 9, batch no : 332, total loss : 0.31553494930267334,  classifier :0.042845048010349274, mask: 0.11759448796510696 ===================
epoch no : 9, batch no : 333, total loss : 0.1559935212135315,  classifier :0.01611793413758278, mask: 0.08429340273141861 ===================
epoch no : 9, batch no : 334, total loss : 0.18167680501937866,  classifier :0.01759386621415615, mask: 0.09216327965259552 ===================
epoch no : 9, batch no : 335, total loss : 0.19747723639011383,  classifier :0.02740110084414482, mask: 0.08515338599681854 ===================
epoch no : 9, batch no : 336, total loss : 0.28872746229171753,  classifier :0.02927354909479618, mask: 0.11852362006902695 ===================
epoch no : 9, batch no : 337, total loss : 0.24752278625965118,  classifier :0.028392845764756203, mask: 0.09484686702489853 ===================
epoch no : 9, batch no : 338, total loss : 0.2566315233707428,  classifier :0.017534056678414345, mask: 0.10879112035036087 ===================
epoch no : 9, batch no : 339, total loss : 0.22155863046646118,  classifier :0.01462071668356657, mask: 0.10270842909812927 ===================
epoch no : 9, batch no : 340, total loss : 0.24270765483379364,  classifier :0.02886367216706276, mask: 0.12314093112945557 ===================
epoch no : 9, batch no : 341, total loss : 0.2817329466342926,  classifier :0.025066111236810684, mask: 0.11636374145746231 ===================
epoch no : 9, batch no : 342, total loss : 0.28246405720710754,  classifier :0.02488126792013645, mask: 0.11627671122550964 ===================
epoch no : 9, batch no : 343, total loss : 0.21939992904663086,  classifier :0.017751306295394897, mask: 0.09173993766307831 ===================
epoch no : 9, batch no : 344, total loss : 0.191450834274292,  classifier :0.022271130234003067, mask: 0.09590204060077667 ===================
epoch no : 9, batch no : 345, total loss : 0.2475021779537201,  classifier :0.02761698141694069, mask: 0.11975675821304321 ===================
epoch no : 9, batch no : 346, total loss : 0.23339754343032837,  classifier :0.035637181252241135, mask: 0.12081947177648544 ===================
epoch no : 9, batch no : 347, total loss : 0.20929592847824097,  classifier :0.03662926331162453, mask: 0.10162032395601273 ===================
epoch no : 9, batch no : 348, total loss : 0.2613331377506256,  classifier :0.03744293004274368, mask: 0.11959986388683319 ===================
epoch no : 9, batch no : 349, total loss : 0.2040892392396927,  classifier :0.026880957186222076, mask: 0.09388093650341034 ===================
epoch no : 9, batch no : 350, total loss : 0.27161306142807007,  classifier :0.02911759912967682, mask: 0.11683478951454163 ===================
epoch no : 9, batch no : 351, total loss : 0.29262349009513855,  classifier :0.025686614215373993, mask: 0.14991562068462372 ===================
epoch no : 9, batch no : 352, total loss : 0.2510513663291931,  classifier :0.021235939115285873, mask: 0.1123083084821701 ===================
epoch no : 9, batch no : 353, total loss : 0.2939518094062805,  classifier :0.029818080365657806, mask: 0.1317063570022583 ===================
epoch no : 9, batch no : 354, total loss : 0.22791273891925812,  classifier :0.025865009054541588, mask: 0.11003243178129196 ===================
epoch no : 9, batch no : 355, total loss : 0.20326566696166992,  classifier :0.02209540456533432, mask: 0.10264398902654648 ===================
epoch no : 9, batch no : 356, total loss : 0.1950804442167282,  classifier :0.026657961308956146, mask: 0.09554336220026016 ===================
epoch no : 9, batch no : 357, total loss : 0.23296962678432465,  classifier :0.02189800515770912, mask: 0.11766752600669861 ===================
epoch no : 9, batch no : 358, total loss : 0.22177807986736298,  classifier :0.02310885861515999, mask: 0.09700823575258255 ===================
epoch no : 9, batch no : 359, total loss : 0.20797812938690186,  classifier :0.020893556997179985, mask: 0.10931862890720367 ===================
epoch no : 9, batch no : 360, total loss : 0.18421339988708496,  classifier :0.021194828674197197, mask: 0.08705023676156998 ===================
epoch no : 9, batch no : 361, total loss : 0.24941803514957428,  classifier :0.024539822712540627, mask: 0.11507488787174225 ===================
epoch no : 9, batch no : 362, total loss : 0.23814456164836884,  classifier :0.027104077860713005, mask: 0.12623462080955505 ===================
epoch no : 9, batch no : 363, total loss : 0.22773034870624542,  classifier :0.026089729741215706, mask: 0.09262802451848984 ===================
epoch no : 9, batch no : 364, total loss : 0.24281354248523712,  classifier :0.031211478635668755, mask: 0.08317665755748749 ===================
epoch no : 9, batch no : 365, total loss : 0.20281744003295898,  classifier :0.02479664236307144, mask: 0.08378303796052933 ===================
epoch no : 9, batch no : 366, total loss : 0.21947026252746582,  classifier :0.01716364175081253, mask: 0.10158680379390717 ===================
epoch no : 9, batch no : 367, total loss : 0.206369087100029,  classifier :0.021349966526031494, mask: 0.09766767919063568 ===================
epoch no : 9, batch no : 368, total loss : 0.20207729935646057,  classifier :0.026031335815787315, mask: 0.08919373899698257 ===================
epoch no : 9, batch no : 369, total loss : 0.2000509649515152,  classifier :0.021013837307691574, mask: 0.08879942446947098 ===================
epoch no : 9, batch no : 370, total loss : 0.17462021112442017,  classifier :0.01614595204591751, mask: 0.08137989789247513 ===================
epoch no : 9, batch no : 371, total loss : 0.24058575928211212,  classifier :0.020218340680003166, mask: 0.13099853694438934 ===================
epoch no : 9, batch no : 372, total loss : 0.20267243683338165,  classifier :0.026603762060403824, mask: 0.09778071939945221 ===================
epoch no : 9, batch no : 373, total loss : 0.25792181491851807,  classifier :0.024550437927246094, mask: 0.12597490847110748 ===================
epoch no : 9, batch no : 374, total loss : 0.196383535861969,  classifier :0.01840207166969776, mask: 0.10591725260019302 ===================
epoch no : 9, batch no : 375, total loss : 0.19674652814865112,  classifier :0.03148098289966583, mask: 0.08867613971233368 ===================
epoch no : 9, batch no : 376, total loss : 0.21654193103313446,  classifier :0.021338006481528282, mask: 0.10166465491056442 ===================
epoch no : 9, batch no : 377, total loss : 0.23188310861587524,  classifier :0.01913565956056118, mask: 0.1063649132847786 ===================
epoch no : 9, batch no : 378, total loss : 0.2825895845890045,  classifier :0.03467937186360359, mask: 0.1037202998995781 ===================
epoch no : 9, batch no : 379, total loss : 0.24691879749298096,  classifier :0.023875266313552856, mask: 0.11547082662582397 ===================
epoch no : 9, batch no : 380, total loss : 0.21139568090438843,  classifier :0.024316828697919846, mask: 0.08808904141187668 ===================
epoch no : 9, batch no : 381, total loss : 0.22687533497810364,  classifier :0.021804146468639374, mask: 0.10578383505344391 ===================
epoch no : 9, batch no : 382, total loss : 0.3848045766353607,  classifier :0.042229387909173965, mask: 0.14575250446796417 ===================
epoch no : 9, batch no : 383, total loss : 0.24234017729759216,  classifier :0.02696392498910427, mask: 0.11411173641681671 ===================
epoch no : 9, batch no : 384, total loss : 0.2787766456604004,  classifier :0.021256547421216965, mask: 0.11773712188005447 ===================
epoch no : 9, batch no : 385, total loss : 0.21512335538864136,  classifier :0.022257167845964432, mask: 0.0996573343873024 ===================
epoch no : 9, batch no : 386, total loss : 0.2280949056148529,  classifier :0.020052101463079453, mask: 0.1284773051738739 ===================
epoch no : 9, batch no : 387, total loss : 0.18113543093204498,  classifier :0.021999375894665718, mask: 0.0744754895567894 ===================
epoch no : 9, batch no : 388, total loss : 0.24560345709323883,  classifier :0.023726915940642357, mask: 0.11364774405956268 ===================
epoch no : 9, batch no : 389, total loss : 0.18186281621456146,  classifier :0.019851911813020706, mask: 0.09276949614286423 ===================
epoch no : 9, batch no : 390, total loss : 0.23785674571990967,  classifier :0.02297111228108406, mask: 0.11059806495904922 ===================
epoch no : 9, batch no : 391, total loss : 0.28012093901634216,  classifier :0.019241735339164734, mask: 0.1408175677061081 ===================
epoch no : 9, batch no : 392, total loss : 0.24680113792419434,  classifier :0.021651100367307663, mask: 0.11770245432853699 ===================
epoch no : 9, batch no : 393, total loss : 0.20501667261123657,  classifier :0.016751909628510475, mask: 0.10530133545398712 ===================
epoch no : 9, batch no : 394, total loss : 0.21798701584339142,  classifier :0.017890689894557, mask: 0.10933683812618256 ===================
epoch no : 9, batch no : 395, total loss : 0.24196119606494904,  classifier :0.023166781291365623, mask: 0.11923575401306152 ===================
epoch no : 9, batch no : 396, total loss : 0.26405397057533264,  classifier :0.020394351333379745, mask: 0.11974053084850311 ===================
epoch no : 9, batch no : 397, total loss : 0.22647440433502197,  classifier :0.025122778490185738, mask: 0.111814945936203 ===================
epoch no : 9, batch no : 398, total loss : 0.27889662981033325,  classifier :0.027006132528185844, mask: 0.13401255011558533 ===================
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch no : 10, batch no : 0, total loss : 0.3459154963493347,  classifier :0.022078029811382294, mask: 0.16033583879470825 ===================
epoch no : 10, batch no : 1, total loss : 0.39941421151161194,  classifier :0.046409666538238525, mask: 0.17049522697925568 ===================
epoch no : 10, batch no : 2, total loss : 0.4288026988506317,  classifier :0.034011874347925186, mask: 0.19503110647201538 ===================
epoch no : 10, batch no : 3, total loss : 0.32582855224609375,  classifier :0.035121671855449677, mask: 0.15682131052017212 ===================
epoch no : 10, batch no : 4, total loss : 0.2989359200000763,  classifier :0.024127397686243057, mask: 0.1561504304409027 ===================
epoch no : 10, batch no : 5, total loss : 0.2093706727027893,  classifier :0.026773033663630486, mask: 0.09583819657564163 ===================
epoch no : 10, batch no : 6, total loss : 0.32655367255210876,  classifier :0.0422532819211483, mask: 0.14367665350437164 ===================
epoch no : 10, batch no : 7, total loss : 0.322177529335022,  classifier :0.02491077408194542, mask: 0.14882442355155945 ===================
epoch no : 10, batch no : 8, total loss : 0.23503011465072632,  classifier :0.037452150136232376, mask: 0.10602499544620514 ===================
epoch no : 10, batch no : 9, total loss : 0.1942513883113861,  classifier :0.023447109386324883, mask: 0.08867625892162323 ===================
epoch no : 10, batch no : 10, total loss : 0.20404617488384247,  classifier :0.02446082793176174, mask: 0.09433364868164062 ===================
epoch no : 10, batch no : 11, total loss : 0.2327263355255127,  classifier :0.020054271444678307, mask: 0.116742804646492 ===================
epoch no : 10, batch no : 12, total loss : 0.31208035349845886,  classifier :0.02432418055832386, mask: 0.12971992790699005 ===================
epoch no : 10, batch no : 13, total loss : 0.18936632573604584,  classifier :0.018450602889060974, mask: 0.08248046040534973 ===================
epoch no : 10, batch no : 14, total loss : 0.22900107502937317,  classifier :0.020994825288653374, mask: 0.10547887533903122 ===================
epoch no : 10, batch no : 15, total loss : 0.3173924684524536,  classifier :0.047705426812171936, mask: 0.13897301256656647 ===================
epoch no : 10, batch no : 16, total loss : 0.4166956841945648,  classifier :0.15409979224205017, mask: 0.13845610618591309 ===================
epoch no : 10, batch no : 17, total loss : 0.5134325623512268,  classifier :0.11170526593923569, mask: 0.2313789427280426 ===================
epoch no : 10, batch no : 18, total loss : 0.27500593662261963,  classifier :0.023700380697846413, mask: 0.12152634561061859 ===================
epoch no : 10, batch no : 19, total loss : 0.23950646817684174,  classifier :0.02235899306833744, mask: 0.12183072417974472 ===================
epoch no : 10, batch no : 20, total loss : 0.24140077829360962,  classifier :0.021413620561361313, mask: 0.1090046763420105 ===================
epoch no : 10, batch no : 21, total loss : 0.23241953551769257,  classifier :0.022033395245671272, mask: 0.10268735140562057 ===================
epoch no : 10, batch no : 22, total loss : 0.24616049230098724,  classifier :0.02572149597108364, mask: 0.13110852241516113 ===================
epoch no : 10, batch no : 23, total loss : 0.24963243305683136,  classifier :0.030677394941449165, mask: 0.11328639835119247 ===================
epoch no : 10, batch no : 24, total loss : 0.23197893798351288,  classifier :0.029811173677444458, mask: 0.10644742101430893 ===================
epoch no : 10, batch no : 25, total loss : 0.2697087228298187,  classifier :0.028707273304462433, mask: 0.11550740152597427 ===================
epoch no : 10, batch no : 26, total loss : 0.23700687289237976,  classifier :0.02157333306968212, mask: 0.11895538866519928 ===================
epoch no : 10, batch no : 27, total loss : 0.31302890181541443,  classifier :0.046267542988061905, mask: 0.13480232656002045 ===================
epoch no : 10, batch no : 28, total loss : 0.279593288898468,  classifier :0.028609372675418854, mask: 0.13796302676200867 ===================
epoch no : 10, batch no : 29, total loss : 0.23261156678199768,  classifier :0.03600545600056648, mask: 0.11181599646806717 ===================
epoch no : 10, batch no : 30, total loss : 0.20147119462490082,  classifier :0.016018005087971687, mask: 0.0912695825099945 ===================
epoch no : 10, batch no : 31, total loss : 0.18419241905212402,  classifier :0.02524108812212944, mask: 0.08677060902118683 ===================
epoch no : 10, batch no : 32, total loss : 0.20480184257030487,  classifier :0.019762704148888588, mask: 0.10557352006435394 ===================
epoch no : 10, batch no : 33, total loss : 0.15413914620876312,  classifier :0.019059136509895325, mask: 0.08240890502929688 ===================
epoch no : 10, batch no : 34, total loss : 0.20592303574085236,  classifier :0.023800699040293694, mask: 0.10941531509160995 ===================
epoch no : 10, batch no : 35, total loss : 0.21307675540447235,  classifier :0.02001228928565979, mask: 0.11654377728700638 ===================
epoch no : 10, batch no : 36, total loss : 0.20042023062705994,  classifier :0.015748711302876472, mask: 0.09295927733182907 ===================
epoch no : 10, batch no : 37, total loss : 0.2084304392337799,  classifier :0.030603010207414627, mask: 0.10653070360422134 ===================
epoch no : 10, batch no : 38, total loss : 0.2209387719631195,  classifier :0.017126642167568207, mask: 0.08643969893455505 ===================
epoch no : 10, batch no : 39, total loss : 0.18644832074642181,  classifier :0.018230561167001724, mask: 0.10783568024635315 ===================
epoch no : 10, batch no : 40, total loss : 0.20724648237228394,  classifier :0.017322195693850517, mask: 0.09237990528345108 ===================
epoch no : 10, batch no : 41, total loss : 0.21835839748382568,  classifier :0.025473445653915405, mask: 0.0965576097369194 ===================
epoch no : 10, batch no : 42, total loss : 0.16249074041843414,  classifier :0.020043490454554558, mask: 0.08065325766801834 ===================
epoch no : 10, batch no : 43, total loss : 0.2115916907787323,  classifier :0.023816194385290146, mask: 0.10722178965806961 ===================
epoch no : 10, batch no : 44, total loss : 0.1769734025001526,  classifier :0.02053525485098362, mask: 0.08718448877334595 ===================
epoch no : 10, batch no : 45, total loss : 0.22837184369564056,  classifier :0.018272729590535164, mask: 0.1156357079744339 ===================
epoch no : 10, batch no : 46, total loss : 0.23069189488887787,  classifier :0.025996020063757896, mask: 0.08914081752300262 ===================
epoch no : 10, batch no : 47, total loss : 0.24898234009742737,  classifier :0.02390558272600174, mask: 0.0931830033659935 ===================
epoch no : 10, batch no : 48, total loss : 0.25875574350357056,  classifier :0.030786806717514992, mask: 0.11040733009576797 ===================
epoch no : 10, batch no : 49, total loss : 0.1882830411195755,  classifier :0.01573771983385086, mask: 0.0851520448923111 ===================
epoch no : 10, batch no : 50, total loss : 0.18615862727165222,  classifier :0.020171940326690674, mask: 0.09189078211784363 ===================
epoch no : 10, batch no : 51, total loss : 0.22876456379890442,  classifier :0.027286527678370476, mask: 0.09298546612262726 ===================
epoch no : 10, batch no : 52, total loss : 0.33320966362953186,  classifier :0.020890282467007637, mask: 0.1325681209564209 ===================
epoch no : 10, batch no : 53, total loss : 0.3326795995235443,  classifier :0.03019961155951023, mask: 0.13491970300674438 ===================
epoch no : 10, batch no : 54, total loss : 0.2819358706474304,  classifier :0.019985316321253777, mask: 0.1436641812324524 ===================
epoch no : 10, batch no : 55, total loss : 0.2350737750530243,  classifier :0.02373996563255787, mask: 0.11019227653741837 ===================
epoch no : 10, batch no : 56, total loss : 0.1648246794939041,  classifier :0.024617668241262436, mask: 0.08271791785955429 ===================
epoch no : 10, batch no : 57, total loss : 0.1776060312986374,  classifier :0.023577243089675903, mask: 0.09868795424699783 ===================
epoch no : 10, batch no : 58, total loss : 0.2682928740978241,  classifier :0.02442684769630432, mask: 0.14399436116218567 ===================
epoch no : 10, batch no : 59, total loss : 0.21995453536510468,  classifier :0.027308303862810135, mask: 0.09601368010044098 ===================
epoch no : 10, batch no : 60, total loss : 0.3513574004173279,  classifier :0.10460885614156723, mask: 0.12382008880376816 ===================
epoch no : 10, batch no : 61, total loss : 0.24300342798233032,  classifier :0.02363760583102703, mask: 0.11902859061956406 ===================
epoch no : 10, batch no : 62, total loss : 0.2573542594909668,  classifier :0.03445965796709061, mask: 0.11482001096010208 ===================
epoch no : 10, batch no : 63, total loss : 0.23624444007873535,  classifier :0.023887772113084793, mask: 0.09928936511278152 ===================
epoch no : 10, batch no : 64, total loss : 0.29364076256752014,  classifier :0.017844825983047485, mask: 0.13280455768108368 ===================
epoch no : 10, batch no : 65, total loss : 0.31199586391448975,  classifier :0.02555568888783455, mask: 0.1609843671321869 ===================
epoch no : 10, batch no : 66, total loss : 0.20218166708946228,  classifier :0.025658369064331055, mask: 0.09292875230312347 ===================
epoch no : 10, batch no : 67, total loss : 0.207985058426857,  classifier :0.017705850303173065, mask: 0.0932897999882698 ===================
epoch no : 10, batch no : 68, total loss : 0.3600390553474426,  classifier :0.04667159914970398, mask: 0.15328970551490784 ===================
epoch no : 10, batch no : 69, total loss : 0.22180452942848206,  classifier :0.028636034578084946, mask: 0.09863069653511047 ===================
epoch no : 10, batch no : 70, total loss : 0.2094275951385498,  classifier :0.025453533977270126, mask: 0.09648559987545013 ===================
epoch no : 10, batch no : 71, total loss : 0.25135713815689087,  classifier :0.03373054787516594, mask: 0.10586364567279816 ===================
epoch no : 10, batch no : 72, total loss : 0.26259881258010864,  classifier :0.025499464944005013, mask: 0.11195878684520721 ===================
epoch no : 10, batch no : 73, total loss : 0.2833903133869171,  classifier :0.03173936530947685, mask: 0.11973810940980911 ===================
epoch no : 10, batch no : 74, total loss : 0.3030136823654175,  classifier :0.02475045621395111, mask: 0.10153350979089737 ===================
epoch no : 10, batch no : 75, total loss : 0.2511754631996155,  classifier :0.01739487797021866, mask: 0.09661296010017395 ===================
epoch no : 10, batch no : 76, total loss : 0.24472621083259583,  classifier :0.02351345866918564, mask: 0.1183956190943718 ===================
epoch no : 10, batch no : 77, total loss : 0.19653645157814026,  classifier :0.01775507442653179, mask: 0.1214672103524208 ===================
epoch no : 10, batch no : 78, total loss : 0.17132824659347534,  classifier :0.015462858602404594, mask: 0.09858614206314087 ===================
epoch no : 10, batch no : 79, total loss : 0.2945347726345062,  classifier :0.03000776655972004, mask: 0.14521640539169312 ===================
epoch no : 10, batch no : 80, total loss : 0.22218206524848938,  classifier :0.01569816656410694, mask: 0.10082471370697021 ===================
epoch no : 10, batch no : 81, total loss : 0.18244656920433044,  classifier :0.01994941383600235, mask: 0.08307704329490662 ===================
epoch no : 10, batch no : 82, total loss : 0.20507954061031342,  classifier :0.016188303008675575, mask: 0.10452350229024887 ===================
epoch no : 10, batch no : 83, total loss : 0.16652904450893402,  classifier :0.0191620122641325, mask: 0.0847831666469574 ===================
epoch no : 10, batch no : 84, total loss : 0.19535963237285614,  classifier :0.021819446235895157, mask: 0.08362355083227158 ===================
epoch no : 10, batch no : 85, total loss : 0.2535390257835388,  classifier :0.027787573635578156, mask: 0.1275620311498642 ===================
epoch no : 10, batch no : 86, total loss : 0.2164953500032425,  classifier :0.027348851785063744, mask: 0.08860234171152115 ===================
epoch no : 10, batch no : 87, total loss : 0.2169470191001892,  classifier :0.022039270028471947, mask: 0.09890317916870117 ===================
epoch no : 10, batch no : 88, total loss : 0.21481360495090485,  classifier :0.026077423244714737, mask: 0.12226403504610062 ===================
epoch no : 10, batch no : 89, total loss : 0.20821692049503326,  classifier :0.017500482499599457, mask: 0.0945114716887474 ===================
epoch no : 10, batch no : 90, total loss : 0.19250266253948212,  classifier :0.020682981237769127, mask: 0.09264291822910309 ===================
epoch no : 10, batch no : 91, total loss : 0.18841584026813507,  classifier :0.016248229891061783, mask: 0.08483326435089111 ===================
epoch no : 10, batch no : 92, total loss : 0.25650134682655334,  classifier :0.023304738104343414, mask: 0.11607518792152405 ===================
epoch no : 10, batch no : 93, total loss : 0.24739976227283478,  classifier :0.020899135619401932, mask: 0.1173550933599472 ===================
epoch no : 10, batch no : 94, total loss : 0.23345401883125305,  classifier :0.03592687100172043, mask: 0.1152794361114502 ===================
epoch no : 10, batch no : 95, total loss : 0.16094161570072174,  classifier :0.01700652949512005, mask: 0.0817103385925293 ===================
epoch no : 10, batch no : 96, total loss : 0.20879919826984406,  classifier :0.021828141063451767, mask: 0.11083687841892242 ===================
epoch no : 10, batch no : 97, total loss : 0.1941690742969513,  classifier :0.02055099792778492, mask: 0.1012866273522377 ===================
epoch no : 10, batch no : 98, total loss : 0.22438564896583557,  classifier :0.025324441492557526, mask: 0.10047072172164917 ===================
epoch no : 10, batch no : 99, total loss : 0.24435856938362122,  classifier :0.02910172939300537, mask: 0.10402847081422806 ===================
epoch no : 10, batch no : 100, total loss : 0.2263120412826538,  classifier :0.018709860742092133, mask: 0.11117717623710632 ===================
epoch no : 10, batch no : 101, total loss : 0.23003213107585907,  classifier :0.02099239081144333, mask: 0.10132794082164764 ===================
epoch no : 10, batch no : 102, total loss : 0.286539763212204,  classifier :0.03367971256375313, mask: 0.09705427289009094 ===================
epoch no : 10, batch no : 103, total loss : 0.25017425417900085,  classifier :0.03022102639079094, mask: 0.0762467235326767 ===================
epoch no : 10, batch no : 104, total loss : 0.2354549616575241,  classifier :0.02498738467693329, mask: 0.11193393915891647 ===================
epoch no : 10, batch no : 105, total loss : 0.3003096282482147,  classifier :0.02115132100880146, mask: 0.1344207227230072 ===================
epoch no : 10, batch no : 106, total loss : 0.23648756742477417,  classifier :0.025248024612665176, mask: 0.10548920184373856 ===================
epoch no : 10, batch no : 107, total loss : 0.21687550842761993,  classifier :0.024023674428462982, mask: 0.10084357112646103 ===================
epoch no : 10, batch no : 108, total loss : 0.18983078002929688,  classifier :0.015730001032352448, mask: 0.10067950189113617 ===================
epoch no : 10, batch no : 109, total loss : 0.29914161562919617,  classifier :0.03253902867436409, mask: 0.15091122686862946 ===================
epoch no : 10, batch no : 110, total loss : 0.1943993866443634,  classifier :0.017155541107058525, mask: 0.0948590412735939 ===================
epoch no : 10, batch no : 111, total loss : 0.2497623860836029,  classifier :0.03306804597377777, mask: 0.09501120448112488 ===================
epoch no : 10, batch no : 112, total loss : 0.23151089251041412,  classifier :0.020252369344234467, mask: 0.10852745920419693 ===================
epoch no : 10, batch no : 113, total loss : 0.1861058622598648,  classifier :0.019855277612805367, mask: 0.0919695645570755 ===================
epoch no : 10, batch no : 114, total loss : 0.20667774975299835,  classifier :0.020518818870186806, mask: 0.10585193336009979 ===================
epoch no : 10, batch no : 115, total loss : 0.2510274648666382,  classifier :0.018977221101522446, mask: 0.14303278923034668 ===================
epoch no : 10, batch no : 116, total loss : 0.23773768544197083,  classifier :0.02040625549852848, mask: 0.12144062668085098 ===================
epoch no : 10, batch no : 117, total loss : 0.2966909408569336,  classifier :0.02337268367409706, mask: 0.14463698863983154 ===================
epoch no : 10, batch no : 118, total loss : 0.22376620769500732,  classifier :0.02143964171409607, mask: 0.10251984000205994 ===================
epoch no : 10, batch no : 119, total loss : 0.1947307139635086,  classifier :0.020949458703398705, mask: 0.08155085146427155 ===================
epoch no : 10, batch no : 120, total loss : 0.2603585422039032,  classifier :0.02816968597471714, mask: 0.12191792577505112 ===================
epoch no : 10, batch no : 121, total loss : 0.19900013506412506,  classifier :0.017115969210863113, mask: 0.08814985305070877 ===================
epoch no : 10, batch no : 122, total loss : 0.230096697807312,  classifier :0.019928358495235443, mask: 0.10810282081365585 ===================
epoch no : 10, batch no : 123, total loss : 0.22491133213043213,  classifier :0.025249870494008064, mask: 0.10765469074249268 ===================
epoch no : 10, batch no : 124, total loss : 0.2083047777414322,  classifier :0.019245393574237823, mask: 0.09873145818710327 ===================
epoch no : 10, batch no : 125, total loss : 0.2071359008550644,  classifier :0.01780041866004467, mask: 0.10102289915084839 ===================
epoch no : 10, batch no : 126, total loss : 0.20022377371788025,  classifier :0.019225534051656723, mask: 0.10745588690042496 ===================
epoch no : 10, batch no : 127, total loss : 0.2012121081352234,  classifier :0.019982218742370605, mask: 0.11692973971366882 ===================
epoch no : 10, batch no : 128, total loss : 0.20439277589321136,  classifier :0.01348019763827324, mask: 0.088283970952034 ===================
epoch no : 10, batch no : 129, total loss : 0.2009187787771225,  classifier :0.028688713908195496, mask: 0.08503395318984985 ===================
epoch no : 10, batch no : 130, total loss : 0.19994717836380005,  classifier :0.030684838071465492, mask: 0.0800609290599823 ===================
epoch no : 10, batch no : 131, total loss : 0.31801003217697144,  classifier :0.05184675008058548, mask: 0.11282707750797272 ===================
epoch no : 10, batch no : 132, total loss : 0.21602314710617065,  classifier :0.02328534610569477, mask: 0.11819876730442047 ===================
epoch no : 10, batch no : 133, total loss : 0.1873500645160675,  classifier :0.021856671199202538, mask: 0.08325815945863724 ===================
epoch no : 10, batch no : 134, total loss : 0.19956132769584656,  classifier :0.026349715888500214, mask: 0.10271969437599182 ===================
epoch no : 10, batch no : 135, total loss : 0.20607371628284454,  classifier :0.024838248267769814, mask: 0.09703439474105835 ===================
epoch no : 10, batch no : 136, total loss : 0.1950007528066635,  classifier :0.023267636075615883, mask: 0.09760827571153641 ===================
epoch no : 10, batch no : 137, total loss : 0.2105131894350052,  classifier :0.022160189226269722, mask: 0.10867699235677719 ===================
epoch no : 10, batch no : 138, total loss : 0.2363290637731552,  classifier :0.027217447757720947, mask: 0.13028346002101898 ===================
epoch no : 10, batch no : 139, total loss : 0.18441931903362274,  classifier :0.014010529033839703, mask: 0.09702721238136292 ===================
epoch no : 10, batch no : 140, total loss : 0.2542951703071594,  classifier :0.031037529930472374, mask: 0.09336040914058685 ===================
epoch no : 10, batch no : 141, total loss : 0.18964077532291412,  classifier :0.019618889316916466, mask: 0.10219137370586395 ===================
epoch no : 10, batch no : 142, total loss : 0.19036999344825745,  classifier :0.016369320452213287, mask: 0.09291624277830124 ===================
epoch no : 10, batch no : 143, total loss : 0.19655029475688934,  classifier :0.02033127285540104, mask: 0.10486624389886856 ===================
epoch no : 10, batch no : 144, total loss : 0.17626702785491943,  classifier :0.020840786397457123, mask: 0.08627662807703018 ===================
epoch no : 10, batch no : 145, total loss : 0.2646470367908478,  classifier :0.03034154698252678, mask: 0.10503794252872467 ===================
epoch no : 10, batch no : 146, total loss : 0.2356008142232895,  classifier :0.020463628694415092, mask: 0.11855600029230118 ===================
epoch no : 10, batch no : 147, total loss : 0.20733138918876648,  classifier :0.014869668520987034, mask: 0.1117304190993309 ===================
epoch no : 10, batch no : 148, total loss : 0.1737152338027954,  classifier :0.024452190846204758, mask: 0.08803126960992813 ===================
epoch no : 10, batch no : 149, total loss : 0.1990046501159668,  classifier :0.01990773156285286, mask: 0.08762511610984802 ===================
epoch no : 10, batch no : 150, total loss : 0.24279804527759552,  classifier :0.02199200913310051, mask: 0.12285991758108139 ===================
epoch no : 10, batch no : 151, total loss : 0.21639567613601685,  classifier :0.02099555730819702, mask: 0.11770273000001907 ===================
epoch no : 10, batch no : 152, total loss : 0.24413873255252838,  classifier :0.018733182922005653, mask: 0.12072275578975677 ===================
epoch no : 10, batch no : 153, total loss : 0.22330455482006073,  classifier :0.023538844659924507, mask: 0.09955418109893799 ===================
epoch no : 10, batch no : 154, total loss : 0.26464372873306274,  classifier :0.0219324491918087, mask: 0.09754309803247452 ===================
epoch no : 10, batch no : 155, total loss : 0.30778658390045166,  classifier :0.0313967727124691, mask: 0.12267351895570755 ===================
epoch no : 10, batch no : 156, total loss : 0.34213992953300476,  classifier :0.09855135530233383, mask: 0.11452015489339828 ===================
epoch no : 10, batch no : 157, total loss : 0.19349201023578644,  classifier :0.022040115669369698, mask: 0.10245107114315033 ===================
epoch no : 10, batch no : 158, total loss : 0.1732163280248642,  classifier :0.016669750213623047, mask: 0.09182700514793396 ===================
epoch no : 10, batch no : 159, total loss : 0.2512850761413574,  classifier :0.022212237119674683, mask: 0.09943898022174835 ===================
epoch no : 10, batch no : 160, total loss : 0.18689978122711182,  classifier :0.01885133981704712, mask: 0.09272782504558563 ===================
epoch no : 10, batch no : 161, total loss : 0.270113080739975,  classifier :0.024362538009881973, mask: 0.09849311411380768 ===================
epoch no : 10, batch no : 162, total loss : 0.22759221494197845,  classifier :0.018176205456256866, mask: 0.10433632135391235 ===================
epoch no : 10, batch no : 163, total loss : 0.233470156788826,  classifier :0.019971342757344246, mask: 0.10251676291227341 ===================
epoch no : 10, batch no : 164, total loss : 0.2017936408519745,  classifier :0.01760444976389408, mask: 0.09814543277025223 ===================
epoch no : 10, batch no : 165, total loss : 0.3008827865123749,  classifier :0.06465388089418411, mask: 0.13705036044120789 ===================
epoch no : 10, batch no : 166, total loss : 0.21507614850997925,  classifier :0.018822133541107178, mask: 0.12194426357746124 ===================
epoch no : 10, batch no : 167, total loss : 0.22388505935668945,  classifier :0.026854893192648888, mask: 0.08838579058647156 ===================
epoch no : 10, batch no : 168, total loss : 0.22894874215126038,  classifier :0.020875582471489906, mask: 0.11524727940559387 ===================
epoch no : 10, batch no : 169, total loss : 0.23744729161262512,  classifier :0.01639481447637081, mask: 0.10384499281644821 ===================
epoch no : 10, batch no : 170, total loss : 0.18768970668315887,  classifier :0.021995583549141884, mask: 0.08773017674684525 ===================
epoch no : 10, batch no : 171, total loss : 0.18479976058006287,  classifier :0.016265608370304108, mask: 0.09589219838380814 ===================
epoch no : 10, batch no : 172, total loss : 0.1666237711906433,  classifier :0.02863624505698681, mask: 0.07015710324048996 ===================
epoch no : 10, batch no : 173, total loss : 0.24583880603313446,  classifier :0.02364387735724449, mask: 0.07385443150997162 ===================
epoch no : 10, batch no : 174, total loss : 0.26743677258491516,  classifier :0.020888319239020348, mask: 0.10942326486110687 ===================
epoch no : 10, batch no : 175, total loss : 0.22085320949554443,  classifier :0.01989385299384594, mask: 0.0948963463306427 ===================
epoch no : 10, batch no : 176, total loss : 0.28171706199645996,  classifier :0.0219902154058218, mask: 0.10771679133176804 ===================
epoch no : 10, batch no : 177, total loss : 0.21993263065814972,  classifier :0.019561009481549263, mask: 0.09068948030471802 ===================
epoch no : 10, batch no : 178, total loss : 0.22632835805416107,  classifier :0.02716437354683876, mask: 0.10934758186340332 ===================
epoch no : 10, batch no : 179, total loss : 0.19927763938903809,  classifier :0.01725834608078003, mask: 0.09407473355531693 ===================
epoch no : 10, batch no : 180, total loss : 0.20025981962680817,  classifier :0.022481780499219894, mask: 0.0955977663397789 ===================
epoch no : 10, batch no : 181, total loss : 0.20977728068828583,  classifier :0.015968753024935722, mask: 0.09675092995166779 ===================
epoch no : 10, batch no : 182, total loss : 0.2720184624195099,  classifier :0.029350318014621735, mask: 0.10795968025922775 ===================
epoch no : 10, batch no : 183, total loss : 0.20212066173553467,  classifier :0.020577184855937958, mask: 0.09100961685180664 ===================
epoch no : 10, batch no : 184, total loss : 0.15274527668952942,  classifier :0.016251109540462494, mask: 0.07393331080675125 ===================
epoch no : 10, batch no : 185, total loss : 0.20131516456604004,  classifier :0.027797332033514977, mask: 0.08468081802129745 ===================
epoch no : 10, batch no : 186, total loss : 0.23877084255218506,  classifier :0.022324606776237488, mask: 0.10913343727588654 ===================
epoch no : 10, batch no : 187, total loss : 0.27291339635849,  classifier :0.03160179778933525, mask: 0.12097254395484924 ===================
epoch no : 10, batch no : 188, total loss : 0.23779229819774628,  classifier :0.017338864505290985, mask: 0.13643009960651398 ===================
epoch no : 10, batch no : 189, total loss : 0.21357481181621552,  classifier :0.024398954585194588, mask: 0.09129652380943298 ===================
epoch no : 10, batch no : 190, total loss : 0.22249971330165863,  classifier :0.026039250195026398, mask: 0.09970540553331375 ===================
epoch no : 10, batch no : 191, total loss : 0.20729798078536987,  classifier :0.01571935974061489, mask: 0.09215392172336578 ===================
epoch no : 10, batch no : 192, total loss : 0.20163843035697937,  classifier :0.017759811133146286, mask: 0.10371800512075424 ===================
epoch no : 10, batch no : 193, total loss : 0.19474121928215027,  classifier :0.014415302313864231, mask: 0.10216692090034485 ===================
epoch no : 10, batch no : 194, total loss : 0.21492323279380798,  classifier :0.023314055055379868, mask: 0.09059896320104599 ===================
epoch no : 10, batch no : 195, total loss : 0.20740406215190887,  classifier :0.023244522511959076, mask: 0.09358885139226913 ===================
epoch no : 10, batch no : 196, total loss : 0.1981910914182663,  classifier :0.021606039255857468, mask: 0.09031439572572708 ===================
epoch no : 10, batch no : 197, total loss : 0.3094936013221741,  classifier :0.0763121172785759, mask: 0.11779941618442535 ===================
epoch no : 10, batch no : 198, total loss : 0.18801306188106537,  classifier :0.017079532146453857, mask: 0.11282464861869812 ===================
epoch no : 10, batch no : 199, total loss : 0.2593729794025421,  classifier :0.028345158323645592, mask: 0.13750316202640533 ===================
epoch no : 10, batch no : 200, total loss : 0.218927800655365,  classifier :0.02825351245701313, mask: 0.10089904814958572 ===================
epoch no : 10, batch no : 201, total loss : 0.22158636152744293,  classifier :0.017556555569171906, mask: 0.10041952133178711 ===================
epoch no : 10, batch no : 202, total loss : 0.23121242225170135,  classifier :0.019661353901028633, mask: 0.08514603972434998 ===================
epoch no : 10, batch no : 203, total loss : 0.25264477729797363,  classifier :0.01746184751391411, mask: 0.10126084834337234 ===================
epoch no : 10, batch no : 204, total loss : 0.2585563361644745,  classifier :0.018891332671046257, mask: 0.11153080314397812 ===================
epoch no : 10, batch no : 205, total loss : 0.22732987999916077,  classifier :0.020286401733756065, mask: 0.13112135231494904 ===================
epoch no : 10, batch no : 206, total loss : 0.3623347580432892,  classifier :0.07311790436506271, mask: 0.15049444139003754 ===================
epoch no : 10, batch no : 207, total loss : 0.25484704971313477,  classifier :0.024177035316824913, mask: 0.12531626224517822 ===================
epoch no : 10, batch no : 208, total loss : 0.2507833242416382,  classifier :0.030411435291171074, mask: 0.12720084190368652 ===================
epoch no : 10, batch no : 209, total loss : 0.27179253101348877,  classifier :0.030712833628058434, mask: 0.09295476973056793 ===================
epoch no : 10, batch no : 210, total loss : 0.22467954456806183,  classifier :0.029490867629647255, mask: 0.0917758122086525 ===================
epoch no : 10, batch no : 211, total loss : 0.32395708560943604,  classifier :0.04019275680184364, mask: 0.14795440435409546 ===================
epoch no : 10, batch no : 212, total loss : 0.19372789561748505,  classifier :0.016491688787937164, mask: 0.09066548198461533 ===================
epoch no : 10, batch no : 213, total loss : 0.21886059641838074,  classifier :0.017993204295635223, mask: 0.12106484919786453 ===================
epoch no : 10, batch no : 214, total loss : 0.17154014110565186,  classifier :0.02727290615439415, mask: 0.08028005063533783 ===================
epoch no : 10, batch no : 215, total loss : 0.2750011682510376,  classifier :0.019579941406846046, mask: 0.1513192504644394 ===================
epoch no : 10, batch no : 216, total loss : 0.28670281171798706,  classifier :0.017344791442155838, mask: 0.13719317317008972 ===================
epoch no : 10, batch no : 217, total loss : 0.2453441172838211,  classifier :0.026625201106071472, mask: 0.10003641992807388 ===================
epoch no : 10, batch no : 218, total loss : 0.23827077448368073,  classifier :0.02413024939596653, mask: 0.11405403167009354 ===================
epoch no : 10, batch no : 219, total loss : 0.1982712745666504,  classifier :0.02840815670788288, mask: 0.09082378447055817 ===================
epoch no : 10, batch no : 220, total loss : 0.36465945839881897,  classifier :0.06814160943031311, mask: 0.1701110303401947 ===================
epoch no : 10, batch no : 221, total loss : 0.16461603343486786,  classifier :0.015351581387221813, mask: 0.10151025652885437 ===================
epoch no : 10, batch no : 222, total loss : 0.27971795201301575,  classifier :0.03870062902569771, mask: 0.13062404096126556 ===================
epoch no : 10, batch no : 223, total loss : 0.23355361819267273,  classifier :0.018269069492816925, mask: 0.12138866633176804 ===================
epoch no : 10, batch no : 224, total loss : 0.22812031209468842,  classifier :0.01900971122086048, mask: 0.09028404206037521 ===================
epoch no : 10, batch no : 225, total loss : 0.18461064994335175,  classifier :0.01542141567915678, mask: 0.09776486456394196 ===================
epoch no : 10, batch no : 226, total loss : 0.2033102959394455,  classifier :0.023335743695497513, mask: 0.09102047979831696 ===================
epoch no : 10, batch no : 227, total loss : 0.20057432353496552,  classifier :0.022487133741378784, mask: 0.0811387374997139 ===================
epoch no : 10, batch no : 228, total loss : 0.2581250071525574,  classifier :0.020515549927949905, mask: 0.11594269424676895 ===================
epoch no : 10, batch no : 229, total loss : 0.29610636830329895,  classifier :0.023245548829436302, mask: 0.13970330357551575 ===================
epoch no : 10, batch no : 230, total loss : 0.1890595257282257,  classifier :0.01963423192501068, mask: 0.08667395263910294 ===================
epoch no : 10, batch no : 231, total loss : 0.22362852096557617,  classifier :0.02388884872198105, mask: 0.07581155002117157 ===================
epoch no : 10, batch no : 232, total loss : 0.28384271264076233,  classifier :0.02877030149102211, mask: 0.11488642543554306 ===================
epoch no : 10, batch no : 233, total loss : 0.21959127485752106,  classifier :0.022748500108718872, mask: 0.10074597597122192 ===================
epoch no : 10, batch no : 234, total loss : 0.28095972537994385,  classifier :0.02858421765267849, mask: 0.12565414607524872 ===================
epoch no : 10, batch no : 235, total loss : 0.27605459094047546,  classifier :0.023914789780974388, mask: 0.13252805173397064 ===================
epoch no : 10, batch no : 236, total loss : 0.21228928864002228,  classifier :0.02285299263894558, mask: 0.10715646296739578 ===================
epoch no : 10, batch no : 237, total loss : 0.20345620810985565,  classifier :0.019384119659662247, mask: 0.10988256335258484 ===================
epoch no : 10, batch no : 238, total loss : 0.21214807033538818,  classifier :0.022306540980935097, mask: 0.0980270728468895 ===================
epoch no : 10, batch no : 239, total loss : 0.32275593280792236,  classifier :0.04620978981256485, mask: 0.13220392167568207 ===================
epoch no : 10, batch no : 240, total loss : 0.17674580216407776,  classifier :0.02279961295425892, mask: 0.08239632844924927 ===================
epoch no : 10, batch no : 241, total loss : 0.20255179703235626,  classifier :0.02550109475851059, mask: 0.07387225329875946 ===================
epoch no : 10, batch no : 242, total loss : 0.2605249881744385,  classifier :0.026541419327259064, mask: 0.07629246264696121 ===================
epoch no : 10, batch no : 243, total loss : 0.2316054403781891,  classifier :0.024430163204669952, mask: 0.10457555949687958 ===================
epoch no : 10, batch no : 244, total loss : 0.21880602836608887,  classifier :0.027825074270367622, mask: 0.09282008558511734 ===================
epoch no : 10, batch no : 245, total loss : 0.20257771015167236,  classifier :0.018875639885663986, mask: 0.09351690858602524 ===================
epoch no : 10, batch no : 246, total loss : 0.21278579533100128,  classifier :0.021295731887221336, mask: 0.10429219901561737 ===================
epoch no : 10, batch no : 247, total loss : 0.16466447710990906,  classifier :0.020022468641400337, mask: 0.07825290411710739 ===================
epoch no : 10, batch no : 248, total loss : 0.20957843959331512,  classifier :0.020464766770601273, mask: 0.09978096187114716 ===================
epoch no : 10, batch no : 249, total loss : 0.20454704761505127,  classifier :0.024221865460276604, mask: 0.09639303386211395 ===================
epoch no : 10, batch no : 250, total loss : 0.21884199976921082,  classifier :0.02267325483262539, mask: 0.10526668280363083 ===================
epoch no : 10, batch no : 251, total loss : 0.22243265807628632,  classifier :0.018390800803899765, mask: 0.12288770079612732 ===================
epoch no : 10, batch no : 252, total loss : 0.25757667422294617,  classifier :0.020657943561673164, mask: 0.12326010316610336 ===================
epoch no : 10, batch no : 253, total loss : 0.17004519701004028,  classifier :0.01784709468483925, mask: 0.07884896546602249 ===================
epoch no : 10, batch no : 254, total loss : 0.22324149310588837,  classifier :0.01764613948762417, mask: 0.10201676189899445 ===================
epoch no : 10, batch no : 255, total loss : 0.35522690415382385,  classifier :0.05458312854170799, mask: 0.1626429408788681 ===================
epoch no : 10, batch no : 256, total loss : 0.19997933506965637,  classifier :0.02347041293978691, mask: 0.09097354859113693 ===================
epoch no : 10, batch no : 257, total loss : 0.24424149096012115,  classifier :0.019596856087446213, mask: 0.10815847665071487 ===================
epoch no : 10, batch no : 258, total loss : 0.2774721682071686,  classifier :0.01972634345293045, mask: 0.1139720231294632 ===================
epoch no : 10, batch no : 259, total loss : 0.25671881437301636,  classifier :0.020320935174822807, mask: 0.11720693111419678 ===================
epoch no : 10, batch no : 260, total loss : 0.21967686712741852,  classifier :0.02288956195116043, mask: 0.08991406857967377 ===================
epoch no : 10, batch no : 261, total loss : 0.23941750824451447,  classifier :0.028124770149588585, mask: 0.11624269187450409 ===================
epoch no : 10, batch no : 262, total loss : 0.22261816263198853,  classifier :0.022959161549806595, mask: 0.1073780506849289 ===================
epoch no : 10, batch no : 263, total loss : 0.2029779851436615,  classifier :0.017176112160086632, mask: 0.11137012392282486 ===================
epoch no : 10, batch no : 264, total loss : 0.24382388591766357,  classifier :0.026328083127737045, mask: 0.08409085124731064 ===================
epoch no : 10, batch no : 265, total loss : 0.26227685809135437,  classifier :0.015631534159183502, mask: 0.11908165365457535 ===================
epoch no : 10, batch no : 266, total loss : 0.2455206960439682,  classifier :0.031961046159267426, mask: 0.09848111122846603 ===================
epoch no : 10, batch no : 267, total loss : 0.24375911056995392,  classifier :0.023938152939081192, mask: 0.11786589026451111 ===================
epoch no : 10, batch no : 268, total loss : 0.22835324704647064,  classifier :0.02798912301659584, mask: 0.09319378435611725 ===================
epoch no : 10, batch no : 269, total loss : 0.29182058572769165,  classifier :0.025020133703947067, mask: 0.1465877741575241 ===================
epoch no : 10, batch no : 270, total loss : 0.3702669143676758,  classifier :0.03343770280480385, mask: 0.17100128531455994 ===================
epoch no : 10, batch no : 271, total loss : 0.25645431876182556,  classifier :0.023836135864257812, mask: 0.10283538699150085 ===================
epoch no : 10, batch no : 272, total loss : 0.23878324031829834,  classifier :0.01794763095676899, mask: 0.1240844801068306 ===================
epoch no : 10, batch no : 273, total loss : 0.22424359619617462,  classifier :0.019913140684366226, mask: 0.09515596926212311 ===================
epoch no : 10, batch no : 274, total loss : 0.2786700427532196,  classifier :0.027276283130049706, mask: 0.13016484677791595 ===================
epoch no : 10, batch no : 275, total loss : 0.2049354761838913,  classifier :0.025071999058127403, mask: 0.09947088360786438 ===================
epoch no : 10, batch no : 276, total loss : 0.2624281644821167,  classifier :0.027238640934228897, mask: 0.12418565154075623 ===================
epoch no : 10, batch no : 277, total loss : 0.217916801571846,  classifier :0.023008979856967926, mask: 0.11136991530656815 ===================
epoch no : 10, batch no : 278, total loss : 0.1717488020658493,  classifier :0.017640171572566032, mask: 0.09344253689050674 ===================
epoch no : 10, batch no : 279, total loss : 0.18391859531402588,  classifier :0.021369144320487976, mask: 0.10225684940814972 ===================
epoch no : 10, batch no : 280, total loss : 0.16751845180988312,  classifier :0.019062045961618423, mask: 0.08870600163936615 ===================
epoch no : 10, batch no : 281, total loss : 0.2546060085296631,  classifier :0.03368382528424263, mask: 0.1108807846903801 ===================
epoch no : 10, batch no : 282, total loss : 0.2563859820365906,  classifier :0.023478077724575996, mask: 0.12522871792316437 ===================
epoch no : 10, batch no : 283, total loss : 0.23730744421482086,  classifier :0.016748832538723946, mask: 0.12303294241428375 ===================
epoch no : 10, batch no : 284, total loss : 0.2742951810359955,  classifier :0.06020531430840492, mask: 0.10881886631250381 ===================
epoch no : 10, batch no : 285, total loss : 0.2045964002609253,  classifier :0.022619687020778656, mask: 0.10361406207084656 ===================
epoch no : 10, batch no : 286, total loss : 0.16975137591362,  classifier :0.017312968149781227, mask: 0.08565040677785873 ===================
epoch no : 10, batch no : 287, total loss : 0.21253353357315063,  classifier :0.02272639237344265, mask: 0.11487743258476257 ===================
epoch no : 10, batch no : 288, total loss : 0.23999179899692535,  classifier :0.02225947007536888, mask: 0.12394486367702484 ===================
epoch no : 10, batch no : 289, total loss : 0.227666437625885,  classifier :0.02216983772814274, mask: 0.0936751738190651 ===================
epoch no : 10, batch no : 290, total loss : 0.2692887485027313,  classifier :0.027136502787470818, mask: 0.12497018277645111 ===================
epoch no : 10, batch no : 291, total loss : 0.20032961666584015,  classifier :0.03274624049663544, mask: 0.09076577425003052 ===================
epoch no : 10, batch no : 292, total loss : 0.1832428276538849,  classifier :0.017925702035427094, mask: 0.08301626145839691 ===================
epoch no : 10, batch no : 293, total loss : 0.17603462934494019,  classifier :0.022810576483607292, mask: 0.07590782642364502 ===================
epoch no : 10, batch no : 294, total loss : 0.18966442346572876,  classifier :0.024843158200383186, mask: 0.10146580636501312 ===================
epoch no : 10, batch no : 295, total loss : 0.18502779304981232,  classifier :0.016412334516644478, mask: 0.09667772054672241 ===================
epoch no : 10, batch no : 296, total loss : 0.18396197259426117,  classifier :0.020768888294696808, mask: 0.09060483425855637 ===================
epoch no : 10, batch no : 297, total loss : 0.17520290613174438,  classifier :0.016359584406018257, mask: 0.08781557530164719 ===================
epoch no : 10, batch no : 298, total loss : 0.1880592256784439,  classifier :0.01792214624583721, mask: 0.09407667815685272 ===================
epoch no : 10, batch no : 299, total loss : 0.1684749573469162,  classifier :0.01890755444765091, mask: 0.07937754690647125 ===================
epoch no : 10, batch no : 300, total loss : 0.28799647092819214,  classifier :0.026795867830514908, mask: 0.0987464115023613 ===================
epoch no : 10, batch no : 301, total loss : 0.22377462685108185,  classifier :0.0206539835780859, mask: 0.08962469547986984 ===================
epoch no : 10, batch no : 302, total loss : 0.21258249878883362,  classifier :0.028144940733909607, mask: 0.09811767935752869 ===================
epoch no : 10, batch no : 303, total loss : 0.22316183149814606,  classifier :0.0201150793582201, mask: 0.09900133311748505 ===================
epoch no : 10, batch no : 304, total loss : 0.23128938674926758,  classifier :0.017723120748996735, mask: 0.10456991195678711 ===================
epoch no : 10, batch no : 305, total loss : 0.3234923779964447,  classifier :0.03890301287174225, mask: 0.10930679738521576 ===================
epoch no : 10, batch no : 306, total loss : 0.22865617275238037,  classifier :0.02119748294353485, mask: 0.10836423188447952 ===================
epoch no : 10, batch no : 307, total loss : 0.3318554759025574,  classifier :0.022802140563726425, mask: 0.13974212110042572 ===================
epoch no : 10, batch no : 308, total loss : 0.34769660234451294,  classifier :0.0375497005879879, mask: 0.10890903323888779 ===================
epoch no : 10, batch no : 309, total loss : 0.25837451219558716,  classifier :0.033351898193359375, mask: 0.10656151920557022 ===================
epoch no : 10, batch no : 310, total loss : 0.19399510324001312,  classifier :0.017770882695913315, mask: 0.09351524710655212 ===================
epoch no : 10, batch no : 311, total loss : 0.21478338539600372,  classifier :0.021017586812376976, mask: 0.08509539812803268 ===================
epoch no : 10, batch no : 312, total loss : 0.326320081949234,  classifier :0.020754940807819366, mask: 0.15861406922340393 ===================
epoch no : 10, batch no : 313, total loss : 0.3253921866416931,  classifier :0.024472331628203392, mask: 0.15183435380458832 ===================
epoch no : 10, batch no : 314, total loss : 0.3011113703250885,  classifier :0.02916763536632061, mask: 0.11772099137306213 ===================
epoch no : 10, batch no : 315, total loss : 0.20387370884418488,  classifier :0.032873522490262985, mask: 0.08594619482755661 ===================
epoch no : 10, batch no : 316, total loss : 0.248101606965065,  classifier :0.026547878980636597, mask: 0.10607676208019257 ===================
epoch no : 10, batch no : 317, total loss : 0.18895360827445984,  classifier :0.01637471467256546, mask: 0.0935947373509407 ===================
epoch no : 10, batch no : 318, total loss : 0.17663559317588806,  classifier :0.022996898740530014, mask: 0.07671337574720383 ===================
epoch no : 10, batch no : 319, total loss : 0.29288747906684875,  classifier :0.051993563771247864, mask: 0.11184622347354889 ===================
epoch no : 10, batch no : 320, total loss : 0.2456079125404358,  classifier :0.02185809798538685, mask: 0.14509668946266174 ===================
epoch no : 10, batch no : 321, total loss : 0.24370594322681427,  classifier :0.02176661603152752, mask: 0.11760738492012024 ===================
epoch no : 10, batch no : 322, total loss : 0.27797526121139526,  classifier :0.024862509220838547, mask: 0.11777667701244354 ===================
epoch no : 10, batch no : 323, total loss : 0.29931217432022095,  classifier :0.042464978992938995, mask: 0.13240835070610046 ===================
epoch no : 10, batch no : 324, total loss : 0.20185396075248718,  classifier :0.024757804349064827, mask: 0.08607165515422821 ===================
epoch no : 10, batch no : 325, total loss : 0.23021166026592255,  classifier :0.027759084478020668, mask: 0.11522392183542252 ===================
epoch no : 10, batch no : 326, total loss : 0.2365008145570755,  classifier :0.025216786190867424, mask: 0.09436637908220291 ===================
epoch no : 10, batch no : 327, total loss : 0.38467082381248474,  classifier :0.05757550895214081, mask: 0.12144902348518372 ===================
epoch no : 10, batch no : 328, total loss : 0.2584591507911682,  classifier :0.02327541448175907, mask: 0.13103660941123962 ===================
epoch no : 10, batch no : 329, total loss : 0.18914948403835297,  classifier :0.014249502681195736, mask: 0.10485969483852386 ===================
epoch no : 10, batch no : 330, total loss : 0.15907464921474457,  classifier :0.01969206891953945, mask: 0.0846867486834526 ===================
epoch no : 10, batch no : 331, total loss : 0.17230382561683655,  classifier :0.017994849011301994, mask: 0.08981535583734512 ===================
epoch no : 10, batch no : 332, total loss : 0.20957264304161072,  classifier :0.019280683249235153, mask: 0.09050252288579941 ===================
epoch no : 10, batch no : 333, total loss : 0.16460804641246796,  classifier :0.01756558194756508, mask: 0.08740703761577606 ===================
epoch no : 10, batch no : 334, total loss : 0.18333281576633453,  classifier :0.014217115007340908, mask: 0.08837222307920456 ===================
epoch no : 10, batch no : 335, total loss : 0.19912153482437134,  classifier :0.02079659327864647, mask: 0.09255894273519516 ===================
epoch no : 10, batch no : 336, total loss : 0.21218891441822052,  classifier :0.026259858161211014, mask: 0.11244584619998932 ===================
epoch no : 10, batch no : 337, total loss : 0.2222079038619995,  classifier :0.020687995478510857, mask: 0.10783613473176956 ===================
epoch no : 10, batch no : 338, total loss : 0.1885552555322647,  classifier :0.020623022690415382, mask: 0.09708438813686371 ===================
epoch no : 10, batch no : 339, total loss : 0.19572418928146362,  classifier :0.0173022598028183, mask: 0.10271193087100983 ===================
epoch no : 10, batch no : 340, total loss : 0.2435467690229416,  classifier :0.018068348988890648, mask: 0.11898166686296463 ===================
epoch no : 10, batch no : 341, total loss : 0.2471926063299179,  classifier :0.028151769191026688, mask: 0.11622001975774765 ===================
epoch no : 10, batch no : 342, total loss : 0.20240023732185364,  classifier :0.014742493629455566, mask: 0.09965898841619492 ===================
epoch no : 10, batch no : 343, total loss : 0.19367793202400208,  classifier :0.023765170946717262, mask: 0.08806144446134567 ===================
epoch no : 10, batch no : 344, total loss : 0.18206477165222168,  classifier :0.02041347697377205, mask: 0.09029445052146912 ===================
epoch no : 10, batch no : 345, total loss : 0.18044662475585938,  classifier :0.016793208196759224, mask: 0.09683892130851746 ===================
epoch no : 10, batch no : 346, total loss : 0.1939801573753357,  classifier :0.020080681890249252, mask: 0.09385275840759277 ===================
epoch no : 10, batch no : 347, total loss : 0.2257191389799118,  classifier :0.030752280727028847, mask: 0.11318109929561615 ===================
epoch no : 10, batch no : 348, total loss : 0.19528312981128693,  classifier :0.018149947747588158, mask: 0.081886425614357 ===================
epoch no : 10, batch no : 349, total loss : 0.30524876713752747,  classifier :0.033769525587558746, mask: 0.12502741813659668 ===================
epoch no : 10, batch no : 350, total loss : 0.21654263138771057,  classifier :0.02587335743010044, mask: 0.08927921950817108 ===================
epoch no : 10, batch no : 351, total loss : 0.2409248650074005,  classifier :0.03538795933127403, mask: 0.11743850260972977 ===================
epoch no : 10, batch no : 352, total loss : 0.1761161983013153,  classifier :0.020944079384207726, mask: 0.08775436878204346 ===================
epoch no : 10, batch no : 353, total loss : 0.20370915532112122,  classifier :0.020922143012285233, mask: 0.09782633930444717 ===================
epoch no : 10, batch no : 354, total loss : 0.1671772450208664,  classifier :0.018921809270977974, mask: 0.08975107967853546 ===================
epoch no : 10, batch no : 355, total loss : 0.2818240225315094,  classifier :0.03533562645316124, mask: 0.12839165329933167 ===================
epoch no : 10, batch no : 356, total loss : 0.18581348657608032,  classifier :0.015685901045799255, mask: 0.0940714105963707 ===================
epoch no : 10, batch no : 357, total loss : 0.21099252998828888,  classifier :0.018216826021671295, mask: 0.0990624949336052 ===================
epoch no : 10, batch no : 358, total loss : 0.22203142940998077,  classifier :0.022837527096271515, mask: 0.08958512544631958 ===================
epoch no : 10, batch no : 359, total loss : 0.2155688852071762,  classifier :0.023218391463160515, mask: 0.10040940344333649 ===================
epoch no : 10, batch no : 360, total loss : 0.20224232971668243,  classifier :0.0280133169144392, mask: 0.08598288148641586 ===================
epoch no : 10, batch no : 361, total loss : 0.20748773217201233,  classifier :0.025504672899842262, mask: 0.1040380671620369 ===================
epoch no : 10, batch no : 362, total loss : 0.2383369654417038,  classifier :0.022913530468940735, mask: 0.12451758235692978 ===================
epoch no : 10, batch no : 363, total loss : 0.157859206199646,  classifier :0.015068233013153076, mask: 0.08264176547527313 ===================
epoch no : 10, batch no : 364, total loss : 0.19931718707084656,  classifier :0.018538424745202065, mask: 0.10611430555582047 ===================
epoch no : 10, batch no : 365, total loss : 0.18450523912906647,  classifier :0.023246316239237785, mask: 0.09631258249282837 ===================
epoch no : 10, batch no : 366, total loss : 0.29466724395751953,  classifier :0.028657827526330948, mask: 0.17536887526512146 ===================
epoch no : 10, batch no : 367, total loss : 0.27926644682884216,  classifier :0.02454410307109356, mask: 0.13413332402706146 ===================
epoch no : 10, batch no : 368, total loss : 0.31472843885421753,  classifier :0.023290883749723434, mask: 0.12414828687906265 ===================
epoch no : 10, batch no : 369, total loss : 0.22335855662822723,  classifier :0.018500356003642082, mask: 0.09660045057535172 ===================
epoch no : 10, batch no : 370, total loss : 0.21779581904411316,  classifier :0.02564810775220394, mask: 0.09798470884561539 ===================
epoch no : 10, batch no : 371, total loss : 0.19075369834899902,  classifier :0.020880544558167458, mask: 0.09041813015937805 ===================
epoch no : 10, batch no : 372, total loss : 0.21217378973960876,  classifier :0.014878964051604271, mask: 0.12394987046718597 ===================
epoch no : 10, batch no : 373, total loss : 0.18275412917137146,  classifier :0.01986413076519966, mask: 0.08296087384223938 ===================
epoch no : 10, batch no : 374, total loss : 0.18233206868171692,  classifier :0.022477569058537483, mask: 0.08030413836240768 ===================
epoch no : 10, batch no : 375, total loss : 0.212296262383461,  classifier :0.019757773727178574, mask: 0.12201425433158875 ===================
epoch no : 10, batch no : 376, total loss : 0.1778150349855423,  classifier :0.016825366765260696, mask: 0.09158360958099365 ===================
epoch no : 10, batch no : 377, total loss : 0.1936502605676651,  classifier :0.022221772000193596, mask: 0.09381841868162155 ===================
epoch no : 10, batch no : 378, total loss : 0.20673362910747528,  classifier :0.017494358122348785, mask: 0.11479782313108444 ===================
epoch no : 10, batch no : 379, total loss : 0.1805780977010727,  classifier :0.015368737280368805, mask: 0.09897926449775696 ===================
epoch no : 10, batch no : 380, total loss : 0.1575535535812378,  classifier :0.01851840130984783, mask: 0.07581476867198944 ===================
epoch no : 10, batch no : 381, total loss : 0.261181116104126,  classifier :0.023959660902619362, mask: 0.15263256430625916 ===================
epoch no : 10, batch no : 382, total loss : 0.29136282205581665,  classifier :0.02356843091547489, mask: 0.13519060611724854 ===================
epoch no : 10, batch no : 383, total loss : 0.24931444227695465,  classifier :0.020919784903526306, mask: 0.11827565729618073 ===================
epoch no : 10, batch no : 384, total loss : 0.29637202620506287,  classifier :0.02144400216639042, mask: 0.14118683338165283 ===================
epoch no : 10, batch no : 385, total loss : 0.30486711859703064,  classifier :0.029042651876807213, mask: 0.14198097586631775 ===================
epoch no : 10, batch no : 386, total loss : 0.197657510638237,  classifier :0.019112830981612206, mask: 0.09348689019680023 ===================
epoch no : 10, batch no : 387, total loss : 0.18760736286640167,  classifier :0.019501807168126106, mask: 0.08443644642829895 ===================
epoch no : 10, batch no : 388, total loss : 0.18953996896743774,  classifier :0.025891005992889404, mask: 0.0927184671163559 ===================
epoch no : 10, batch no : 389, total loss : 0.20781439542770386,  classifier :0.02109581232070923, mask: 0.0923762321472168 ===================
epoch no : 10, batch no : 390, total loss : 0.21822227537631989,  classifier :0.01822364144027233, mask: 0.10840346664190292 ===================
epoch no : 10, batch no : 391, total loss : 0.2014109045267105,  classifier :0.021570993587374687, mask: 0.0912446454167366 ===================
epoch no : 10, batch no : 392, total loss : 0.2005796581506729,  classifier :0.023995233699679375, mask: 0.08875925838947296 ===================
epoch no : 10, batch no : 393, total loss : 0.19819778203964233,  classifier :0.020172862336039543, mask: 0.10184028744697571 ===================
epoch no : 10, batch no : 394, total loss : 0.15316899120807648,  classifier :0.017105737701058388, mask: 0.07588988542556763 ===================
epoch no : 10, batch no : 395, total loss : 0.15578702092170715,  classifier :0.01767047867178917, mask: 0.07782032340765 ===================
epoch no : 10, batch no : 396, total loss : 0.18556250631809235,  classifier :0.01450770441442728, mask: 0.0949816107749939 ===================
epoch no : 10, batch no : 397, total loss : 0.21465462446212769,  classifier :0.02355108968913555, mask: 0.11180185526609421 ===================
epoch no : 10, batch no : 398, total loss : 0.1638094037771225,  classifier :0.013818103820085526, mask: 0.07451838999986649 ===================
creating index...
index created!
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
Test:  [   0/3188]  eta: 0:36:02  model_time: 0.1127 (0.1127)  evaluator_time: 0.0279 (0.0279)  time: 0.6783  data: 0.3849  max mem: 9500
Test:  [ 100/3188]  eta: 0:10:46  model_time: 0.0833 (0.0879)  evaluator_time: 0.0077 (0.0101)  time: 0.2005  data: 0.0048  max mem: 9500
Test:  [ 200/3188]  eta: 0:10:16  model_time: 0.0859 (0.0874)  evaluator_time: 0.0088 (0.0098)  time: 0.2080  data: 0.0053  max mem: 9500
Test:  [ 300/3188]  eta: 0:09:53  model_time: 0.0849 (0.0871)  evaluator_time: 0.0091 (0.0097)  time: 0.2043  data: 0.0055  max mem: 9500
Test:  [ 400/3188]  eta: 0:09:34  model_time: 0.0850 (0.0876)  evaluator_time: 0.0081 (0.0099)  time: 0.2030  data: 0.0052  max mem: 9500
Test:  [ 500/3188]  eta: 0:09:14  model_time: 0.0861 (0.0879)  evaluator_time: 0.0100 (0.0099)  time: 0.2075  data: 0.0045  max mem: 9500
Test:  [ 600/3188]  eta: 0:08:53  model_time: 0.0837 (0.0879)  evaluator_time: 0.0100 (0.0100)  time: 0.2008  data: 0.0055  max mem: 9500
Test:  [ 700/3188]  eta: 0:08:31  model_time: 0.0871 (0.0879)  evaluator_time: 0.0079 (0.0099)  time: 0.2047  data: 0.0044  max mem: 9500
Test:  [ 800/3188]  eta: 0:08:10  model_time: 0.0836 (0.0878)  evaluator_time: 0.0096 (0.0099)  time: 0.1989  data: 0.0045  max mem: 9500
Test:  [ 900/3188]  eta: 0:07:50  model_time: 0.0901 (0.0878)  evaluator_time: 0.0106 (0.0100)  time: 0.2222  data: 0.0053  max mem: 9500
Test:  [1000/3188]  eta: 0:07:29  model_time: 0.0849 (0.0878)  evaluator_time: 0.0087 (0.0100)  time: 0.2049  data: 0.0053  max mem: 9500
Test:  [1100/3188]  eta: 0:07:09  model_time: 0.0837 (0.0878)  evaluator_time: 0.0084 (0.0101)  time: 0.1976  data: 0.0050  max mem: 9500
Test:  [1200/3188]  eta: 0:06:49  model_time: 0.0875 (0.0879)  evaluator_time: 0.0085 (0.0101)  time: 0.2129  data: 0.0050  max mem: 9500
Test:  [1300/3188]  eta: 0:06:27  model_time: 0.0836 (0.0878)  evaluator_time: 0.0096 (0.0100)  time: 0.1975  data: 0.0046  max mem: 9500
Test:  [1400/3188]  eta: 0:06:06  model_time: 0.0835 (0.0877)  evaluator_time: 0.0077 (0.0099)  time: 0.1942  data: 0.0045  max mem: 9500
Test:  [1500/3188]  eta: 0:05:46  model_time: 0.0851 (0.0876)  evaluator_time: 0.0077 (0.0098)  time: 0.2038  data: 0.0045  max mem: 9500
Test:  [1600/3188]  eta: 0:05:25  model_time: 0.0830 (0.0875)  evaluator_time: 0.0074 (0.0098)  time: 0.1924  data: 0.0044  max mem: 9500
Test:  [1700/3188]  eta: 0:05:04  model_time: 0.0846 (0.0873)  evaluator_time: 0.0105 (0.0097)  time: 0.2023  data: 0.0054  max mem: 9500
Test:  [1800/3188]  eta: 0:04:43  model_time: 0.0843 (0.0872)  evaluator_time: 0.0083 (0.0097)  time: 0.1985  data: 0.0052  max mem: 9500
Test:  [1900/3188]  eta: 0:04:22  model_time: 0.0843 (0.0871)  evaluator_time: 0.0075 (0.0097)  time: 0.1952  data: 0.0046  max mem: 9500
Test:  [2000/3188]  eta: 0:04:02  model_time: 0.0860 (0.0871)  evaluator_time: 0.0086 (0.0097)  time: 0.2028  data: 0.0048  max mem: 9500
Test:  [2100/3188]  eta: 0:03:42  model_time: 0.0874 (0.0871)  evaluator_time: 0.0080 (0.0097)  time: 0.2096  data: 0.0046  max mem: 9500
Test:  [2200/3188]  eta: 0:03:21  model_time: 0.0876 (0.0871)  evaluator_time: 0.0100 (0.0097)  time: 0.2038  data: 0.0047  max mem: 9500
Test:  [2300/3188]  eta: 0:03:01  model_time: 0.0893 (0.0871)  evaluator_time: 0.0084 (0.0097)  time: 0.2230  data: 0.0048  max mem: 9500
Test:  [2400/3188]  eta: 0:02:40  model_time: 0.0845 (0.0872)  evaluator_time: 0.0080 (0.0097)  time: 0.1962  data: 0.0046  max mem: 9500
Test:  [2500/3188]  eta: 0:02:20  model_time: 0.0847 (0.0871)  evaluator_time: 0.0081 (0.0097)  time: 0.2011  data: 0.0046  max mem: 9500
Test:  [2600/3188]  eta: 0:01:59  model_time: 0.0849 (0.0871)  evaluator_time: 0.0074 (0.0096)  time: 0.1978  data: 0.0046  max mem: 9500
Test:  [2700/3188]  eta: 0:01:39  model_time: 0.0865 (0.0871)  evaluator_time: 0.0076 (0.0096)  time: 0.2051  data: 0.0045  max mem: 9500
Test:  [2800/3188]  eta: 0:01:19  model_time: 0.0878 (0.0871)  evaluator_time: 0.0084 (0.0096)  time: 0.2074  data: 0.0044  max mem: 9500
Test:  [2900/3188]  eta: 0:00:58  model_time: 0.0853 (0.0871)  evaluator_time: 0.0081 (0.0096)  time: 0.1997  data: 0.0045  max mem: 9500
Test:  [3000/3188]  eta: 0:00:38  model_time: 0.0838 (0.0870)  evaluator_time: 0.0078 (0.0096)  time: 0.1946  data: 0.0046  max mem: 9500
Test:  [3100/3188]  eta: 0:00:17  model_time: 0.0845 (0.0870)  evaluator_time: 0.0093 (0.0096)  time: 0.2021  data: 0.0051  max mem: 9500
Test:  [3187/3188]  eta: 0:00:00  model_time: 0.0864 (0.0870)  evaluator_time: 0.0079 (0.0096)  time: 0.2041  data: 0.0046  max mem: 9500
Test: Total time: 0:10:49 (0.2037 s / it)
Averaged stats: model_time: 0.0864 (0.0870)  evaluator_time: 0.0079 (0.0096)
Accumulating evaluation results...
DONE-test (t=1.47s).
Accumulating evaluation results...
DONE-test (t=1.43s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.844
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.958
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.954
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.844
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.891
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.902
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.902
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.902
IoU metric: segm
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.837
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.958
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.949
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.837
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.879
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.891
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.891
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.891
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch no : 11, batch no : 0, total loss : 0.23291794955730438,  classifier :0.024184836074709892, mask: 0.1123581975698471 ===================
epoch no : 11, batch no : 1, total loss : 0.24573054909706116,  classifier :0.030745450407266617, mask: 0.09572664648294449 ===================
epoch no : 11, batch no : 2, total loss : 0.16853255033493042,  classifier :0.01857495680451393, mask: 0.07693496346473694 ===================
epoch no : 11, batch no : 3, total loss : 0.20232293009757996,  classifier :0.020959334447979927, mask: 0.09459961205720901 ===================
epoch no : 11, batch no : 4, total loss : 0.21396008133888245,  classifier :0.0200651902705431, mask: 0.11368681490421295 ===================
epoch no : 11, batch no : 5, total loss : 0.21912316977977753,  classifier :0.02269086241722107, mask: 0.11506756395101547 ===================
epoch no : 11, batch no : 6, total loss : 0.21700651943683624,  classifier :0.013744399882853031, mask: 0.12983328104019165 ===================
epoch no : 11, batch no : 7, total loss : 0.24994513392448425,  classifier :0.03664235398173332, mask: 0.11811724305152893 ===================
epoch no : 11, batch no : 8, total loss : 0.23447659611701965,  classifier :0.019379818812012672, mask: 0.11034857481718063 ===================
epoch no : 11, batch no : 9, total loss : 0.22633053362369537,  classifier :0.025271154940128326, mask: 0.10937777161598206 ===================
epoch no : 11, batch no : 10, total loss : 0.2110224813222885,  classifier :0.01735874079167843, mask: 0.08536513894796371 ===================
epoch no : 11, batch no : 11, total loss : 0.23285190761089325,  classifier :0.025885088369250298, mask: 0.09361971169710159 ===================
epoch no : 11, batch no : 12, total loss : 0.2038992941379547,  classifier :0.025804808363318443, mask: 0.09644946455955505 ===================
epoch no : 11, batch no : 13, total loss : 0.18950577080249786,  classifier :0.028313955292105675, mask: 0.08743104338645935 ===================
epoch no : 11, batch no : 14, total loss : 0.24794769287109375,  classifier :0.020642055198550224, mask: 0.11890532821416855 ===================
epoch no : 11, batch no : 15, total loss : 0.19309282302856445,  classifier :0.02340191975235939, mask: 0.07656633853912354 ===================
epoch no : 11, batch no : 16, total loss : 0.20975735783576965,  classifier :0.02595888078212738, mask: 0.09603800624608994 ===================
epoch no : 11, batch no : 17, total loss : 0.2409331351518631,  classifier :0.02052549459040165, mask: 0.1211620420217514 ===================
epoch no : 11, batch no : 18, total loss : 0.18683435022830963,  classifier :0.019863270223140717, mask: 0.07253260910511017 ===================
epoch no : 11, batch no : 19, total loss : 0.23894816637039185,  classifier :0.027390705421566963, mask: 0.08562635630369186 ===================
epoch no : 11, batch no : 20, total loss : 0.2900346517562866,  classifier :0.023285260424017906, mask: 0.14625723659992218 ===================
epoch no : 11, batch no : 21, total loss : 0.16804178059101105,  classifier :0.015238468535244465, mask: 0.08755684643983841 ===================
epoch no : 11, batch no : 22, total loss : 0.26161491870880127,  classifier :0.01581159047782421, mask: 0.1118038222193718 ===================
epoch no : 11, batch no : 23, total loss : 0.20320354402065277,  classifier :0.025795679539442062, mask: 0.09103721380233765 ===================
epoch no : 11, batch no : 24, total loss : 0.2649386525154114,  classifier :0.024567056447267532, mask: 0.09733489155769348 ===================
epoch no : 11, batch no : 25, total loss : 0.3583221435546875,  classifier :0.044164083898067474, mask: 0.14612998068332672 ===================
epoch no : 11, batch no : 26, total loss : 0.24638919532299042,  classifier :0.023670481517910957, mask: 0.12463928759098053 ===================
epoch no : 11, batch no : 27, total loss : 0.2807714641094208,  classifier :0.05016687139868736, mask: 0.12435072660446167 ===================
epoch no : 11, batch no : 28, total loss : 0.16759662330150604,  classifier :0.016306506469845772, mask: 0.09151121973991394 ===================
epoch no : 11, batch no : 29, total loss : 0.200985848903656,  classifier :0.024669025093317032, mask: 0.10513833910226822 ===================
epoch no : 11, batch no : 30, total loss : 0.19941850006580353,  classifier :0.016424953937530518, mask: 0.10339181125164032 ===================
epoch no : 11, batch no : 31, total loss : 0.24988053739070892,  classifier :0.01630789041519165, mask: 0.11810555309057236 ===================
epoch no : 11, batch no : 32, total loss : 0.27451005578041077,  classifier :0.02156819775700569, mask: 0.10477668792009354 ===================
epoch no : 11, batch no : 33, total loss : 0.27018117904663086,  classifier :0.022545836865901947, mask: 0.12913112342357635 ===================
epoch no : 11, batch no : 34, total loss : 0.220067098736763,  classifier :0.031924985349178314, mask: 0.09060044586658478 ===================
epoch no : 11, batch no : 35, total loss : 0.3760209083557129,  classifier :0.049915608018636703, mask: 0.15121713280677795 ===================
epoch no : 11, batch no : 36, total loss : 0.22181081771850586,  classifier :0.022803423926234245, mask: 0.09668398648500443 ===================
epoch no : 11, batch no : 37, total loss : 0.23214507102966309,  classifier :0.023046471178531647, mask: 0.1002512127161026 ===================
epoch no : 11, batch no : 38, total loss : 0.18935978412628174,  classifier :0.02291918732225895, mask: 0.08709272742271423 ===================
epoch no : 11, batch no : 39, total loss : 0.2073923647403717,  classifier :0.023136353120207787, mask: 0.09315099567174911 ===================
epoch no : 11, batch no : 40, total loss : 0.23195716738700867,  classifier :0.018874647095799446, mask: 0.09253054857254028 ===================
epoch no : 11, batch no : 41, total loss : 0.23083136975765228,  classifier :0.022165609523653984, mask: 0.10394866019487381 ===================
epoch no : 11, batch no : 42, total loss : 0.2822090983390808,  classifier :0.03851744532585144, mask: 0.13166171312332153 ===================
epoch no : 11, batch no : 43, total loss : 0.18428929150104523,  classifier :0.018615232780575752, mask: 0.11185109615325928 ===================
epoch no : 11, batch no : 44, total loss : 0.22395585477352142,  classifier :0.024017512798309326, mask: 0.12217727303504944 ===================
epoch no : 11, batch no : 45, total loss : 0.20038999617099762,  classifier :0.021982336416840553, mask: 0.09453264623880386 ===================
epoch no : 11, batch no : 46, total loss : 0.21685846149921417,  classifier :0.01712574064731598, mask: 0.09382730722427368 ===================
epoch no : 11, batch no : 47, total loss : 0.20736968517303467,  classifier :0.016857419162988663, mask: 0.08194124698638916 ===================
epoch no : 11, batch no : 48, total loss : 0.24954219162464142,  classifier :0.027408214285969734, mask: 0.11164279282093048 ===================
epoch no : 11, batch no : 49, total loss : 0.2617950439453125,  classifier :0.019716890528798103, mask: 0.1092071607708931 ===================
epoch no : 11, batch no : 50, total loss : 0.2094922959804535,  classifier :0.021463222801685333, mask: 0.09187551587820053 ===================
epoch no : 11, batch no : 51, total loss : 0.1791979819536209,  classifier :0.01869199238717556, mask: 0.08684910833835602 ===================
epoch no : 11, batch no : 52, total loss : 0.22164934873580933,  classifier :0.022540809586644173, mask: 0.11181367188692093 ===================
epoch no : 11, batch no : 53, total loss : 0.241568922996521,  classifier :0.03769121691584587, mask: 0.10945585370063782 ===================
epoch no : 11, batch no : 54, total loss : 0.19336730241775513,  classifier :0.021298673003911972, mask: 0.08917100727558136 ===================
epoch no : 11, batch no : 55, total loss : 0.22322212159633636,  classifier :0.019443828612565994, mask: 0.11932139098644257 ===================
epoch no : 11, batch no : 56, total loss : 0.27292531728744507,  classifier :0.030758783221244812, mask: 0.1254391074180603 ===================
epoch no : 11, batch no : 57, total loss : 0.2984534204006195,  classifier :0.03807449713349342, mask: 0.14258037507534027 ===================
epoch no : 11, batch no : 58, total loss : 0.2418384552001953,  classifier :0.023388894274830818, mask: 0.11358430981636047 ===================
epoch no : 11, batch no : 59, total loss : 0.18175196647644043,  classifier :0.018565449863672256, mask: 0.08470852673053741 ===================
epoch no : 11, batch no : 60, total loss : 0.24740289151668549,  classifier :0.03484182432293892, mask: 0.10709244757890701 ===================
epoch no : 11, batch no : 61, total loss : 0.2081880122423172,  classifier :0.020080342888832092, mask: 0.0947980210185051 ===================
epoch no : 11, batch no : 62, total loss : 0.19922669231891632,  classifier :0.027399031445384026, mask: 0.08945796638727188 ===================
epoch no : 11, batch no : 63, total loss : 0.18372471630573273,  classifier :0.016811151057481766, mask: 0.08519376069307327 ===================
epoch no : 11, batch no : 64, total loss : 0.22448745369911194,  classifier :0.022926053032279015, mask: 0.1108449175953865 ===================
epoch no : 11, batch no : 65, total loss : 0.254121869802475,  classifier :0.02775661088526249, mask: 0.10707452893257141 ===================
epoch no : 11, batch no : 66, total loss : 0.22958824038505554,  classifier :0.026136789470911026, mask: 0.12564490735530853 ===================
epoch no : 11, batch no : 67, total loss : 0.26519447565078735,  classifier :0.020615432411432266, mask: 0.128163680434227 ===================
epoch no : 11, batch no : 68, total loss : 0.2728230953216553,  classifier :0.0313151590526104, mask: 0.10928262025117874 ===================
epoch no : 11, batch no : 69, total loss : 0.2588020861148834,  classifier :0.01721775531768799, mask: 0.10356924682855606 ===================
epoch no : 11, batch no : 70, total loss : 0.2579778730869293,  classifier :0.020101632922887802, mask: 0.09386467933654785 ===================
epoch no : 11, batch no : 71, total loss : 0.30261707305908203,  classifier :0.02277197875082493, mask: 0.11874623596668243 ===================
epoch no : 11, batch no : 72, total loss : 0.18807052075862885,  classifier :0.022008640691637993, mask: 0.08397959172725677 ===================
epoch no : 11, batch no : 73, total loss : 0.19493912160396576,  classifier :0.022733289748430252, mask: 0.09461609274148941 ===================
epoch no : 11, batch no : 74, total loss : 0.2211381047964096,  classifier :0.027791744098067284, mask: 0.09761196374893188 ===================
epoch no : 11, batch no : 75, total loss : 0.2361147701740265,  classifier :0.024666307494044304, mask: 0.08564537763595581 ===================
epoch no : 11, batch no : 76, total loss : 0.18016669154167175,  classifier :0.017357774078845978, mask: 0.07792440056800842 ===================
epoch no : 11, batch no : 77, total loss : 0.23208710551261902,  classifier :0.030470049008727074, mask: 0.11150160431861877 ===================
epoch no : 11, batch no : 78, total loss : 0.16173703968524933,  classifier :0.017712309956550598, mask: 0.08120663464069366 ===================
epoch no : 11, batch no : 79, total loss : 0.24001052975654602,  classifier :0.020922137424349785, mask: 0.11892864108085632 ===================
epoch no : 11, batch no : 80, total loss : 0.19000999629497528,  classifier :0.016672348603606224, mask: 0.10708630830049515 ===================
epoch no : 11, batch no : 81, total loss : 0.18369798362255096,  classifier :0.022995008155703545, mask: 0.09202849119901657 ===================
epoch no : 11, batch no : 82, total loss : 0.1598639190196991,  classifier :0.01961684040725231, mask: 0.08034312725067139 ===================
epoch no : 11, batch no : 83, total loss : 0.15510983765125275,  classifier :0.015674713999032974, mask: 0.08416033536195755 ===================
epoch no : 11, batch no : 84, total loss : 0.16787448525428772,  classifier :0.016237949952483177, mask: 0.08745218813419342 ===================
epoch no : 11, batch no : 85, total loss : 0.2172684371471405,  classifier :0.021955622360110283, mask: 0.1308881938457489 ===================
epoch no : 11, batch no : 86, total loss : 0.1818869560956955,  classifier :0.0213482566177845, mask: 0.10126440972089767 ===================
epoch no : 11, batch no : 87, total loss : 0.19281798601150513,  classifier :0.017426634207367897, mask: 0.1132412850856781 ===================
epoch no : 11, batch no : 88, total loss : 0.21181775629520416,  classifier :0.017117943614721298, mask: 0.10024631023406982 ===================
epoch no : 11, batch no : 89, total loss : 0.18286412954330444,  classifier :0.012418756261467934, mask: 0.08133695274591446 ===================
epoch no : 11, batch no : 90, total loss : 0.20502616465091705,  classifier :0.016612093895673752, mask: 0.10081885755062103 ===================
epoch no : 11, batch no : 91, total loss : 0.1397877037525177,  classifier :0.01662481762468815, mask: 0.06652019917964935 ===================
epoch no : 11, batch no : 92, total loss : 0.19496002793312073,  classifier :0.017543300986289978, mask: 0.10224513709545135 ===================
epoch no : 11, batch no : 93, total loss : 0.22312027215957642,  classifier :0.01934298314154148, mask: 0.10314863920211792 ===================
epoch no : 11, batch no : 94, total loss : 0.22114472091197968,  classifier :0.021900301799178123, mask: 0.10383963584899902 ===================
epoch no : 11, batch no : 95, total loss : 0.26704972982406616,  classifier :0.019544297829270363, mask: 0.1021534875035286 ===================
epoch no : 11, batch no : 96, total loss : 0.2042931318283081,  classifier :0.020009273663163185, mask: 0.08660995215177536 ===================
epoch no : 11, batch no : 97, total loss : 0.2067696899175644,  classifier :0.029177270829677582, mask: 0.09081730246543884 ===================
epoch no : 11, batch no : 98, total loss : 0.18118663132190704,  classifier :0.0199030302464962, mask: 0.07428610324859619 ===================
epoch no : 11, batch no : 99, total loss : 0.18673019111156464,  classifier :0.022252950817346573, mask: 0.08612030744552612 ===================
epoch no : 11, batch no : 100, total loss : 0.2251562476158142,  classifier :0.029079465195536613, mask: 0.09630326926708221 ===================
epoch no : 11, batch no : 101, total loss : 0.23339881002902985,  classifier :0.03249510005116463, mask: 0.09112945944070816 ===================
epoch no : 11, batch no : 102, total loss : 0.19248560070991516,  classifier :0.02415047399699688, mask: 0.08337711542844772 ===================
epoch no : 11, batch no : 103, total loss : 0.2082398235797882,  classifier :0.02311800606548786, mask: 0.09287963807582855 ===================
epoch no : 11, batch no : 104, total loss : 0.18038219213485718,  classifier :0.017435196787118912, mask: 0.09610090404748917 ===================
epoch no : 11, batch no : 105, total loss : 0.1654542088508606,  classifier :0.014623988419771194, mask: 0.08802110701799393 ===================
epoch no : 11, batch no : 106, total loss : 0.17554040253162384,  classifier :0.024889102205634117, mask: 0.08031051605939865 ===================
epoch no : 11, batch no : 107, total loss : 0.2170347422361374,  classifier :0.016935385763645172, mask: 0.08565475046634674 ===================
epoch no : 11, batch no : 108, total loss : 0.29967668652534485,  classifier :0.023239757865667343, mask: 0.143437460064888 ===================
epoch no : 11, batch no : 109, total loss : 0.2007637619972229,  classifier :0.02100331522524357, mask: 0.10148484259843826 ===================
epoch no : 11, batch no : 110, total loss : 0.18309906125068665,  classifier :0.014278550632297993, mask: 0.09183020144701004 ===================
epoch no : 11, batch no : 111, total loss : 0.19977128505706787,  classifier :0.019288791343569756, mask: 0.11452127248048782 ===================
epoch no : 11, batch no : 112, total loss : 0.15712296962738037,  classifier :0.016325637698173523, mask: 0.0882662907242775 ===================
epoch no : 11, batch no : 113, total loss : 0.33229535818099976,  classifier :0.05256834253668785, mask: 0.12943245470523834 ===================
epoch no : 11, batch no : 114, total loss : 0.13509483635425568,  classifier :0.015683982521295547, mask: 0.06054743379354477 ===================
epoch no : 11, batch no : 115, total loss : 0.20236244797706604,  classifier :0.015586014837026596, mask: 0.12172234058380127 ===================
epoch no : 11, batch no : 116, total loss : 0.20924745500087738,  classifier :0.02628500759601593, mask: 0.10368980467319489 ===================
epoch no : 11, batch no : 117, total loss : 0.19712017476558685,  classifier :0.016504479572176933, mask: 0.09818761795759201 ===================
epoch no : 11, batch no : 118, total loss : 0.19487325847148895,  classifier :0.020257284864783287, mask: 0.09966948628425598 ===================
epoch no : 11, batch no : 119, total loss : 0.1875590980052948,  classifier :0.01717202179133892, mask: 0.0907820463180542 ===================
epoch no : 11, batch no : 120, total loss : 0.21181125938892365,  classifier :0.020451119169592857, mask: 0.0891108512878418 ===================
epoch no : 11, batch no : 121, total loss : 0.17836657166481018,  classifier :0.015473650768399239, mask: 0.08757691830396652 ===================
epoch no : 11, batch no : 122, total loss : 0.21311961114406586,  classifier :0.018378693610429764, mask: 0.10635349899530411 ===================
epoch no : 11, batch no : 123, total loss : 0.2108849287033081,  classifier :0.0189063623547554, mask: 0.11108182370662689 ===================
epoch no : 11, batch no : 124, total loss : 0.2269524186849594,  classifier :0.016861479729413986, mask: 0.12321187555789948 ===================
epoch no : 11, batch no : 125, total loss : 0.18142756819725037,  classifier :0.01696731522679329, mask: 0.09210505336523056 ===================
epoch no : 11, batch no : 126, total loss : 0.21685104072093964,  classifier :0.02198248915374279, mask: 0.09959050267934799 ===================
epoch no : 11, batch no : 127, total loss : 0.19171375036239624,  classifier :0.02579990215599537, mask: 0.09594790637493134 ===================
epoch no : 11, batch no : 128, total loss : 0.21287043392658234,  classifier :0.018767300993204117, mask: 0.0946764200925827 ===================
epoch no : 11, batch no : 129, total loss : 0.21395224332809448,  classifier :0.026252444833517075, mask: 0.08960089087486267 ===================
epoch no : 11, batch no : 130, total loss : 0.17063121497631073,  classifier :0.01529287826269865, mask: 0.08629748225212097 ===================
epoch no : 11, batch no : 131, total loss : 0.28236013650894165,  classifier :0.02697983756661415, mask: 0.15378707647323608 ===================
epoch no : 11, batch no : 132, total loss : 0.2648894488811493,  classifier :0.036465153098106384, mask: 0.11616019159555435 ===================
epoch no : 11, batch no : 133, total loss : 0.2034120410680771,  classifier :0.01615273579955101, mask: 0.08626823872327805 ===================
epoch no : 11, batch no : 134, total loss : 0.20752467215061188,  classifier :0.021866776049137115, mask: 0.09690764546394348 ===================
epoch no : 11, batch no : 135, total loss : 0.2051658183336258,  classifier :0.02766852080821991, mask: 0.09528174251317978 ===================
epoch no : 11, batch no : 136, total loss : 0.1892111450433731,  classifier :0.014567251317203045, mask: 0.10563816875219345 ===================
epoch no : 11, batch no : 137, total loss : 0.20731884241104126,  classifier :0.026194211095571518, mask: 0.0982290729880333 ===================
epoch no : 11, batch no : 138, total loss : 0.2701798379421234,  classifier :0.028642071411013603, mask: 0.13110633194446564 ===================
epoch no : 11, batch no : 139, total loss : 0.29801836609840393,  classifier :0.018906109035015106, mask: 0.15910829603672028 ===================
epoch no : 11, batch no : 140, total loss : 0.34170040488243103,  classifier :0.02676655538380146, mask: 0.1321641355752945 ===================
epoch no : 11, batch no : 141, total loss : 0.26740434765815735,  classifier :0.022804461419582367, mask: 0.10146042704582214 ===================
epoch no : 11, batch no : 142, total loss : 0.2650684416294098,  classifier :0.0247243233025074, mask: 0.13290882110595703 ===================
epoch no : 11, batch no : 143, total loss : 0.2011290341615677,  classifier :0.019252164289355278, mask: 0.10169914364814758 ===================
epoch no : 11, batch no : 144, total loss : 0.182206392288208,  classifier :0.027707673609256744, mask: 0.08991575241088867 ===================
epoch no : 11, batch no : 145, total loss : 0.19120290875434875,  classifier :0.01862107403576374, mask: 0.07745084911584854 ===================
epoch no : 11, batch no : 146, total loss : 0.1994498372077942,  classifier :0.018388820812106133, mask: 0.07887197285890579 ===================
epoch no : 11, batch no : 147, total loss : 0.20757946372032166,  classifier :0.0206163227558136, mask: 0.08627955615520477 ===================
epoch no : 11, batch no : 148, total loss : 0.24392937123775482,  classifier :0.021051743999123573, mask: 0.11527467519044876 ===================
epoch no : 11, batch no : 149, total loss : 0.22029204666614532,  classifier :0.02763606607913971, mask: 0.10538896918296814 ===================
epoch no : 11, batch no : 150, total loss : 0.25904443860054016,  classifier :0.02871531993150711, mask: 0.12598004937171936 ===================
epoch no : 11, batch no : 151, total loss : 0.21987862884998322,  classifier :0.024876678362488747, mask: 0.11130902916193008 ===================
epoch no : 11, batch no : 152, total loss : 0.1586480736732483,  classifier :0.016197694465517998, mask: 0.08861423283815384 ===================
epoch no : 11, batch no : 153, total loss : 0.16268756985664368,  classifier :0.018383489921689034, mask: 0.07707933336496353 ===================
epoch no : 11, batch no : 154, total loss : 0.19421899318695068,  classifier :0.016496211290359497, mask: 0.09114061295986176 ===================
epoch no : 11, batch no : 155, total loss : 0.1805875301361084,  classifier :0.021283958107233047, mask: 0.08739142119884491 ===================
epoch no : 11, batch no : 156, total loss : 0.23391509056091309,  classifier :0.019532224163413048, mask: 0.09472233802080154 ===================
epoch no : 11, batch no : 157, total loss : 0.27388066053390503,  classifier :0.02107103168964386, mask: 0.1434967815876007 ===================
epoch no : 11, batch no : 158, total loss : 0.23250220715999603,  classifier :0.019765594974160194, mask: 0.10670695453882217 ===================
epoch no : 11, batch no : 159, total loss : 0.19340354204177856,  classifier :0.0174249280244112, mask: 0.07911770790815353 ===================
epoch no : 11, batch no : 160, total loss : 0.23388755321502686,  classifier :0.015320912934839725, mask: 0.12286731600761414 ===================
epoch no : 11, batch no : 161, total loss : 0.19260771572589874,  classifier :0.018840506672859192, mask: 0.09331458061933517 ===================
epoch no : 11, batch no : 162, total loss : 0.24148251116275787,  classifier :0.031101517379283905, mask: 0.10342149436473846 ===================
epoch no : 11, batch no : 163, total loss : 0.19016560912132263,  classifier :0.022279027849435806, mask: 0.08875660598278046 ===================
epoch no : 11, batch no : 164, total loss : 0.18441545963287354,  classifier :0.02358587272465229, mask: 0.07155292481184006 ===================
epoch no : 11, batch no : 165, total loss : 0.1881970465183258,  classifier :0.013249285519123077, mask: 0.10128720849752426 ===================
epoch no : 11, batch no : 166, total loss : 0.1636500358581543,  classifier :0.015172496438026428, mask: 0.08365903049707413 ===================
epoch no : 11, batch no : 167, total loss : 0.26108500361442566,  classifier :0.028677430003881454, mask: 0.12318312376737595 ===================
epoch no : 11, batch no : 168, total loss : 0.2171531319618225,  classifier :0.025534892454743385, mask: 0.09698094427585602 ===================
epoch no : 11, batch no : 169, total loss : 0.20287935435771942,  classifier :0.018627071753144264, mask: 0.11510347574949265 ===================
epoch no : 11, batch no : 170, total loss : 0.18299782276153564,  classifier :0.019796425476670265, mask: 0.09513094276189804 ===================
epoch no : 11, batch no : 171, total loss : 0.20120005309581757,  classifier :0.022294627502560616, mask: 0.09591995179653168 ===================
epoch no : 11, batch no : 172, total loss : 0.29999321699142456,  classifier :0.04601249843835831, mask: 0.14970430731773376 ===================
epoch no : 11, batch no : 173, total loss : 0.270397812128067,  classifier :0.022693151608109474, mask: 0.1286672055721283 ===================
epoch no : 11, batch no : 174, total loss : 0.20587214827537537,  classifier :0.028677308931946754, mask: 0.1045762300491333 ===================
epoch no : 11, batch no : 175, total loss : 0.1807168871164322,  classifier :0.023009851574897766, mask: 0.08720565587282181 ===================
epoch no : 11, batch no : 176, total loss : 0.18395400047302246,  classifier :0.01693672500550747, mask: 0.08845721930265427 ===================
epoch no : 11, batch no : 177, total loss : 0.27952203154563904,  classifier :0.037859413772821426, mask: 0.12841971218585968 ===================
epoch no : 11, batch no : 178, total loss : 0.15345169603824615,  classifier :0.021986931562423706, mask: 0.07335580885410309 ===================
epoch no : 11, batch no : 179, total loss : 0.23888029158115387,  classifier :0.018929505720734596, mask: 0.09653626382350922 ===================
epoch no : 11, batch no : 180, total loss : 0.2828938663005829,  classifier :0.026495961472392082, mask: 0.10771989822387695 ===================
epoch no : 11, batch no : 181, total loss : 0.261345237493515,  classifier :0.026509832590818405, mask: 0.1180013120174408 ===================
epoch no : 11, batch no : 182, total loss : 0.22742392122745514,  classifier :0.015171067789196968, mask: 0.10642018914222717 ===================
epoch no : 11, batch no : 183, total loss : 0.1690433919429779,  classifier :0.014904849231243134, mask: 0.08879918605089188 ===================
epoch no : 11, batch no : 184, total loss : 0.20127612352371216,  classifier :0.023177120834589005, mask: 0.10888057947158813 ===================
epoch no : 11, batch no : 185, total loss : 0.15950298309326172,  classifier :0.021583406254649162, mask: 0.07164902985095978 ===================
epoch no : 11, batch no : 186, total loss : 0.31300774216651917,  classifier :0.02397521771490574, mask: 0.12894181907176971 ===================
epoch no : 11, batch no : 187, total loss : 0.2295113503932953,  classifier :0.019120918586850166, mask: 0.10344184190034866 ===================
epoch no : 11, batch no : 188, total loss : 0.25040045380592346,  classifier :0.01967398077249527, mask: 0.14409804344177246 ===================
epoch no : 11, batch no : 189, total loss : 0.2783350348472595,  classifier :0.025300633162260056, mask: 0.12373684346675873 ===================
epoch no : 11, batch no : 190, total loss : 0.24839191138744354,  classifier :0.026239220052957535, mask: 0.11701293289661407 ===================
epoch no : 11, batch no : 191, total loss : 0.2493087351322174,  classifier :0.0207498949021101, mask: 0.0973680317401886 ===================
epoch no : 11, batch no : 192, total loss : 0.2882896065711975,  classifier :0.031027650460600853, mask: 0.10910068452358246 ===================
epoch no : 11, batch no : 193, total loss : 0.2868214249610901,  classifier :0.03203681856393814, mask: 0.12689191102981567 ===================
epoch no : 11, batch no : 194, total loss : 0.20270977914333344,  classifier :0.023507965728640556, mask: 0.09061495959758759 ===================
epoch no : 11, batch no : 195, total loss : 0.1865929216146469,  classifier :0.01676495186984539, mask: 0.10305678099393845 ===================
epoch no : 11, batch no : 196, total loss : 0.2823256552219391,  classifier :0.026857290416955948, mask: 0.14481748640537262 ===================
epoch no : 11, batch no : 197, total loss : 0.2502661347389221,  classifier :0.032639503479003906, mask: 0.11914953589439392 ===================
epoch no : 11, batch no : 198, total loss : 0.2167452722787857,  classifier :0.024799810722470284, mask: 0.10404188930988312 ===================
epoch no : 11, batch no : 199, total loss : 0.2870570123195648,  classifier :0.025540249422192574, mask: 0.09817428886890411 ===================
epoch no : 11, batch no : 200, total loss : 0.19340327382087708,  classifier :0.02155294083058834, mask: 0.08635333925485611 ===================
epoch no : 11, batch no : 201, total loss : 0.21652266383171082,  classifier :0.024573270231485367, mask: 0.09627049416303635 ===================
epoch no : 11, batch no : 202, total loss : 0.1630679816007614,  classifier :0.017977241426706314, mask: 0.0866299495100975 ===================
epoch no : 11, batch no : 203, total loss : 0.15799294412136078,  classifier :0.018397029489278793, mask: 0.08672119677066803 ===================
epoch no : 11, batch no : 204, total loss : 0.33378350734710693,  classifier :0.04254031926393509, mask: 0.13684825599193573 ===================
epoch no : 11, batch no : 205, total loss : 0.17069359123706818,  classifier :0.02030019275844097, mask: 0.07415216416120529 ===================
epoch no : 11, batch no : 206, total loss : 0.3090711236000061,  classifier :0.04004756361246109, mask: 0.14234130084514618 ===================
epoch no : 11, batch no : 207, total loss : 0.1956409215927124,  classifier :0.020177731290459633, mask: 0.09849036484956741 ===================
epoch no : 11, batch no : 208, total loss : 0.21785284578800201,  classifier :0.021798312664031982, mask: 0.10245108604431152 ===================
epoch no : 11, batch no : 209, total loss : 0.2911258637905121,  classifier :0.022178132086992264, mask: 0.1443282961845398 ===================
epoch no : 11, batch no : 210, total loss : 0.16636747121810913,  classifier :0.02445441484451294, mask: 0.08780497312545776 ===================
epoch no : 11, batch no : 211, total loss : 0.23963984847068787,  classifier :0.0194450244307518, mask: 0.1113608330488205 ===================
epoch no : 11, batch no : 212, total loss : 0.25020110607147217,  classifier :0.027304112911224365, mask: 0.12214072793722153 ===================
epoch no : 11, batch no : 213, total loss : 0.20780184864997864,  classifier :0.024829281494021416, mask: 0.0921359583735466 ===================
epoch no : 11, batch no : 214, total loss : 0.22490166127681732,  classifier :0.028918515890836716, mask: 0.0872371569275856 ===================
epoch no : 11, batch no : 215, total loss : 0.2501714527606964,  classifier :0.017764929682016373, mask: 0.11496851593255997 ===================
epoch no : 11, batch no : 216, total loss : 0.22758445143699646,  classifier :0.022887814790010452, mask: 0.09459251910448074 ===================
epoch no : 11, batch no : 217, total loss : 0.1914558708667755,  classifier :0.02660926803946495, mask: 0.08981382101774216 ===================
epoch no : 11, batch no : 218, total loss : 0.24984684586524963,  classifier :0.016277657821774483, mask: 0.10338234156370163 ===================
epoch no : 11, batch no : 219, total loss : 0.19426020979881287,  classifier :0.014079190790653229, mask: 0.11156689375638962 ===================
epoch no : 11, batch no : 220, total loss : 0.23453466594219208,  classifier :0.030362270772457123, mask: 0.11249014735221863 ===================
epoch no : 11, batch no : 221, total loss : 0.19740858674049377,  classifier :0.02043558470904827, mask: 0.1121741533279419 ===================
epoch no : 11, batch no : 222, total loss : 0.1660987138748169,  classifier :0.019043518230319023, mask: 0.08764693140983582 ===================
epoch no : 11, batch no : 223, total loss : 0.20274291932582855,  classifier :0.018180279061198235, mask: 0.09486565738916397 ===================
epoch no : 11, batch no : 224, total loss : 0.18706414103507996,  classifier :0.02513180673122406, mask: 0.07745721191167831 ===================
epoch no : 11, batch no : 225, total loss : 0.18385674059391022,  classifier :0.016211099922657013, mask: 0.09463614970445633 ===================
epoch no : 11, batch no : 226, total loss : 0.20500265061855316,  classifier :0.01704053394496441, mask: 0.13382433354854584 ===================
epoch no : 11, batch no : 227, total loss : 0.17426693439483643,  classifier :0.01615608111023903, mask: 0.08540542423725128 ===================
epoch no : 11, batch no : 228, total loss : 0.188212051987648,  classifier :0.014571454375982285, mask: 0.09924837201833725 ===================
epoch no : 11, batch no : 229, total loss : 0.26144295930862427,  classifier :0.036419179290533066, mask: 0.11970873922109604 ===================
epoch no : 11, batch no : 230, total loss : 0.19524706900119781,  classifier :0.022267771884799004, mask: 0.09394870698451996 ===================
epoch no : 11, batch no : 231, total loss : 0.168975830078125,  classifier :0.01977112703025341, mask: 0.08335863053798676 ===================
epoch no : 11, batch no : 232, total loss : 0.15910783410072327,  classifier :0.018227500841021538, mask: 0.08826153725385666 ===================
epoch no : 11, batch no : 233, total loss : 0.19396410882472992,  classifier :0.020296143367886543, mask: 0.10125736147165298 ===================
epoch no : 11, batch no : 234, total loss : 0.2259136587381363,  classifier :0.02139684371650219, mask: 0.11188101023435593 ===================
epoch no : 11, batch no : 235, total loss : 0.2718929946422577,  classifier :0.019450176507234573, mask: 0.10617887228727341 ===================
epoch no : 11, batch no : 236, total loss : 0.255076140165329,  classifier :0.022788578644394875, mask: 0.09112948924303055 ===================
epoch no : 11, batch no : 237, total loss : 0.21476401388645172,  classifier :0.02766016311943531, mask: 0.09199940413236618 ===================
epoch no : 11, batch no : 238, total loss : 0.23559966683387756,  classifier :0.019089514389634132, mask: 0.11010424792766571 ===================
epoch no : 11, batch no : 239, total loss : 0.21526402235031128,  classifier :0.020007923245429993, mask: 0.08791355788707733 ===================
epoch no : 11, batch no : 240, total loss : 0.20165380835533142,  classifier :0.01858421228826046, mask: 0.09553717821836472 ===================
epoch no : 11, batch no : 241, total loss : 0.22846241295337677,  classifier :0.01429613959044218, mask: 0.11755970865488052 ===================
epoch no : 11, batch no : 242, total loss : 0.24215225875377655,  classifier :0.01968619041144848, mask: 0.09975598007440567 ===================
epoch no : 11, batch no : 243, total loss : 0.2529009282588959,  classifier :0.023378655314445496, mask: 0.10246188938617706 ===================
epoch no : 11, batch no : 244, total loss : 0.2280125766992569,  classifier :0.01980506256222725, mask: 0.11673145741224289 ===================
epoch no : 11, batch no : 245, total loss : 0.24173302948474884,  classifier :0.015537007711827755, mask: 0.09988197684288025 ===================
epoch no : 11, batch no : 246, total loss : 0.1905076801776886,  classifier :0.01881249248981476, mask: 0.09055324643850327 ===================
epoch no : 11, batch no : 247, total loss : 0.2132025957107544,  classifier :0.022879583761096, mask: 0.1058480516076088 ===================
epoch no : 11, batch no : 248, total loss : 0.1681787073612213,  classifier :0.0185343399643898, mask: 0.07227805256843567 ===================
epoch no : 11, batch no : 249, total loss : 0.2139074206352234,  classifier :0.029629632830619812, mask: 0.08060403168201447 ===================
epoch no : 11, batch no : 250, total loss : 0.18557322025299072,  classifier :0.02051105909049511, mask: 0.10080818086862564 ===================
epoch no : 11, batch no : 251, total loss : 0.22541706264019012,  classifier :0.023517245426774025, mask: 0.1299312859773636 ===================
epoch no : 11, batch no : 252, total loss : 0.21046148240566254,  classifier :0.023669684305787086, mask: 0.09847953915596008 ===================
epoch no : 11, batch no : 253, total loss : 0.1526932716369629,  classifier :0.029822003096342087, mask: 0.07347928732633591 ===================
epoch no : 11, batch no : 254, total loss : 0.2283148169517517,  classifier :0.01624792255461216, mask: 0.11207259446382523 ===================
epoch no : 11, batch no : 255, total loss : 0.1806117743253708,  classifier :0.020605498924851418, mask: 0.09571120142936707 ===================
epoch no : 11, batch no : 256, total loss : 0.22360067069530487,  classifier :0.020422976464033127, mask: 0.11763782054185867 ===================
epoch no : 11, batch no : 257, total loss : 0.19211678206920624,  classifier :0.019915593788027763, mask: 0.09044265002012253 ===================
epoch no : 11, batch no : 258, total loss : 0.25075387954711914,  classifier :0.027535922825336456, mask: 0.11590173095464706 ===================
epoch no : 11, batch no : 259, total loss : 0.23934507369995117,  classifier :0.02611437253654003, mask: 0.09838554263114929 ===================
epoch no : 11, batch no : 260, total loss : 0.26392364501953125,  classifier :0.020033160224556923, mask: 0.13749173283576965 ===================
epoch no : 11, batch no : 261, total loss : 0.16975100338459015,  classifier :0.02001293934881687, mask: 0.07734023779630661 ===================
epoch no : 11, batch no : 262, total loss : 0.21563321352005005,  classifier :0.02458752878010273, mask: 0.08872222155332565 ===================
epoch no : 11, batch no : 263, total loss : 0.19056850671768188,  classifier :0.014336870983242989, mask: 0.08988568931818008 ===================
epoch no : 11, batch no : 264, total loss : 0.18985790014266968,  classifier :0.018371323123574257, mask: 0.08285181224346161 ===================
epoch no : 11, batch no : 265, total loss : 0.23196177184581757,  classifier :0.01564333215355873, mask: 0.11161457747220993 ===================
epoch no : 11, batch no : 266, total loss : 0.26383328437805176,  classifier :0.018665272742509842, mask: 0.13051708042621613 ===================
epoch no : 11, batch no : 267, total loss : 0.2528744041919708,  classifier :0.022063681855797768, mask: 0.13000883162021637 ===================
epoch no : 11, batch no : 268, total loss : 0.23414833843708038,  classifier :0.02682521566748619, mask: 0.11585144698619843 ===================
epoch no : 11, batch no : 269, total loss : 0.16460072994232178,  classifier :0.017245253548026085, mask: 0.08084277808666229 ===================
epoch no : 11, batch no : 270, total loss : 0.18133112788200378,  classifier :0.019495777785778046, mask: 0.09108418971300125 ===================
epoch no : 11, batch no : 271, total loss : 0.21813853085041046,  classifier :0.021673832088708878, mask: 0.09626653790473938 ===================
epoch no : 11, batch no : 272, total loss : 0.20587940514087677,  classifier :0.021359531208872795, mask: 0.09674356132745743 ===================
epoch no : 11, batch no : 273, total loss : 0.269550621509552,  classifier :0.023354547098279, mask: 0.13640256226062775 ===================
epoch no : 11, batch no : 274, total loss : 0.22505304217338562,  classifier :0.020043212920427322, mask: 0.10168906301259995 ===================
epoch no : 11, batch no : 275, total loss : 0.17789146304130554,  classifier :0.014466960914433002, mask: 0.09052024036645889 ===================
epoch no : 11, batch no : 276, total loss : 0.23891492187976837,  classifier :0.022609470412135124, mask: 0.08743581175804138 ===================
epoch no : 11, batch no : 277, total loss : 0.20354387164115906,  classifier :0.014124084264039993, mask: 0.10952209681272507 ===================
epoch no : 11, batch no : 278, total loss : 0.20844602584838867,  classifier :0.023743407800793648, mask: 0.10507021099328995 ===================
epoch no : 11, batch no : 279, total loss : 0.24018758535385132,  classifier :0.023834459483623505, mask: 0.09667114913463593 ===================
epoch no : 11, batch no : 280, total loss : 0.2200859785079956,  classifier :0.024806058034300804, mask: 0.0804838016629219 ===================
epoch no : 11, batch no : 281, total loss : 0.23582027852535248,  classifier :0.02159670554101467, mask: 0.12329769134521484 ===================
epoch no : 11, batch no : 282, total loss : 0.17706120014190674,  classifier :0.01579674705862999, mask: 0.09511767327785492 ===================
epoch no : 11, batch no : 283, total loss : 0.16755418479442596,  classifier :0.021670330315828323, mask: 0.09571684151887894 ===================
epoch no : 11, batch no : 284, total loss : 0.17048227787017822,  classifier :0.01952560804784298, mask: 0.07825422286987305 ===================
epoch no : 11, batch no : 285, total loss : 0.21780933439731598,  classifier :0.022201841697096825, mask: 0.08325813710689545 ===================
epoch no : 11, batch no : 286, total loss : 0.18535111844539642,  classifier :0.016256563365459442, mask: 0.09494641423225403 ===================
epoch no : 11, batch no : 287, total loss : 0.2251218855381012,  classifier :0.017767833545804024, mask: 0.12405871599912643 ===================
epoch no : 11, batch no : 288, total loss : 0.1873372197151184,  classifier :0.024689124897122383, mask: 0.08569008111953735 ===================
epoch no : 11, batch no : 289, total loss : 0.23308444023132324,  classifier :0.017450107261538506, mask: 0.1260436624288559 ===================
epoch no : 11, batch no : 290, total loss : 0.18517838418483734,  classifier :0.015547537244856358, mask: 0.09404292702674866 ===================
epoch no : 11, batch no : 291, total loss : 0.2183668464422226,  classifier :0.022076735273003578, mask: 0.11139031499624252 ===================
epoch no : 11, batch no : 292, total loss : 0.1571739763021469,  classifier :0.014639156870543957, mask: 0.08129365742206573 ===================
epoch no : 11, batch no : 293, total loss : 0.18646396696567535,  classifier :0.02146136574447155, mask: 0.09234059602022171 ===================
epoch no : 11, batch no : 294, total loss : 0.20411446690559387,  classifier :0.020861122757196426, mask: 0.10980172455310822 ===================
epoch no : 11, batch no : 295, total loss : 0.1765751987695694,  classifier :0.017516134306788445, mask: 0.09100525826215744 ===================
epoch no : 11, batch no : 296, total loss : 0.15581759810447693,  classifier :0.017175128683447838, mask: 0.08457089215517044 ===================
epoch no : 11, batch no : 297, total loss : 0.2561703622341156,  classifier :0.028590429574251175, mask: 0.11425258964300156 ===================
epoch no : 11, batch no : 298, total loss : 0.2557283937931061,  classifier :0.019276488572359085, mask: 0.09511817991733551 ===================
epoch no : 11, batch no : 299, total loss : 0.20397457480430603,  classifier :0.014444224536418915, mask: 0.11487679928541183 ===================
epoch no : 11, batch no : 300, total loss : 0.1927877515554428,  classifier :0.019553212448954582, mask: 0.08913617581129074 ===================
epoch no : 11, batch no : 301, total loss : 0.2032584547996521,  classifier :0.019184786826372147, mask: 0.08368290215730667 ===================
epoch no : 11, batch no : 302, total loss : 0.182335764169693,  classifier :0.024595722556114197, mask: 0.08259069174528122 ===================
epoch no : 11, batch no : 303, total loss : 0.22528325021266937,  classifier :0.022132914513349533, mask: 0.11194659024477005 ===================
epoch no : 11, batch no : 304, total loss : 0.20120161771774292,  classifier :0.022849086672067642, mask: 0.10096553713083267 ===================
epoch no : 11, batch no : 305, total loss : 0.34694579243659973,  classifier :0.037562545388936996, mask: 0.1548747569322586 ===================
epoch no : 11, batch no : 306, total loss : 0.21477970480918884,  classifier :0.022453542798757553, mask: 0.10421853512525558 ===================
epoch no : 11, batch no : 307, total loss : 0.24191556870937347,  classifier :0.017704132944345474, mask: 0.125036358833313 ===================
epoch no : 11, batch no : 308, total loss : 0.19990503787994385,  classifier :0.016243908554315567, mask: 0.09712152183055878 ===================
epoch no : 11, batch no : 309, total loss : 0.2054508626461029,  classifier :0.020426033064723015, mask: 0.09113110601902008 ===================
epoch no : 11, batch no : 310, total loss : 0.21995744109153748,  classifier :0.02114960551261902, mask: 0.11726030707359314 ===================
epoch no : 11, batch no : 311, total loss : 0.1938151717185974,  classifier :0.019500667229294777, mask: 0.0872974693775177 ===================
epoch no : 11, batch no : 312, total loss : 0.208605095744133,  classifier :0.01694009080529213, mask: 0.10570530593395233 ===================
epoch no : 11, batch no : 313, total loss : 0.20470446348190308,  classifier :0.02158169075846672, mask: 0.08745142072439194 ===================
epoch no : 11, batch no : 314, total loss : 0.2465580701828003,  classifier :0.015244065783917904, mask: 0.1356326788663864 ===================
epoch no : 11, batch no : 315, total loss : 0.1895942986011505,  classifier :0.018851127475500107, mask: 0.08266987651586533 ===================
epoch no : 11, batch no : 316, total loss : 0.2615056037902832,  classifier :0.022869514301419258, mask: 0.10674548149108887 ===================
epoch no : 11, batch no : 317, total loss : 0.24418282508850098,  classifier :0.02842528373003006, mask: 0.11765451729297638 ===================
epoch no : 11, batch no : 318, total loss : 0.28175246715545654,  classifier :0.01882554590702057, mask: 0.1373519003391266 ===================
epoch no : 11, batch no : 319, total loss : 0.19781740009784698,  classifier :0.023579861968755722, mask: 0.0975487008690834 ===================
epoch no : 11, batch no : 320, total loss : 0.193479984998703,  classifier :0.018045924603939056, mask: 0.08477979898452759 ===================
epoch no : 11, batch no : 321, total loss : 0.18580487370491028,  classifier :0.020191634073853493, mask: 0.08017463237047195 ===================
epoch no : 11, batch no : 322, total loss : 0.1730005443096161,  classifier :0.016481146216392517, mask: 0.07200165092945099 ===================
epoch no : 11, batch no : 323, total loss : 0.20296910405158997,  classifier :0.02187192812561989, mask: 0.08665085583925247 ===================
epoch no : 11, batch no : 324, total loss : 0.18882551789283752,  classifier :0.02243131212890148, mask: 0.09443189948797226 ===================
epoch no : 11, batch no : 325, total loss : 0.17501753568649292,  classifier :0.025149935856461525, mask: 0.07624173164367676 ===================
epoch no : 11, batch no : 326, total loss : 0.20008105039596558,  classifier :0.018047995865345, mask: 0.07417948544025421 ===================
epoch no : 11, batch no : 327, total loss : 0.19894425570964813,  classifier :0.020261472091078758, mask: 0.10980807989835739 ===================
epoch no : 11, batch no : 328, total loss : 0.2636759281158447,  classifier :0.01900932751595974, mask: 0.12544721364974976 ===================
epoch no : 11, batch no : 329, total loss : 0.2851334512233734,  classifier :0.02263372763991356, mask: 0.10696787387132645 ===================
epoch no : 11, batch no : 330, total loss : 0.27777230739593506,  classifier :0.026181312277913094, mask: 0.10403566062450409 ===================
epoch no : 11, batch no : 331, total loss : 0.2739884853363037,  classifier :0.023646313697099686, mask: 0.1080503985285759 ===================
epoch no : 11, batch no : 332, total loss : 0.18555901944637299,  classifier :0.01785535179078579, mask: 0.09022979438304901 ===================
epoch no : 11, batch no : 333, total loss : 0.2553738057613373,  classifier :0.02215871773660183, mask: 0.11889201402664185 ===================
epoch no : 11, batch no : 334, total loss : 0.15143343806266785,  classifier :0.016889628022909164, mask: 0.0750046893954277 ===================
epoch no : 11, batch no : 335, total loss : 0.25364261865615845,  classifier :0.025381015613675117, mask: 0.12215524911880493 ===================
epoch no : 11, batch no : 336, total loss : 0.19838403165340424,  classifier :0.029604323208332062, mask: 0.10313044488430023 ===================
epoch no : 11, batch no : 337, total loss : 0.18109354376792908,  classifier :0.01864265650510788, mask: 0.0887099951505661 ===================
epoch no : 11, batch no : 338, total loss : 0.21540626883506775,  classifier :0.014379377476871014, mask: 0.09585659950971603 ===================
epoch no : 11, batch no : 339, total loss : 0.2860778570175171,  classifier :0.016839081421494484, mask: 0.14627355337142944 ===================
epoch no : 11, batch no : 340, total loss : 0.24182353913784027,  classifier :0.016958752647042274, mask: 0.1074971929192543 ===================
epoch no : 11, batch no : 341, total loss : 0.26068004965782166,  classifier :0.020638111978769302, mask: 0.1029108464717865 ===================
epoch no : 11, batch no : 342, total loss : 0.42637643218040466,  classifier :0.05016934126615524, mask: 0.17193128168582916 ===================
epoch no : 11, batch no : 343, total loss : 0.23298001289367676,  classifier :0.019476523622870445, mask: 0.10903964191675186 ===================
epoch no : 11, batch no : 344, total loss : 0.2053956836462021,  classifier :0.019224543124437332, mask: 0.09006446599960327 ===================
epoch no : 11, batch no : 345, total loss : 0.25185346603393555,  classifier :0.023918678984045982, mask: 0.12791311740875244 ===================
epoch no : 11, batch no : 346, total loss : 0.21505755186080933,  classifier :0.027512580156326294, mask: 0.10313154011964798 ===================
epoch no : 11, batch no : 347, total loss : 0.19166089594364166,  classifier :0.02153225615620613, mask: 0.09644635766744614 ===================
epoch no : 11, batch no : 348, total loss : 0.24341125786304474,  classifier :0.024617468938231468, mask: 0.12051282823085785 ===================
epoch no : 11, batch no : 349, total loss : 0.19800318777561188,  classifier :0.017587898299098015, mask: 0.10060927271842957 ===================
epoch no : 11, batch no : 350, total loss : 0.2730197310447693,  classifier :0.03373559191823006, mask: 0.1289866715669632 ===================
epoch no : 11, batch no : 351, total loss : 0.23781701922416687,  classifier :0.02942153997719288, mask: 0.10982522368431091 ===================
epoch no : 11, batch no : 352, total loss : 0.20942682027816772,  classifier :0.02036881633102894, mask: 0.09996979683637619 ===================
epoch no : 11, batch no : 353, total loss : 0.21711327135562897,  classifier :0.01819298230111599, mask: 0.11845681071281433 ===================
epoch no : 11, batch no : 354, total loss : 0.13812366127967834,  classifier :0.012237648479640484, mask: 0.07490488886833191 ===================
epoch no : 11, batch no : 355, total loss : 0.21971014142036438,  classifier :0.017302177846431732, mask: 0.11414477974176407 ===================
epoch no : 11, batch no : 356, total loss : 0.20560669898986816,  classifier :0.026439758017659187, mask: 0.08592411130666733 ===================
epoch no : 11, batch no : 357, total loss : 0.18344342708587646,  classifier :0.015483970753848553, mask: 0.08138331025838852 ===================
epoch no : 11, batch no : 358, total loss : 0.17198649048805237,  classifier :0.020915016531944275, mask: 0.08500739932060242 ===================
epoch no : 11, batch no : 359, total loss : 0.17201228439807892,  classifier :0.017911728471517563, mask: 0.10173936933279037 ===================
epoch no : 11, batch no : 360, total loss : 0.15906113386154175,  classifier :0.018556663766503334, mask: 0.08596483618021011 ===================
epoch no : 11, batch no : 361, total loss : 0.17476677894592285,  classifier :0.01543212216347456, mask: 0.09131786227226257 ===================
epoch no : 11, batch no : 362, total loss : 0.19014351069927216,  classifier :0.013730527833104134, mask: 0.08403617143630981 ===================
epoch no : 11, batch no : 363, total loss : 0.27159836888313293,  classifier :0.020383330062031746, mask: 0.13971011340618134 ===================
epoch no : 11, batch no : 364, total loss : 0.27214211225509644,  classifier :0.02558407187461853, mask: 0.1200340986251831 ===================
epoch no : 11, batch no : 365, total loss : 0.17280693352222443,  classifier :0.021150192245841026, mask: 0.08634964376688004 ===================
epoch no : 11, batch no : 366, total loss : 0.17547190189361572,  classifier :0.019909651950001717, mask: 0.08795927464962006 ===================
epoch no : 11, batch no : 367, total loss : 0.1873551458120346,  classifier :0.02880740351974964, mask: 0.08715452998876572 ===================
epoch no : 11, batch no : 368, total loss : 0.21009159088134766,  classifier :0.022583132609725, mask: 0.11847575753927231 ===================
epoch no : 11, batch no : 369, total loss : 0.2327769696712494,  classifier :0.014822632074356079, mask: 0.13011996448040009 ===================
epoch no : 11, batch no : 370, total loss : 0.17268939316272736,  classifier :0.022329548373818398, mask: 0.07836543023586273 ===================
epoch no : 11, batch no : 371, total loss : 0.19191747903823853,  classifier :0.018137307837605476, mask: 0.09843459725379944 ===================
epoch no : 11, batch no : 372, total loss : 0.18339093029499054,  classifier :0.022774647921323776, mask: 0.08696109056472778 ===================
epoch no : 11, batch no : 373, total loss : 0.23385757207870483,  classifier :0.021864276379346848, mask: 0.10959214717149734 ===================
epoch no : 11, batch no : 374, total loss : 0.24215111136436462,  classifier :0.015987010672688484, mask: 0.11591634154319763 ===================
epoch no : 11, batch no : 375, total loss : 0.23383517563343048,  classifier :0.01765962317585945, mask: 0.12253038585186005 ===================
epoch no : 11, batch no : 376, total loss : 0.29439398646354675,  classifier :0.01870604231953621, mask: 0.14085125923156738 ===================
epoch no : 11, batch no : 377, total loss : 0.2507002055644989,  classifier :0.023465946316719055, mask: 0.12209556996822357 ===================
epoch no : 11, batch no : 378, total loss : 0.25221773982048035,  classifier :0.022239716723561287, mask: 0.10985218733549118 ===================
epoch no : 11, batch no : 379, total loss : 0.17475566267967224,  classifier :0.018001103773713112, mask: 0.08620478957891464 ===================
epoch no : 11, batch no : 380, total loss : 0.279226154088974,  classifier :0.022009052336215973, mask: 0.1254255622625351 ===================
epoch no : 11, batch no : 381, total loss : 0.31406858563423157,  classifier :0.02267005667090416, mask: 0.14108604192733765 ===================
epoch no : 11, batch no : 382, total loss : 0.24163348972797394,  classifier :0.031304627656936646, mask: 0.10407353937625885 ===================
epoch no : 11, batch no : 383, total loss : 0.2374809831380844,  classifier :0.029208647087216377, mask: 0.11401024460792542 ===================
epoch no : 11, batch no : 384, total loss : 0.15006862580776215,  classifier :0.01670372486114502, mask: 0.0815933346748352 ===================
epoch no : 11, batch no : 385, total loss : 0.1674771010875702,  classifier :0.013744802214205265, mask: 0.08570456504821777 ===================
epoch no : 11, batch no : 386, total loss : 0.16579118371009827,  classifier :0.015496724285185337, mask: 0.08343057334423065 ===================
epoch no : 11, batch no : 387, total loss : 0.19403597712516785,  classifier :0.016946345567703247, mask: 0.09499645233154297 ===================
epoch no : 11, batch no : 388, total loss : 0.20319098234176636,  classifier :0.023085840046405792, mask: 0.09504568576812744 ===================
epoch no : 11, batch no : 389, total loss : 0.1789332628250122,  classifier :0.017260512337088585, mask: 0.08689477294683456 ===================
epoch no : 11, batch no : 390, total loss : 0.21505184471607208,  classifier :0.022578056901693344, mask: 0.08570047467947006 ===================
epoch no : 11, batch no : 391, total loss : 0.23135434091091156,  classifier :0.029364395886659622, mask: 0.10704796761274338 ===================
epoch no : 11, batch no : 392, total loss : 0.1994783878326416,  classifier :0.014376250095665455, mask: 0.10520895570516586 ===================
epoch no : 11, batch no : 393, total loss : 0.16365382075309753,  classifier :0.021075939759612083, mask: 0.08056723326444626 ===================
epoch no : 11, batch no : 394, total loss : 0.14691464602947235,  classifier :0.02034478820860386, mask: 0.07005089521408081 ===================
epoch no : 11, batch no : 395, total loss : 0.17027439177036285,  classifier :0.01625872030854225, mask: 0.07620688527822495 ===================
epoch no : 11, batch no : 396, total loss : 0.22797757387161255,  classifier :0.025319308042526245, mask: 0.11705633252859116 ===================
epoch no : 11, batch no : 397, total loss : 0.19455711543560028,  classifier :0.016860952600836754, mask: 0.08852279931306839 ===================
epoch no : 11, batch no : 398, total loss : 0.2763349413871765,  classifier :0.030458293855190277, mask: 0.10139494389295578 ===================

 =================The Model is Trained!====================
-----------------Visualizing Model predictions----------------
  0%|          | 0/2 [00:00<?, ?it/s]
 /gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/test-patients/images

0it [00:00, ?it/s][A0it [00:00, ?it/s]
100%|██████████| 2/2 [00:00<00:00, 34.18it/s]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: epoch ▁▁▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇███
wandb:  loss █▇▄▃▂▃▃▃▃▄▃▂▃▂▃▃▂▂▁▂▃▂▂▂▂▂▂▂▁▁▂▁▁▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb: epoch 11
wandb:  loss 0.27633
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /wynton/home/finkbeiner/vgramas/Projects/amyb-plaque-detection/src/models/wandb/offline-run-20230329_171817-1r7w4vw6
wandb: Find logs at: ./wandb/offline-run-20230329_171817-1r7w4vw6/logs

 /gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/test-patients/labels
The model is running on node qb3-idgpu10
Successfully stopped recording stats for 2286668.
Successfully retrieved statistics for job: 2286668. 
+------------------------------------------------------------------------------+
| GPU ID: 2                                                                    |
+====================================+=========================================+
|-----  Execution Stats  ------------+-----------------------------------------|
| Start Time                         | Wed Mar 29 17:17:16 2023                |
| End Time                           | Wed Mar 29 19:58:11 2023                |
| Total Execution Time (sec)         | 9655.29                                 |
| No. of Processes                   | 0                                       |
+-----  Performance Stats  ----------+-----------------------------------------+
| Energy Consumed (Joules)           | 23412                                   |
| Power Usage (Watts)                | Avg: 6.80845, Max: 8.395, Min: 5.531    |
| Max GPU Memory Used (bytes)        | 0                                       |
| SM Clock (MHz)                     | Avg: 300, Max: 300, Min: 300            |
| Memory Clock (MHz)                 | Avg: 405, Max: 405, Min: 405            |
| SM Utilization (%)                 | Avg: 0, Max: 0, Min: 0                  |
| Memory Utilization (%)             | Avg: 0, Max: 0, Min: 0                  |
| PCIe Rx Bandwidth (megabytes)      | Avg: N/A, Max: N/A, Min: N/A            |
| PCIe Tx Bandwidth (megabytes)      | Avg: N/A, Max: N/A, Min: N/A            |
+-----  Event Stats  ----------------+-----------------------------------------+
| Single Bit ECC Errors              | 0                                       |
| Double Bit ECC Errors              | 0                                       |
| PCIe Replay Warnings               | 0                                       |
| Critical XID Errors                | 0                                       |
+-----  Slowdown Stats  -------------+-----------------------------------------+
| Due to - Power (%)                 | 0                                       |
|        - Thermal (%)               | 0                                       |
|        - Reliability (%)           | Not Supported                           |
|        - Board Limit (%)           | Not Supported                           |
|        - Low Utilization (%)       | Not Supported                           |
|        - Sync Boost (%)            | 0                                       |
+-----  Overall Health  -------------+-----------------------------------------+
| Overall Health                     | Healthy                                 |
+------------------------------------+-----------------------------------------+

Successfully removed group 69
