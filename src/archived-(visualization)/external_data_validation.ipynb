{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahirwar/anaconda3/envs/amy_plague/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from genericpath import exists\n",
    "import pdb\n",
    "from pickletools import uint8\n",
    "from turtle import pd\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "\n",
    "import os\n",
    "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "# from torchknickknacks import modelutils\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import requests\n",
    "from pytorch_grad_cam.ablation_layer import AblationLayerFasterRCNN\n",
    "from pytorch_grad_cam.utils.model_targets import FasterRCNNBoxScoreTarget\n",
    "from pytorch_grad_cam.utils.reshape_transforms import fasterrcnn_reshape_transform\n",
    "from pytorch_grad_cam.ablation_layer import AblationLayerFasterRCNN\n",
    "import random\n",
    "import glob\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "from skimage import data, filters, measure, morphology\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from skimage import data\n",
    "from skimage.color import rgb2hed, hed2rgb\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from models.model_mrcnn import _default_mrcnn_config, build_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExplainPredictions():\n",
    "    \n",
    "    # TODO fix the visualization flags\n",
    "    def __init__(self, model, model_input_path, test_input_path, detection_threshold, wandb, save_result, ablation_cam, save_thresholds):\n",
    "        self.model = model\n",
    "        self.model_input_path = model_input_path\n",
    "        self.test_input_path = test_input_path\n",
    "        self.detection_threshold = detection_threshold\n",
    "        self.wandb = wandb\n",
    "        self.save_result = save_result\n",
    "        self.ablation_cam = ablation_cam\n",
    "        self.save_thresholds = save_thresholds\n",
    "        self.class_names = ['Unknown', 'Core', 'Diffuse', 'CAA']\n",
    "        self.class_to_colors = {'Core': (255, 0, 0), 'Diffuse': (0,255,0), 'CAA':(225, 255, 0)}\n",
    "        #TODO change this to nas location later\n",
    "        #self.result_save_dir= \"/wynton/home/finkbeiner/vgramas/Projects/amyb-plaque-detection/reports/figures/\"\n",
    "        self.result_save_dir= \"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/UCDavis-Dataset/Results/\"\n",
    "        self.colors = np.random.uniform(0, 255, size=(len(self.class_names), 3))\n",
    "        self.column_names = [\"image_name\", \"region\", \"region_mask\", \"label\", \n",
    "                            \"confidence\", \"brown_pixels\", \"centroid\", \n",
    "                            \"eccentricity\", \"area\", \"equivalent_diameter\"]\n",
    "        self.results_path = \"\"\n",
    "        self.masks_path = \"\" \n",
    "        self.detections_path = \"\" \n",
    "        self.ablations_path = \"\"\n",
    "        self.quantify_path = \"\"\n",
    "      \n",
    "    def get_brown_pixel_cnt(self, img, img_name):\n",
    "\n",
    "        # Separate the stains from the IHC image\n",
    "        ihc_hed = rgb2hed(img)\n",
    "\n",
    "        # Create an RGB image for each of the stains\n",
    "        null = np.zeros_like(ihc_hed[:, :, 0])\n",
    "        ihc_h = hed2rgb(np.stack((ihc_hed[:, :, 0], null, null), axis=-1))\n",
    "        ihc_e = hed2rgb(np.stack((null, ihc_hed[:, :, 1], null), axis=-1))\n",
    "        ihc_d = hed2rgb(np.stack((null, null, ihc_hed[:, :, 2]), axis=-1))\n",
    "        ihc_d = ihc_d.astype('float32')\n",
    "\n",
    "        gray = cv2.cvtColor(ihc_d, cv2.COLOR_RGB2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        x = gray[gray<0.35]\n",
    "\n",
    "\n",
    "        if len(x) != 0:\n",
    "            if self.save_thresholds:\n",
    "                # Display\n",
    "                fig, axes = plt.subplots(2, 2, figsize=(7, 6), sharex=True, sharey=True)\n",
    "                ax = axes.ravel()\n",
    "\n",
    "                ax[0].imshow(img)\n",
    "                ax[0].set_title(\"Original image\")\n",
    "\n",
    "                ax[1].imshow(ihc_h)\n",
    "                ax[1].set_title(\"Hematoxylin\")\n",
    "\n",
    "                ax[2].imshow(gray)\n",
    "                ax[2].set_title(\"gray\")  # Note that there is no Eosin stain in this image\n",
    "\n",
    "                ax[3].imshow(ihc_d)\n",
    "                ax[3].set_title(\"DAB\")\n",
    "\n",
    "                for a in ax.ravel():\n",
    "                    a.axis('off')\n",
    "\n",
    "                fig.tight_layout()\n",
    "            \n",
    "                \n",
    "                final_save_path = img_name + \"_count_threhold.png\"\n",
    "                final_save_path = os.path.join(self.pixel_count_path, final_save_path)\n",
    "                fig.savefig(final_save_path)\n",
    "                plt.close()\n",
    "            return len(x)\n",
    "        return 0\n",
    "\n",
    "\n",
    "    def get_outputs(self, input_tensor, model, threshold):\n",
    "        with torch.no_grad():\n",
    "            # forward pass of the image through the modle\n",
    "            outputs = model(input_tensor)\n",
    "        \n",
    "        # get all the scores\n",
    "        scores = list(outputs[0]['scores'].detach().cpu().numpy())\n",
    "        # print(\"\\n scores\", max(scores))\n",
    "        # index of those scores which are above a certain threshold\n",
    "        thresholded_preds_inidices = [scores.index(i) for i in scores if i > threshold]\n",
    "        thresholded_preds_count = len(thresholded_preds_inidices)\n",
    "\n",
    "        scores = scores[:thresholded_preds_count]\n",
    "        # get the masks\n",
    "        masks = (outputs[0]['masks']>0.5).squeeze().detach().cpu().numpy()\n",
    "        # print(\"masks\", masks)\n",
    "        # discard masks for objects which are below threshold\n",
    "        masks = masks[:thresholded_preds_count]\n",
    "        # get the bounding boxes, in (x1, y1), (x2, y2) format\n",
    "        boxes = [[(int(i[0]), int(i[1])), (int(i[2]), int(i[3]))]  for i in outputs[0]['boxes'].detach().cpu()]\n",
    "        # discard bounding boxes below threshold value\n",
    "        boxes = boxes[:thresholded_preds_count]\n",
    "        # get the classes labels\n",
    "        # print('labels', outputs[0]['labels'])\n",
    "        labels = [self.class_names[i] for i in outputs[0]['labels']]\n",
    "        labels = labels[:thresholded_preds_count]\n",
    "\n",
    "        # [1,1,1, 2, 2, 2, 3, 3]\n",
    "        return masks, boxes, labels, scores\n",
    "\n",
    "    def draw_segmentation_map(self, image, masks, boxes, labels):\n",
    "        alpha = 1 \n",
    "        beta = 0.6 # transparency for the segmentation map\n",
    "        gamma = 0 # scalar added to each \n",
    "        segmentation_map = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
    "        result_masks = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
    "\n",
    "        for i in range(len(masks)):\n",
    "\n",
    "            # TODO fix the color segmentation masks\n",
    "            red_map = np.zeros_like(masks[i]).astype(np.uint8)\n",
    "            green_map = np.zeros_like(masks[i]).astype(np.uint8)\n",
    "            blue_map = np.zeros_like(masks[i]).astype(np.uint8)\n",
    "            \n",
    "            # apply a randon color mask to each object\n",
    "            rect_color = (0,0,0)\n",
    "            color = self.colors[random.randrange(0, len(self.colors))]\n",
    "            red_map[masks[i] == 1], green_map[masks[i] == 1], blue_map[masks[i] == 1]  = self.class_to_colors[labels[i]]\n",
    "            result_masks[masks[i] == 1] = 255\n",
    "            # combine all the masks into a single image\n",
    "            # change the format of mask to W,H, C\n",
    "\n",
    "            # segmentation_map = np.stack([red_map, green_map, blue_map], axis=2)\n",
    "            #convert the original PIL image into NumPy format\n",
    "            image = np.array(image)\n",
    "            # convert from RGB to OpenCV BGR format\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            # apply mask on the image\n",
    "            # cv2.addWeighted(image, alpha, segmentation_map, beta, gamma, image)\n",
    "            # draw the bounding boxes around the objects\n",
    "            cv2.rectangle(image, boxes[i][0], boxes[i][1], color=rect_color, \n",
    "                        thickness=2)\n",
    "            # Get the centre coords of the rectangle-plaque-detection/src/visualizat\n",
    "            x1 = boxes[i][0][0]\n",
    "            y1 = boxes[i][0][1]\n",
    "            x2 = boxes[i][1][0]\n",
    "            y2 = boxes[i][1][1]\n",
    "            x = int((x1 + x2) / 2)\n",
    "            y = int((y1+y2) / 2)\n",
    "\n",
    "            \n",
    "            # put the label text above the objects\n",
    "            cv2.putText(image , labels[i], (x1, y1-20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, color, \n",
    "                        thickness=2, lineType=cv2.LINE_AA)\n",
    "            \n",
    "            # Convert Back\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return image, result_masks\n",
    "\n",
    "    def prepare_input(self, image):\n",
    "    \n",
    "        image_float_np = np.float32(image) / 255\n",
    "\n",
    "        # define the torchvision image transforms\n",
    "        transform = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize(1024),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        \n",
    "        input_tensor = transform(transforms.ToPILImage()(image))\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        input_tensor = input_tensor.to(device)\n",
    "        # Add a batch dimension:\n",
    "        input_tensor = input_tensor.unsqueeze(0)\n",
    "\n",
    "        return input_tensor, image_float_np\n",
    "    \n",
    "    def predict(self, input_tensor, model, device, detection_threshold):\n",
    "        outputs = model(input_tensor)\n",
    "        # i- 1 zero indexing - the model outputs a non zero indexing format ( 1, 2, 3)\n",
    "        pred_classes = [self.class_names[i] for i in outputs[0]['labels'].cpu().numpy()]\n",
    "        pred_labels = outputs[0]['labels'].cpu().numpy()\n",
    "        pred_scores = outputs[0]['scores'].detach().cpu().numpy()\n",
    "        pred_bboxes = outputs[0]['boxes'].detach().cpu().numpy()\n",
    "        \n",
    "        boxes, classes, labels, indices = [], [], [], []\n",
    "        for index in range(len(pred_scores)):\n",
    "            if pred_scores[index] >= detection_threshold:\n",
    "                boxes.append(pred_bboxes[index].astype(np.int32))\n",
    "                classes.append(pred_classes[index])\n",
    "                labels.append(pred_labels[index])\n",
    "                indices.append(index)\n",
    "        boxes = np.int32(boxes)\n",
    "        return boxes, classes, labels, indices\n",
    "\n",
    "    def draw_boxes(self, boxes, labels, classes, image):\n",
    "        for i, box in enumerate(boxes):\n",
    "            color = self.colors[labels[i]]\n",
    "            cv2.rectangle(\n",
    "                image,\n",
    "                (int(box[0]), int(box[1])),\n",
    "                (int(box[2]), int(box[3])),\n",
    "                color, 2\n",
    "            )\n",
    "            cv2.putText(image, classes[i], (int(box[0]), int(box[1] + 30)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 1,\n",
    "                        lineType=cv2.LINE_AA)\n",
    "        return image\n",
    "\n",
    "    def make_result_dirs(self, folder_name):\n",
    "\n",
    "        # TODO remove this later and replace with self.wandb.name\n",
    "        # folder_name = self.wandb.name + \"_\" + folder_name\n",
    "        folder_name = \"runtest\" + \"_\" + folder_name\n",
    "        save_path = os.path.join(self.result_save_dir, folder_name)\n",
    "        results_path = os.path.join(save_path, \"results\")\n",
    "        if not os.path.exists(results_path):\n",
    "            os.makedirs(results_path)\n",
    "        \n",
    "        detections_path = os.path.join(save_path, \"detections\")\n",
    "        if not os.path.exists(detections_path):\n",
    "            os.makedirs(detections_path)\n",
    "        \n",
    "        masks_path = os.path.join(save_path, \"masks\")\n",
    "        if not os.path.exists(masks_path):\n",
    "            os.makedirs(masks_path)\n",
    "        \n",
    "        ablations_path = os.path.join(save_path, \"ablations\")\n",
    "        if not os.path.exists(ablations_path):\n",
    "            os.makedirs(ablations_path)\n",
    "        \n",
    "        pixel_count_path = os.path.join(self.result_save_dir, \"pixel_count\")\n",
    "        if not os.path.exists(pixel_count_path):\n",
    "            os.makedirs(pixel_count_path)\n",
    "        \n",
    "        csv_name = folder_name + \"_quantify.csv\"\n",
    "        quantify_path = os.path.join(save_path, csv_name)\n",
    "\n",
    "        self.results_path = results_path\n",
    "        self.masks_path = masks_path\n",
    "        self.detections_path = detections_path\n",
    "        self.ablations_path = ablations_path\n",
    "        self.quantify_path = quantify_path\n",
    "        self.pixel_count_path = pixel_count_path\n",
    "\n",
    "    def quantify_plaques(self, df, wandb_result, img_name, result_img, result_masks, boxes, labels, scores, total_brown_pixels):\n",
    "        '''This function will take masks image and generate attributes like plaque\n",
    "        count, area, eccentricity'''\n",
    "\n",
    "        csv_result = []\n",
    "        \n",
    "    \n",
    "        for i in range(len(labels)):\n",
    "\n",
    "            props = {}\n",
    "            data = {}\n",
    "            # Here x and y axis are flipped\n",
    "            total_core_plaques = 0\n",
    "            total_neuritic_plaques = 0\n",
    "            total_diffused_plaques = 0\n",
    "\n",
    "            if len(boxes)!= 0:\n",
    "\n",
    "                x1 = boxes[i][0][1]\n",
    "                x2 =  boxes[i][1][1]\n",
    "                y1 = boxes[i][0][0]\n",
    "                y2 = boxes[i][1][0]\n",
    "\n",
    "               \n",
    "                cropped_img = result_img[x1:x2, y1:y2]\n",
    "                cropped_img_mask = result_masks[x1:x2, y1:y2]\n",
    "\n",
    "                ret, bw_img = cv2.threshold(cropped_img_mask,0,255,cv2.THRESH_BINARY)\n",
    "\n",
    "                kernel = np.ones((5,5),np.uint8)\n",
    "                \n",
    "                # Closing operation Dilation followed by erosion\n",
    "                closing = cv2.morphologyEx(bw_img, cv2.MORPH_CLOSE, kernel)\n",
    "                regions = regionprops(closing)\n",
    "\n",
    "                for props in regions:\n",
    "\n",
    "                    if labels[i] == \"Core\":\n",
    "                        total_core_plaques+=1\n",
    "                    elif labels[i] == \"Neuritic\":\n",
    "                        total_neuritic_plaques+=1\n",
    "                    elif labels[i] == \"Diffuse\":\n",
    "                        total_diffused_plaques+=1\n",
    "                    \n",
    "                    data_record = pd.DataFrame.from_records([{ 'image_name': img_name, 'label': labels[i] , 'confidence': scores[i],\n",
    "                                                               'brown_pixels': total_brown_pixels,\n",
    "                                                               'core': total_core_plaques, 'neuritic': total_neuritic_plaques, 'diffuse': total_diffused_plaques,\n",
    "                                                               'centroid': props.centroid, 'eccentricity': props.eccentricity, \n",
    "                                                               'area': props.area, 'equivalent_diameter': props.equivalent_diameter}])\n",
    "                    wandb_result.append([img_name, wandb.Image(cropped_img), wandb.Image(cropped_img_mask), labels[i], scores[i], \n",
    "                                         total_brown_pixels, props.centroid, props.eccentricity, props.area, props.equivalent_diameter])\n",
    "\n",
    "                    df = pd.concat([df, data_record], ignore_index=True)\n",
    "                   \n",
    "        \n",
    "        return df, wandb_result\n",
    " \n",
    "    def generate_results(self):\n",
    "        # This will help us create a different color for each class\n",
    "        # Load Trained \n",
    "        \n",
    "        self.model.load_state_dict(torch.load(self.model_input_path))\n",
    "    \n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.eval().to(device)\n",
    "        output_dict=dict()\n",
    "        output_score=dict()\n",
    "        \n",
    "\n",
    "        test_folders = glob.glob(os.path.join(self.test_input_path, \"*\"))\n",
    "        \n",
    "        # Test images from each WSI folder\n",
    "        test_folders = sorted(test_folders)\n",
    "        \n",
    "        print(\"length of test folders\", len(test_folders))\n",
    "        \n",
    "        output_dict = dict()\n",
    "      \n",
    "        for test_folder in tqdm(test_folders):\n",
    "\n",
    "            print(\"\\n\", test_folder)\n",
    "            \n",
    "            folder_name = os.path.basename(test_folder)\n",
    "\n",
    "            if folder_name == \"labels\":\n",
    "                continue\n",
    "\n",
    "            # make all necessary folders\n",
    "            self.make_result_dirs(folder_name)\n",
    "            images = glob.glob(os.path.join(test_folder, '*.jpg'))\n",
    "            \n",
    "            print(\"Images in Test Folder\", len(images))\n",
    "            i = 0\n",
    "            df = pd.DataFrame()\n",
    "            wandb_result = []\n",
    "            total_core_plaques = 0\n",
    "            total_neuritic_plaques = 0\n",
    "            total_diffused_plaques = 0\n",
    "            total_brown_pixels = 0\n",
    "            total_image_pixels = 0\n",
    "\n",
    "            for img in tqdm(images):\n",
    "                result_img = 0\n",
    "                img_name = os.path.basename(img).split('.')[0]\n",
    "                \n",
    "                image = np.array(Image.open(img))\n",
    "\n",
    "                total_image_pixels+= image.shape[0] * image.shape[1]\n",
    "                # Check if image has alpha channel\n",
    "                if image.shape[2] == 4:\n",
    "                    image = image[:,:, :3]\n",
    "                input_tensor, image_float_np = self.prepare_input(image)\n",
    "\n",
    "                masks, boxes, labels, scores = self.get_outputs(input_tensor, self.model, self.detection_threshold)\n",
    "                #print(labels, scores)\n",
    "                #print(labels)\n",
    "                output_dict[img_name] = labels\n",
    "                output_score[img_name]=scores\n",
    "        return output_dict, output_score\n",
    "    \n",
    "    def generate_results_per_image(self):\n",
    "        # This will help us create a different color for each class\n",
    "        # Load Trained \n",
    "        output_dict=dict()\n",
    "        output_score=dict()\n",
    "        \n",
    "        self.model.load_state_dict(torch.load(self.model_input_path))\n",
    "    \n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.eval().to(device)\n",
    "        output_dict=dict()\n",
    "        output_score=dict()\n",
    "        test_folders = glob.glob(os.path.join(\"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/UCDavis-Dataset/tiles/train/NA4751-02_AB\", \"*.jpg\"))\n",
    "        print(len(test_folders))\n",
    "        #for Finkbeiner-Steve/work/data/npsad_data/vivek/Datasets/UCDavis-Dataset/tiles/train/NA4751-02_AB \n",
    "        for img in  test_folders:\n",
    "            #img = \"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/UCDavis-Dataset/tiles/train/NA4751-02_AB/NA4751-02_AB_19_6_34.jpg\"\n",
    "            #img = \"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/amyb_wsi/train/images/A_0_0_XE10-045_1_AmyB_1_49175x_54069y_image.png\"\n",
    "            img_name = os.path.basename(img).split('.')[0]\n",
    "            image = np.array(Image.open(img))\n",
    "\n",
    "            #total_image_pixels+= image.shape[0] * image.shape[1]\n",
    "            # Check if image has alpha channel\n",
    "            if image.shape[2] == 4:\n",
    "                image = image[:,:, :3]\n",
    "            input_tensor, image_float_np = self.prepare_input(image)\n",
    "\n",
    "            masks, boxes, labels, scores = self.get_outputs(input_tensor, self.model, self.detection_threshold)\n",
    "            #print(labels, scores)\n",
    "            #print(labels)\n",
    "            output_dict[img_name] = labels\n",
    "            output_score[img_name]=scores\n",
    "        return output_dict, output_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate External Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset =  \"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/UCDavis-Dataset/tiles/train/\"\n",
    "\n",
    "#image_dataset =  \"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/UCDavis-Dataset/tiles/validation\"\n",
    "\n",
    "gt_train = \"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/UCDavis-Dataset/classification_dataset/train.csv\"\n",
    "\n",
    "gt_val = \"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/UCDavis-Dataset/tiles/validation.csv\"\n",
    "\n",
    "#model_input_path = \"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/models/peachy-firefly-487_mrcnn_model_50.pth\"\n",
    "\n",
    "model_input_path = \"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/models/eager-frog-489_mrcnn_model_100.pth\"\n",
    "\n",
    "#model_input_path = \"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/models/dry-disco-560_mrcnn_model_50.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_output(gt_train, output_df, output_score, train_flag):\n",
    "    gt_train_df = pd.read_csv(gt_train)\n",
    "    gt_train_df[\"imagename2\"]= gt_train_df[\"imagename\"].apply(lambda l: l.split(\"/\")[-1].replace(\".jpg\",\"\"))\n",
    "    if train_flag:\n",
    "        gt_train_df[\"cored_gt\"] = gt_train_df[\"cored_bool\"].apply(lambda l: 1 if l==True else 0)\n",
    "        gt_train_df[\"diffuse_gt\"] = gt_train_df[\"diffuse_bool\"].apply(lambda l: 1 if l==True else 0)\n",
    "        gt_train_df[\"CAA_gt\"] = gt_train_df[\"CAA_bool\"].apply(lambda l: 1 if l==True else 0)\n",
    "    else:\n",
    "        gt_train_df[\"cored_gt\"] = gt_train_df[\"cored\"].apply(lambda l: 1 if l>0 else 0)\n",
    "        gt_train_df[\"diffuse_gt\"] = gt_train_df[\"diffuse\"].apply(lambda l: 1 if l>0 else 0)\n",
    "        gt_train_df[\"CAA_gt\"] = gt_train_df[\"CAA\"].apply(lambda l: 1 if l>0 else 0)\n",
    "    gt_train_df[\"cored_pred\"] = 0\n",
    "    gt_train_df[\"diffuse_pred\"] = 0\n",
    "    gt_train_df[\"CAA_pred\"] = 0\n",
    "    \n",
    "    def assign_pred_scores(row, val):\n",
    "        if row[\"imagename2\"] in output_df.keys():\n",
    "            l = output_df[row[\"imagename2\"]]\n",
    "            s = output_score[row[\"imagename2\"]]\n",
    "            indices = [i for i in range(len(l)) if l[i] == val]\n",
    "            s_selected = [ s[i] for i in indices]\n",
    "            if len(s_selected)!=0:\n",
    "                return max(s_selected)\n",
    "            else:\n",
    "                return 0\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    gt_train_df[\"cored_score\"] = gt_train_df.apply(lambda l:  assign_pred_scores(l, \"Core\"), axis=1)\n",
    "    gt_train_df[\"diffuse_score\"] = gt_train_df.apply(lambda l:  assign_pred_scores(l, \"Diffuse\"),axis=1)\n",
    "    gt_train_df[\"CAA_score\"] = gt_train_df.apply(lambda l:  assign_pred_scores(l, \"CAA\"),axis=1)\n",
    "    \n",
    "    def assign_pred_labels(row, val):\n",
    "        if row[\"imagename2\"] in output_df.keys():\n",
    "            l = output_df[row[\"imagename2\"]]\n",
    "            if val in l:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    gt_train_df[\"cored_pred\"] = gt_train_df.apply(lambda l:  assign_pred_labels(l, \"Core\"), axis=1)\n",
    "    gt_train_df[\"diffuse_pred\"] = gt_train_df.apply(lambda l:  assign_pred_labels(l, \"Diffuse\"),axis=1)\n",
    "    gt_train_df[\"CAA_pred\"] = gt_train_df.apply(lambda l:  assign_pred_labels(l, \"CAA\"),axis=1)\n",
    "    return gt_train_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config = dict(\n",
    "        batch_size = 1,\n",
    "        num_classes = 3)\n",
    "    \n",
    "model_config = _default_mrcnn_config(num_classes=1 + test_config['num_classes']).config\n",
    "model = build_default(model_config, im_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run = wandb.init(project=\"LBD\",  entity=\"monika-ahirwar\")\n",
    "run =\"\"\n",
    "explain = ExplainPredictions(model, model_input_path = model_input_path, test_input_path=image_dataset, \n",
    "                                detection_threshold=0.5, wandb=run, save_result=True, ablation_cam=False, save_thresholds=False)\n",
    "output_df, output_scores = explain.generate_results()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running validation dataset\n",
    "gt_val_df = evaluate_output(gt_val, output_df, output_scores, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running train dataset\n",
    "gt_train_df = evaluate_output(gt_train, output_df, output_scores, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excluding NA values from val\n",
    "notna_gt_val_df = gt_val_df[~gt_val_df[\"cored_pred\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excluding NA values from train\n",
    "notna_gt_train_df = gt_train_df[~gt_train_df[\"cored_pred\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_88777/1838933179.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  notna_gt_train_df.drop(['Unnamed: 0',\"cored_bool\",\"diffuse_bool\",\"CAA_bool\"], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# dropping irrelevant columns from train\n",
    "notna_gt_train_df.drop(['Unnamed: 0',\"cored_bool\",\"diffuse_bool\",\"CAA_bool\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate train and val outputs\n",
    "final_df = pd.concat([notna_gt_train_df,notna_gt_val_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>imagename</th>\n",
       "      <th>cored</th>\n",
       "      <th>diffuse</th>\n",
       "      <th>CAA</th>\n",
       "      <th>negative</th>\n",
       "      <th>flag</th>\n",
       "      <th>notsure</th>\n",
       "      <th>imagename2</th>\n",
       "      <th>cored_gt</th>\n",
       "      <th>diffuse_gt</th>\n",
       "      <th>CAA_gt</th>\n",
       "      <th>cored_pred</th>\n",
       "      <th>diffuse_pred</th>\n",
       "      <th>CAA_pred</th>\n",
       "      <th>cored_score</th>\n",
       "      <th>diffuse_score</th>\n",
       "      <th>CAA_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10748</td>\n",
       "      <td>NA4757-02_AB/NA4757-02_AB_18_25_61.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA4757-02_AB_18_25_61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29503</td>\n",
       "      <td>NA4918-02_AB17-24/NA4918-02_AB17-24_9_18_12.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.832462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA4918-02_AB17-24_9_18_12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.956901</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42524</td>\n",
       "      <td>NA4885-02_AB17-24/NA4885-02_AB17-24_4_23_50.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA4885-02_AB17-24_4_23_50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34432</td>\n",
       "      <td>NA4749-02_AB/NA4749-02_AB_17_12_50.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.770270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA4749-02_AB_17_12_50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4137</td>\n",
       "      <td>NA4751-02_AB/NA4751-02_AB_19_6_34.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA4751-02_AB_19_6_34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.98904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160621</th>\n",
       "      <td>0</td>\n",
       "      <td>NA_4933_02_AB17-24/neg_NA_4933_02_AB17-24_9_19...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neg_NA_4933_02_AB17-24_9_19_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160622</th>\n",
       "      <td>0</td>\n",
       "      <td>NA_4933_02_AB17-24/neg_NA_4933_02_AB17-24_9_27...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neg_NA_4933_02_AB17-24_9_27_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160623</th>\n",
       "      <td>33873</td>\n",
       "      <td>NA_4933_02_AB17-24/NA_4933_02_AB17-24_9_3_1.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA_4933_02_AB17-24_9_3_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160624</th>\n",
       "      <td>0</td>\n",
       "      <td>NA_4933_02_AB17-24/neg_NA_4933_02_AB17-24_9_3_...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neg_NA_4933_02_AB17-24_9_3_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160625</th>\n",
       "      <td>8617</td>\n",
       "      <td>NA_4933_02_AB17-24/NA_4933_02_AB17-24_9_6_1.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA_4933_02_AB17-24_9_6_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160626 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                          imagename  cored  \\\n",
       "0       10748             NA4757-02_AB/NA4757-02_AB_18_25_61.jpg    1.0   \n",
       "1       29503    NA4918-02_AB17-24/NA4918-02_AB17-24_9_18_12.jpg    0.0   \n",
       "2       42524    NA4885-02_AB17-24/NA4885-02_AB17-24_4_23_50.jpg    1.0   \n",
       "3       34432             NA4749-02_AB/NA4749-02_AB_17_12_50.jpg    0.0   \n",
       "4        4137              NA4751-02_AB/NA4751-02_AB_19_6_34.jpg    0.0   \n",
       "...       ...                                                ...    ...   \n",
       "160621      0  NA_4933_02_AB17-24/neg_NA_4933_02_AB17-24_9_19...    0.0   \n",
       "160622      0  NA_4933_02_AB17-24/neg_NA_4933_02_AB17-24_9_27...    0.0   \n",
       "160623  33873    NA_4933_02_AB17-24/NA_4933_02_AB17-24_9_3_1.jpg    0.0   \n",
       "160624      0  NA_4933_02_AB17-24/neg_NA_4933_02_AB17-24_9_3_...    0.0   \n",
       "160625   8617    NA_4933_02_AB17-24/NA_4933_02_AB17-24_9_6_1.jpg    0.0   \n",
       "\n",
       "         diffuse  CAA  negative  flag  notsure                     imagename2  \\\n",
       "0       0.000000  0.0       0.0   0.0      0.0          NA4757-02_AB_18_25_61   \n",
       "1       2.832462  0.0       0.0   0.0      0.0      NA4918-02_AB17-24_9_18_12   \n",
       "2       1.000000  0.0       0.0   1.0      0.0      NA4885-02_AB17-24_4_23_50   \n",
       "3       3.770270  0.0       0.0   0.0      0.0          NA4749-02_AB_17_12_50   \n",
       "4       1.000000  2.0       0.0   2.0      0.0           NA4751-02_AB_19_6_34   \n",
       "...          ...  ...       ...   ...      ...                            ...   \n",
       "160621  0.000000  0.0       1.0   0.0      0.0  neg_NA_4933_02_AB17-24_9_19_0   \n",
       "160622  0.000000  0.0       1.0   0.0      0.0  neg_NA_4933_02_AB17-24_9_27_4   \n",
       "160623  1.000000  0.0       0.0   0.0      0.0       NA_4933_02_AB17-24_9_3_1   \n",
       "160624  0.000000  0.0       1.0   0.0      0.0   neg_NA_4933_02_AB17-24_9_3_4   \n",
       "160625  0.000000  0.0       1.0   0.0      0.0       NA_4933_02_AB17-24_9_6_1   \n",
       "\n",
       "        cored_gt  diffuse_gt  CAA_gt  cored_pred  diffuse_pred  CAA_pred  \\\n",
       "0              1           0       0         1.0           0.0       0.0   \n",
       "1              0           1       0         0.0           1.0       0.0   \n",
       "2              1           1       0         1.0           0.0       0.0   \n",
       "3              0           1       0         0.0           0.0       0.0   \n",
       "4              0           1       1         0.0           0.0       1.0   \n",
       "...          ...         ...     ...         ...           ...       ...   \n",
       "160621         0           0       0         0.0           0.0       0.0   \n",
       "160622         0           0       0         0.0           0.0       0.0   \n",
       "160623         0           1       0         0.0           0.0       0.0   \n",
       "160624         0           0       0         0.0           0.0       0.0   \n",
       "160625         0           0       0         0.0           0.0       0.0   \n",
       "\n",
       "        cored_score  diffuse_score  CAA_score  \n",
       "0          0.856956       0.000000    0.00000  \n",
       "1          0.000000       0.956901    0.00000  \n",
       "2          0.992662       0.000000    0.00000  \n",
       "3          0.000000       0.000000    0.00000  \n",
       "4          0.000000       0.000000    0.98904  \n",
       "...             ...            ...        ...  \n",
       "160621     0.000000       0.000000    0.00000  \n",
       "160622     0.000000       0.000000    0.00000  \n",
       "160623     0.000000       0.000000    0.00000  \n",
       "160624     0.000000       0.000000    0.00000  \n",
       "160625     0.000000       0.000000    0.00000  \n",
       "\n",
       "[160626 rows x 18 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Metric - Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.64      0.73    109671\n",
      "           1       0.49      0.76      0.60     50955\n",
      "\n",
      "    accuracy                           0.68    160626\n",
      "   macro avg       0.67      0.70      0.66    160626\n",
      "weighted avg       0.74      0.68      0.69    160626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(final_df[\"cored_gt\"], final_df[\"cored_pred\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Metric - Diffuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.88      0.63     73941\n",
      "           1       0.67      0.21      0.32     86685\n",
      "\n",
      "    accuracy                           0.52    160626\n",
      "   macro avg       0.58      0.55      0.47    160626\n",
      "weighted avg       0.59      0.52      0.46    160626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(final_df[\"diffuse_gt\"], final_df[\"diffuse_pred\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Metric - CAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.99      0.86    110685\n",
      "           1       0.96      0.29      0.44     49941\n",
      "\n",
      "    accuracy                           0.78    160626\n",
      "   macro avg       0.86      0.64      0.65    160626\n",
      "weighted avg       0.82      0.78      0.73    160626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(final_df[\"CAA_gt\"], final_df[\"CAA_pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"/gladstone/finkbeiner/steve/work/data/npsad_data/vivek/Datasets/UCDavis-Dataset/classification_dataset/final_output_train_val.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "colors={\"cored\":'royalblue', \"diffuse\":'firebrick','CAA':\"green\"}\n",
    "df = final_df\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_shape(\n",
    "    type='line', line=dict(dash='dash'),\n",
    "    x0=0, x1=1, y0=0, y1=1\n",
    ")\n",
    "\n",
    "for class_name in [\"cored\",\"diffuse\",\"CAA\"]:\n",
    "    fpr, tpr, _ = roc_curve(df[class_name + \"_gt\"], df[class_name+\"_score\"])\n",
    "    fig.add_trace(go.Scatter(x=fpr, y=tpr, name=class_name, mode='lines',line=dict(color=colors[class_name], width=2)))\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='False Positive Rate',\n",
    "    yaxis_title='True Positive Rate',\n",
    "    yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n",
    "    xaxis=dict(constrain='domain'),\n",
    "    width=700, height=700\n",
    ")\n",
    "fig.update_layout( plot_bgcolor='white', title=\"Receiver operating characteristic Curve\")\n",
    "fig.update_xaxes(mirror=True, ticks='outside', showline=True, linecolor='black',gridcolor='lightgrey')\n",
    "fig.update_yaxes(mirror=True, ticks='outside', showline=True, linecolor='black',gridcolor='lightgrey')\n",
    "fig.write_html(\"ROC_Curve.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_df\n",
    "\n",
    "fig = go.Figure()\n",
    "colors={\"cored\":'royalblue', \"diffuse\":'firebrick','CAA':\"green\"}\n",
    "for class_name in [\"cored\",\"diffuse\",\"CAA\"]:\n",
    "    pr, rc, _ = precision_recall_curve(df[class_name + \"_gt\"], df[class_name+\"_score\"])\n",
    "    rp = (df[class_name + \"_gt\"]).sum()/len(df)\n",
    "    fig.add_trace(go.Scatter(x=rc, y=pr, name=class_name, mode='lines',line=dict(color=colors[class_name], width=2)))\n",
    "    #fig.add_trace(go.Scatter(x=[0,1], y=[rp,rp], name=class_name+\"_random\", mode='lines',line=dict(color=colors[class_name], width=2,dash='dash')))\n",
    "    #fig.add_shape(type='line', line=dict(dash='dash',color=colors[class_name]), x0=0, x1=1, y0=rp, y1=rp, name=class_name)\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Recall',\n",
    "    yaxis_title='Precision',\n",
    "    yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n",
    "    xaxis=dict(constrain='domain'),\n",
    "    width=700, height=700\n",
    ")\n",
    "fig.update_layout( plot_bgcolor='white',title=\"Precision-Recall Curve\")\n",
    "fig.update_xaxes(mirror=True, ticks='outside', showline=True, linecolor='black',gridcolor='lightgrey')\n",
    "fig.update_yaxes(mirror=True, ticks='outside', showline=True, linecolor='black',gridcolor='lightgrey')\n",
    "fig.write_html(\"PR_Curve.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amy_plague",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
